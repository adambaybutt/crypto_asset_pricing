{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "6359323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import requests\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import json.decoder\n",
    "from typing import Dict, Any, Optional\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d16ae31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formCoingeckoAssetUniverse(cmc_assets_fp: str, base_params: dict, base_url: str) -> pd.DataFrame:\n",
    "    \"\"\" form universe of coingecko assets to obtain data for, mapped to cmc slugs.\n",
    "\n",
    "    Args:\n",
    "        cmc_assets_fp (str): filepath for the cmc asset universe.\n",
    "        base_params (dict): dictionary containing the basic parameters for the coingecko api call.\n",
    "        base_url (str): the base url for pinging the coingecko api.\n",
    "\n",
    "    Returns:\n",
    "        cmc_assets_df (pd.DataFrame): dataframe containing the crosswalk between the cmc and cg assets.\n",
    "    \"\"\"\n",
    "    # little helper function\n",
    "    def removeNonLetters(text):\n",
    "        return re.sub(r'[^a-zA-Z]', '', text)\n",
    "\n",
    "    # import cmc token universe\n",
    "    with open(cmc_assets_fp, 'rb') as f:\n",
    "        cmc_asset_universe_dict = pickle.load(f)\n",
    "\n",
    "    # form unique asset df\n",
    "    cmc_assets = []\n",
    "    for k, v in cmc_asset_universe_dict.items():\n",
    "        cmc_assets.extend(v)\n",
    "    cmc_assets = list(np.unique(np.array(cmc_assets)))\n",
    "    cmc_assets_df = pd.DataFrame(data={'asset_cmc': cmc_assets})\n",
    "                                \n",
    "    # obtain coingecko asset ids\n",
    "    endpoint = '/coins/list'\n",
    "    url = f\"{base_url}{endpoint}\"                           \n",
    "    params = base_params.copy()\n",
    "    params['include_platform'] = 'false'\n",
    "    r = requests.get(url, params=params)\n",
    "    id_symbol_dict_list = r.json()\n",
    "\n",
    "    # create editted names of cmc asset\n",
    "    cmc_assets_df['asset_cmc_lower'] = cmc_assets_df.asset_cmc.str.lower()\n",
    "    cmc_assets_lower = list(cmc_assets_df.asset_cmc_lower.values)\n",
    "    cmc_assets_df['asset_cmc_lower_nosymbol'] = cmc_assets_df.asset_cmc_lower.apply(removeNonLetters)\n",
    "    cmc_assets_lower_nosymbol = list(cmc_assets_df.asset_cmc_lower_nosymbol.values)\n",
    "    assert(cmc_assets_df.shape[0]==len(np.unique(np.array(cmc_assets_lower_nosymbol))))\n",
    "\n",
    "    # match the symbols on various logic\n",
    "    cmc_assets_df['asset_gecko'] = None\n",
    "    for id_symbol_dict in id_symbol_dict_list:\n",
    "        gecko_name = id_symbol_dict['name'].lower()\n",
    "        gecko_id   = id_symbol_dict['id'].lower()\n",
    "        if gecko_name in cmc_assets_lower:\n",
    "            cmc_assets_df.loc[cmc_assets_df.asset_gecko.isnull()\n",
    "                & (cmc_assets_df.asset_cmc_lower==gecko_name), 'asset_gecko'] = gecko_id\n",
    "        elif gecko_id in cmc_assets_lower:\n",
    "            cmc_assets_df.loc[cmc_assets_df.asset_gecko.isnull()\n",
    "                & (cmc_assets_df.asset_cmc_lower==gecko_id), 'asset_gecko'] = gecko_id\n",
    "        elif removeNonLetters(gecko_name) in cmc_assets_lower_nosymbol:\n",
    "            cmc_assets_df.loc[cmc_assets_df.asset_gecko.isnull()\n",
    "                & (cmc_assets_df.asset_cmc_lower_nosymbol==removeNonLetters(gecko_name)), 'asset_gecko'] = gecko_id\n",
    "        elif removeNonLetters(gecko_id) in cmc_assets_lower_nosymbol:\n",
    "            cmc_assets_df.loc[cmc_assets_df.asset_gecko.isnull()\n",
    "                & (cmc_assets_df.asset_cmc_lower_nosymbol==removeNonLetters(gecko_id)), 'asset_gecko'] = gecko_id\n",
    "\n",
    "    # manually fix non matches\n",
    "    cmc_assets_df.loc[cmc_assets_df.asset_cmc=='aave-old', 'asset_gecko'] = 'aave'\n",
    "    cmc_assets_df.loc[cmc_assets_df.asset_cmc=='alpha-finance-lab', 'asset_gecko'] = 'alpha-finance'\n",
    "    cmc_assets_df.loc[cmc_assets_df.asset_cmc=='crypto-com', 'asset_gecko'] = 'crypto-com-chain'\n",
    "    cmc_assets_df.loc[cmc_assets_df.asset_cmc=='ethereum-pow', 'asset_gecko']  = 'ethereum-pow-iou'\n",
    "    cmc_assets_df.loc[cmc_assets_df.asset_cmc=='sushiswap', 'asset_gecko'] = 'sushi'\n",
    "    cmc_assets_df.loc[cmc_assets_df.asset_cmc=='abbc-coin', 'asset_gecko'] = 'abcc-token'\n",
    "    cmc_assets_df.loc[cmc_assets_df.asset_cmc=='cream-finance', 'asset_gecko'] = 'cream'\n",
    "    cmc_assets_df.loc[cmc_assets_df.asset_cmc=='haven-protocol', 'asset_gecko'] = 'haven'\n",
    "    cmc_assets_df.loc[cmc_assets_df.asset_cmc=='fetch', 'asset_gecko'] = 'fetch-ai'\n",
    "    cmc_assets_df.loc[cmc_assets_df.asset_cmc=='kucoin-token', 'asset_gecko'] = 'kucoin-shares'\n",
    "    cmc_assets_df.loc[cmc_assets_df.asset_cmc=='orchid', 'asset_gecko'] = 'orchid-protocol'\n",
    "    cmc_assets_df.loc[cmc_assets_df.asset_cmc=='yearn-finance-ii', 'asset_gecko'] = 'yearn-finance'\n",
    "\n",
    "    # return the crosswalk\n",
    "    return cmc_assets_df[['asset_cmc', 'asset_gecko']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "bbf6b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCMCApiCall(url: str, params: dict, retries: int=3) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\" makes an API call to CoinGecko using the provided url and parameters.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The API endpoint URL to call.\n",
    "        params (dict): A dictionary of parameters to include in the API call.\n",
    "        retries (int): The number of times to retry the API call if it fails. Default is 3.\n",
    "        \n",
    "    Returns:\n",
    "        response.json() (dict): the data from the api response, or None if the api call failed.\n",
    "    \"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=3)\n",
    "        except requests.exceptions.Timeout:\n",
    "            # Timeout error, retry after a short delay\n",
    "            print('The API call timed out, retrying...')\n",
    "            time.sleep(0.5)\n",
    "            continue\n",
    "        \n",
    "        if response.ok:\n",
    "            try:\n",
    "                return response.json()\n",
    "            except json.decoder.JSONDecodeError as e:\n",
    "                print(f'Error decoding JSON response: {str(e)}')\n",
    "        else:\n",
    "            # There was an error, retry after a short delay\n",
    "            print(f'The API call failed with status code {response.status_code}, retrying...')\n",
    "            time.sleep(0.2)\n",
    "\n",
    "    print('The api call failed after 3 attempts.')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "296fec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullPriceMcapVolume(base_url: str, base_params: dict, gecko_id_universe: list) -> pd.DataFrame:\n",
    "    \"\"\" Pull price, market cap, and volume data for a given universe of CoinGecko IDs.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): The base URL for the Coingecko API.\n",
    "        base_params (dict): A dictionary containing the basic parameters for the Coingecko API call.\n",
    "        gecko_id_universe (list): A list of unique gecko ids to pull.\n",
    "\n",
    "    Returns:\n",
    "        panel_df (pd.DataFrame): panel data with columns 'date', 'asset_gecko', 'usd_per_token_cg', \n",
    "                                 'usd_mcap_cg', and 'usd_volume_24h_cg'.\n",
    "    \"\"\"\n",
    "    # set up params\n",
    "    params = base_params.copy()\n",
    "    params.update({\n",
    "        'vs_currency': 'usd',\n",
    "        'days': 'max'\n",
    "    })\n",
    "\n",
    "    # set up object to store all\n",
    "    panel_df = pd.DataFrame()\n",
    "\n",
    "    # loop over assets to pull\n",
    "    for i in range(len(gecko_id_universe)):\n",
    "        # set current id to pull\n",
    "        gecko_id = gecko_id_universe[i]\n",
    "\n",
    "        # monitor progress\n",
    "        print(f\"Processing id #{i+1} ({(i+1)/len(gecko_id_universe)*100:.2f}%): {gecko_id}\")\n",
    "\n",
    "        # set up endpoint\n",
    "        endpoint = f\"/coins/{gecko_id}/market_chart\"\n",
    "        url = f\"{base_url}{endpoint}\"\n",
    "\n",
    "        # update params with this id\n",
    "        params['id'] = gecko_id\n",
    "\n",
    "        # make the call\n",
    "        response_json = makeCMCApiCall(url, params)\n",
    "\n",
    "        # extract the data\n",
    "        prices_df = pd.DataFrame(response_json['prices'], columns=['date', 'usd_per_token_cg']).dropna()\n",
    "        mcaps_df = pd.DataFrame(response_json['market_caps'], columns=['date', 'usd_mcap_cg']).dropna()\n",
    "        volumes_df = pd.DataFrame(response_json['total_volumes'], columns=['date', 'usd_volume_24h_cg']).dropna()\n",
    "\n",
    "        # format the dfs and put it together\n",
    "        asset_df = prices_df.copy()\n",
    "        asset_df['date'] = pd.to_datetime(asset_df.date, unit='ms').dt.ceil('D').dt.date\n",
    "        mcaps_df['date'] = pd.to_datetime(mcaps_df.date, unit='ms').dt.ceil('D').dt.date\n",
    "        volumes_df['date'] = pd.to_datetime(volumes_df.date, unit='ms').dt.ceil('D').dt.date\n",
    "        asset_df   = asset_df.groupby('date').last().reset_index()\n",
    "        mcaps_df   = mcaps_df.groupby('date').last().reset_index()\n",
    "        volumes_df = volumes_df.groupby('date').last().reset_index()\n",
    "        asset_df = asset_df.merge(mcaps_df,\n",
    "                                on='date',\n",
    "                                how='outer',\n",
    "                                validate='one_to_one')\n",
    "        asset_df = asset_df.merge(volumes_df,\n",
    "                                on='date',\n",
    "                                how='outer',\n",
    "                                validate='one_to_one')\n",
    "        asset_df['asset_gecko'] = gecko_id\n",
    "        asset_df = asset_df[['date', 'asset_gecko', 'usd_per_token_cg', 'usd_mcap_cg', 'usd_volume_24h_cg']]\n",
    "\n",
    "        # append results\n",
    "        panel_df = pd.concat((panel_df, asset_df))\n",
    "\n",
    "        # space out the calls\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    return panel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "8bf36224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(V3) To the Moon!\n",
      "Processing id #1 (0.13%): 01coin\n",
      "Processing id #2 (0.27%): 12ships\n",
      "Processing id #3 (0.40%): 1eco\n",
      "Processing id #4 (0.54%): 1inch\n",
      "Processing id #5 (0.67%): 888tron\n",
      "Processing id #6 (0.81%): 8x8-protocol\n",
      "Processing id #7 (0.94%): aave\n",
      "Processing id #8 (1.08%): aavegotchi\n",
      "Processing id #9 (1.21%): abcc-token\n",
      "Processing id #10 (1.34%): acala\n",
      "Processing id #11 (1.48%): achain\n",
      "Processing id #12 (1.61%): acute-angle-cloud\n",
      "Processing id #13 (1.75%): adshares\n",
      "Processing id #14 (1.88%): adtoken\n",
      "Processing id #15 (2.02%): aelf\n",
      "Processing id #16 (2.15%): aeon\n",
      "Processing id #17 (2.28%): aergo\n",
      "Processing id #18 (2.42%): aeternity\n",
      "Processing id #19 (2.55%): agavecoin\n",
      "Processing id #20 (2.69%): aidos-kuneen\n",
      "Processing id #21 (2.82%): aioz-network\n",
      "Processing id #22 (2.96%): akash-network\n",
      "Processing id #23 (3.09%): akropolis\n",
      "Processing id #24 (3.23%): alchemy-pay\n",
      "Processing id #25 (3.36%): aleph\n",
      "Processing id #26 (3.49%): algorand\n",
      "Processing id #27 (3.63%): alien-worlds\n",
      "Processing id #28 (3.76%): alitas\n",
      "Processing id #29 (3.90%): all-sports-2\n",
      "Processing id #30 (4.03%): allianceblock\n",
      "Processing id #31 (4.17%): alpaca-finance\n",
      "Processing id #32 (4.30%): alpha-finance\n",
      "Processing id #33 (4.44%): alpha-quark-token\n",
      "Processing id #34 (4.57%): amber\n",
      "Processing id #35 (4.70%): amp-token\n",
      "Processing id #36 (4.84%): ampleforth-governance-token\n",
      "Processing id #37 (4.97%): anchor-protocol\n",
      "Processing id #38 (5.11%): ankr\n",
      "Processing id #39 (5.24%): anyswap\n",
      "Processing id #40 (5.38%): apex-token-2\n",
      "Processing id #41 (5.51%): api3\n",
      "Processing id #42 (5.65%): appcoins\n",
      "Processing id #43 (5.78%): aragon\n",
      "Processing id #44 (5.91%): arcblock\n",
      "Processing id #45 (6.05%): ardor\n",
      "Processing id #46 (6.18%): ark\n",
      "Processing id #47 (6.32%): artbyte\n",
      "Processing id #48 (6.45%): arweave\n",
      "Processing id #49 (6.59%): assemble-protocol\n",
      "Processing id #50 (6.72%): astar\n",
      "Processing id #51 (6.85%): atbcoin\n",
      "Processing id #52 (6.99%): atlas-protocol\n",
      "Processing id #53 (7.12%): atmos\n",
      "Processing id #54 (7.26%): attila\n",
      "Processing id #55 (7.39%): audius\n",
      "Processing id #56 (7.53%): augur\n",
      "Processing id #57 (7.66%): aurora\n",
      "Processing id #58 (7.80%): auroracoin\n",
      "Processing id #59 (7.93%): aurory\n",
      "Processing id #60 (8.06%): avalanche-2\n",
      "Processing id #61 (8.20%): aventus\n",
      "Processing id #62 (8.33%): avinoc\n",
      "Processing id #63 (8.47%): axel\n",
      "Processing id #64 (8.60%): axie-infinity\n",
      "Processing id #65 (8.74%): babb\n",
      "Processing id #66 (8.87%): baby-doge-coin\n",
      "Processing id #67 (9.01%): babyswap\n",
      "Processing id #68 (9.14%): bakerytoken\n",
      "Processing id #69 (9.27%): banana-token\n",
      "Processing id #70 (9.41%): banca\n",
      "Processing id #71 (9.54%): bancor\n",
      "Processing id #72 (9.68%): band-protocol\n",
      "Processing id #73 (9.81%): bankera\n",
      "Processing id #74 (9.95%): barnbridge\n",
      "Processing id #75 (10.08%): basic\n",
      "Processing id #76 (10.22%): basic-attention-token\n",
      "Processing id #77 (10.35%): bata\n",
      "Processing id #78 (10.48%): beam\n",
      "Processing id #79 (10.62%): bean-cash\n",
      "Processing id #80 (10.75%): beefy-finance\n",
      "Processing id #81 (10.89%): beldex\n",
      "Processing id #82 (11.02%): bella-protocol\n",
      "Processing id #83 (11.16%): beta-finance\n",
      "Processing id #84 (11.29%): beyond-protocol\n",
      "Processing id #85 (11.42%): bibox-token\n",
      "Processing id #86 (11.56%): biconomy\n",
      "Processing id #87 (11.69%): binance-usd\n",
      "Processing id #88 (11.83%): binancecoin\n",
      "Processing id #89 (11.96%): biswap\n",
      "Processing id #90 (12.10%): bitball-treasure\n",
      "Processing id #91 (12.23%): bitcoin\n",
      "Processing id #92 (12.37%): bitcoin-bep2\n",
      "Processing id #93 (12.50%): bitcoin-cash\n",
      "Processing id #94 (12.63%): bitcoin-cash-sv\n",
      "Processing id #95 (12.77%): bitcoin-diamond\n",
      "Processing id #96 (12.90%): bitcoin-gold\n",
      "Processing id #97 (13.04%): bitcoin-hd\n",
      "Processing id #98 (13.17%): bitcoin-plus\n",
      "Processing id #99 (13.31%): bitcoin-private\n",
      "Processing id #100 (13.44%): bitcoinpos\n",
      "Processing id #101 (13.58%): bitconnect\n",
      "Processing id #102 (13.71%): bitcore\n",
      "Processing id #103 (13.84%): bitdao\n",
      "Processing id #104 (13.98%): bitmark\n",
      "Processing id #105 (14.11%): bitpanda-ecosystem-token\n",
      "Processing id #106 (14.25%): bitrise-token\n",
      "Processing id #107 (14.38%): bitshares\n",
      "Processing id #108 (14.52%): bitswift\n",
      "Processing id #109 (14.65%): bittorrent\n",
      "Processing id #110 (14.78%): blackcoin\n",
      "Processing id #111 (14.92%): blocknet\n",
      "Processing id #112 (15.05%): blockstack\n",
      "Processing id #113 (15.19%): blockv\n",
      "Processing id #114 (15.32%): bloktopia\n",
      "Processing id #115 (15.46%): bloomzed-token\n",
      "Processing id #116 (15.59%): blox\n",
      "Processing id #117 (15.73%): bluzelle\n",
      "Processing id #118 (15.86%): bnktothefuture\n",
      "Processing id #119 (15.99%): boba-network\n",
      "Processing id #120 (16.13%): bonfida\n",
      "Processing id #121 (16.26%): bora\n",
      "Processing id #122 (16.40%): bosagora\n",
      "Processing id #123 (16.53%): boson-protocol\n",
      "Processing id #124 (16.67%): bottos\n",
      "Processing id #125 (16.80%): botxcoin\n",
      "Processing id #126 (16.94%): bread\n",
      "Processing id #127 (17.07%): breezecoin\n",
      "Processing id #128 (17.20%): bridge-oracle\n",
      "Processing id #129 (17.34%): bridgecoin-2\n",
      "Processing id #130 (17.47%): bscpad\n",
      "Processing id #131 (17.61%): btc-standard-hashrate-token\n",
      "Processing id #132 (17.74%): btu-protocol\n",
      "Processing id #133 (17.88%): bytom\n",
      "Processing id #134 (18.01%): bzx-protocol\n",
      "Processing id #135 (18.15%): cappasity\n",
      "Processing id #136 (18.28%): cardano\n",
      "Processing id #137 (18.41%): carry\n",
      "Processing id #138 (18.55%): cartesi\n",
      "Processing id #139 (18.68%): casinocoin\n",
      "Processing id #140 (18.82%): celer-network\n",
      "Processing id #141 (18.95%): celo\n",
      "Processing id #142 (19.09%): celo-dollar\n",
      "Processing id #143 (19.22%): centrality\n",
      "Processing id #144 (19.35%): centrifuge\n",
      "Processing id #145 (19.49%): centurion\n",
      "Processing id #146 (19.62%): chain-2\n",
      "Processing id #147 (19.76%): chainlink\n",
      "Processing id #148 (19.89%): chainx\n",
      "Processing id #149 (20.03%): chiliz\n",
      "Processing id #150 (20.16%): chromaway\n",
      "Processing id #151 (20.30%): chronobank\n",
      "Processing id #152 (20.43%): cindicator\n",
      "Processing id #153 (20.56%): circuits-of-value\n",
      "Processing id #154 (20.70%): civic\n",
      "Processing id #155 (20.83%): clams\n",
      "Processing id #156 (20.97%): cloakcoin\n",
      "Processing id #157 (21.10%): clover\n",
      "Processing id #158 (21.24%): cocos-bcx\n",
      "Processing id #159 (21.37%): coindom\n",
      "Processing id #160 (21.51%): constellation-labs\n",
      "Processing id #161 (21.64%): constitutiondao\n",
      "Processing id #162 (21.77%): contentos\n",
      "Processing id #163 (21.91%): contracoin\n",
      "Processing id #164 (22.04%): conun\n",
      "Processing id #165 (22.18%): cortex\n",
      "Processing id #166 (22.31%): cosmos\n",
      "Processing id #167 (22.45%): coti\n",
      "Processing id #168 (22.58%): counos-coin\n",
      "Processing id #169 (22.72%): counosx\n",
      "Processing id #170 (22.85%): counterparty\n",
      "Processing id #171 (22.98%): covalent\n",
      "Processing id #172 (23.12%): cratos\n",
      "Processing id #173 (23.25%): cream\n",
      "Processing id #174 (23.39%): creditcoin-2\n",
      "Processing id #175 (23.52%): crevacoin\n",
      "Processing id #176 (23.66%): crown\n",
      "Processing id #177 (23.79%): crust-network\n",
      "Processing id #178 (23.92%): crypto-com-chain\n",
      "Processing id #179 (24.06%): cryptonex\n",
      "Processing id #180 (24.19%): curecoin\n",
      "Processing id #181 (24.33%): curve-dao-token\n",
      "Processing id #182 (24.46%): cvault-finance\n",
      "Processing id #183 (24.60%): cybermiles\n",
      "Processing id #184 (24.73%): cybervein\n",
      "Processing id #185 (24.87%): dao-maker\n",
      "Processing id #186 (25.00%): darwinia-network-native-token\n",
      "Processing id #187 (25.13%): dascoin\n",
      "Processing id #188 (25.27%): dash\n",
      "Processing id #189 (25.40%): data\n",
      "Processing id #190 (25.54%): davinci-coin\n",
      "Processing id #191 (25.67%): dawn-protocol\n",
      "Processing id #192 (25.81%): deapcoin\n",
      "Processing id #193 (25.94%): decentral-games\n",
      "Processing id #194 (26.08%): decentraland\n",
      "Processing id #195 (26.21%): decentralized-advertising\n",
      "Processing id #196 (26.34%): decred\n",
      "Processing id #197 (26.48%): deepbrain-chain\n",
      "Processing id #198 (26.61%): deeper-network\n",
      "Processing id #199 (26.75%): defichain\n",
      "Processing id #200 (26.88%): define\n",
      "Processing id #201 (27.02%): defipulse-index\n",
      "Processing id #202 (27.15%): dego-finance\n",
      "Processing id #203 (27.28%): delphy\n",
      "Processing id #204 (27.42%): dentacoin\n",
      "Processing id #205 (27.55%): derace\n",
      "Processing id #206 (27.69%): derivadao\n",
      "Processing id #207 (27.82%): dero\n",
      "Processing id #208 (27.96%): deso\n",
      "Processing id #209 (28.09%): dexe\n",
      "Processing id #210 (28.23%): dia-data\n",
      "Processing id #211 (28.36%): diamond\n",
      "Processing id #212 (28.49%): digibyte\n",
      "Processing id #213 (28.63%): digitalbits\n",
      "Processing id #214 (28.76%): digitalnote\n",
      "Processing id #215 (28.90%): digitex-futures-exchange\n",
      "Processing id #216 (29.03%): digixdao\n",
      "Processing id #217 (29.17%): district0x\n",
      "Processing id #218 (29.30%): divi\n",
      "Processing id #219 (29.44%): dkargo\n",
      "Processing id #220 (29.57%): dodo\n",
      "Processing id #221 (29.70%): dogecoin\n",
      "Processing id #222 (29.84%): dos-network\n",
      "Processing id #223 (29.97%): dragonchain\n",
      "Processing id #224 (30.11%): dusk-network\n",
      "Processing id #225 (30.24%): dvision-network\n",
      "Processing id #226 (30.38%): dydx\n",
      "Processing id #227 (30.51%): ecash\n",
      "Processing id #228 (30.65%): ecomi\n",
      "Processing id #229 (30.78%): ecoreal-estate\n",
      "Processing id #230 (30.91%): edgeless\n",
      "Processing id #231 (31.05%): efinity\n",
      "Processing id #232 (31.18%): egretia\n",
      "Processing id #233 (31.32%): einsteinium\n",
      "Processing id #234 (31.45%): elamachain\n",
      "Processing id #235 (31.59%): elastos\n",
      "Processing id #236 (31.72%): electra\n",
      "Processing id #237 (31.85%): electroneum\n",
      "Processing id #238 (31.99%): elitium\n",
      "Processing id #239 (32.12%): ellipsis\n",
      "Processing id #240 (32.26%): emercoin\n",
      "Processing id #241 (32.39%): empty-set-dollar\n",
      "Processing id #242 (32.53%): endor\n",
      "Processing id #243 (32.66%): energi\n",
      "Processing id #244 (32.80%): enigma\n",
      "Processing id #245 (32.93%): enjincoin\n",
      "Processing id #246 (33.06%): envion\n",
      "Processing id #247 (33.20%): eos\n",
      "Processing id #248 (33.33%): eosdac\n",
      "Processing id #249 (33.47%): equitrader\n",
      "Processing id #250 (33.60%): ergo\n",
      "Processing id #251 (33.74%): espers\n",
      "Processing id #252 (33.87%): ethereum\n",
      "Processing id #253 (34.01%): ethereum-name-service\n",
      "Processing id #254 (34.14%): ethereum-pow-iou\n",
      "Processing id #255 (34.27%): etherparty\n",
      "Processing id #256 (34.41%): everex\n",
      "Processing id #257 (34.54%): everid\n",
      "Processing id #258 (34.68%): everipedia\n",
      "Processing id #259 (34.81%): everscale\n",
      "Processing id #260 (34.95%): expanse\n",
      "Processing id #261 (35.08%): fantom\n",
      "Processing id #262 (35.22%): feathercoin\n",
      "Processing id #263 (35.35%): fedoracoin\n",
      "Processing id #264 (35.48%): fei-usd\n",
      "Processing id #265 (35.62%): ferrum-network\n",
      "Processing id #266 (35.75%): fetch-ai\n",
      "Processing id #267 (35.89%): flow\n",
      "Processing id #268 (36.02%): frax\n",
      "Processing id #269 (36.16%): frax-share\n",
      "Processing id #270 (36.29%): fsn\n",
      "Processing id #271 (36.42%): fx-coin\n",
      "Processing id #272 (36.56%): gala\n",
      "Processing id #273 (36.69%): game\n",
      "Processing id #274 (36.83%): gamecredits\n",
      "Processing id #275 (36.96%): gas\n",
      "Processing id #276 (37.10%): gatechain-token\n",
      "Processing id #277 (37.23%): gemini-dollar\n",
      "Processing id #278 (37.37%): genaro-network\n",
      "Processing id #279 (37.50%): genesis-vision\n",
      "Processing id #280 (37.63%): gensokishis-metaverse\n",
      "Processing id #281 (37.77%): geocoin\n",
      "Processing id #282 (37.90%): gifto\n",
      "Processing id #283 (38.04%): gitcoin\n",
      "Processing id #284 (38.17%): gny\n",
      "Processing id #285 (38.31%): gods-unchained\n",
      "Processing id #286 (38.44%): goldcoin\n",
      "Processing id #287 (38.58%): gridcoin-research\n",
      "Processing id #288 (38.71%): groestlcoin\n",
      "Processing id #289 (38.84%): gulden\n",
      "Processing id #290 (38.98%): handshake\n",
      "Processing id #291 (39.11%): harmony\n",
      "Processing id #292 (39.25%): harvest-finance\n",
      "Processing id #293 (39.38%): hashgard\n",
      "Processing id #294 (39.52%): hathor\n",
      "Processing id #295 (39.65%): haven\n",
      "Processing id #296 (39.78%): hedera-hashgraph\n",
      "Processing id #297 (39.92%): hedgetrade\n",
      "Processing id #298 (40.05%): hegic\n",
      "Processing id #299 (40.19%): helleniccoin\n",
      "Processing id #300 (40.32%): hempcoin-thc\n",
      "Processing id #301 (40.46%): hex\n",
      "Processing id #302 (40.59%): hicoin\n",
      "Processing id #303 (40.73%): high-performance-blockchain\n",
      "Processing id #304 (40.86%): hoge-finance\n",
      "Processing id #305 (40.99%): holotoken\n",
      "Processing id #306 (41.13%): homeros\n",
      "Processing id #307 (41.26%): hoo-token\n",
      "Processing id #308 (41.40%): hshare\n",
      "Processing id #309 (41.53%): htmlcoin\n",
      "Processing id #310 (41.67%): humaniq\n",
      "Processing id #311 (41.80%): humanscape\n",
      "Processing id #312 (41.94%): hunt-token\n",
      "Processing id #313 (42.07%): huobi-btc\n",
      "Processing id #314 (42.20%): huobi-pool-token\n",
      "Processing id #315 (42.34%): huobi-token\n",
      "Processing id #316 (42.47%): hush\n",
      "Processing id #317 (42.61%): hxro\n",
      "Processing id #318 (42.74%): ichi-farm\n",
      "Processing id #319 (42.88%): icon\n",
      "Processing id #320 (43.01%): ilcoin\n",
      "Processing id #321 (43.15%): illuvium\n",
      "Processing id #322 (43.28%): immutable-x\n",
      "Processing id #323 (43.41%): indahash\n",
      "Processing id #324 (43.55%): injective-protocol\n",
      "Processing id #325 (43.68%): ink\n",
      "Processing id #326 (43.82%): insure\n",
      "Processing id #327 (43.95%): insurex\n",
      "Processing id #328 (44.09%): internet-computer\n",
      "Processing id #329 (44.22%): internet-node-token\n",
      "Processing id #330 (44.35%): iocoin\n",
      "Processing id #331 (44.49%): ion\n",
      "Processing id #332 (44.62%): iota\n",
      "Processing id #333 (44.76%): iotex\n",
      "Processing id #334 (44.89%): ipx-token\n",
      "Processing id #335 (45.03%): iris-network\n",
      "Processing id #336 (45.16%): joe\n",
      "Processing id #337 (45.30%): jupiter\n",
      "Processing id #338 (45.43%): just\n",
      "Processing id #339 (45.56%): kadena\n",
      "Processing id #340 (45.70%): kan\n",
      "Processing id #341 (45.83%): kardiachain\n",
      "Processing id #342 (45.97%): karura\n",
      "Processing id #343 (46.10%): kava\n",
      "Processing id #344 (46.24%): kcash\n",
      "Processing id #345 (46.37%): keep-network\n",
      "Processing id #346 (46.51%): keep3rv1\n",
      "Processing id #347 (46.64%): kilt-protocol\n",
      "Processing id #348 (46.77%): kin\n",
      "Processing id #349 (46.91%): klay-token\n",
      "Processing id #350 (47.04%): klayswap-protocol\n",
      "Processing id #351 (47.18%): kleros\n",
      "Processing id #352 (47.31%): klever\n",
      "Processing id #353 (47.45%): komodo\n",
      "Processing id #354 (47.58%): kucoin-shares\n",
      "Processing id #355 (47.72%): kusama\n",
      "Processing id #356 (47.85%): kyber-network\n",
      "Processing id #357 (47.98%): lambda\n",
      "Processing id #358 (48.12%): latoken\n",
      "Processing id #359 (48.25%): lcx\n",
      "Processing id #360 (48.39%): level\n",
      "Processing id #361 (48.52%): libra-credit\n",
      "Processing id #362 (48.66%): lido-dao\n",
      "Processing id #363 (48.79%): lightning-bitcoin\n",
      "Processing id #364 (48.92%): linear\n",
      "Processing id #365 (49.06%): link\n",
      "Processing id #366 (49.19%): liquity\n",
      "Processing id #367 (49.33%): liquity-usd\n",
      "Processing id #368 (49.46%): lisk\n",
      "Processing id #369 (49.60%): litecoin\n",
      "Processing id #370 (49.73%): litecoin-cash\n",
      "Processing id #371 (49.87%): litentry\n",
      "Processing id #372 (50.00%): litex\n",
      "Processing id #373 (50.13%): livepeer\n",
      "Processing id #374 (50.27%): lockchain\n",
      "Processing id #375 (50.40%): locus-chain\n",
      "Processing id #376 (50.54%): loki-network\n",
      "Processing id #377 (50.67%): looksrare\n",
      "Processing id #378 (50.81%): loom-network\n",
      "Processing id #379 (50.94%): loopring\n",
      "Processing id #380 (51.08%): luckchain\n",
      "Processing id #381 (51.21%): lukso-token\n",
      "Processing id #382 (51.34%): lunyr\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # set args\n",
    "    api_fp = '../../admin/coingecko.txt'\n",
    "    start_date = date(2015, 1, 1)\n",
    "    end_date   = date(2023, 2, 1)\n",
    "    base_url = \"https://pro-api.coingecko.com/api/v3\"\n",
    "    base_params = {'x_cg_pro_api_key': API_KEY}\n",
    "    cmc_assets_fp = \"../data/raw/cmc_asset_universe.pkl\"\n",
    "    cw_fp = \"../data/raw/coingecko_cmc_cw.pkl\"\n",
    "\n",
    "    # import api key\n",
    "    with open(api_fp) as f:\n",
    "        API_KEY = f.readlines()\n",
    "        API_KEY = API_KEY[0].strip()\n",
    "\n",
    "    # Test it is working\n",
    "    url = f\"{base_url}/ping\"\n",
    "    r = requests.get(url, params=base_params)\n",
    "    print(r.json()['gecko_says'])\n",
    "\n",
    "    # obtain coingecko assets\n",
    "    cmc_assets_df = formCoingeckoAssetUniverse(cmc_assets_fp, base_params, base_url)\n",
    "    cmc_assets_df.to_pickle(cw_fp)\n",
    "    gecko_id_universe = list(np.unique(cmc_assets_df[~cmc_assets_df.asset_gecko.isnull()].asset_gecko.values))\n",
    "\n",
    "    # pull price mcap and volume data\n",
    "    panel_df = pullPriceMcapVolume(base_url, base_params, gecko_id_universe)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15426c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_df[panel_df.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the universe for assets that had price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ca287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO pull coins/id/history for everything it has; ensure timestamp is right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04902ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullAssetCovariates(base_url: str, base_params: dict, gecko_id_universe: list, panel_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" Pull various asset covariates for a given universe of CoinGecko IDs.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): The base URL for the Coingecko API.\n",
    "        base_params (dict): A dictionary containing the basic parameters for the Coingecko API call.\n",
    "        gecko_id_universe (list): A list of unique gecko ids to pull.\n",
    "        panel_df (pd.DataFrame): panel data with columns 'date', 'asset_gecko', 'usd_per_token_cg', \n",
    "                                 'usd_mcap_cg', and 'usd_volume_24h_cg'.\n",
    "\n",
    "    Returns:\n",
    "        asset_covars_df (pd.DataFrame): panel data with columns for ... TODO\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d36765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up object to store all\n",
    "gecko_covars_dict = {'date':[],\n",
    "                     'gecko_id': [],\n",
    "                     'twitter_followers': [],\n",
    "                     'reddit_average_posts_48h': [],\n",
    "                     'reddit_average_comments_48h': [],\n",
    "                     'reddit_subscribers': [],\n",
    "                     'reddit_accounts_active_48h': [],\n",
    "                     'forks': [],\n",
    "                     'stars': [],\n",
    "                     'subscribers': [],\n",
    "                     'total_issues': [],\n",
    "                     'closed_issues': [],\n",
    "                     'pull_requests_merged': [],\n",
    "                     'pull_request_contributors': [],\n",
    "                     'code_additions_4_weeks': [],\n",
    "                     'code_deletions_4_weeks': [],\n",
    "                     'commit_count_4_weeks': [],\n",
    "                     'alexa_rank': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb4554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over assets to pull\n",
    "for i in range(len(gecko_id_universe)):\n",
    "    # set current id to pull\n",
    "    gecko_id = gecko_id_universe[i]\n",
    "\n",
    "    # monitor progress\n",
    "    print(f\"Processing id #{i+1} ({(i+1)/len(gecko_id_universe)*100:.2f}%): {gecko_id}\")\n",
    "    \n",
    "    # set up endpoint\n",
    "    endpoint = f\"/coins/{gecko_id}/history\"\n",
    "    url = f\"{base_url}{endpoint}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053d9dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gecko_id = gecko_id_universe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDateList(start_date_str, end_date_str):\n",
    "    # Convert input strings to datetime objects\n",
    "    start_date = datetime.strptime(start_date_str, '%d-%m-%Y')\n",
    "    end_date = datetime.strptime(end_date_str, '%d-%m-%Y')\n",
    "    \n",
    "    # Calculate the number of days between the start and end dates\n",
    "    delta = end_date - start_date\n",
    "    \n",
    "    # Create a list of dates using a list comprehension\n",
    "    date_list = [start_date + timedelta(days=i) for i in range(delta.days + 1)]\n",
    "    \n",
    "    # Convert the datetime objects back to strings in the desired format\n",
    "    date_list = [datetime.strftime(date, '%d-%m-%Y') for date in date_list]\n",
    "    \n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e1ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up params\n",
    "params = base_params.copy()\n",
    "params['id'] = gecko_id\n",
    "\n",
    "# extract dates for this asset\n",
    "first_date = np.min(panel_df[panel_df.asset_gecko==gecko_id]['date'])).dt.strtime(format='%d-%m-%Y')\n",
    "last_date  = np.max(panel_df[panel_df.asset_gecko==gecko_id]['date'])).dt.strtime(format='%d-%m-%Y')\n",
    "all_dates  = getDateList(first_date, last_date)\n",
    "\n",
    "for current_date in all_dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c762d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update params\n",
    "params['date'] = current_date\n",
    "\n",
    "# make the call\n",
    "response_json = makeCMCApiCall(url, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf10ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346033a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_covars_df = pd.DataFrame(gecko_covars_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c46a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # extract the data\n",
    "    prices_df = pd.DataFrame(response_json['prices'], columns=['date', 'usd_per_token_cg']).dropna()\n",
    "    mcaps_df = pd.DataFrame(response_json['market_caps'], columns=['date', 'usd_mcap_cg']).dropna()\n",
    "    volumes_df = pd.DataFrame(response_json['total_volumes'], columns=['date', 'usd_volume_24h_cg']).dropna()\n",
    "\n",
    "    # format the dfs and put it together\n",
    "    asset_df = prices_df.copy()\n",
    "    asset_df['date'] = pd.to_datetime(asset_df.date, unit='ms').dt.ceil('D').dt.date\n",
    "    mcaps_df['date'] = pd.to_datetime(mcaps_df.date, unit='ms').dt.ceil('D').dt.date\n",
    "    volumes_df['date'] = pd.to_datetime(volumes_df.date, unit='ms').dt.ceil('D').dt.date\n",
    "    asset_df   = asset_df.groupby('date').last().reset_index()\n",
    "    mcaps_df   = mcaps_df.groupby('date').last().reset_index()\n",
    "    volumes_df = volumes_df.groupby('date').last().reset_index()\n",
    "    asset_df = asset_df.merge(mcaps_df,\n",
    "                            on='date',\n",
    "                            how='outer',\n",
    "                            validate='one_to_one')\n",
    "    asset_df = asset_df.merge(volumes_df,\n",
    "                            on='date',\n",
    "                            how='outer',\n",
    "                            validate='one_to_one')\n",
    "    asset_df['asset_gecko'] = gecko_id\n",
    "    asset_df = asset_df[['date', 'asset_gecko', 'usd_per_token_cg', 'usd_mcap_cg', 'usd_volume_24h_cg']]\n",
    "\n",
    "    # append results\n",
    "    panel_df = pd.concat((panel_df, asset_df))\n",
    "\n",
    "    # space out the calls\n",
    "    time.sleep(0.2)\n",
    "\n",
    "return panel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4187dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "904ba51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        # Add data to dictionary\n",
    "        date_of_call = date_to_call[-4:] + '-' + date_to_call[3:5] + '-' + date_to_call[:2]\n",
    "        gecko_covars_dict['date'].append(date_of_call)\n",
    "        gecko_covars_dict['gecko_id'].append(gecko_id)\n",
    "\n",
    "        if 'community_data' in r_json.keys():\n",
    "            gecko_covars_dict['twitter_followers'].append(r_json['community_data']['twitter_followers'])\n",
    "            gecko_covars_dict['reddit_average_posts_48h'].append(r_json['community_data']['reddit_average_posts_48h'])\n",
    "            gecko_covars_dict['reddit_average_comments_48h'].append(r_json['community_data']['reddit_average_comments_48h'])\n",
    "            gecko_covars_dict['reddit_subscribers'].append(r_json['community_data']['reddit_subscribers'])\n",
    "            gecko_covars_dict['reddit_accounts_active_48h'].append(r_json['community_data']['reddit_accounts_active_48h'])\n",
    "        else:\n",
    "            gecko_covars_dict['twitter_followers'].append(None)\n",
    "            gecko_covars_dict['reddit_average_posts_48h'].append(None)\n",
    "            gecko_covars_dict['reddit_average_comments_48h'].append(None)\n",
    "            gecko_covars_dict['reddit_subscribers'].append(None)\n",
    "            gecko_covars_dict['reddit_accounts_active_48h'].append(None)\n",
    "\n",
    "        if 'developer_data' in r_json.keys():\n",
    "            gecko_covars_dict['forks'].append(r_json['developer_data']['forks'])\n",
    "            gecko_covars_dict['stars'].append(r_json['developer_data']['stars'])\n",
    "            gecko_covars_dict['subscribers'].append(r_json['developer_data']['subscribers'])\n",
    "            gecko_covars_dict['total_issues'].append(r_json['developer_data']['total_issues'])\n",
    "            gecko_covars_dict['closed_issues'].append(r_json['developer_data']['closed_issues'])\n",
    "            gecko_covars_dict['pull_requests_merged'].append(r_json['developer_data']['pull_requests_merged'])\n",
    "            gecko_covars_dict['pull_request_contributors'].append(r_json['developer_data']['pull_request_contributors'])\n",
    "            gecko_covars_dict['code_additions_4_weeks'].append(r_json['developer_data']['code_additions_deletions_4_weeks']['additions'])\n",
    "            gecko_covars_dict['code_deletions_4_weeks'].append(r_json['developer_data']['code_additions_deletions_4_weeks']['deletions'])\n",
    "            gecko_covars_dict['commit_count_4_weeks'].append(r_json['developer_data']['commit_count_4_weeks'])\n",
    "        else:\n",
    "            gecko_covars_dict['forks'].append(None)\n",
    "            gecko_covars_dict['stars'].append(None)\n",
    "            gecko_covars_dict['subscribers'].append(None)\n",
    "            gecko_covars_dict['total_issues'].append(None)\n",
    "            gecko_covars_dict['closed_issues'].append(None)\n",
    "            gecko_covars_dict['pull_requests_merged'].append(None)\n",
    "            gecko_covars_dict['pull_request_contributors'].append(None)\n",
    "            gecko_covars_dict['code_additions_4_weeks'].append(None)\n",
    "            gecko_covars_dict['code_deletions_4_weeks'].append(None)\n",
    "            gecko_covars_dict['commit_count_4_weeks'].append(None)\n",
    "\n",
    "        if 'public_interest_stats' in r_json.keys():\n",
    "            gecko_covars_dict['alexa_rank'].append(r_json['public_interest_stats']['alexa_rank'])\n",
    "        else:\n",
    "            gecko_covars_dict['alexa_rank'].append(None)\n",
    "        \n",
    "        # Space out the calls and increment counter\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    # Update the counter for the tokens\n",
    "    i += 1\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41459075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c022d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a dataframe\n",
    "gecko_covars_df = pd.DataFrame(gecko_covars_dict)\n",
    "gecko_covars_df = gecko_covars_df[~gecko_covars_df.duplicated(subset=['date', 'gecko_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "877f4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes together\n",
    "df = gecko_df.merge(gecko_covars_df,\n",
    "                    on=['date', 'gecko_id'],\n",
    "                    how='outer',\n",
    "                    validate='one_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61110f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "df.to_csv('../3-data/raw/coingecko_panel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eb5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a dataframe\n",
    "gecko_covars_df = pd.DataFrame(gecko_covars_dict)\n",
    "gecko_covars_df = gecko_covars_df[~gecko_covars_df.duplicated(subset=['date', 'gecko_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062bd0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes together\n",
    "df = gecko_df.merge(gecko_covars_df,\n",
    "                    on=['date', 'gecko_id'],\n",
    "                    how='outer',\n",
    "                    validate='one_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e99e989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d3701f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO pull all the exchanges and obtain data for the ones i did with cmc, e.g. volumes\n",
    "# TODO pull derivative exchange data\n",
    "# TODO pull global data\n",
    "# TODO pull global/defi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a962fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab3845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447624c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ca53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBTAIN THE MACRO DATA\n",
    "\n",
    "gecko_macro_dict = {'date':[],\n",
    "                    'total_mcap': [],\n",
    "                    'total_volume': [],\n",
    "                    'total_markets': []}\n",
    "\n",
    "# Build list of dates to pull\n",
    "dates = list(pd.date_range('01-12-2015', '28-07-2022', freq='D').strftime('%d-%m-%Y'))\n",
    "\n",
    "# Loop over all the dates\n",
    "for date_to_call in dates:\n",
    "    # Set up the call\n",
    "    endpoint       = '/global'\n",
    "    final_url      = base_url+endpoint\n",
    "    params         = base_params.copy()\n",
    "    params['id']   = gecko_id \n",
    "    params['date'] = date_to_call\n",
    "\n",
    "    # Make the call while checking it is successful\n",
    "    nb_tries = 5\n",
    "    while True:\n",
    "        nb_tries -= 1\n",
    "        try:\n",
    "            r = requests.get(final_url, params=params, timeout=2)\n",
    "            if r.status_code == 200:\n",
    "                r_json = r.json()\n",
    "                break\n",
    "            else:\n",
    "                if nb_tries <= 0:\n",
    "                    assert(1==0),('some other error')\n",
    "                time.sleep(2)\n",
    "                pass\n",
    "        except (ConnectionError, requests.exceptions.Timeout) as err:\n",
    "            if nb_tries <= 0:\n",
    "                raise err\n",
    "            else:\n",
    "                print('connection or timeout error')\n",
    "                time.sleep(5)\n",
    "\n",
    "    # Add data to dictionary\n",
    "    date_of_call = date_to_call[-4:] + '-' + date_to_call[3:5] + '-' + date_to_call[:2]\n",
    "    gecko_covars_dict['date'].append(date_of_call)\n",
    "    gecko_covars_dict['gecko_id'].append(gecko_id)\n",
    "\n",
    "    if 'community_data' in r_json.keys():\n",
    "        gecko_covars_dict['twitter_followers'].append(r_json['community_data']['twitter_followers'])\n",
    "    else:\n",
    "        gecko_covars_dict['twitter_followers'].append(None)\n",
    "\n",
    "    # Space out the calls and increment counter\n",
    "    time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae64b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "df.to_csv('../3-data/raw/coingecko_panel.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e428bc405edc59f3352e9792cab27c5e28560f7efb4b47308a6c6ea38cd15df2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
