{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6359323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from datetime import date\n",
    "from requests import Request, Session\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
    "import json\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import json.decoder\n",
    "from typing import Dict, Any, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bcf65d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiateAPI(base_url: str) -> Session:\n",
    "    \"\"\" confirm the cmc api is working for the set api key.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): the url for the pro api at cmc. \n",
    "    \n",
    "    Returns:\n",
    "        session (requests.Session): request class for pinging cmc.\n",
    "    \"\"\"\n",
    "    endpoint = '/v1/key/info'\n",
    "    headers = {'Accepts': 'application/json',\n",
    "               'X-CMC_PRO_API_KEY': API_KEY}\n",
    "    final_url = base_url + endpoint\n",
    "    session = Session()\n",
    "    session.headers.update(headers)\n",
    "    r = session.get(final_url)\n",
    "    print(r.json())\n",
    "\n",
    "    return session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fad6930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCMCApiCall(session: Session, url: str, params: dict, retries: int=3) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\" makes an API call to CoinMarketCap using the provided requests.Session object.\n",
    "    \n",
    "    Args:\n",
    "        session (requests.Session): A requests.Session object that will be used to make the API call.\n",
    "        url (str): The API endpoint URL to call.\n",
    "        params (dict): A dictionary of parameters to include in the API call.\n",
    "        retries (int): The number of times to retry the API call if it fails. Default is 3.\n",
    "        \n",
    "    Returns:\n",
    "        data (dict): the data from the api response, or None if the api call failed.\n",
    "    \"\"\"\n",
    "    for attempt in range(retries):\n",
    "        response = session.get(url, params=params)\n",
    "        if response.ok:\n",
    "            try:\n",
    "                return response.json()['data']\n",
    "            except json.decoder.JSONDecodeError as e:\n",
    "                print(f'Error decoding JSON response: {str(e)}')\n",
    "        else:\n",
    "            # There was an error, retry after a short delay\n",
    "            print(f'The API call failed with status code {response.status_code}, retrying...')\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    print('The api call failed after 3 attempts.')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "10cec1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtainTopCMCTokens(base_url: str, session: Session, start_date: date, end_date: date) -> list:\n",
    "    \"\"\" obtain the top cmc tokens for each month of the study peiod.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): The url for the pro api at cmc. \n",
    "        session (Session): A requests.Session object that will be used to make the API call.\n",
    "        start_date (datetime.date): start of study period.\n",
    "        end_date (datetime.date): end of study period.\n",
    "    \n",
    "    Returns:\n",
    "        unique_token_cmc_ids (list): unique cmc token integer ids.\n",
    "    \"\"\"\n",
    "    # specify the dates to obtain\n",
    "    dates = [start_date]\n",
    "    current_date = start_date+relativedelta(months=1)\n",
    "    while current_date <= end_date:\n",
    "        dates.append(current_date)\n",
    "        current_date += relativedelta(months=1)\n",
    "\n",
    "    # set up target url\n",
    "    endpoint = '/v1/cryptocurrency/listings/historical'\n",
    "    url = f\"{base_url}{endpoint}\"\n",
    "\n",
    "    # obtain the top 500 tokens by cmc ranking for each month in the study period\n",
    "    token_cmc_ids = []\n",
    "    for date in dates:\n",
    "        # set up params for call\n",
    "        if date.year < 2017:\n",
    "            limit = 200\n",
    "        elif date.year < 2020:\n",
    "            limit = 400\n",
    "        else:\n",
    "            limit = 650\n",
    "        params = {'date': date,\n",
    "                  'limit': limit,\n",
    "                  'convert': 'USD',\n",
    "                  'aux': 'cmc_rank'}\n",
    "\n",
    "        # make the call\n",
    "        data = makeCMCApiCall(session, url, params)\n",
    "\n",
    "        # extract the token ids\n",
    "        new_tokens = [token['id'] for token in data]\n",
    "        token_cmc_ids.extend(new_tokens)\n",
    "\n",
    "        # space out calls\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # drop redundant tokens\n",
    "    unique_token_cmc_ids = list(np.unique(np.array(token_cmc_ids)))\n",
    "\n",
    "    # manually drop tokens\n",
    "    unique_token_cmc_ids.remove()\n",
    "\n",
    "    return unique_token_cmc_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0d764cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formDataframeOfTopCMCTokens(base_url: str, session: Session, cmc_ids: list) -> pd.DataFrame():\n",
    "    \"\"\" pull all cmc meta data for tokens and merge onto universe of top tokens in cmc_ids.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): the url for the pro api at cmc. \n",
    "        session (Session): A requests.Session object that will be used to make the API call.\n",
    "        cmc_ids (list): top tokens by cmc ranking.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        token_df (pd.DataFrame): dataframe of token meta data for top tokens by cmc ranking.\n",
    "    \"\"\"\n",
    "\n",
    "    # set up target url for obtaining mapping from id to token info\n",
    "    endpoint = '/v1/cryptocurrency/map'\n",
    "    url = f\"{base_url}{endpoint}\"\n",
    "\n",
    "    # obtain the CMC mapping of IDs to token info\n",
    "    full_data = []\n",
    "    starts = [1, 5001, 10001, 15001]\n",
    "    for start in starts:\n",
    "        # set up params for call\n",
    "        params = {'listing_status': 'active,inactive,untracked',\n",
    "                  'limit': 5000,\n",
    "                  'start': start,\n",
    "                  'aux': 'platform,first_historical_data,last_historical_data'}\n",
    "\n",
    "        # make the call\n",
    "        data = makeCMCApiCall(session, url, params)\n",
    "\n",
    "        # Append the results\n",
    "        full_data.extend(data)\n",
    "\n",
    "        # space out calls\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # clean up token info dictionaries\n",
    "    clean_full_data = []\n",
    "    for token_dict in full_data:\n",
    "        new_dict = {}\n",
    "        new_dict['cmc_id'] = token_dict['id']\n",
    "        new_dict['cmc_symbol'] = token_dict['symbol']\n",
    "        new_dict['name'] = token_dict['name']\n",
    "        new_dict['cmc_slug'] = token_dict['slug']\n",
    "        try:\n",
    "            new_dict['cmc_first_date'] = token_dict['first_historical_data']\n",
    "            new_dict['cmc_last_date'] = token_dict['last_historical_data']\n",
    "        except KeyError:\n",
    "            new_dict['cmc_first_date'] = None\n",
    "            new_dict['cmc_last_date'] = None\n",
    "        if token_dict['platform'] != None:\n",
    "            new_dict['platform_cmc_slug'] = token_dict['platform']['slug']\n",
    "        else:\n",
    "            new_dict['platform_cmc_slug'] = None\n",
    "        clean_full_data.append(new_dict)\n",
    "\n",
    "    cmc_tokens_df = pd.DataFrame(clean_full_data)\n",
    "\n",
    "    # Merge down to just the tokens of interest\n",
    "    target_tokens_df = pd.DataFrame(data = {'cmc_id': cmc_ids})\n",
    "    token_df = cmc_tokens_df.merge(target_tokens_df,\n",
    "                                on='cmc_id',\n",
    "                                how='inner',\n",
    "                                validate='one_to_one')\n",
    "\n",
    "    # reset index and sort\n",
    "    token_df = token_df.sort_values(by='cmc_id', ignore_index=True)\n",
    "\n",
    "    return token_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9bb6a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullPriceMcapVolume(base_url: str, session: Session, \n",
    "        token_df: pd.DataFrame, start_date: date, end_date: date) -> pd.DataFrame:\n",
    "    \"\"\" pulls historical price, volume, and mcap data for token ids in token_df.\n",
    "    \n",
    "    Args:\n",
    "        base_url (str): The base URL for the CoinMarketCap API.\n",
    "        session (requests.Session): A requests.Session object to be used to make the API calls.\n",
    "        token_df (pd.DataFrame): A pandas DataFrame that contains information about the tokens to \n",
    "                                 retrieve data for. Must include columns 'cmc_id' and 'cmc_slug'.\n",
    "        start_date (date): A datetime.date object representing the start date for the study period.\n",
    "        end_date (date): A datetime.date object representing the end date for the study period.\n",
    "    Returns:\n",
    "        df (pd.DataFrame): price, volume, and mcap for target tokens within specified date range. \n",
    "                           The DataFrame has columns 'cmc_id', 'date', 'usd_per_token', 'usd_mcap',\n",
    "                           and 'usd_volume_24h'.\n",
    "    \"\"\"\n",
    "    # initialize list to build\n",
    "    token_dfs = []\n",
    "\n",
    "    # set up target url\n",
    "    endpoint = '/v1/cryptocurrency/quotes/historical'\n",
    "    url = f\"{base_url}{endpoint}\"\n",
    "\n",
    "    # loop over tokens\n",
    "    token_ids = list(token_df.cmc_id.values)\n",
    "    token_names = list(token_df.cmc_slug.values)\n",
    "    for i, (token_id, token_name) in enumerate(zip(token_ids, token_names)):\n",
    "        # monitor progress\n",
    "        print(f\"Processing the {i+1}th token ({(i+1)/len(token_ids)*100:.2f}%): {token_name}\")\n",
    "\n",
    "        # build parameters\n",
    "        params = {'id': str(token_id),\n",
    "                'time_start': start_date.strftime('%Y-%m-%d'),\n",
    "                'time_end': end_date.strftime('%Y-%m-%d'),\n",
    "                'count': 1,\n",
    "                'interval': '1d',\n",
    "                'convert': 'USD'} \n",
    "        \n",
    "        # make the api call\n",
    "        data = makeCMCApiCall(session, url, params, retries=3)\n",
    "\n",
    "        # clean the data\n",
    "        if data != None:\n",
    "            if data['is_fiat'] == 0:\n",
    "                token_quote_dict_list = []\n",
    "                for quote in data['quotes']:\n",
    "                    new_dict = {}\n",
    "                    new_dict['date']           = quote['quote']['USD']['timestamp'][:10]\n",
    "                    new_dict['usd_per_token']  = quote['quote']['USD']['price']\n",
    "                    new_dict['usd_volume_24h'] = quote['quote']['USD']['volume_24h']\n",
    "                    new_dict['usd_mcap']       = quote['quote']['USD']['market_cap']\n",
    "                    token_quote_dict_list.append(new_dict)\n",
    "\n",
    "                token_df = pd.DataFrame(token_quote_dict_list)\n",
    "                token_df['cmc_id'] = data['id']\n",
    "                token_dfs.append(token_df)\n",
    "            else:\n",
    "                print(f\"{data['name']} is fiat\")        \n",
    "\n",
    "        # space out calls\n",
    "        time.sleep(1)\n",
    "\n",
    "    # build final dataframe\n",
    "    df = pd.concat(token_dfs)\n",
    "\n",
    "    return df            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b3f2a56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the 0th token (1/2930.00%): bitcoin\n",
      "Processing the 1th token (2/2930.00%): litecoin\n",
      "Processing the 2th token (3/2930.00%): namecoin\n",
      "Processing the 3th token (4/2930.00%): terracoin\n",
      "Processing the 4th token (5/2930.00%): peercoin\n",
      "Processing the 5th token (6/2930.00%): novacoin\n",
      "Processing the 6th token (7/2930.00%): devcoin\n",
      "Processing the 7th token (8/2930.00%): feathercoin\n",
      "Processing the 8th token (9/2930.00%): freicoin\n",
      "Processing the 9th token (10/2930.00%): bbqcoin\n",
      "Processing the 10th token (11/2930.00%): ixcoin\n",
      "Processing the 11th token (12/2930.00%): bitbar\n",
      "Processing the 12th token (13/2930.00%): worldcoin\n",
      "Processing the 13th token (14/2930.00%): yacoin\n",
      "Processing the 14th token (15/2930.00%): digitalcoin\n",
      "Processing the 15th token (16/2930.00%): franko\n",
      "Processing the 16th token (17/2930.00%): goldcoin\n",
      "Processing the 17th token (18/2930.00%): bottlecaps\n",
      "Processing the 18th token (19/2930.00%): argentum\n",
      "Processing the 19th token (20/2930.00%): fastcoin\n",
      "Processing the 20th token (21/2930.00%): phoenixcoin\n",
      "Processing the 21th token (22/2930.00%): megacoin\n",
      "Processing the 22th token (23/2930.00%): infinitecoin\n",
      "Processing the 23th token (24/2930.00%): primecoin\n",
      "Processing the 24th token (25/2930.00%): anoncoin\n",
      "Processing the 25th token (26/2930.00%): casinocoin\n",
      "Processing the 26th token (27/2930.00%): spots\n",
      "Processing the 27th token (28/2930.00%): bullion\n",
      "Processing the 28th token (29/2930.00%): emerald\n",
      "Processing the 29th token (30/2930.00%): globalcoin\n",
      "Processing the 30th token (31/2930.00%): xrp\n",
      "Processing the 31th token (32/2930.00%): quark\n",
      "Processing the 32th token (33/2930.00%): zetacoin\n",
      "Processing the 33th token (34/2930.00%): securecoin\n",
      "Processing the 34th token (35/2930.00%): sexcoin\n",
      "Processing the 35th token (36/2930.00%): tickets\n",
      "Processing the 36th token (37/2930.00%): copperlark\n",
      "Processing the 37th token (38/2930.00%): tagcoin\n",
      "Processing the 38th token (39/2930.00%): bitshares-pts\n",
      "Processing the 39th token (40/2930.00%): i0coin\n",
      "Processing the 40th token (41/2930.00%): public-index-network\n",
      "Processing the 41th token (42/2930.00%): colossuscoin\n",
      "Processing the 42th token (43/2930.00%): nxt\n",
      "Processing the 43th token (44/2930.00%): unobtanium\n",
      "Processing the 44th token (45/2930.00%): joulecoin\n",
      "Processing the 45th token (46/2930.00%): datacoin\n",
      "Processing the 46th token (47/2930.00%): deutsche-emark\n",
      "Processing the 47th token (48/2930.00%): dogecoin\n",
      "Processing the 48th token (49/2930.00%): netcoin\n",
      "Processing the 49th token (50/2930.00%): diamond\n",
      "Processing the 50th token (51/2930.00%): hobonickels\n",
      "Processing the 51th token (52/2930.00%): tigercoin\n",
      "Processing the 52th token (53/2930.00%): orbitcoin\n",
      "Processing the 53th token (54/2930.00%): memorycoin\n",
      "Processing the 54th token (55/2930.00%): lottocoin\n",
      "Processing the 55th token (56/2930.00%): omni\n",
      "Processing the 56th token (57/2930.00%): earthcoin\n",
      "Processing the 57th token (58/2930.00%): asiccoin\n",
      "Processing the 58th token (59/2930.00%): fedoracoin\n",
      "Processing the 59th token (60/2930.00%): mooncoin\n",
      "Processing the 60th token (61/2930.00%): dimecoin\n",
      "Processing the 61th token (62/2930.00%): 42-coin\n",
      "Processing the 62th token (63/2930.00%): ybcoin\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # set args\n",
    "    api_fp = '../../admin/cmc.txt'\n",
    "    start_date = date(2015, 1, 1)\n",
    "    end_date   = date(2023, 2, 1)\n",
    "    base_url = \"https://pro-api.coinmarketcap.com\"\n",
    "\n",
    "    # import api key\n",
    "    with open(api_fp) as f:\n",
    "        API_KEY = f.readlines()\n",
    "        API_KEY = API_KEY[0].strip()\n",
    "    \n",
    "    # confirm api is working\n",
    "    session = initiateAPI(base_url)\n",
    "\n",
    "    # obtain potential token ids to include in study\n",
    "    cmc_ids  = obtainTopCMCTokens(base_url, session, start_date, end_date)\n",
    "    token_df = formDataframeOfTopCMCTokens(base_url, session, cmc_ids)\n",
    "\n",
    "    # obtain price, volume, and mcap data for target tokens\n",
    "    cmc_df = pullPriceMcapVolume(base_url, session, token_df, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e9c746",
   "metadata": {},
   "source": [
    "## (3) Pull other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "d730593d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-22\n",
      "\n",
      "\n",
      "2020-09-23\n",
      "\n",
      "\n",
      "2020-09-24\n",
      "\n",
      "\n",
      "2020-09-25\n",
      "\n",
      "\n",
      "2020-09-26\n",
      "\n",
      "\n",
      "2020-09-27\n",
      "\n",
      "\n",
      "2020-09-28\n",
      "\n",
      "\n",
      "2020-09-29\n",
      "\n",
      "\n",
      "2020-09-30\n",
      "\n",
      "\n",
      "2020-10-01\n",
      "\n",
      "\n",
      "2020-10-02\n",
      "\n",
      "\n",
      "2020-10-03\n",
      "\n",
      "\n",
      "2020-10-04\n",
      "\n",
      "\n",
      "2020-10-05\n",
      "\n",
      "\n",
      "2020-10-06\n",
      "\n",
      "\n",
      "2020-10-07\n",
      "\n",
      "\n",
      "2020-10-08\n",
      "\n",
      "\n",
      "2020-10-09\n",
      "\n",
      "\n",
      "2020-10-10\n",
      "\n",
      "\n",
      "2020-10-11\n",
      "\n",
      "\n",
      "2020-10-12\n",
      "\n",
      "\n",
      "2020-10-13\n",
      "\n",
      "\n",
      "2020-10-14\n",
      "\n",
      "\n",
      "2020-10-15\n",
      "\n",
      "\n",
      "2020-10-16\n",
      "\n",
      "\n",
      "2020-10-17\n",
      "\n",
      "\n",
      "2020-10-18\n",
      "\n",
      "\n",
      "2020-10-19\n",
      "\n",
      "\n",
      "2020-10-20\n",
      "\n",
      "\n",
      "2020-10-21\n",
      "\n",
      "\n",
      "2020-10-22\n",
      "\n",
      "\n",
      "2020-10-23\n",
      "\n",
      "\n",
      "2020-10-24\n",
      "\n",
      "\n",
      "2020-10-25\n",
      "\n",
      "\n",
      "2020-10-26\n",
      "\n",
      "\n",
      "2020-10-27\n",
      "\n",
      "\n",
      "2020-10-28\n",
      "\n",
      "\n",
      "2020-10-29\n",
      "\n",
      "\n",
      "2020-10-30\n",
      "\n",
      "\n",
      "2020-10-31\n",
      "\n",
      "\n",
      "2020-11-01\n",
      "\n",
      "\n",
      "2020-11-02\n",
      "\n",
      "\n",
      "2020-11-03\n",
      "\n",
      "\n",
      "2020-11-04\n",
      "\n",
      "\n",
      "2020-11-05\n",
      "\n",
      "\n",
      "2020-11-06\n",
      "\n",
      "\n",
      "2020-11-07\n",
      "\n",
      "\n",
      "2020-11-08\n",
      "\n",
      "\n",
      "2020-11-09\n",
      "\n",
      "\n",
      "2020-11-10\n",
      "\n",
      "\n",
      "2020-11-11\n",
      "\n",
      "\n",
      "2020-11-12\n",
      "\n",
      "\n",
      "2020-11-13\n",
      "\n",
      "\n",
      "2020-11-14\n",
      "\n",
      "\n",
      "2020-11-15\n",
      "\n",
      "\n",
      "2020-11-16\n",
      "\n",
      "\n",
      "2020-11-17\n",
      "\n",
      "\n",
      "2020-11-18\n",
      "\n",
      "\n",
      "2020-11-19\n",
      "\n",
      "\n",
      "2020-11-20\n",
      "\n",
      "\n",
      "2020-11-21\n",
      "\n",
      "\n",
      "2020-11-22\n",
      "\n",
      "\n",
      "2020-11-23\n",
      "\n",
      "\n",
      "2020-11-24\n",
      "\n",
      "\n",
      "2020-11-25\n",
      "\n",
      "\n",
      "2020-11-26\n",
      "\n",
      "\n",
      "2020-11-27\n",
      "\n",
      "\n",
      "2020-11-28\n",
      "\n",
      "\n",
      "2020-11-29\n",
      "\n",
      "\n",
      "2020-11-30\n",
      "\n",
      "\n",
      "2020-12-01\n",
      "\n",
      "\n",
      "2020-12-02\n",
      "\n",
      "\n",
      "2020-12-03\n",
      "\n",
      "\n",
      "2020-12-04\n",
      "\n",
      "\n",
      "2020-12-05\n",
      "\n",
      "\n",
      "2020-12-06\n",
      "\n",
      "\n",
      "2020-12-07\n",
      "\n",
      "\n",
      "2020-12-08\n",
      "\n",
      "\n",
      "2020-12-09\n",
      "\n",
      "\n",
      "2020-12-10\n",
      "\n",
      "\n",
      "2020-12-11\n",
      "\n",
      "\n",
      "2020-12-12\n",
      "\n",
      "\n",
      "2020-12-13\n",
      "\n",
      "\n",
      "2020-12-14\n",
      "\n",
      "\n",
      "2020-12-15\n",
      "\n",
      "\n",
      "2020-12-16\n",
      "\n",
      "\n",
      "2020-12-17\n",
      "\n",
      "\n",
      "2020-12-18\n",
      "\n",
      "\n",
      "2020-12-19\n",
      "\n",
      "\n",
      "2020-12-20\n",
      "\n",
      "\n",
      "2020-12-21\n",
      "\n",
      "\n",
      "2020-12-22\n",
      "\n",
      "\n",
      "error due to out of range\n",
      "2020-12-23\n",
      "\n",
      "\n",
      "2020-12-24\n",
      "\n",
      "\n",
      "2020-12-25\n",
      "\n",
      "\n",
      "2020-12-26\n",
      "\n",
      "\n",
      "2020-12-27\n",
      "\n",
      "\n",
      "2020-12-28\n",
      "\n",
      "\n",
      "2020-12-29\n",
      "\n",
      "\n",
      "2020-12-30\n",
      "\n",
      "\n",
      "2020-12-31\n",
      "\n",
      "\n",
      "2021-01-01\n",
      "\n",
      "\n",
      "2021-01-02\n",
      "\n",
      "\n",
      "2021-01-03\n",
      "\n",
      "\n",
      "2021-01-04\n",
      "\n",
      "\n",
      "2021-01-05\n",
      "\n",
      "\n",
      "2021-01-06\n",
      "\n",
      "\n",
      "2021-01-07\n",
      "\n",
      "\n",
      "2021-01-08\n",
      "\n",
      "\n",
      "2021-01-09\n",
      "\n",
      "\n",
      "2021-01-10\n",
      "\n",
      "\n",
      "2021-01-11\n",
      "\n",
      "\n",
      "2021-01-12\n",
      "\n",
      "\n",
      "2021-01-13\n",
      "\n",
      "\n",
      "2021-01-14\n",
      "\n",
      "\n",
      "2021-01-15\n",
      "\n",
      "\n",
      "2021-01-16\n",
      "\n",
      "\n",
      "2021-01-17\n",
      "\n",
      "\n",
      "2021-01-18\n",
      "\n",
      "\n",
      "2021-01-19\n",
      "\n",
      "\n",
      "2021-01-20\n",
      "\n",
      "\n",
      "2021-01-21\n",
      "\n",
      "\n",
      "2021-01-22\n",
      "\n",
      "\n",
      "2021-01-23\n",
      "\n",
      "\n",
      "2021-01-24\n",
      "\n",
      "\n",
      "2021-01-25\n",
      "\n",
      "\n",
      "2021-01-26\n",
      "\n",
      "\n",
      "2021-01-27\n",
      "\n",
      "\n",
      "2021-01-28\n",
      "\n",
      "\n",
      "2021-01-29\n",
      "\n",
      "\n",
      "2021-01-30\n",
      "\n",
      "\n",
      "2021-01-31\n",
      "\n",
      "\n",
      "2021-02-01\n",
      "\n",
      "\n",
      "2021-02-02\n",
      "\n",
      "\n",
      "2021-02-03\n",
      "\n",
      "\n",
      "2021-02-04\n",
      "\n",
      "\n",
      "2021-02-05\n",
      "\n",
      "\n",
      "2021-02-06\n",
      "\n",
      "\n",
      "2021-02-07\n",
      "\n",
      "\n",
      "2021-02-08\n",
      "\n",
      "\n",
      "2021-02-09\n",
      "\n",
      "\n",
      "2021-02-10\n",
      "\n",
      "\n",
      "2021-02-11\n",
      "\n",
      "\n",
      "2021-02-12\n",
      "\n",
      "\n",
      "2021-02-13\n",
      "\n",
      "\n",
      "2021-02-14\n",
      "\n",
      "\n",
      "2021-02-15\n",
      "\n",
      "\n",
      "2021-02-16\n",
      "\n",
      "\n",
      "2021-02-17\n",
      "\n",
      "\n",
      "2021-02-18\n",
      "\n",
      "\n",
      "2021-02-19\n",
      "\n",
      "\n",
      "2021-02-20\n",
      "\n",
      "\n",
      "2021-02-21\n",
      "\n",
      "\n",
      "2021-02-22\n",
      "\n",
      "\n",
      "2021-02-23\n",
      "\n",
      "\n",
      "2021-02-24\n",
      "\n",
      "\n",
      "2021-02-25\n",
      "\n",
      "\n",
      "2021-02-26\n",
      "\n",
      "\n",
      "2021-02-27\n",
      "\n",
      "\n",
      "2021-02-28\n",
      "\n",
      "\n",
      "2021-03-01\n",
      "\n",
      "\n",
      "2021-03-02\n",
      "\n",
      "\n",
      "2021-03-03\n",
      "\n",
      "\n",
      "2021-03-04\n",
      "\n",
      "\n",
      "2021-03-05\n",
      "\n",
      "\n",
      "2021-03-06\n",
      "\n",
      "\n",
      "2021-03-07\n",
      "\n",
      "\n",
      "2021-03-08\n",
      "\n",
      "\n",
      "2021-03-09\n",
      "\n",
      "\n",
      "2021-03-10\n",
      "\n",
      "\n",
      "2021-03-11\n",
      "\n",
      "\n",
      "2021-03-12\n",
      "\n",
      "\n",
      "2021-03-13\n",
      "\n",
      "\n",
      "2021-03-14\n",
      "\n",
      "\n",
      "2021-03-15\n",
      "\n",
      "\n",
      "2021-03-16\n",
      "\n",
      "\n",
      "2021-03-17\n",
      "\n",
      "\n",
      "2021-03-18\n",
      "\n",
      "\n",
      "2021-03-19\n",
      "\n",
      "\n",
      "2021-03-20\n",
      "\n",
      "\n",
      "2021-03-21\n",
      "\n",
      "\n",
      "2021-03-22\n",
      "\n",
      "\n",
      "2021-03-23\n",
      "\n",
      "\n",
      "2021-03-24\n",
      "\n",
      "\n",
      "2021-03-25\n",
      "\n",
      "\n",
      "2021-03-26\n",
      "\n",
      "\n",
      "2021-03-27\n",
      "\n",
      "\n",
      "2021-03-28\n",
      "\n",
      "\n",
      "2021-03-29\n",
      "\n",
      "\n",
      "2021-03-30\n",
      "\n",
      "\n",
      "2021-03-31\n",
      "\n",
      "\n",
      "2021-04-01\n",
      "\n",
      "\n",
      "2021-04-02\n",
      "\n",
      "\n",
      "2021-04-03\n",
      "\n",
      "\n",
      "2021-04-04\n",
      "\n",
      "\n",
      "2021-04-05\n",
      "\n",
      "\n",
      "2021-04-06\n",
      "\n",
      "\n",
      "2021-04-07\n",
      "\n",
      "\n",
      "2021-04-08\n",
      "\n",
      "\n",
      "2021-04-09\n",
      "\n",
      "\n",
      "2021-04-10\n",
      "\n",
      "\n",
      "2021-04-11\n",
      "\n",
      "\n",
      "2021-04-12\n",
      "\n",
      "\n",
      "2021-04-13\n",
      "\n",
      "\n",
      "2021-04-14\n",
      "\n",
      "\n",
      "2021-04-15\n",
      "\n",
      "\n",
      "2021-04-16\n",
      "\n",
      "\n",
      "2021-04-17\n",
      "\n",
      "\n",
      "2021-04-18\n",
      "\n",
      "\n",
      "2021-04-19\n",
      "\n",
      "\n",
      "2021-04-20\n",
      "\n",
      "\n",
      "2021-04-21\n",
      "\n",
      "\n",
      "2021-04-22\n",
      "\n",
      "\n",
      "2021-04-23\n",
      "\n",
      "\n",
      "2021-04-24\n",
      "\n",
      "\n",
      "2021-04-25\n",
      "\n",
      "\n",
      "2021-04-26\n",
      "\n",
      "\n",
      "2021-04-27\n",
      "\n",
      "\n",
      "2021-04-28\n",
      "\n",
      "\n",
      "2021-04-29\n",
      "\n",
      "\n",
      "2021-04-30\n",
      "\n",
      "\n",
      "2021-05-01\n",
      "\n",
      "\n",
      "2021-05-02\n",
      "\n",
      "\n",
      "2021-05-03\n",
      "\n",
      "\n",
      "2021-05-04\n",
      "\n",
      "\n",
      "2021-05-05\n",
      "\n",
      "\n",
      "2021-05-06\n",
      "\n",
      "\n",
      "2021-05-07\n",
      "\n",
      "\n",
      "2021-05-08\n",
      "\n",
      "\n",
      "2021-05-09\n",
      "\n",
      "\n",
      "2021-05-10\n",
      "\n",
      "\n",
      "2021-05-11\n",
      "\n",
      "\n",
      "2021-05-12\n",
      "\n",
      "\n",
      "2021-05-13\n",
      "\n",
      "\n",
      "2021-05-14\n",
      "\n",
      "\n",
      "2021-05-15\n",
      "\n",
      "\n",
      "2021-05-16\n",
      "\n",
      "\n",
      "2021-05-17\n",
      "\n",
      "\n",
      "2021-05-18\n",
      "\n",
      "\n",
      "2021-05-19\n",
      "\n",
      "\n",
      "2021-05-20\n",
      "\n",
      "\n",
      "2021-05-21\n",
      "\n",
      "\n",
      "2021-05-22\n",
      "\n",
      "\n",
      "2021-05-23\n",
      "\n",
      "\n",
      "2021-05-24\n",
      "\n",
      "\n",
      "2021-05-25\n",
      "\n",
      "\n",
      "2021-05-26\n",
      "\n",
      "\n",
      "2021-05-27\n",
      "\n",
      "\n",
      "2021-05-28\n",
      "\n",
      "\n",
      "2021-05-29\n",
      "\n",
      "\n",
      "2021-05-30\n",
      "\n",
      "\n",
      "2021-05-31\n",
      "\n",
      "\n",
      "2021-06-01\n",
      "\n",
      "\n",
      "2021-06-02\n",
      "\n",
      "\n",
      "2021-06-03\n",
      "\n",
      "\n",
      "2021-06-04\n",
      "\n",
      "\n",
      "2021-06-05\n",
      "\n",
      "\n",
      "2021-06-06\n",
      "\n",
      "\n",
      "2021-06-07\n",
      "\n",
      "\n",
      "2021-06-08\n",
      "\n",
      "\n",
      "2021-06-09\n",
      "\n",
      "\n",
      "2021-06-10\n",
      "\n",
      "\n",
      "2021-06-11\n",
      "\n",
      "\n",
      "2021-06-12\n",
      "\n",
      "\n",
      "2021-06-13\n",
      "\n",
      "\n",
      "2021-06-14\n",
      "\n",
      "\n",
      "2021-06-15\n",
      "\n",
      "\n",
      "2021-06-16\n",
      "\n",
      "\n",
      "2021-06-17\n",
      "\n",
      "\n",
      "2021-06-18\n",
      "\n",
      "\n",
      "2021-06-19\n",
      "\n",
      "\n",
      "2021-06-20\n",
      "\n",
      "\n",
      "2021-06-21\n",
      "\n",
      "\n",
      "2021-06-22\n",
      "\n",
      "\n",
      "2021-06-23\n",
      "\n",
      "\n",
      "2021-06-24\n",
      "\n",
      "\n",
      "2021-06-25\n",
      "\n",
      "\n",
      "2021-06-26\n",
      "\n",
      "\n",
      "2021-06-27\n",
      "\n",
      "\n",
      "2021-06-28\n",
      "\n",
      "\n",
      "2021-06-29\n",
      "\n",
      "\n",
      "2021-06-30\n",
      "\n",
      "\n",
      "2021-07-01\n",
      "\n",
      "\n",
      "2021-07-02\n",
      "\n",
      "\n",
      "2021-07-03\n",
      "\n",
      "\n",
      "2021-07-04\n",
      "\n",
      "\n",
      "2021-07-05\n",
      "\n",
      "\n",
      "2021-07-06\n",
      "\n",
      "\n",
      "2021-07-07\n",
      "\n",
      "\n",
      "2021-07-08\n",
      "\n",
      "\n",
      "2021-07-09\n",
      "\n",
      "\n",
      "2021-07-10\n",
      "\n",
      "\n",
      "2021-07-11\n",
      "\n",
      "\n",
      "2021-07-12\n",
      "\n",
      "\n",
      "2021-07-13\n",
      "\n",
      "\n",
      "2021-07-14\n",
      "\n",
      "\n",
      "2021-07-15\n",
      "\n",
      "\n",
      "2021-07-16\n",
      "\n",
      "\n",
      "2021-07-17\n",
      "\n",
      "\n",
      "2021-07-18\n",
      "\n",
      "\n",
      "2021-07-19\n",
      "\n",
      "\n",
      "2021-07-20\n",
      "\n",
      "\n",
      "2021-07-21\n",
      "\n",
      "\n",
      "2021-07-22\n",
      "\n",
      "\n",
      "2021-07-23\n",
      "\n",
      "\n",
      "2021-07-24\n",
      "\n",
      "\n",
      "2021-07-25\n",
      "\n",
      "\n",
      "2021-07-26\n",
      "\n",
      "\n",
      "2021-07-27\n",
      "\n",
      "\n",
      "2021-07-28\n",
      "\n",
      "\n",
      "2021-07-29\n",
      "\n",
      "\n",
      "2021-07-30\n",
      "\n",
      "\n",
      "2021-07-31\n",
      "\n",
      "\n",
      "2021-08-01\n",
      "\n",
      "\n",
      "2021-08-02\n",
      "\n",
      "\n",
      "2021-08-03\n",
      "\n",
      "\n",
      "2021-08-04\n",
      "\n",
      "\n",
      "2021-08-05\n",
      "\n",
      "\n",
      "2021-08-06\n",
      "\n",
      "\n",
      "2021-08-07\n",
      "\n",
      "\n",
      "2021-08-08\n",
      "\n",
      "\n",
      "2021-08-09\n",
      "\n",
      "\n",
      "2021-08-10\n",
      "\n",
      "\n",
      "2021-08-11\n",
      "\n",
      "\n",
      "2021-08-12\n",
      "\n",
      "\n",
      "2021-08-13\n",
      "\n",
      "\n",
      "2021-08-14\n",
      "\n",
      "\n",
      "2021-08-15\n",
      "\n",
      "\n",
      "2021-08-16\n",
      "\n",
      "\n",
      "2021-08-17\n",
      "\n",
      "\n",
      "2021-08-18\n",
      "\n",
      "\n",
      "2021-08-19\n",
      "\n",
      "\n",
      "2021-08-20\n",
      "\n",
      "\n",
      "2021-08-21\n",
      "\n",
      "\n",
      "2021-08-22\n",
      "\n",
      "\n",
      "2021-08-23\n",
      "\n",
      "\n",
      "2021-08-24\n",
      "\n",
      "\n",
      "2021-08-25\n",
      "\n",
      "\n",
      "2021-08-26\n",
      "\n",
      "\n",
      "2021-08-27\n",
      "\n",
      "\n",
      "2021-08-28\n",
      "\n",
      "\n",
      "2021-08-29\n",
      "\n",
      "\n",
      "2021-08-30\n",
      "\n",
      "\n",
      "2021-08-31\n",
      "\n",
      "\n",
      "2021-09-01\n",
      "\n",
      "\n",
      "2021-09-02\n",
      "\n",
      "\n",
      "2021-09-03\n",
      "\n",
      "\n",
      "2021-09-04\n",
      "\n",
      "\n",
      "2021-09-05\n",
      "\n",
      "\n",
      "2021-09-06\n",
      "\n",
      "\n",
      "2021-09-07\n",
      "\n",
      "\n",
      "2021-09-08\n",
      "\n",
      "\n",
      "2021-09-09\n",
      "\n",
      "\n",
      "2021-09-10\n",
      "\n",
      "\n",
      "2021-09-11\n",
      "\n",
      "\n",
      "2021-09-12\n",
      "\n",
      "\n",
      "2021-09-13\n",
      "\n",
      "\n",
      "2021-09-14\n",
      "\n",
      "\n",
      "2021-09-15\n",
      "\n",
      "\n",
      "2021-09-16\n",
      "\n",
      "\n",
      "error due to out of range\n",
      "2021-09-17\n",
      "\n",
      "\n",
      "2021-09-18\n",
      "\n",
      "\n",
      "2021-09-19\n",
      "\n",
      "\n",
      "2021-09-20\n",
      "\n",
      "\n",
      "2021-09-21\n",
      "\n",
      "\n",
      "2021-09-22\n",
      "\n",
      "\n",
      "2021-09-23\n",
      "\n",
      "\n",
      "2021-09-24\n",
      "\n",
      "\n",
      "2021-09-25\n",
      "\n",
      "\n",
      "2021-09-26\n",
      "\n",
      "\n",
      "2021-09-27\n",
      "\n",
      "\n",
      "2021-09-28\n",
      "\n",
      "\n",
      "2021-09-29\n",
      "\n",
      "\n",
      "2021-09-30\n",
      "\n",
      "\n",
      "2021-10-01\n",
      "\n",
      "\n",
      "2021-10-02\n",
      "\n",
      "\n",
      "2021-10-03\n",
      "\n",
      "\n",
      "2021-10-04\n",
      "\n",
      "\n",
      "2021-10-05\n",
      "\n",
      "\n",
      "2021-10-06\n",
      "\n",
      "\n",
      "2021-10-07\n",
      "\n",
      "\n",
      "2021-10-08\n",
      "\n",
      "\n",
      "2021-10-09\n",
      "\n",
      "\n",
      "2021-10-10\n",
      "\n",
      "\n",
      "2021-10-11\n",
      "\n",
      "\n",
      "2021-10-12\n",
      "\n",
      "\n",
      "2021-10-13\n",
      "\n",
      "\n",
      "2021-10-14\n",
      "\n",
      "\n",
      "2021-10-15\n",
      "\n",
      "\n",
      "2021-10-16\n",
      "\n",
      "\n",
      "2021-10-17\n",
      "\n",
      "\n",
      "2021-10-18\n",
      "\n",
      "\n",
      "2021-10-19\n",
      "\n",
      "\n",
      "2021-10-20\n",
      "\n",
      "\n",
      "2021-10-21\n",
      "\n",
      "\n",
      "2021-10-22\n",
      "\n",
      "\n",
      "2021-10-23\n",
      "\n",
      "\n",
      "2021-10-24\n",
      "\n",
      "\n",
      "2021-10-25\n",
      "\n",
      "\n",
      "2021-10-26\n",
      "\n",
      "\n",
      "2021-10-27\n",
      "\n",
      "\n",
      "2021-10-28\n",
      "\n",
      "\n",
      "2021-10-29\n",
      "\n",
      "\n",
      "2021-10-30\n",
      "\n",
      "\n",
      "2021-10-31\n",
      "\n",
      "\n",
      "2021-11-01\n",
      "\n",
      "\n",
      "2021-11-02\n",
      "\n",
      "\n",
      "2021-11-03\n",
      "\n",
      "\n",
      "2021-11-04\n",
      "\n",
      "\n",
      "2021-11-05\n",
      "\n",
      "\n",
      "2021-11-06\n",
      "\n",
      "\n",
      "2021-11-07\n",
      "\n",
      "\n",
      "2021-11-08\n",
      "\n",
      "\n",
      "2021-11-09\n",
      "\n",
      "\n",
      "2021-11-10\n",
      "\n",
      "\n",
      "2021-11-11\n",
      "\n",
      "\n",
      "2021-11-12\n",
      "\n",
      "\n",
      "2021-11-13\n",
      "\n",
      "\n",
      "2021-11-14\n",
      "\n",
      "\n",
      "2021-11-15\n",
      "\n",
      "\n",
      "2021-11-16\n",
      "\n",
      "\n",
      "2021-11-17\n",
      "\n",
      "\n",
      "2021-11-18\n",
      "\n",
      "\n",
      "2021-11-19\n",
      "\n",
      "\n",
      "2021-11-20\n",
      "\n",
      "\n",
      "2021-11-21\n",
      "\n",
      "\n",
      "2021-11-22\n",
      "\n",
      "\n",
      "2021-11-23\n",
      "\n",
      "\n",
      "2021-11-24\n",
      "\n",
      "\n",
      "2021-11-25\n",
      "\n",
      "\n",
      "2021-11-26\n",
      "\n",
      "\n",
      "2021-11-27\n",
      "\n",
      "\n",
      "2021-11-28\n",
      "\n",
      "\n",
      "2021-11-29\n",
      "\n",
      "\n",
      "2021-11-30\n",
      "\n",
      "\n",
      "2021-12-01\n",
      "\n",
      "\n",
      "2021-12-02\n",
      "\n",
      "\n",
      "2021-12-03\n",
      "\n",
      "\n",
      "2021-12-04\n",
      "\n",
      "\n",
      "2021-12-05\n",
      "\n",
      "\n",
      "2021-12-06\n",
      "\n",
      "\n",
      "2021-12-07\n",
      "\n",
      "\n",
      "2021-12-08\n",
      "\n",
      "\n",
      "2021-12-09\n",
      "\n",
      "\n",
      "2021-12-10\n",
      "\n",
      "\n",
      "2021-12-11\n",
      "\n",
      "\n",
      "2021-12-12\n",
      "\n",
      "\n",
      "2021-12-13\n",
      "\n",
      "\n",
      "2021-12-14\n",
      "\n",
      "\n",
      "2021-12-15\n",
      "\n",
      "\n",
      "2021-12-16\n",
      "\n",
      "\n",
      "2021-12-17\n",
      "\n",
      "\n",
      "2021-12-18\n",
      "\n",
      "\n",
      "2021-12-19\n",
      "\n",
      "\n",
      "2021-12-20\n",
      "\n",
      "\n",
      "2021-12-21\n",
      "\n",
      "\n",
      "2021-12-22\n",
      "\n",
      "\n",
      "2021-12-23\n",
      "\n",
      "\n",
      "2021-12-24\n",
      "\n",
      "\n",
      "2021-12-25\n",
      "\n",
      "\n",
      "2021-12-26\n",
      "\n",
      "\n",
      "2021-12-27\n",
      "\n",
      "\n",
      "2021-12-28\n",
      "\n",
      "\n",
      "2021-12-29\n",
      "\n",
      "\n",
      "2021-12-30\n",
      "\n",
      "\n",
      "2021-12-31\n",
      "\n",
      "\n",
      "2022-01-01\n",
      "\n",
      "\n",
      "2022-01-02\n",
      "\n",
      "\n",
      "2022-01-03\n",
      "\n",
      "\n",
      "2022-01-04\n",
      "\n",
      "\n",
      "2022-01-05\n",
      "\n",
      "\n",
      "2022-01-06\n",
      "\n",
      "\n",
      "2022-01-07\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OBTAIN CMC COVARIATES AT DAILY LEVEL FOR ALL TOKENS\n",
    "# NOTE: THIS TAKES 40K CREDITS AND ABOUT 60 MINUTES!\n",
    "\n",
    "# Form list of strings of all dates in study period\n",
    "dates = list(pd.date_range('2015-01-01', '2022-01-07', freq='D').strftime('%Y-%m-%d'))\n",
    "             \n",
    "# Initialize dictionary for the data\n",
    "cmc_covars_dict = {'date': [],\n",
    "                   'cmc_id': [],\n",
    "                   'num_market_pairs': [],\n",
    "                   'max_supply': [],\n",
    "                   'circulating_supply': [],\n",
    "                   'total_supply': [],\n",
    "                   'cmc_rank': [],\n",
    "                   'tags': []}\n",
    "\n",
    "for date in dates: \n",
    "    # Update where we are\n",
    "    print(date)\n",
    "    print('\\n')\n",
    "    \n",
    "    # Set up the call\n",
    "    endpoint = '/v1/cryptocurrency/listings/historical'\n",
    "    final_url = base_url+endpoint\n",
    "    parameters = {'date': date,\n",
    "                  'limit': 5000,\n",
    "                  'convert': 'USD',\n",
    "                  'aux': 'tags,circulating_supply,total_supply,max_supply,cmc_rank,num_market_pairs'}\n",
    "\n",
    "    # Make the call\n",
    "    nb_tries = 3\n",
    "    while True:\n",
    "        nb_tries -= 1\n",
    "        try:\n",
    "            response = session.get(final_url, params=parameters)\n",
    "            r_json = json.loads(response.text)\n",
    "            if (r_json['status']['error_message'] == None):\n",
    "                break\n",
    "            elif (r_json['status']['error_message'][:29] == 'Search query is out of range.'):\n",
    "                print('error due to out of range')\n",
    "                time.sleep(1)\n",
    "                if nb_tries <= 0:\n",
    "                    assert(1==0),'out of range error occured several times'\n",
    "            else:\n",
    "                assert(1==0),'json has error'\n",
    "\n",
    "        except (ConnectionError, Timeout, TooManyRedirects) as err:\n",
    "            if nb_tries <= 0:\n",
    "                raise err\n",
    "            else:\n",
    "                print('error due to connection, timeout, or redirect')\n",
    "                time.sleep(1)\n",
    "\n",
    "    # Add the data for that day to the dictionary\n",
    "    for token in r_json['data']:\n",
    "        cmc_covars_dict['date'].append(date)\n",
    "        cmc_covars_dict['cmc_id'].append(token['id'])\n",
    "        cmc_covars_dict['num_market_pairs'].append(token['num_market_pairs'])\n",
    "        cmc_covars_dict['max_supply'].append(token['max_supply'])\n",
    "        cmc_covars_dict['circulating_supply'].append(token['circulating_supply'])\n",
    "        cmc_covars_dict['total_supply'].append(token['total_supply'])\n",
    "        cmc_covars_dict['cmc_rank'].append(token['cmc_rank'])\n",
    "        cmc_covars_dict['tags'].append(token['tags'])\n",
    "\n",
    "    # Delay next call to not break limits\n",
    "    time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "a7180ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into a df\n",
    "cmc_covars_df = pd.DataFrame(cmc_covars_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "5eaa138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset data down to IDs common in the two different pulls of top tokens\n",
    "unique_ids_1 = final_df.cmc_id.values\n",
    "unique_ids_2 = np.unique(cmc_covars_df.cmc_id.values)\n",
    "unique_ids_common = list(set(unique_ids_2).intersection(set(unique_ids_1)))\n",
    "cmc_covars_df = cmc_covars_df[cmc_covars_df.cmc_id.isin(unique_ids_common)]\n",
    "final_df = final_df[final_df.cmc_id.isin(unique_ids_common)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "7d8c2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBTAIN GLOBAL COINMARKETCAP DATA\n",
    "\n",
    "# Set up the call\n",
    "endpoint = '/v1/global-metrics/quotes/historical'\n",
    "final_url = base_url+endpoint\n",
    "parameters = {'time_start': '2014-12-30',\n",
    "              'time_end': '2022-01-07',\n",
    "              'count': 10,\n",
    "              'interval': '1d',\n",
    "              'convert': 'USD',\n",
    "              'aux': 'btc_dominance,active_cryptocurrencies,active_exchanges,active_market_pairs,total_volume_24h,total_volume_24h_reported,altcoin_market_cap,altcoin_volume_24h,altcoin_volume_24h_reported'}\n",
    "\n",
    "response = session.get(final_url, params=parameters)\n",
    "r_json = json.loads(response.text)\n",
    "\n",
    "# Initialize dictionary for the data\n",
    "cmc_macro_dict = {'date': [],\n",
    "                  'total_market_cap': [],\n",
    "                  'total_volume_24h': [],\n",
    "                  'total_volume_24h_reported': [],\n",
    "                  'altcoin_market_cap': [],\n",
    "                  'altcoin_volume_24h': [],\n",
    "                  'altcoin_volume_24h_reported': [],\n",
    "                  'btc_dominance': [],\n",
    "                  'active_cryptocurrencies': [],\n",
    "                  'active_exchanges': [],\n",
    "                  'active_market_pairs': []}\n",
    "\n",
    "# Convert JSON into dictionary\n",
    "for token in r_json['data']['quotes']:\n",
    "    cmc_macro_dict['date'].append(token['timestamp'][:10])\n",
    "    cmc_macro_dict['total_market_cap'].append(token['quote']['USD']['total_market_cap'])\n",
    "    cmc_macro_dict['total_volume_24h'].append(token['quote']['USD']['total_volume_24h'])\n",
    "    cmc_macro_dict['total_volume_24h_reported'].append(token['quote']['USD']['total_volume_24h_reported'])\n",
    "    cmc_macro_dict['altcoin_market_cap'].append(token['quote']['USD']['altcoin_market_cap'])\n",
    "    cmc_macro_dict['altcoin_volume_24h'].append(token['quote']['USD']['altcoin_volume_24h'])\n",
    "    cmc_macro_dict['altcoin_volume_24h_reported'].append(token['quote']['USD']['altcoin_volume_24h_reported'])\n",
    "    cmc_macro_dict['btc_dominance'].append(token['btc_dominance'])\n",
    "    cmc_macro_dict['active_cryptocurrencies'].append(token['active_cryptocurrencies'])\n",
    "    cmc_macro_dict['active_exchanges'].append(token['active_exchanges'])\n",
    "    cmc_macro_dict['active_market_pairs'].append(token['active_market_pairs'])\n",
    "\n",
    "# Clean up the dataframe to have all study period dates and interpolate missing dates\n",
    "macro_df = pd.DataFrame(cmc_macro_dict)[1:-6]\n",
    "macro_df = macro_df[~macro_df.duplicated(keep='last', subset=['date'])] # One duplicated row to drop\n",
    "dates = dates = list(pd.date_range('2015-01-01', '2021-12-31', freq='D').strftime('%Y-%m-%d'))\n",
    "dates_df = pd.DataFrame(data = {'date': dates})\n",
    "macro_df = macro_df.merge(dates_df, \n",
    "                          on='date',\n",
    "                          how='outer',\n",
    "                          validate='one_to_one')\n",
    "macro_df['date'] = macro_df['date'].astype('datetime64[ns]')\n",
    "macro_df = macro_df.sort_values(by='date')\n",
    "macro_df = macro_df.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "133712f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETERMINE RELEVANT EXCHANGES TO PULL HISTORICAL DATA ON\n",
    "\n",
    "# Set up the call\n",
    "endpoint = '/v1/exchange/map'\n",
    "final_url = base_url+endpoint\n",
    "parameters = {'listing_status': 'active',\n",
    "              'limit': 500,\n",
    "              'aux': 'first_historical_data'}\n",
    "\n",
    "# Make the call\n",
    "response = session.get(final_url, params=parameters)\n",
    "r_json = json.loads(response.text)\n",
    "\n",
    "# Clean it up\n",
    "exchange_df = pd.concat([pd.DataFrame(exchange, index=[0]) for exchange in r_json['data']])\n",
    "exchange_df = exchange_df.reset_index(drop=True)\n",
    "exchange_df = exchange_df.rename(columns = {'id': 'exchange_id',\n",
    "                                            'slug': 'exchange_slug'})\n",
    "exchange_df = exchange_df[['exchange_id', 'exchange_slug']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "5cfac098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBTAIN METADATA\n",
    "\n",
    "# Set up the call\n",
    "exchange_ids = ','.join([str(ex_id)for ex_id in exchange_df.exchange_id.values])\n",
    "endpoint = '/v1/exchange/info'\n",
    "final_url = base_url+endpoint\n",
    "parameters = {'id': exchange_ids,\n",
    "              'aux': 'date_launched'}\n",
    "\n",
    "# Make the call\n",
    "response = session.get(final_url, params=parameters)\n",
    "r_json = json.loads(response.text)\n",
    "\n",
    "# Add date launched to the data frame\n",
    "for key in r_json['data'].keys():\n",
    "    exchange_df.loc[exchange_df.exchange_id == int(key), \n",
    "                    'date_launched'] = r_json['data'][key]['date_launched']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "991459d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping exchanges that do not have historical data\n",
    "exchange_names_to_drop = ['feg-exchange', 'uniswap-v3-arbitrum', 'huckleberry', \n",
    "                          'photonswap-finance', 'maiar-exchange', 'katana', \n",
    "                          'kine-protocol-polygon', 'bit2me', 'balancer-v2-polygon',\n",
    "                          'balancer-v2-arbitrum', 'uniswap-v3-polygon', 'tinyman', \n",
    "                          'algebra', 'kine-protocol-bsc', 'btcex-exchange']\n",
    "exchange_df = exchange_df[~exchange_df.exchange_slug.isin(exchange_names_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "857fe205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poloniex\n",
      "bittrex\n",
      "kraken\n",
      "bleutrade\n",
      "bittylicious\n",
      "cex-io\n",
      "bitfinex\n",
      "hitbtc\n",
      "exmo\n",
      "okcoin\n",
      "indodax\n",
      "bitstamp\n",
      "itbit\n",
      "zaif\n",
      "therocktrading\n",
      "coinmate\n",
      "zonda\n",
      "coinbase-exchange\n",
      "bitex-la\n",
      "bitonic\n",
      "yobit\n",
      "huobi-global\n",
      "litebit\n",
      "coincheck\n",
      "liquid\n",
      "southxchange\n",
      "bitso\n",
      "btcbox\n",
      "coincorner\n",
      "bitflyer\n",
      "isx\n",
      "gemini\n",
      "dex-trade\n",
      "exrates\n",
      "bitmex\n",
      "independent-reserve\n",
      "luno\n",
      "coinone\n",
      "bisq\n",
      "korbit\n",
      "bithumb\n",
      "lykke-exchange\n",
      "kuna\n",
      "mercatox\n",
      "p2pb2b\n",
      "tidex\n",
      "heat-wallet\n",
      "freiexchange\n",
      "btc-markets\n",
      "paribu\n",
      "btc-alpha\n",
      "coingi\n",
      "ripplefox\n",
      "gatehub\n",
      "coss\n",
      "btcturk-pro\n",
      "stex\n",
      "waves-exchange\n",
      "koinim\n",
      "stellar-decentralized-exchange\n",
      "buda\n",
      "btc-trade-ua\n",
      "localtrade\n",
      "bitbank\n",
      "mercado-bitcoin\n",
      "altcoin-trader\n",
      "bancor-network\n",
      "binance\n",
      "bits-blockchain\n",
      "tidebit\n",
      "cryptomarket\n",
      "okx\n",
      "gate-io\n",
      "idex\n",
      "kucoin\n",
      "bitcointrade\n",
      "topbtc\n",
      "aex\n",
      "coinfalcon\n",
      "coinut\n",
      "satang-pro\n",
      "zb-com\n",
      "bigone\n",
      "lbank\n",
      "gopax\n",
      "bibox\n",
      "coinbene\n",
      "coinex\n",
      "upbit\n",
      "tradeogre\n",
      "c-patex\n",
      "crxzone\n",
      "fatbtc\n",
      "paymium\n",
      "ddex\n",
      "rudex\n",
      "zebpay\n",
      "bitbns\n",
      "unocoin\n",
      "latoken\n",
      "crex24\n",
      "bithesap\n",
      "cryptonex\n",
      "cointiger\n",
      "b2bx\n",
      "dragonex\n",
      "hotbit\n",
      "switcheo\n",
      "bitforex\n",
      "kyber-network\n",
      "coindeal\n",
      "bitmart\n",
      "digifinex\n",
      "tokenomy\n",
      "bilaxy\n",
      "graviex\n",
      "idcm\n",
      "abcc\n",
      "hoo\n",
      "wazirx\n",
      "bitfront\n",
      "zbg\n",
      "bitrue\n",
      "yunex\n",
      "bitkub\n",
      "bgogo\n",
      "cryptology\n",
      "coinbit\n",
      "gdac\n",
      "tokok\n",
      "coineal\n",
      "ascendex\n",
      "polonidex\n",
      "bw-com\n",
      "coinsbit\n",
      "huobi-korea\n",
      "oceanex\n",
      "probit-exchange\n",
      "bhex-bluehelix\n",
      "dcoin\n",
      "catex\n",
      "alterdice\n",
      "bkex\n",
      "hanbitco\n",
      "coinfield\n",
      "binance-dex\n",
      "vindax\n",
      "coinmetro\n",
      "bithumb-global\n",
      "safetrade\n",
      "velic\n",
      "folgory\n",
      "exnomy\n",
      "bione\n",
      "polyx\n",
      "tokenize-xchange\n",
      "whitebit\n",
      "birake-network\n",
      "zg-com\n",
      "cbx\n",
      "chainx\n",
      "bitget\n",
      "finexbox\n",
      "dydx\n",
      "coinw\n",
      "triv-pro\n",
      "bitvavo\n",
      "bybit\n",
      "deribit\n",
      "beaxy\n",
      "ftx\n",
      "xt\n",
      "btc-exchange\n",
      "bitexbook\n",
      "exmarkets\n",
      "virtuse-exchange\n",
      "coinflex\n",
      "mxc\n",
      "citex\n",
      "loex\n",
      "globitex\n",
      "paybito\n",
      "txbit\n",
      "secondbtc\n",
      "cross-exchange\n",
      "wbf-exchange\n",
      "serenity\n",
      "basefex\n",
      "bitstorage\n",
      "indoex\n",
      "bitci\n",
      "bitpanda-pro\n",
      "bankcex\n",
      "bithumb-singapore\n",
      "50x\n",
      "bitvast\n",
      "novadax\n",
      "qtrade\n",
      "ecxx\n",
      "binance-us\n",
      "mandala\n",
      "bitsten\n",
      "paritex\n",
      "exir\n",
      "coinzo\n",
      "foblgate\n",
      "bitubu\n",
      "artis-turba\n",
      "bitexlive\n",
      "timex\n",
      "omgfin\n",
      "coinjar\n",
      "btse\n",
      "bitclude\n",
      "bqt\n",
      "trontrade\n",
      "currency-com\n",
      "newdex\n",
      "delta-exchange\n",
      "tokocrypto\n",
      "bitopro\n",
      "rekeningku-com\n",
      "emirex\n",
      "vcc-exchange\n",
      "dove-wallet\n",
      "ace\n",
      "vitex\n",
      "ataix\n",
      "pionex\n",
      "bitbuy\n",
      "digitalexchange-id\n",
      "xcalibra\n",
      "decoin\n",
      "nominex\n",
      "prizmbit\n",
      "nicehash\n",
      "aax\n",
      "tokenlon\n",
      "bitcoin-com-exchange\n",
      "stakecube\n",
      "tokencan\n",
      "max-exchange\n",
      "crypterum\n",
      "bitay\n",
      "etorox\n",
      "valr\n",
      "stormgain\n",
      "namebase\n",
      "biconomy\n",
      "hotcoin-global\n",
      "coindcx\n",
      "phemex\n",
      "farhadmarket\n",
      "resfinex\n",
      "loopring-exchange\n",
      "bitribe\n",
      "huobi-japan\n",
      "chiliz\n",
      "jubi-exchange\n",
      "giottus\n",
      "coinlist-pro\n",
      "felixo\n",
      "bitturk\n",
      "coinzoom\n",
      "flybit\n",
      "compound\n",
      "gokumarket\n",
      "1inch-exchange\n",
      "deversifi\n",
      "balancer\n",
      "curve-finance\n",
      "bingx\n",
      "coincasso\n",
      "uniswap-v2\n",
      "nash-exchange\n",
      "aprobit\n",
      "crosstower\n",
      "kwenta\n",
      "zipmex\n",
      "narkasa\n",
      "ripio\n",
      "polkaswap\n",
      "mooniswap\n",
      "nexus-mutual\n",
      "aave\n",
      "kickex\n",
      "cybex-dex\n",
      "tokensets\n",
      "justswap\n",
      "azbit\n",
      "bitazza\n",
      "changelly-pro\n",
      "eqonex\n",
      "bitcoiva\n",
      "xtheta-global\n",
      "mexo-exchange\n",
      "bitexen\n",
      "serum-dex\n",
      "sushiswap\n",
      "koinbazar\n",
      "crypto-com-exchange\n",
      "sinegy-marketplace\n",
      "paraswap\n",
      "bit-com\n",
      "hotbit-korea\n",
      "pancakeswap\n",
      "sashimiswap\n",
      "ftx-us\n",
      "acdx\n",
      "aryana\n",
      "deepcoin\n",
      "mov\n",
      "bitwell\n",
      "dodo\n",
      "honeyswap\n",
      "luaswap\n",
      "bvnex\n",
      "bepswap\n",
      "mento\n",
      "bit4you\n",
      "venus\n",
      "defichain-dex\n",
      "kulap\n",
      "demex\n",
      "linkswap\n",
      "blockchain-com-exchange\n",
      "block-dx\n",
      "terraswap\n",
      "openocean\n",
      "1inch-liquidity-protocol\n",
      "wanswap\n",
      "idex-bsc\n",
      "mdex\n",
      "apeswap\n",
      "sifchain\n",
      "wootrade\n",
      "quickswap\n",
      "lcx-exchange\n",
      "perpetual-protocol\n",
      "bakeryswap\n",
      "dfyn-network\n",
      "capital-dex\n",
      "bloctoswap\n",
      "kwikswap\n",
      "put-on-your-metamask\n",
      "dodo-bsc\n",
      "swipeswap\n",
      "plasmaswap\n",
      "thorchain-erc20\n",
      "mdex-bsc\n",
      "kyberdmm\n",
      "unicly\n",
      "ubeswap\n",
      "pangolin\n",
      "raydium\n",
      "pancakeswap-v2\n",
      "polyzap\n",
      "comethswap\n",
      "uniswap-v3\n",
      "viperswap\n",
      "spiritswap\n",
      "globe-derivative-exchange\n",
      "waultswap\n",
      "binance-tr\n",
      "bunicorn\n",
      "lydia-finance\n",
      "convergence\n",
      "babyswap\n",
      "coinswap-space\n",
      "thorchain-bep20\n",
      "thorchain-btc\n",
      "balancer-v2\n",
      "probit-korea\n",
      "sovryn\n",
      "shibaswap\n",
      "nowswap\n",
      "unifi-protocol-dao\n",
      "sushiswap-bsc\n",
      "kine-protocol\n",
      "mars-ecosystem\n",
      "sushiswap-fantom\n",
      "sushiswap-polygon\n",
      "sushiswap-xdai\n",
      "kuswap\n",
      "orca\n",
      "balanced\n",
      "kswap-finance\n",
      "pandaswap\n",
      "cherryswap\n",
      "waultswap-polygon\n",
      "kalata\n",
      "polydex\n",
      "biswap\n",
      "osmosis\n",
      "apollox\n",
      "yetiswap\n",
      "kava-swap\n",
      "spookyswap\n",
      "traderjoe\n",
      "jetswap\n",
      "clipper\n",
      "jetswap-polygon\n",
      "sushiswap-arbitrum\n",
      "freeriver\n",
      "apeswap-finance-polygon\n",
      "moonswap-moonriver\n",
      "dodo-polygon\n",
      "partyswap\n",
      "sushiswap-harmony\n",
      "kyberdmm-polygon\n",
      "kyberdmm-bsc\n",
      "kyberdmm-avalanche\n",
      "autoshark-finance\n",
      "dodo-arbitrum\n",
      "mcdex\n",
      "kaidex\n",
      "aldrin\n",
      "planet-finance\n",
      "plasmaswap-bsc\n",
      "plasmaswap-polygon\n",
      "zilswap\n",
      "siennaswap\n",
      "dinosaur-eggs\n",
      "deri-protocol\n",
      "bitcoke\n",
      "ref-finance\n",
      "paintswap\n",
      "elk-finance\n",
      "wagyuswap\n",
      "sphynx-swap\n",
      "mojitoswap\n",
      "dfx-finance\n",
      "elk-finance-polygon\n",
      "elk-finance-bsc\n",
      "crodex\n",
      "vvs-finance\n",
      "apollox-dex\n",
      "sushiswap-celo\n",
      "beethovenx\n",
      "oolongswap\n",
      "cronaswap\n"
     ]
    }
   ],
   "source": [
    "# OBTAIN EXCHANGE HISTORICAL DATA\n",
    "\n",
    "ex_hist_data_dict = {'exchange_id': [],\n",
    "                     'date': [],\n",
    "                     'exchange_volume_24h': [],\n",
    "                     'num_market_pairs': []}\n",
    "\n",
    "# Loop over all exchanges\n",
    "for exchange_id in exchange_df.exchange_id.values: \n",
    "    print(exchange_df[exchange_df.exchange_id == exchange_id]['exchange_slug'].values[0])\n",
    "\n",
    "    # Set up the call\n",
    "    endpoint = '/v1/exchange/quotes/historical'\n",
    "    final_url = base_url+endpoint\n",
    "    parameters = {'id': exchange_id,\n",
    "                  'time_start': '2015-01-01',\n",
    "                  'time_end': '2021-12-31',\n",
    "                  'interval': '1d',\n",
    "                  'count': 10000,\n",
    "                  'convert': 'USD'}\n",
    "\n",
    "    # Make the call\n",
    "    response = session.get(final_url, params=parameters)\n",
    "    r_json = json.loads(response.text)\n",
    "\n",
    "    # Add the data to the dictionary\n",
    "    for ex_data in r_json['data']['quotes']:\n",
    "        ex_hist_data_dict['exchange_id'].append(exchange_id)\n",
    "        ex_hist_data_dict['date'].append(ex_data['quote']['USD']['timestamp'])\n",
    "        ex_hist_data_dict['exchange_volume_24h'].append(ex_data['quote']['USD']['volume_24h'])\n",
    "        ex_hist_data_dict['num_market_pairs'].append(ex_data['num_market_pairs'])\n",
    "        \n",
    "    # Sleep\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "e3703240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe\n",
    "ex_historical_df = pd.DataFrame(ex_hist_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1b939d",
   "metadata": {},
   "source": [
    "## (4) Save all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "0cc2a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cmc token id crosswalk\n",
    "final_df.to_csv('../3-data/raw/cmc_token_universe.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "2ff71bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cmc price volume mcap panel\n",
    "df.to_csv('../3-data/raw/cmc_price_vol_mcap_panel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "84c307d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cmc token covars panel\n",
    "cmc_covars_df.to_csv('../3-data/raw/cmc_token_covars_panel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "85ae5cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cmc macro timeseries data\n",
    "macro_df.to_csv('../3-data/raw/cmc_macro_timeseries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "3d1139f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cmc exchange covariates\n",
    "exchange_df.to_csv('../3-data/raw/cmc_exchange_covar.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "fd72cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cmc exchange panel data\n",
    "ex_historical_df.to_csv('../3-data/raw/cmc_exchange_panel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160c0b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVE THESE NOTES TO CLEANING\n",
    "\n",
    "# manually look through it to confirm they are legit tokens\n",
    "# or maybe give this task to jacob\n",
    "# or maybe schedule a time to do this with jacob so we 2x the speed\n",
    "\n",
    "# Lets look to see if the 0.01% mcap rule is good for the entire time period\n",
    "\n",
    "# Jan 1 2015 - $5B - $500k\n",
    "# Jan 1 2016 - $7B - $700k\n",
    "# Jan 1 2017 - $18B - $1.8M\n",
    "# Jan 1 2018 - $600B - $60M\n",
    "# Apr 1 2018 - $300B - $30M\n",
    "# Jul 1 2018 - $250B - $25M\n",
    "# Jan 1 2019 - $125B - $12M\n",
    "# Apr 1 2019 - $145B - $14M\n",
    "# Jul 1 2019 - $330B - $33M\n",
    "# Oct 1 2019 - $220B - $22M\n",
    "# Jan 1 2020 - $200B - $20M\n",
    "# Apr 1 2020 - $175B - $17M\n",
    "# Jul 1 2020 - $260B - $26M\n",
    "# Oct 1 2020 - $340B - $34M\n",
    "# Jan 1 2021 - $770B - $77M\n",
    "# Apr 1 2021 - $1.9T - $190M\n",
    "# Jul 1 2021 - $1.4T - $140M\n",
    "# Oct 1 2021 - $2T - $200M"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e428bc405edc59f3352e9792cab27c5e28560f7efb4b47308a6c6ea38cd15df2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
