{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "60883846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from coinmetrics.api_client import CoinMetricsClient\n",
    "import time\n",
    "import pickle\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import Dict, List\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "e16fe93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCmApiCall(base_url: str, endpoint: str, params: Dict[str, str], num_retries: int = 3) -> requests.Response:\n",
    "    \"\"\"\n",
    "    Makes an API call to the given endpoint with the given parameters.\n",
    "\n",
    "    Args:\n",
    "    - base_url (str): string representing the base URL for the API.\n",
    "    - endpoint (str): string representing the endpoint to call.\n",
    "    - params (Dict): dictionary containing the parameters for the API call.\n",
    "    - num_retries (int): integer representing the number of times to retry the API call in case of an error.\n",
    "\n",
    "    Returns:\n",
    "    - response (requests.Response): the response object from the API call.\n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/{endpoint}\"\n",
    "    retries = 0\n",
    "    while retries < num_retries:\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            if response.status_code == 403:\n",
    "                return params['metrics']\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "        except requests.exceptions.Timeout as e:\n",
    "            logging.warning(f\"Timeout error occurred: {e}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.warning(f\"Request error occurred: {e}\")\n",
    "        retries += 1\n",
    "        if retries == 1:\n",
    "            time.sleep(1)\n",
    "        elif retries == 2:\n",
    "            time.sleep(20)\n",
    "    raise Exception(f\"Failed to make API call after {num_retries} retries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "6ca2afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formCoinmetricsAssetUniverse(client: CoinMetricsClient, cmc_assets_fp: str) -> pd.DataFrame:\n",
    "    \"\"\" map cmc universe to coinmetrics universe. \n",
    "    (1) pull all cm assets and open my universe of cmc assets.\n",
    "    (2) adjust cm asset names so they match to my cmc assets.\n",
    "    (3) merge asset ids together on both the cm asset id and the full name.\n",
    "    (4) clean the merged data.\n",
    "    (5) add assets from cm that should be in the universe but aren't in cmc.\n",
    "    (6) remove stablecoins and derivatives.\n",
    "\n",
    "    Args:\n",
    "        client (CoinMetricsClient): cm client object for pinging api.\n",
    "        cmc_assets_fp (str): filepath to cmc asset universe pickle.\n",
    "    \n",
    "    Returns:\n",
    "        merged_df (pd.DataFrame): dataframe of crosswalk between cmc id and cm id.    \n",
    "    \"\"\"\n",
    "    # import cmc token universe\n",
    "    with open(cmc_assets_fp, 'rb') as f:\n",
    "        cmc_asset_universe_dict = pickle.load(f)\n",
    "\n",
    "    # form unique cmc asset df\n",
    "    cmc_assets = []\n",
    "    for k, v in cmc_asset_universe_dict.items():\n",
    "        cmc_assets.extend(v)\n",
    "    cmc_assets = list(np.unique(np.array(cmc_assets)))\n",
    "    cmc_assets_df = pd.DataFrame(data={'asset_cmc': cmc_assets})\n",
    "\n",
    "    # pull all cm assets\n",
    "    full_asset_catalog = client.catalog_full_assets()\n",
    "    cm_assets_df = pd.DataFrame(full_asset_catalog)\n",
    "\n",
    "    # Check that the \"asset\" column is unique in both dataframes\n",
    "    assert (cmc_assets_df[\"asset_cmc\"].is_unique \n",
    "            and cm_assets_df[\"full_name\"].is_unique \n",
    "            and cm_assets_df['asset'].is_unique)\n",
    "\n",
    "    # remove duplicated cm asset; they have a data error\n",
    "    cm_assets_df = cm_assets_df[~cm_assets_df.asset.isin(['seed', 'tree', 'aurora'])]\n",
    "\n",
    "    # change cm full names before merge so they match cmc for known nonmatches\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='aave', 'full_name'] = 'aave-old'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='alpha', 'full_name'] = 'alpha-finance-lab'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='mco', 'full_name'] = 'crypto-com'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='fet', 'full_name'] = 'fetch'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='clv', 'full_name'] = 'clover'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='gno', 'full_name'] = 'gnosis-gno'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='glm', 'full_name'] = 'golem-network-tokens'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='hive', 'full_name'] = 'hive-blockchain'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='rook', 'full_name'] = 'keeperdao'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='yffii', 'full_name'] = 'yearn-finance-ii'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='btt', 'full_name'] = 'bittorrent'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='idex', 'full_name'] = 'aurora'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='egld', 'full_name'] = 'multiversx-egld'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='cfx', 'full_name'] = 'confluxnetwork'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='xch', 'full_name'] = 'chia-network'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='syn', 'full_name'] = 'synapse2'\n",
    "\n",
    "    # clean the asset names to just low case letters and numbers and merge\n",
    "    cmc_assets_df[\"asset_clean\"] = cmc_assets_df[\"asset_cmc\"].str.lower().str.replace(r\"[^a-zA-Z0-9]\", \"\")\n",
    "    cm_assets_df[\"asset_clean\"] = cm_assets_df[\"full_name\"].str.lower().str.replace(r\"[^a-zA-Z0-9]\", \"\")\n",
    "    merged_df = pd.merge(cmc_assets_df, cm_assets_df, \n",
    "                        on=\"asset_clean\", how='inner',\n",
    "                        validate='one_to_one')\n",
    "\n",
    "    # repeat but use the unique asset abbreviation id from cm\n",
    "    cm_assets_df[\"asset_clean\"] = cm_assets_df[\"asset\"].str.lower().str.replace(r\"[^a-zA-Z0-9]\", \"\")\n",
    "    merged_df2 = pd.merge(cmc_assets_df, cm_assets_df, \n",
    "                        on=\"asset_clean\", how='inner',\n",
    "                        validate='one_to_one')\n",
    "\n",
    "    # remove duplicated assets from the two merged dataframes and put them together\n",
    "    merged_df2 = merged_df2[~merged_df2.asset.isin(list(merged_df.asset.values))]\n",
    "    merged_df = pd.concat((merged_df, merged_df2))\n",
    "    assert merged_df.asset.is_unique\n",
    "\n",
    "    # clean up the merged data\n",
    "    merged_df = merged_df[['asset_cmc', 'asset']]\n",
    "    merged_df = merged_df.rename(columns={'asset': 'asset_cm'})\n",
    "    merged_df = merged_df.reset_index(drop=True)\n",
    "\n",
    "    # manually add to my universe of cm assets these assets to consider\n",
    "    assets_to_add = ['ape', 'apt', 'arpa', 'badger', 'bal', 'cake', 'cel', 'comp', 'cvx',\n",
    "        'dot', 'etc', 'fil', 'flr', 'flux', 'ftt', 'fun', 'gmx', 'grin', 'hnt',\n",
    "        'inv', 'knc', 'krl', 'luna', 'luna2', 'mir', 'multi', 'nft', 'nu', 'ocean', 'ohm',\n",
    "        'op', 'poly', 'qi', 'rndr', 'rpl', 'skl', 'snt', 'theta', 'tru', 'xdc', 'zrx']\n",
    "    merged_df = pd.concat((merged_df, pd.DataFrame(data={'asset_cmc': np.repeat(np.nan, len(assets_to_add)),\n",
    "                                                        'asset_cm': assets_to_add})))\n",
    "\n",
    "    # manually remove stables and derivatives\n",
    "    merged_df = merged_df[~merged_df.asset_cm.isin(['steth', 'wbtc', 'tusd', 'gusd', 'usdd', 'btcb'])]\n",
    "\n",
    "    # manually add in both aave old and new\n",
    "    merged_df = pd.concat((merged_df, pd.DataFrame(data={'asset_cmc': ['aave'],\n",
    "                                                        'asset_cm': ['aave']}))).reset_index(drop=True)\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "9a9aca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullAssetMetrics(client: CoinMetricsClient, base_url: str, cm_asset_universe: list, base_params: dict, num_retries=3):\n",
    "    \"\"\"\n",
    "    Pulls asset metrics for assets in the given asset universe using the given base URL and parameters.\n",
    "\n",
    "    Args:\n",
    "    - client (CoinMetricsClient): client object for interacting with the CM API.\n",
    "    - base_url: string representing the base URL for the API.\n",
    "    - cm_asset_universe: list of strings representing the assets to pull metrics for.\n",
    "    - base_params: dictionary containing the base parameters for the API call.\n",
    "    - num_retries: integer representing the number of times to retry the API call in case of an error.\n",
    "\n",
    "    Returns:\n",
    "    - results_df: Pandas DataFrame containing the asset metrics.\n",
    "    \"\"\"\n",
    "    # Pull all the metrics for all assets\n",
    "    asset_metrics_df = pd.DataFrame(client.catalog_full_assets())\n",
    "\n",
    "    # Cut down to CM universe\n",
    "    asset_metrics_df = asset_metrics_df[asset_metrics_df.asset.isin(cm_asset_universe)]\n",
    "    assert asset_metrics_df.asset.is_unique\n",
    "    asset_universe = list(asset_metrics_df.asset.values)\n",
    "\n",
    "    # Define endpoint and parameters\n",
    "    endpoint = 'timeseries/asset-metrics'\n",
    "    params = base_params.copy()\n",
    "    params['page_size'] = 1000\n",
    "\n",
    "    # Initialize dataframe to return results\n",
    "    results_df = pd.DataFrame(data={'asset': [], 'time': []})\n",
    "\n",
    "    # Initialize list of metrics that are unavailable\n",
    "    unavailable_metrics = []\n",
    "\n",
    "    # For every asset, pull all metrics available for this asset\n",
    "    for i in range(len(asset_universe)):\n",
    "        # Update asset\n",
    "        asset = asset_universe[i]\n",
    "\n",
    "        # Monitor progress\n",
    "        print(f\"Processing the {i+1}th asset ({(i+1)/len(asset_universe)*100:.2f}%): {asset}\")\n",
    "\n",
    "        # Initialize object for this asset results\n",
    "        asset_results_df = pd.DataFrame(data={'asset': [], 'time': []})\n",
    "\n",
    "        # update parameters for this asset\n",
    "        params['assets'] = asset\n",
    "\n",
    "        # determine all metrics for this asset (skip if there aren't metrics for this asset)\n",
    "        metrics = asset_metrics_df[asset_metrics_df.asset==asset].metrics.values[0]\n",
    "        if type(metrics) is not list:\n",
    "            continue\n",
    "        metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "        # pull data for each metric\n",
    "        assert metrics_df.metric.is_unique\n",
    "        for metric in list(metrics_df.metric.values):\n",
    "            # Print out the metric we are doing\n",
    "            print(f\"Working on metric: {metric}.\")\n",
    "\n",
    "            # Skip the metric if we know we don't have access\n",
    "            if metric in unavailable_metrics:\n",
    "                continue\n",
    "\n",
    "            # form dataframe of the different frequency options for this metric\n",
    "            metric_options_df = pd.DataFrame(metrics_df[metrics_df.metric==metric].frequencies.values[0])\n",
    "\n",
    "            # Set frequency to 1d but report if it does not have a one day option and stop execution\n",
    "            if '1d' in list(metric_options_df.frequency.values):\n",
    "                frequency = '1d'\n",
    "            else:\n",
    "                print(metric_options_df)\n",
    "                raise ValueError(f\"The metric {metric} does not have a 1d frequency option.\")\n",
    "        \n",
    "            # Set the start and end time for this frequency\n",
    "            start_time = metric_options_df[metric_options_df.frequency==frequency].min_time.values[0]\n",
    "            end_time = metric_options_df[metric_options_df.frequency==frequency].max_time.values[0]\n",
    "\n",
    "            # Update params for this metric and frequency\n",
    "            params['metrics'] = metric\n",
    "            params['frequency'] = frequency\n",
    "            params['start_time'] = start_time\n",
    "            params['end_time'] = end_time\n",
    "\n",
    "            # Make the API request\n",
    "            response = makeCmApiCall(base_url, endpoint, params)\n",
    "            if type(response)==str:\n",
    "                unavailable_metrics.append(response)\n",
    "                print(f'The metric {metric} is not available for my API key.')\n",
    "                continue\n",
    "            data = response.json()['data']\n",
    "            asset_df = pd.DataFrame(data)\n",
    "\n",
    "            # Confirm we obtained the expected number of obs\n",
    "            start_datetime = datetime.fromisoformat(start_time[:-7] + '+00:00')\n",
    "            end_datetime = datetime.fromisoformat(end_time[:-7]+ '+00:00')\n",
    "            num_days = (end_datetime - start_datetime).days\n",
    "            assert asset_df.shape[0] >= (num_days-1), f\"Did not obtain expected number of days for {asset} {metric['metric']}\"\n",
    "\n",
    "            # Add data to master dataframe\n",
    "            asset_results_df = asset_results_df.merge(asset_df, \n",
    "                                                      on=['asset', 'time'], \n",
    "                                                      how='outer', \n",
    "                                                      validate='one_to_one')\n",
    "            \n",
    "            # Space out the calls\n",
    "            time.sleep(5)\n",
    "\n",
    "        # Add this asset's results to the overall df\n",
    "        results_df = pd.concat((results_df, asset_results_df))\n",
    "\n",
    "        # Space out the calls across assets\n",
    "        time.sleep(20)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c725552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # set parameters\n",
    "    cmc_assets_fp = \"../data/raw/cmc_asset_universe.pkl\"\n",
    "    cm_api_fp = '../../admin/coinmetrics.txt'\n",
    "    cw_fp = \"../data/raw/coinmetrics_cmc_cw.pkl\"\n",
    "    panel_fp = \"../data/raw/coinmetrics_panel.pkl\"\n",
    "    base_params = {'api_key': API_KEY}\n",
    "    base_url = 'https://api.coinmetrics.io/v4/'\n",
    "\n",
    "    # initialize client class\n",
    "    with open(cm_api_fp) as f:\n",
    "        API_KEY = f.readlines()\n",
    "        API_KEY = API_KEY[0].strip()\n",
    "    client = CoinMetricsClient(API_KEY)\n",
    "\n",
    "    # obtain coinmetrics assets\n",
    "    cw_df = formCoinmetricsAssetUniverse(client, cmc_assets_fp)\n",
    "    cw_df.to_pickle(cw_fp)\n",
    "    cm_asset_universe = list(np.unique(cw_df[~cw_df.asset_cm.isnull()].asset_cm.values))\n",
    "\n",
    "    # pull all metrics for assets in universe\n",
    "    asset_metrics_df = pullAssetMetrics(client, base_url, cm_asset_universe, base_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "20e2ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# make sure i got various volume measures and supply / mcap measures\n",
    "# for assets without reference rate nor priceUSD, see if i can get something else\n",
    "# for all assets in my universe, find out when they first have an exchange price at a legit exchange to add this data somewhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9fdf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO pull creation date from asset profile\n",
    "# TODO pull their taxonomy\n",
    "# TODO: get a list of legit exchanges from them; use list i already have and maybe add some if they have?\n",
    "# TODO: pull exchange metrics for those so maybe just volume?\n",
    "# TODO: pull open interest in futures? maybe as macro variable but lets see if i can get for a bunch of assets\n",
    "# TODO: pull the institutions and associated metrics to see if anything of interest\n",
    "# TODO: pull bid and ask price for markets of target coins?\n",
    "# TODO: pull defi balance sheets\n",
    "# TODO: see if i am missing anything else to pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b108c81a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e428bc405edc59f3352e9792cab27c5e28560f7efb4b47308a6c6ea38cd15df2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
