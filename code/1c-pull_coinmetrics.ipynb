{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60883846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from coinmetrics.api_client import CoinMetricsClient\n",
    "import time\n",
    "import pickle\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import Dict, List\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e16fe93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCmApiCall(base_url: str, endpoint: str, params: Dict[str, str], num_retries: int = 3) -> requests.Response:\n",
    "    \"\"\"\n",
    "    Makes an API call to the given endpoint with the given parameters.\n",
    "\n",
    "    Args:\n",
    "    - base_url (str): string representing the base URL for the API.\n",
    "    - endpoint (str): string representing the endpoint to call.\n",
    "    - params (Dict): dictionary containing the parameters for the API call.\n",
    "    - num_retries (int): integer representing the number of times to retry the API call in case of an error.\n",
    "\n",
    "    Returns:\n",
    "    - response (requests.Response): the response object from the API call.\n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/{endpoint}\"\n",
    "    retries = 0\n",
    "    while retries < num_retries:\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            if response.status_code == 403:\n",
    "                try:\n",
    "                    return params['metrics']\n",
    "                except:\n",
    "                    raise Exception(f\"Failed to make API call with response {response.status_code}.\")\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "        except requests.exceptions.Timeout as e:\n",
    "            logging.warning(f\"Timeout error occurred: {e}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.warning(f\"Request error occurred: {e}\")\n",
    "        retries += 1\n",
    "        if retries == 1:\n",
    "            time.sleep(1)\n",
    "        elif retries == 2:\n",
    "            time.sleep(20)\n",
    "    raise Exception(f\"Failed to make API call after {num_retries} retries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca2afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formCoinmetricsAssetUniverse(client: CoinMetricsClient, cmc_assets_fp: str) -> pd.DataFrame:\n",
    "    \"\"\" map cmc universe to coinmetrics universe. \n",
    "    (1) pull all cm assets and open my universe of cmc assets.\n",
    "    (2) adjust cm asset names so they match to my cmc assets.\n",
    "    (3) merge asset ids together on both the cm asset id and the full name.\n",
    "    (4) clean the merged data.\n",
    "    (5) add assets from cm that should be in the universe but aren't in cmc.\n",
    "    (6) remove stablecoins and derivatives.\n",
    "\n",
    "    Args:\n",
    "        client (CoinMetricsClient): cm client object for pinging api.\n",
    "        cmc_assets_fp (str): filepath to cmc asset universe pickle.\n",
    "    \n",
    "    Returns:\n",
    "        merged_df (pd.DataFrame): dataframe of crosswalk between cmc id and cm id.    \n",
    "    \"\"\"\n",
    "    # import cmc token universe\n",
    "    with open(cmc_assets_fp, 'rb') as f:\n",
    "        cmc_asset_universe_dict = pickle.load(f)\n",
    "\n",
    "    # form unique cmc asset df\n",
    "    cmc_assets = []\n",
    "    for k, v in cmc_asset_universe_dict.items():\n",
    "        cmc_assets.extend(v)\n",
    "    cmc_assets = list(np.unique(np.array(cmc_assets)))\n",
    "    cmc_assets_df = pd.DataFrame(data={'asset_cmc': cmc_assets})\n",
    "\n",
    "    # pull all cm assets\n",
    "    full_asset_catalog = client.catalog_full_assets()\n",
    "    cm_assets_df = pd.DataFrame(full_asset_catalog)\n",
    "\n",
    "    # Check that the \"asset\" column is unique in both dataframes\n",
    "    assert (cmc_assets_df[\"asset_cmc\"].is_unique \n",
    "            and cm_assets_df[\"full_name\"].is_unique \n",
    "            and cm_assets_df['asset'].is_unique)\n",
    "\n",
    "    # remove duplicated cm asset; they have a data error\n",
    "    cm_assets_df = cm_assets_df[~cm_assets_df.asset.isin(['seed', 'tree', 'aurora'])]\n",
    "\n",
    "    # change cm full names before merge so they match cmc for known nonmatches\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='aave', 'full_name'] = 'aave-old'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='alpha', 'full_name'] = 'alpha-finance-lab'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='mco', 'full_name'] = 'crypto-com'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='fet', 'full_name'] = 'fetch'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='clv', 'full_name'] = 'clover'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='gno', 'full_name'] = 'gnosis-gno'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='glm', 'full_name'] = 'golem-network-tokens'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='hive', 'full_name'] = 'hive-blockchain'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='rook', 'full_name'] = 'keeperdao'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='yffii', 'full_name'] = 'yearn-finance-ii'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='btt', 'full_name'] = 'bittorrent'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='idex', 'full_name'] = 'aurora'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='egld', 'full_name'] = 'multiversx-egld'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='cfx', 'full_name'] = 'confluxnetwork'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='xch', 'full_name'] = 'chia-network'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='syn', 'full_name'] = 'synapse2'\n",
    "\n",
    "    # clean the asset names to just low case letters and numbers and merge\n",
    "    cmc_assets_df[\"asset_clean\"] = cmc_assets_df[\"asset_cmc\"].str.lower().str.replace(r\"[^a-zA-Z0-9]\", \"\")\n",
    "    cm_assets_df[\"asset_clean\"] = cm_assets_df[\"full_name\"].str.lower().str.replace(r\"[^a-zA-Z0-9]\", \"\")\n",
    "    merged_df = pd.merge(cmc_assets_df, cm_assets_df, \n",
    "                        on=\"asset_clean\", how='inner',\n",
    "                        validate='one_to_one')\n",
    "\n",
    "    # repeat but use the unique asset abbreviation id from cm\n",
    "    cm_assets_df[\"asset_clean\"] = cm_assets_df[\"asset\"].str.lower().str.replace(r\"[^a-zA-Z0-9]\", \"\")\n",
    "    merged_df2 = pd.merge(cmc_assets_df, cm_assets_df, \n",
    "                        on=\"asset_clean\", how='inner',\n",
    "                        validate='one_to_one')\n",
    "\n",
    "    # remove duplicated assets from the two merged dataframes and put them together\n",
    "    merged_df2 = merged_df2[~merged_df2.asset.isin(list(merged_df.asset.values))]\n",
    "    merged_df = pd.concat((merged_df, merged_df2))\n",
    "    assert merged_df.asset.is_unique\n",
    "\n",
    "    # clean up the merged data\n",
    "    merged_df = merged_df[['asset_cmc', 'asset']]\n",
    "    merged_df = merged_df.rename(columns={'asset': 'asset_cm'})\n",
    "    merged_df = merged_df.reset_index(drop=True)\n",
    "\n",
    "    # manually add to my universe of cm assets these assets to consider\n",
    "    assets_to_add = ['ape', 'apt', 'arpa', 'badger', 'bal', 'cake', 'cel', 'comp', 'cvx',\n",
    "        'dot', 'etc', 'fil', 'flr', 'flux', 'ftt', 'fun', 'gmx', 'grin', 'hnt',\n",
    "        'inv', 'knc', 'krl', 'luna', 'luna2', 'mir', 'multi', 'nft', 'nu', 'ocean', 'ohm',\n",
    "        'op', 'poly', 'qi', 'rndr', 'rpl', 'skl', 'snt', 'theta', 'tru', 'xdc', 'zrx']\n",
    "    merged_df = pd.concat((merged_df, pd.DataFrame(data={'asset_cmc': np.repeat(np.nan, len(assets_to_add)),\n",
    "                                                        'asset_cm': assets_to_add})))\n",
    "\n",
    "    # manually remove stables and derivatives\n",
    "    merged_df = merged_df[~merged_df.asset_cm.isin(['steth', 'wbtc', 'tusd', 'gusd', 'usdd', 'btcb'])]\n",
    "\n",
    "    # manually add in both aave old and new\n",
    "    merged_df = pd.concat((merged_df, pd.DataFrame(data={'asset_cmc': ['aave'],\n",
    "                                                        'asset_cm': ['aave']}))).reset_index(drop=True)\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a9aca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullAssetMetrics(client: CoinMetricsClient, base_url: str, cm_asset_universe: list, base_params: dict, num_retries=3):\n",
    "    \"\"\"\n",
    "    Pulls asset metrics for assets in the given asset universe using the given base URL and parameters.\n",
    "\n",
    "    Args:\n",
    "    - client (CoinMetricsClient): client object for interacting with the CM API.\n",
    "    - base_url: string representing the base URL for the API.\n",
    "    - cm_asset_universe: list of strings representing the assets to pull metrics for.\n",
    "    - base_params: dictionary containing the base parameters for the API call.\n",
    "    - num_retries: integer representing the number of times to retry the API call in case of an error.\n",
    "\n",
    "    Returns:\n",
    "    - results_df: Pandas DataFrame containing the asset metrics.\n",
    "    \"\"\"\n",
    "    # Pull all the metrics for all assets\n",
    "    asset_metrics_df = pd.DataFrame(client.catalog_full_assets())\n",
    "\n",
    "    # Cut down to CM universe\n",
    "    asset_metrics_df = asset_metrics_df[asset_metrics_df.asset.isin(cm_asset_universe)]\n",
    "    assert asset_metrics_df.asset.is_unique\n",
    "    asset_universe = list(asset_metrics_df.asset.values)\n",
    "\n",
    "    # Define endpoint and parameters\n",
    "    endpoint = 'timeseries/asset-metrics'\n",
    "    params = base_params.copy()\n",
    "    params['page_size'] = 1000\n",
    "\n",
    "    # Initialize dataframe to return results\n",
    "    results_df = pd.DataFrame(data={'asset': [], 'time': []})\n",
    "\n",
    "    # Initialize list of metrics that are unavailable\n",
    "    unavailable_metrics = []\n",
    "\n",
    "    # For every asset, pull all metrics available for this asset\n",
    "    for i in range(len(asset_universe)):\n",
    "        # Update asset\n",
    "        asset = asset_universe[i]\n",
    "\n",
    "        # Monitor progress\n",
    "        print(f\"Processing the {i+1}th asset ({(i+1)/len(asset_universe)*100:.2f}%): {asset}\")\n",
    "\n",
    "        # Initialize object for this asset results\n",
    "        asset_results_df = pd.DataFrame(data={'asset': [], 'time': []})\n",
    "\n",
    "        # update parameters for this asset\n",
    "        params['assets'] = asset\n",
    "\n",
    "        # determine all metrics for this asset (skip if there aren't metrics for this asset)\n",
    "        metrics = asset_metrics_df[asset_metrics_df.asset==asset].metrics.values[0]\n",
    "        if type(metrics) is not list:\n",
    "            continue\n",
    "        metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "        # pull data for each metric\n",
    "        assert metrics_df.metric.is_unique\n",
    "        for metric in list(metrics_df.metric.values):\n",
    "            # Print out the metric we are doing\n",
    "            print(f\"Working on metric: {metric}.\")\n",
    "\n",
    "            # Skip the metric if we know we don't have access\n",
    "            if metric in unavailable_metrics:\n",
    "                continue\n",
    "\n",
    "            # form dataframe of the different frequency options for this metric\n",
    "            metric_options_df = pd.DataFrame(metrics_df[metrics_df.metric==metric].frequencies.values[0])\n",
    "\n",
    "            # Set frequency to 1d but report if it does not have a one day option and stop execution\n",
    "            if '1d' in list(metric_options_df.frequency.values):\n",
    "                frequency = '1d'\n",
    "            else:\n",
    "                print(metric_options_df)\n",
    "                raise ValueError(f\"The metric {metric} does not have a 1d frequency option.\")\n",
    "        \n",
    "            # Set the start and end time for this frequency\n",
    "            start_time = metric_options_df[metric_options_df.frequency==frequency].min_time.values[0]\n",
    "            end_time = metric_options_df[metric_options_df.frequency==frequency].max_time.values[0]\n",
    "\n",
    "            # Update params for this metric and frequency\n",
    "            params['metrics'] = metric\n",
    "            params['frequency'] = frequency\n",
    "            params['start_time'] = start_time\n",
    "            params['end_time'] = end_time\n",
    "\n",
    "            # Make the API request\n",
    "            response = makeCmApiCall(base_url, endpoint, params)\n",
    "            if type(response)==str:\n",
    "                unavailable_metrics.append(response)\n",
    "                print(f'The metric {metric} is not available for my API key.')\n",
    "                continue\n",
    "            data = response.json()['data']\n",
    "            asset_df = pd.DataFrame(data)\n",
    "\n",
    "            # Confirm we obtained the expected number of obs\n",
    "            start_datetime = datetime.fromisoformat(start_time[:-7] + '+00:00')\n",
    "            end_datetime = datetime.fromisoformat(end_time[:-7]+ '+00:00')\n",
    "            num_days = (end_datetime - start_datetime).days\n",
    "            assert asset_df.shape[0] >= (num_days-1), f\"Did not obtain expected number of days for {asset} {metric['metric']}\"\n",
    "\n",
    "            # Add data to master dataframe\n",
    "            asset_results_df = asset_results_df.merge(asset_df, \n",
    "                                                      on=['asset', 'time'], \n",
    "                                                      how='outer', \n",
    "                                                      validate='one_to_one')\n",
    "            \n",
    "            # Space out the calls\n",
    "            time.sleep(5)\n",
    "\n",
    "        # Add this asset's results to the overall df\n",
    "        results_df = pd.concat((results_df, asset_results_df))\n",
    "\n",
    "        # Space out the calls across assets\n",
    "        time.sleep(20)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae3fd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_383823/3624097208.py:59: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cmc_assets_df[\"asset_clean\"] = cmc_assets_df[\"asset_cmc\"].str.lower().str.replace(r\"[^a-zA-Z0-9]\", \"\")\n",
      "/tmp/ipykernel_383823/3624097208.py:60: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cm_assets_df[\"asset_clean\"] = cm_assets_df[\"full_name\"].str.lower().str.replace(r\"[^a-zA-Z0-9]\", \"\")\n",
      "/tmp/ipykernel_383823/3624097208.py:66: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cm_assets_df[\"asset_clean\"] = cm_assets_df[\"asset\"].str.lower().str.replace(r\"[^a-zA-Z0-9]\", \"\")\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # set parameters\n",
    "    cmc_assets_fp = \"../data/raw/cmc_asset_universe.pkl\"\n",
    "    cm_api_fp = '../../admin/coinmetrics.txt'\n",
    "    cw_fp = \"../data/raw/coinmetrics_cmc_cw.pkl\"\n",
    "    panel_fp = \"../data/raw/coinmetrics_panel.pkl\"\n",
    "    base_url = 'https://api.coinmetrics.io/v4/'\n",
    "\n",
    "    # initialize client class\n",
    "    with open(cm_api_fp) as f:\n",
    "        API_KEY = f.readlines()\n",
    "        API_KEY = API_KEY[0].strip()\n",
    "    client = CoinMetricsClient(API_KEY)\n",
    "\n",
    "    # set up base parameters\n",
    "    base_params = {'api_key': API_KEY}\n",
    "\n",
    "    # obtain coinmetrics assets\n",
    "    cw_df = formCoinmetricsAssetUniverse(client, cmc_assets_fp)\n",
    "    cw_df.to_pickle(cw_fp)\n",
    "    cm_asset_universe = list(np.unique(cw_df[~cw_df.asset_cm.isnull()].asset_cm.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # pull all metrics for assets in universe\n",
    "    asset_metrics_df = pullAssetMetrics(client, base_url, cm_asset_universe, base_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes four hours to just pull price and mcap stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f07fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataframe to return results\n",
    "results_df = pd.DataFrame(data={'asset': [], 'time': []})\n",
    "\n",
    "# Pull all the metrics for all assets\n",
    "asset_metrics_df = pd.DataFrame(client.catalog_full_assets())\n",
    "\n",
    "# Cut down to CM universe\n",
    "asset_metrics_df = asset_metrics_df[asset_metrics_df.asset.isin(cm_asset_universe)]\n",
    "assert asset_metrics_df.asset.is_unique\n",
    "asset_universe = list(asset_metrics_df.asset.values)\n",
    "\n",
    "# Define endpoint and parameters\n",
    "endpoint = 'timeseries/asset-metrics'\n",
    "params = base_params.copy()\n",
    "params['page_size'] = 10000\n",
    "\n",
    "# Initialize list of metrics that are unavailable\n",
    "unavailable_metrics = []\n",
    "\n",
    "# For every asset, pull all metrics available for this asset\n",
    "for i in range(449, len(asset_universe)):\n",
    "    # Update asset\n",
    "    asset = asset_universe[i]\n",
    "\n",
    "    # Monitor progress\n",
    "    print(f\"Processing the {i+1}th asset ({(i+1)/len(asset_universe)*100:.2f}%): {asset}\")\n",
    "\n",
    "    # Initialize object for this asset results\n",
    "    asset_results_df = pd.DataFrame(data={'asset': [], 'time': []})\n",
    "\n",
    "    # update parameters for this asset\n",
    "    params['assets'] = asset\n",
    "\n",
    "    # determine all metrics for this asset (skip if there aren't metrics for this asset)\n",
    "    metrics = asset_metrics_df[asset_metrics_df.asset==asset].metrics.values[0]\n",
    "    if type(metrics) is not list:\n",
    "        continue\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "    # pull data for each metric\n",
    "    assert metrics_df.metric.is_unique\n",
    "    for metric in list(metrics_df.metric.values):\n",
    "        # TODO temp code to get started with mcap and price\n",
    "        if metric not in ['SplyCur',\n",
    "                          'SplyActEver',\n",
    "                          'SplyAct1yr',\n",
    "                          'SplyFF']:\n",
    "            continue\n",
    "\n",
    "        # Print out the metric we are doing\n",
    "        print(f\"Working on metric: {metric}.\")\n",
    "\n",
    "        # Skip the metric if we know we don't have access\n",
    "        if metric in unavailable_metrics:\n",
    "            continue\n",
    "\n",
    "        # form dataframe of the different frequency options for this metric\n",
    "        metric_options_df = pd.DataFrame(metrics_df[metrics_df.metric==metric].frequencies.values[0])\n",
    "\n",
    "        # Set frequency to 1d but report if it does not have a one day option and stop execution\n",
    "        if '1d' in list(metric_options_df.frequency.values):\n",
    "            frequency = '1d'\n",
    "        else:\n",
    "            print(metric_options_df)\n",
    "            print(f\"The metric {metric} for asset {asset} does not have a 1d frequency option.\")\n",
    "            continue\n",
    "    \n",
    "        # Set the start and end time for this frequency\n",
    "        start_time = metric_options_df[metric_options_df.frequency==frequency].min_time.values[0]\n",
    "        end_time = metric_options_df[metric_options_df.frequency==frequency].max_time.values[0]\n",
    "\n",
    "        # Update params for this metric and frequency\n",
    "        params['metrics'] = metric\n",
    "        params['frequency'] = frequency\n",
    "        params['start_time'] = start_time\n",
    "        params['end_time'] = end_time\n",
    "\n",
    "        # Make the API request\n",
    "        response = makeCmApiCall(base_url, endpoint, params)\n",
    "        if type(response)==str:\n",
    "            unavailable_metrics.append(response)\n",
    "            print(f'The metric {metric} is not available for my API key.')\n",
    "            continue\n",
    "        data = response.json()['data']\n",
    "        asset_df = pd.DataFrame(data)\n",
    "\n",
    "        # Confirm we obtained the expected number of obs\n",
    "        start_datetime = datetime.fromisoformat(start_time[:-7] + '+00:00')\n",
    "        end_datetime = datetime.fromisoformat(end_time[:-7]+ '+00:00')\n",
    "        num_days = (end_datetime - start_datetime).days\n",
    "        if asset_df.shape[0] < (num_days-1):\n",
    "            print(f\"Did not obtain expected number of days for {asset} {metric}; there were {num_days-asset_df.shape[0]} fewer days than expected.\")\n",
    "\n",
    "        # Add data to master dataframe\n",
    "        asset_results_df = asset_results_df.merge(asset_df, \n",
    "                                                    on=['asset', 'time'], \n",
    "                                                    how='outer', \n",
    "                                                    validate='one_to_one')\n",
    "        \n",
    "        # Space out the calls\n",
    "        time.sleep(10)\n",
    "\n",
    "    # Add this asset's results to the overall df\n",
    "    results_df = pd.concat((results_df, asset_results_df))\n",
    "\n",
    "    # Space out the calls across assets\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82cda306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AdrAct30dCnt',\n",
       " 'AdrAct7dCnt',\n",
       " 'AdrActCnt',\n",
       " 'AdrActRecCnt',\n",
       " 'AdrActSentCnt',\n",
       " 'AdrBal1in100KCnt',\n",
       " 'AdrBal1in100MCnt',\n",
       " 'AdrBal1in10BCnt',\n",
       " 'AdrBal1in10KCnt',\n",
       " 'AdrBal1in10MCnt',\n",
       " 'AdrBal1in1BCnt',\n",
       " 'AdrBal1in1KCnt',\n",
       " 'AdrBal1in1MCnt',\n",
       " 'AdrBalCnt',\n",
       " 'AdrBalNtv0.001Cnt',\n",
       " 'AdrBalNtv0.01Cnt',\n",
       " 'AdrBalNtv0.1Cnt',\n",
       " 'AdrBalNtv100Cnt',\n",
       " 'AdrBalNtv100KCnt',\n",
       " 'AdrBalNtv10Cnt',\n",
       " 'AdrBalNtv10KCnt',\n",
       " 'AdrBalNtv1Cnt',\n",
       " 'AdrBalNtv1KCnt',\n",
       " 'AdrBalNtv1MCnt',\n",
       " 'AdrBalUSD100Cnt',\n",
       " 'AdrBalUSD100KCnt',\n",
       " 'AdrBalUSD10Cnt',\n",
       " 'AdrBalUSD10KCnt',\n",
       " 'AdrBalUSD10MCnt',\n",
       " 'AdrBalUSD1Cnt',\n",
       " 'AdrBalUSD1KCnt',\n",
       " 'AdrBalUSD1MCnt',\n",
       " 'AdrNewBalCnt',\n",
       " 'AdrNewCnt',\n",
       " 'AssetEODCompletionTime',\n",
       " 'BlkCnt',\n",
       " 'BlkHgt',\n",
       " 'BlkIntMean',\n",
       " 'BlkSizeByte',\n",
       " 'BlkSizeMeanByte',\n",
       " 'BlkWghtMean',\n",
       " 'BlkWghtTot',\n",
       " 'CapAct1yrUSD',\n",
       " 'CapFutExp10yrUSD',\n",
       " 'CapMVRVCur',\n",
       " 'CapMVRVFF',\n",
       " 'CapMrktCurUSD',\n",
       " 'CapMrktEstUSD',\n",
       " 'CapMrktFFUSD',\n",
       " 'CapRealUSD',\n",
       " 'DiffLast',\n",
       " 'DiffMean',\n",
       " 'FeeByteMeanNtv',\n",
       " 'FeeMeanNtv',\n",
       " 'FeeMeanUSD',\n",
       " 'FeeMedNtv',\n",
       " 'FeeMedUSD',\n",
       " 'FeeRevPct',\n",
       " 'FeeTotNtv',\n",
       " 'FeeTotUSD',\n",
       " 'FeeWghtMeanNtv',\n",
       " 'FlowInBFXNtv',\n",
       " 'FlowInBFXUSD',\n",
       " 'FlowInBMXNtv',\n",
       " 'FlowInBMXUSD',\n",
       " 'FlowInBNBNtv',\n",
       " 'FlowInBNBUSD',\n",
       " 'FlowInBSPNtv',\n",
       " 'FlowInBSPUSD',\n",
       " 'FlowInBTXNtv',\n",
       " 'FlowInBTXUSD',\n",
       " 'FlowInExInclNtv',\n",
       " 'FlowInExInclUSD',\n",
       " 'FlowInExNtv',\n",
       " 'FlowInExUSD',\n",
       " 'FlowInGEMNtv',\n",
       " 'FlowInGEMUSD',\n",
       " 'FlowInHUONtv',\n",
       " 'FlowInHUOUSD',\n",
       " 'FlowInKRKNtv',\n",
       " 'FlowInKRKUSD',\n",
       " 'FlowInPOLNtv',\n",
       " 'FlowInPOLUSD',\n",
       " 'FlowMinerIn0HopAllExNtv',\n",
       " 'FlowMinerIn0HopAllExUSD',\n",
       " 'FlowMinerIn0HopAllNtv',\n",
       " 'FlowMinerIn0HopAllUSD',\n",
       " 'FlowMinerIn1HopAllBFXNtv',\n",
       " 'FlowMinerIn1HopAllBFXUSD',\n",
       " 'FlowMinerIn1HopAllBMXNtv',\n",
       " 'FlowMinerIn1HopAllBMXUSD',\n",
       " 'FlowMinerIn1HopAllBNBNtv',\n",
       " 'FlowMinerIn1HopAllBNBUSD',\n",
       " 'FlowMinerIn1HopAllBSPNtv',\n",
       " 'FlowMinerIn1HopAllBSPUSD',\n",
       " 'FlowMinerIn1HopAllBTXNtv',\n",
       " 'FlowMinerIn1HopAllBTXUSD',\n",
       " 'FlowMinerIn1HopAllExNtv',\n",
       " 'FlowMinerIn1HopAllExUSD',\n",
       " 'FlowMinerIn1HopAllGEMNtv',\n",
       " 'FlowMinerIn1HopAllGEMUSD',\n",
       " 'FlowMinerIn1HopAllHUONtv',\n",
       " 'FlowMinerIn1HopAllHUOUSD',\n",
       " 'FlowMinerIn1HopAllKRKNtv',\n",
       " 'FlowMinerIn1HopAllKRKUSD',\n",
       " 'FlowMinerIn1HopAllNtv',\n",
       " 'FlowMinerIn1HopAllPOLNtv',\n",
       " 'FlowMinerIn1HopAllPOLUSD',\n",
       " 'FlowMinerIn1HopAllUSD',\n",
       " 'FlowMinerNet0HopAllNtv',\n",
       " 'FlowMinerNet0HopAllUSD',\n",
       " 'FlowMinerNet1HopAllNtv',\n",
       " 'FlowMinerNet1HopAllUSD',\n",
       " 'FlowMinerOut0HopAllExNtv',\n",
       " 'FlowMinerOut0HopAllExUSD',\n",
       " 'FlowMinerOut0HopAllNtv',\n",
       " 'FlowMinerOut0HopAllUSD',\n",
       " 'FlowMinerOut1HopAllBFXNtv',\n",
       " 'FlowMinerOut1HopAllBFXUSD',\n",
       " 'FlowMinerOut1HopAllBMXNtv',\n",
       " 'FlowMinerOut1HopAllBMXUSD',\n",
       " 'FlowMinerOut1HopAllBNBNtv',\n",
       " 'FlowMinerOut1HopAllBNBUSD',\n",
       " 'FlowMinerOut1HopAllBSPNtv',\n",
       " 'FlowMinerOut1HopAllBSPUSD',\n",
       " 'FlowMinerOut1HopAllBTXNtv',\n",
       " 'FlowMinerOut1HopAllBTXUSD',\n",
       " 'FlowMinerOut1HopAllExNtv',\n",
       " 'FlowMinerOut1HopAllExUSD',\n",
       " 'FlowMinerOut1HopAllGEMNtv',\n",
       " 'FlowMinerOut1HopAllGEMUSD',\n",
       " 'FlowMinerOut1HopAllHUONtv',\n",
       " 'FlowMinerOut1HopAllHUOUSD',\n",
       " 'FlowMinerOut1HopAllKRKNtv',\n",
       " 'FlowMinerOut1HopAllKRKUSD',\n",
       " 'FlowMinerOut1HopAllNtv',\n",
       " 'FlowMinerOut1HopAllPOLNtv',\n",
       " 'FlowMinerOut1HopAllPOLUSD',\n",
       " 'FlowMinerOut1HopAllUSD',\n",
       " 'FlowNetBFXNtv',\n",
       " 'FlowNetBFXUSD',\n",
       " 'FlowNetBMXNtv',\n",
       " 'FlowNetBMXUSD',\n",
       " 'FlowNetBNBNtv',\n",
       " 'FlowNetBNBUSD',\n",
       " 'FlowNetBSPNtv',\n",
       " 'FlowNetBSPUSD',\n",
       " 'FlowNetBTXNtv',\n",
       " 'FlowNetBTXUSD',\n",
       " 'FlowNetGEMNtv',\n",
       " 'FlowNetGEMUSD',\n",
       " 'FlowNetHUONtv',\n",
       " 'FlowNetHUOUSD',\n",
       " 'FlowNetKRKNtv',\n",
       " 'FlowNetKRKUSD',\n",
       " 'FlowNetPOLNtv',\n",
       " 'FlowNetPOLUSD',\n",
       " 'FlowOutBFXNtv',\n",
       " 'FlowOutBFXUSD',\n",
       " 'FlowOutBMXNtv',\n",
       " 'FlowOutBMXUSD',\n",
       " 'FlowOutBNBNtv',\n",
       " 'FlowOutBNBUSD',\n",
       " 'FlowOutBSPNtv',\n",
       " 'FlowOutBSPUSD',\n",
       " 'FlowOutBTXNtv',\n",
       " 'FlowOutBTXUSD',\n",
       " 'FlowOutExInclNtv',\n",
       " 'FlowOutExInclUSD',\n",
       " 'FlowOutExNtv',\n",
       " 'FlowOutExUSD',\n",
       " 'FlowOutGEMNtv',\n",
       " 'FlowOutGEMUSD',\n",
       " 'FlowOutHUONtv',\n",
       " 'FlowOutHUOUSD',\n",
       " 'FlowOutKRKNtv',\n",
       " 'FlowOutKRKUSD',\n",
       " 'FlowOutPOLNtv',\n",
       " 'FlowOutPOLUSD',\n",
       " 'FlowTfrFromExCnt',\n",
       " 'FlowTfrFromExInclCnt',\n",
       " 'FlowTfrInBFXCnt',\n",
       " 'FlowTfrInBMXCnt',\n",
       " 'FlowTfrInBNBCnt',\n",
       " 'FlowTfrInBSPCnt',\n",
       " 'FlowTfrInBTXCnt',\n",
       " 'FlowTfrInGEMCnt',\n",
       " 'FlowTfrInHUOCnt',\n",
       " 'FlowTfrInKRKCnt',\n",
       " 'FlowTfrInPOLCnt',\n",
       " 'FlowTfrOutBFXCnt',\n",
       " 'FlowTfrOutBMXCnt',\n",
       " 'FlowTfrOutBNBCnt',\n",
       " 'FlowTfrOutBSPCnt',\n",
       " 'FlowTfrOutBTXCnt',\n",
       " 'FlowTfrOutGEMCnt',\n",
       " 'FlowTfrOutHUOCnt',\n",
       " 'FlowTfrOutKRKCnt',\n",
       " 'FlowTfrOutPOLCnt',\n",
       " 'FlowTfrToExCnt',\n",
       " 'FlowTfrToExInclCnt',\n",
       " 'HashRate',\n",
       " 'HashRate30d',\n",
       " 'HashRate30dOtherHardware',\n",
       " 'HashRate30dOtherHardwarePct',\n",
       " 'HashRate30dS7',\n",
       " 'HashRate30dS7Pct',\n",
       " 'HashRate30dS9',\n",
       " 'HashRate30dS9Pct',\n",
       " 'IssContNtv',\n",
       " 'IssContPctAnn',\n",
       " 'IssContPctDay',\n",
       " 'IssContUSD',\n",
       " 'IssTotNtv',\n",
       " 'IssTotUSD',\n",
       " 'MCRC',\n",
       " 'MCTC',\n",
       " 'MOMR',\n",
       " 'MRI0HopAll30d',\n",
       " 'MRI1HopAll30d',\n",
       " 'NDF',\n",
       " 'NVTAdj',\n",
       " 'NVTAdj90',\n",
       " 'NVTAdjFF',\n",
       " 'NVTAdjFF90',\n",
       " 'PriceBTC',\n",
       " 'PriceUSD',\n",
       " 'PuellMulCont',\n",
       " 'PuellMulRev',\n",
       " 'PuellMulTot',\n",
       " 'RCTC',\n",
       " 'ROI1yr',\n",
       " 'ROI30d',\n",
       " 'RVTAdj',\n",
       " 'RVTAdj90',\n",
       " 'ReferenceRate',\n",
       " 'ReferenceRateETH',\n",
       " 'ReferenceRateEUR',\n",
       " 'ReferenceRateUSD',\n",
       " 'RevAllTimeUSD',\n",
       " 'RevHash1yAvgNtv',\n",
       " 'RevHash1yAvgUSD',\n",
       " 'RevHashNtv',\n",
       " 'RevHashRateNtv',\n",
       " 'RevHashRateUSD',\n",
       " 'RevHashUSD',\n",
       " 'RevNtv',\n",
       " 'RevUSD',\n",
       " 'SER',\n",
       " 'SOPR',\n",
       " 'SOPROut',\n",
       " 'SplyAct10yr',\n",
       " 'SplyAct180d',\n",
       " 'SplyAct1d',\n",
       " 'SplyAct1yr',\n",
       " 'SplyAct2yr',\n",
       " 'SplyAct30d',\n",
       " 'SplyAct3yr',\n",
       " 'SplyAct4yr',\n",
       " 'SplyAct5yr',\n",
       " 'SplyAct7d',\n",
       " 'SplyAct90d',\n",
       " 'SplyActEver',\n",
       " 'SplyActPct1yr',\n",
       " 'SplyAdrBal1in100K',\n",
       " 'SplyAdrBal1in100M',\n",
       " 'SplyAdrBal1in10B',\n",
       " 'SplyAdrBal1in10K',\n",
       " 'SplyAdrBal1in10M',\n",
       " 'SplyAdrBal1in1B',\n",
       " 'SplyAdrBal1in1K',\n",
       " 'SplyAdrBal1in1M',\n",
       " 'SplyAdrBalNtv0.001',\n",
       " 'SplyAdrBalNtv0.01',\n",
       " 'SplyAdrBalNtv0.1',\n",
       " 'SplyAdrBalNtv1',\n",
       " 'SplyAdrBalNtv10',\n",
       " 'SplyAdrBalNtv100',\n",
       " 'SplyAdrBalNtv100K',\n",
       " 'SplyAdrBalNtv10K',\n",
       " 'SplyAdrBalNtv1K',\n",
       " 'SplyAdrBalNtv1M',\n",
       " 'SplyAdrBalUSD1',\n",
       " 'SplyAdrBalUSD10',\n",
       " 'SplyAdrBalUSD100',\n",
       " 'SplyAdrBalUSD100K',\n",
       " 'SplyAdrBalUSD10K',\n",
       " 'SplyAdrBalUSD10M',\n",
       " 'SplyAdrBalUSD1K',\n",
       " 'SplyAdrBalUSD1M',\n",
       " 'SplyAdrTop100',\n",
       " 'SplyAdrTop10Pct',\n",
       " 'SplyAdrTop1Pct',\n",
       " 'SplyBFXNtv',\n",
       " 'SplyBFXUSD',\n",
       " 'SplyBMXNtv',\n",
       " 'SplyBMXUSD',\n",
       " 'SplyBNBNtv',\n",
       " 'SplyBNBUSD',\n",
       " 'SplyBSPNtv',\n",
       " 'SplyBSPUSD',\n",
       " 'SplyBTXNtv',\n",
       " 'SplyBTXUSD',\n",
       " 'SplyCur',\n",
       " 'SplyExNtv',\n",
       " 'SplyExUSD',\n",
       " 'SplyExpFut10yr',\n",
       " 'SplyExpFut10yrCMBI',\n",
       " 'SplyFF',\n",
       " 'SplyGEMNtv',\n",
       " 'SplyGEMUSD',\n",
       " 'SplyHUONtv',\n",
       " 'SplyHUOUSD',\n",
       " 'SplyKRKNtv',\n",
       " 'SplyKRKUSD',\n",
       " 'SplyMiner0HopAllNtv',\n",
       " 'SplyMiner0HopAllUSD',\n",
       " 'SplyMiner1HopAllNtv',\n",
       " 'SplyMiner1HopAllUSD',\n",
       " 'SplyPOLNtv',\n",
       " 'SplyPOLUSD',\n",
       " 'SplyRvv180d',\n",
       " 'SplyRvv1yr',\n",
       " 'SplyRvv2yr',\n",
       " 'SplyRvv30d',\n",
       " 'SplyRvv3yr',\n",
       " 'SplyRvv4yr',\n",
       " 'SplyRvv5yr',\n",
       " 'SplyRvv7d',\n",
       " 'SplyRvv90d',\n",
       " 'SplyUTXOLoss',\n",
       " 'SplyUTXOProf',\n",
       " 'SplyWalBal1in100M',\n",
       " 'SplyWalBal1in100k',\n",
       " 'SplyWalBal1in10B',\n",
       " 'SplyWalBal1in10M',\n",
       " 'SplyWalBal1in10k',\n",
       " 'SplyWalBal1in1B',\n",
       " 'SplyWalBal1in1M',\n",
       " 'SplyWalBal1in1k',\n",
       " 'SplyWalBalNtv0.001',\n",
       " 'SplyWalBalNtv0.01',\n",
       " 'SplyWalBalNtv0.1',\n",
       " 'SplyWalBalNtv1',\n",
       " 'SplyWalBalNtv10',\n",
       " 'SplyWalBalNtv100',\n",
       " 'SplyWalBalNtv100k',\n",
       " 'SplyWalBalNtv10k',\n",
       " 'SplyWalBalNtv1M',\n",
       " 'SplyWalBalNtv1k',\n",
       " 'SplyWalBalUSD1',\n",
       " 'SplyWalBalUSD10',\n",
       " 'SplyWalBalUSD100',\n",
       " 'SplyWalBalUSD100k',\n",
       " 'SplyWalBalUSD10M',\n",
       " 'SplyWalBalUSD10k',\n",
       " 'SplyWalBalUSD1M',\n",
       " 'SplyWalBalUSD1k',\n",
       " 'TxCnt',\n",
       " 'TxCntSec',\n",
       " 'TxExCnt',\n",
       " 'TxMeanByte',\n",
       " 'TxOpRetCnt',\n",
       " 'TxTfrCnt',\n",
       " 'TxTfrMeanByte',\n",
       " 'TxTfrValAbUSD100MCnt',\n",
       " 'TxTfrValAbUSD100MNtv',\n",
       " 'TxTfrValAbUSD100MUSD',\n",
       " 'TxTfrValAbUSD100kCnt',\n",
       " 'TxTfrValAbUSD100kNtv',\n",
       " 'TxTfrValAbUSD100kUSD',\n",
       " 'TxTfrValAbUSD10MCnt',\n",
       " 'TxTfrValAbUSD10MNtv',\n",
       " 'TxTfrValAbUSD10MUSD',\n",
       " 'TxTfrValAbUSD1MCnt',\n",
       " 'TxTfrValAbUSD1MNtv',\n",
       " 'TxTfrValAbUSD1MUSD',\n",
       " 'TxTfrValAdjByte',\n",
       " 'TxTfrValAdjNtv',\n",
       " 'TxTfrValAdjUSD',\n",
       " 'TxTfrValBelUSD100Cnt',\n",
       " 'TxTfrValBelUSD100Ntv',\n",
       " 'TxTfrValBelUSD100USD',\n",
       " 'TxTfrValBelUSD10kCnt',\n",
       " 'TxTfrValBelUSD10kNtv',\n",
       " 'TxTfrValBelUSD10kUSD',\n",
       " 'TxTfrValBelUSD1kCnt',\n",
       " 'TxTfrValBelUSD1kNtv',\n",
       " 'TxTfrValBelUSD1kUSD',\n",
       " 'TxTfrValBelUSD500Cnt',\n",
       " 'TxTfrValBelUSD500Ntv',\n",
       " 'TxTfrValBelUSD500USD',\n",
       " 'TxTfrValDayDst',\n",
       " 'TxTfrValDayDstMean',\n",
       " 'TxTfrValMeanNtv',\n",
       " 'TxTfrValMeanUSD',\n",
       " 'TxTfrValMedNtv',\n",
       " 'TxTfrValMedUSD',\n",
       " 'TxTfrValNtv',\n",
       " 'TxTfrValUSD',\n",
       " 'UTXOAgeMean',\n",
       " 'UTXOAgeMed',\n",
       " 'UTXOAgeValMean',\n",
       " 'UTXOCnt',\n",
       " 'UTXODay',\n",
       " 'UTXOLossCnt',\n",
       " 'UTXOLossUnrealUSD',\n",
       " 'UTXOProfCnt',\n",
       " 'UTXOProfUnrealUSD',\n",
       " 'VelAct1yr',\n",
       " 'VelActAdj1yr',\n",
       " 'VelCur1yr',\n",
       " 'VelCurAdj1yr',\n",
       " 'VtyDayRet180d',\n",
       " 'VtyDayRet30d',\n",
       " 'VtyDayRet60d',\n",
       " 'WalActCnt',\n",
       " 'WalActRecCnt',\n",
       " 'WalActSentCnt',\n",
       " 'WalBalCnt',\n",
       " 'confirmation_suggestion_min',\n",
       " 'open_interest_reported_future_coin_margined_usd',\n",
       " 'open_interest_reported_future_nonperpetual_usd',\n",
       " 'open_interest_reported_future_perpetual_usd',\n",
       " 'open_interest_reported_future_tether_margined_usd',\n",
       " 'open_interest_reported_future_usd',\n",
       " 'principal_market_price_usd',\n",
       " 'principal_market_usd',\n",
       " 'volatility_realized_usd_rolling_24h',\n",
       " 'volatility_realized_usd_rolling_30d',\n",
       " 'volatility_realized_usd_rolling_7d',\n",
       " 'volume_reported_future_coin_margined_usd_1d',\n",
       " 'volume_reported_future_coin_margined_usd_1h',\n",
       " 'volume_reported_future_nonperpetual_usd_1d',\n",
       " 'volume_reported_future_nonperpetual_usd_1h',\n",
       " 'volume_reported_future_perpetual_usd_1d',\n",
       " 'volume_reported_future_perpetual_usd_1h',\n",
       " 'volume_reported_future_tether_margined_usd_1d',\n",
       " 'volume_reported_future_tether_margined_usd_1h',\n",
       " 'volume_reported_future_usd_1d',\n",
       " 'volume_reported_future_usd_1h',\n",
       " 'volume_reported_spot_usd_1d',\n",
       " 'volume_reported_spot_usd_1h',\n",
       " 'volume_trusted_spot_usd_1d',\n",
       " 'volume_trusted_spot_usd_1h']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_metrics = []\n",
    "for metrics in asset_metrics_df[asset_metrics_df.asset=='btc'].metrics.values:\n",
    "    if metrics is not np.nan:\n",
    "        for metric in metrics:\n",
    "            all_metrics.append(metric['metric'])\n",
    "list(np.unique(np.array(all_metrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "751b124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_markets = []\n",
    "for markets in asset_metrics_df.markets.values:\n",
    "    if markets is not np.nan:\n",
    "        all_markets.extend(markets)\n",
    "all_markets = list(np.unique(np.array(all_markets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6fe5bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exchanges = list(np.unique([s.split(\"-\")[0] for s in all_markets if \"spot\" in s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5bdb0ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset</th>\n",
       "      <th>full_name</th>\n",
       "      <th>exchanges</th>\n",
       "      <th>markets</th>\n",
       "      <th>metrics</th>\n",
       "      <th>atlas</th>\n",
       "      <th>experimental</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1inch</td>\n",
       "      <td>1inch</td>\n",
       "      <td>[bibox, binance, binance.us, bitfinex, bitstam...</td>\n",
       "      <td>[bibox-1inch-usdt-spot, binance-1INCHUSDT-futu...</td>\n",
       "      <td>[{'metric': 'AdrAct30dCnt', 'frequencies': [{'...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1st</td>\n",
       "      <td>FirstBlood</td>\n",
       "      <td>[bittrex, gatecoin, hitbtc, zb.com]</td>\n",
       "      <td>[bittrex-1st-btc-spot, gatecoin-1st-btc-spot, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2give</td>\n",
       "      <td>2GIVE</td>\n",
       "      <td>[bittrex]</td>\n",
       "      <td>[bittrex-2give-btc-spot]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aac</td>\n",
       "      <td>Acute Angle Cloud</td>\n",
       "      <td>[huobi, lbank, okex]</td>\n",
       "      <td>[huobi-aac-btc-spot, huobi-aac-eth-spot, huobi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>aave</td>\n",
       "      <td>Aave</td>\n",
       "      <td>[bibox, binance, binance.us, bitfinex, bitmex,...</td>\n",
       "      <td>[bibox-aave-btc-spot, bibox-aave-eth-spot, bib...</td>\n",
       "      <td>[{'metric': 'AdrAct30dCnt', 'frequencies': [{'...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302</th>\n",
       "      <td>zlw</td>\n",
       "      <td>Zelwin</td>\n",
       "      <td>[gate.io]</td>\n",
       "      <td>[gate.io-zlw-eth-spot, gate.io-zlw-usdt-spot]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>zrc</td>\n",
       "      <td>ZrCoin</td>\n",
       "      <td>[hitbtc]</td>\n",
       "      <td>[hitbtc-zrc-btc-spot]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>zrx</td>\n",
       "      <td>0x</td>\n",
       "      <td>[bibox, binance, binance.us, bitfinex, bithumb...</td>\n",
       "      <td>[bibox-zrx-usdt-spot, binance-ZRXUSDT-future, ...</td>\n",
       "      <td>[{'metric': 'AdrAct30dCnt', 'frequencies': [{'...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>zsc</td>\n",
       "      <td>Zeusshield</td>\n",
       "      <td>[gate.io, hitbtc]</td>\n",
       "      <td>[gate.io-zsc-eth-spot, gate.io-zsc-usdt-spot, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320</th>\n",
       "      <td>zyn</td>\n",
       "      <td>Zynecoin</td>\n",
       "      <td>[bibox, hitbtc]</td>\n",
       "      <td>[bibox-zyn-usdt-spot, hitbtc-zyn-usdt-spot]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>794 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      asset          full_name  \\\n",
       "6     1inch              1inch   \n",
       "9       1st         FirstBlood   \n",
       "12    2give              2GIVE   \n",
       "17      aac  Acute Angle Cloud   \n",
       "19     aave               Aave   \n",
       "...     ...                ...   \n",
       "3302    zlw             Zelwin   \n",
       "3314    zrc             ZrCoin   \n",
       "3315    zrx                 0x   \n",
       "3316    zsc         Zeusshield   \n",
       "3320    zyn           Zynecoin   \n",
       "\n",
       "                                              exchanges  \\\n",
       "6     [bibox, binance, binance.us, bitfinex, bitstam...   \n",
       "9                   [bittrex, gatecoin, hitbtc, zb.com]   \n",
       "12                                            [bittrex]   \n",
       "17                                 [huobi, lbank, okex]   \n",
       "19    [bibox, binance, binance.us, bitfinex, bitmex,...   \n",
       "...                                                 ...   \n",
       "3302                                          [gate.io]   \n",
       "3314                                           [hitbtc]   \n",
       "3315  [bibox, binance, binance.us, bitfinex, bithumb...   \n",
       "3316                                  [gate.io, hitbtc]   \n",
       "3320                                    [bibox, hitbtc]   \n",
       "\n",
       "                                                markets  \\\n",
       "6     [bibox-1inch-usdt-spot, binance-1INCHUSDT-futu...   \n",
       "9     [bittrex-1st-btc-spot, gatecoin-1st-btc-spot, ...   \n",
       "12                             [bittrex-2give-btc-spot]   \n",
       "17    [huobi-aac-btc-spot, huobi-aac-eth-spot, huobi...   \n",
       "19    [bibox-aave-btc-spot, bibox-aave-eth-spot, bib...   \n",
       "...                                                 ...   \n",
       "3302      [gate.io-zlw-eth-spot, gate.io-zlw-usdt-spot]   \n",
       "3314                              [hitbtc-zrc-btc-spot]   \n",
       "3315  [bibox-zrx-usdt-spot, binance-ZRXUSDT-future, ...   \n",
       "3316  [gate.io-zsc-eth-spot, gate.io-zsc-usdt-spot, ...   \n",
       "3320        [bibox-zyn-usdt-spot, hitbtc-zyn-usdt-spot]   \n",
       "\n",
       "                                                metrics atlas experimental  \n",
       "6     [{'metric': 'AdrAct30dCnt', 'frequencies': [{'...  True          NaN  \n",
       "9                                                   NaN   NaN          NaN  \n",
       "12                                                  NaN   NaN          NaN  \n",
       "17                                                  NaN   NaN          NaN  \n",
       "19    [{'metric': 'AdrAct30dCnt', 'frequencies': [{'...  True          NaN  \n",
       "...                                                 ...   ...          ...  \n",
       "3302                                                NaN   NaN          NaN  \n",
       "3314                                                NaN   NaN          NaN  \n",
       "3315  [{'metric': 'AdrAct30dCnt', 'frequencies': [{'...  True          NaN  \n",
       "3316                                                NaN   NaN          NaN  \n",
       "3320                                                NaN   NaN          NaN  \n",
       "\n",
       "[794 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asset_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e7acce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ba6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO obtain all markets for each asset, cut it down to legit ones, obtain it's first market price\n",
    "\n",
    "legit_exchanges = ['binance',\n",
    "                   'binance.us',\n",
    "                   'bitfinex',\n",
    "                   'coinbase',\n",
    "                   'crypto.com',\n",
    "                   'ftx',\n",
    "                   'ftx.us',\n",
    "                   'gemini',\n",
    "                   'huobi',\n",
    "                   'kraken',\n",
    "                   'kucoin',\n",
    "                   'mt.gox',\n",
    "                   'okex',\n",
    "                   'poloniex',\n",
    "                   'uniswap_v2_eth',\n",
    "                   'uniswap_v3_eth']\n",
    "\n",
    "# loop over every asset\n",
    "# find its markets that are SPOT and is an exchange in my list\n",
    "# build dictionary of asset and all these legit markets\n",
    "\n",
    "# loop over that dictionary to take, for each asset, all its markets, find the first date, and take the min\n",
    "asset_metrics_df[asset_metrics_df.asset=='btc'].markets.values[0]\n",
    "market = 'bibox-aave-btc-spot'\n",
    "client.catalog_full_markets(markets=market) # can take min_date in here for each market\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ff4055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO see if there are assets with creation date after the first exchange date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a683378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO pull various supply mesaures to see if i can calc mcap myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "742bdb64",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "results_price_mcap_df.to_csv('cm_mcap_price_panel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a0a93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9fdf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO pull their taxonomy\n",
    "# TODO: get a list of legit exchanges from them; use list i already have and maybe add some if they have?\n",
    "# TODO: pull exchange metrics for those so maybe just volume?\n",
    "# TODO: pull open interest in futures? maybe as macro variable but lets see if i can get for a bunch of assets\n",
    "# TODO: pull the institutions and associated metrics to see if anything of interest\n",
    "# TODO: pull bid and ask price for markets of target coins?\n",
    "# TODO: pull defi balance sheets\n",
    "# TODO: see if i am missing anything else to pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b108c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = []\n",
    "for metrics in asset_metrics_df.metrics.values:\n",
    "    if metrics is not np.nan:\n",
    "        for metric in metrics:\n",
    "            all_metrics.append(metric['metric'])\n",
    "list(np.unique(np.array(all_metrics)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e428bc405edc59f3352e9792cab27c5e28560f7efb4b47308a6c6ea38cd15df2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
