{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb7eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO UPDATE THIS OLD MESSY CODE WITH NEW PANEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c2bd1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6953a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsetToAssetUniverse(df, asset_universe_dict, train_or_test):\n",
    "    # determine the asset universe to use for whether train or test data\n",
    "    if train_or_test == 'train':\n",
    "        index_start = 0\n",
    "        index_end   = len(asset_universe_dict)-4\n",
    "    elif train_or_test=='test':\n",
    "        index_start = len(asset_universe_dict)-4\n",
    "        index_end   = len(asset_universe_dict)\n",
    "    else:\n",
    "        assert(False),('get wit zee program')\n",
    "        \n",
    "    # subset to included assets\n",
    "    for i in range(index_start, index_end):\n",
    "        # extract this quarter and its included assets\n",
    "        date = list(asset_universe_dict.keys())[i]\n",
    "        assets = asset_universe_dict[date]\n",
    "\n",
    "        # form start and end date for this window\n",
    "        start_date = datetime.strptime(date, '%Y-%m-%d')\n",
    "        end_date   = datetime.strptime(date, '%Y-%m-%d') + relativedelta(months=3)\n",
    "\n",
    "        # drop rows in this time period that are not the included assets\n",
    "        df = df[~(((df.date>=start_date) & (df.date<end_date)) & (~df.asset.isin(assets)))]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d57747f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsetColumnsToAssetCovariates(df):\n",
    "    df = df.drop('date', axis=1)\n",
    "    df = df.set_index('week_idx')\n",
    "    columns = df.columns.values\n",
    "    covariates = [col for col in columns if (col[:6]=='covar_')]\n",
    "    df = df[['asset', 'r_tplus7', 'usd_mcap']+covariates]  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07fea258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelUnivariateFactorSortedPortfolios(df, covar, calc_corr=True, \n",
    "                                          sort_ascending=None):\n",
    "    # determine is pos or neg correlation for how to rank\n",
    "    if calc_corr==True:\n",
    "        corr = np.corrcoef(df.r_tplus7.values, df[covar].values)[0,1]\n",
    "        if corr>0:\n",
    "            sort_ascending = True\n",
    "        else:\n",
    "            sort_ascending = False\n",
    "    # or just take the passed param if we do not want to calc it\n",
    "    else:\n",
    "        assert((sort_ascending==True) | (sort_ascending==False))\n",
    "\n",
    "    # form tertile portfolios each week\n",
    "    tertile_col                 = 'tertile_'+covar[6:]\n",
    "    df                          = df.sort_values(by=['week_idx', covar], \n",
    "                                                 ascending=[True, sort_ascending])\n",
    "    df['ranking']               = df.groupby(['week_idx']).cumcount()\n",
    "    df['counts']                = 1\n",
    "    df['total_assets_per_week'] = df.groupby('week_idx').counts.transform('sum')\n",
    "    df['ranking']               = df.ranking/df.total_assets_per_week\n",
    "    df.loc[df.ranking < 1/3, tertile_col] = 1\n",
    "    df.loc[(df.ranking>=1/3) & \n",
    "           (df.ranking<2/3), tertile_col] = 2\n",
    "    df.loc[df.ranking>=2/3, tertile_col]  = 3\n",
    "    df = df.drop(['ranking', 'counts', 'total_assets_per_week'],axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a85ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelMultivarFactorSortedPortfolio(df, covars):\n",
    "    # form the tertile col names from the covar names\n",
    "    tertile_cols = []\n",
    "    for covar in covars:\n",
    "        tertile_col = 'tertile_'+covar[6:]\n",
    "        tertile_cols.append(tertile_col)\n",
    "\n",
    "    # form an equally spaced tertile sum ranking within week\n",
    "    df['tertile_sum'] = 0\n",
    "    for tertile_col in tertile_cols:\n",
    "        df['tertile_sum'] = df.tertile_sum + df[tertile_col]\n",
    "        \n",
    "    # form tertiles based on tertile sum with ~equal number of assets\n",
    "    np.random.seed(42)\n",
    "    df['rand']    = np.random.uniform(size=df.shape[0])\n",
    "    df = df.sort_values(by=['week_idx', 'tertile_sum', 'rand'])\n",
    "    df['ranking'] = df.groupby(['week_idx']).cumcount()\n",
    "    df['counts']  = 1\n",
    "    df['total_assets_per_week'] = df.groupby('week_idx').counts.transform('sum')\n",
    "    df['ranking']               = df.ranking/df.total_assets_per_week\n",
    "    df.loc[df.ranking < 1/3, 'tertile'] = 1\n",
    "    df.loc[(df.ranking>=1/3) & \n",
    "           (df.ranking<2/3), 'tertile'] = 2\n",
    "    df.loc[df.ranking>=2/3,  'tertile']  = 3\n",
    "    df = df.drop(['tertile_sum', 'rand', 'ranking', \n",
    "                  'counts', 'total_assets_per_week'], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfef32cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formWeekly3m1PortfolioReturnDF(df):\n",
    "    # assign weekly within-tertile mcap weighted portfolio weights \n",
    "    df['mcap_sum']   = df.groupby(['week_idx', 'tertile']).usd_mcap.transform('sum')\n",
    "    df['mcap_wght']  = df.usd_mcap / df.mcap_sum\n",
    "\n",
    "    # confirm portfolio weights roughly sum to 1 each week-tertile\n",
    "    assert(len(np.unique(df.index))*3 == \n",
    "           np.sum(np.isclose(df.groupby(['week_idx', 'tertile']).mcap_wght.sum(), 1,\n",
    "                             rtol=1e-2, atol=1e-2)))\n",
    "\n",
    "    # calculate weekly portfolio return\n",
    "    df['r'] = df.mcap_wght * df.r_tplus7\n",
    "    r_df    = df.groupby(['week_idx', 'tertile'])[['r']].sum().reset_index()\n",
    "    returns = r_df[r_df.tertile == 3].r.values - r_df[r_df.tertile == 1].r.values\n",
    "    r_df    = pd.DataFrame(data={'week_idx': np.unique(r_df.week_idx.values),\n",
    "                                 'r': returns})\n",
    "\n",
    "    return r_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52e8300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPortfolioReturn(df):\n",
    "    num_wks  = df.shape[0]\n",
    "    if np.sum(df.r.values <= -1)>=1:\n",
    "        return -1\n",
    "    else:\n",
    "        tot_ret  = np.product(df.r.values+1)-1\n",
    "        wkly_ret = (tot_ret+1)**(1/num_wks)-1\n",
    "        annl_ret = (wkly_ret+1)**(52.18)-1\n",
    "        return annl_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6876b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFactorPerformance(df, covariates, factors=[]):\n",
    "    results_df = pd.DataFrame()\n",
    "    for covar in covariates:\n",
    "        df         = labelMultivarFactorSortedPortfolio(df, covars=factors+[covar])\n",
    "        r_df       = formWeekly3m1PortfolioReturnDF(df)\n",
    "        annl_ret   = calcPortfolioReturn(r_df)\n",
    "        temp_df    = pd.DataFrame(data={'covariate': [covar],\n",
    "                                        'annual_return': [annl_ret]})\n",
    "        results_df = pd.concat((results_df, temp_df))\n",
    "    results_df = results_df.sort_values('annual_return', ascending=False)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "207d347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelPortfolioWeightsAndReturns(df):\n",
    "    # assign weekly within-tertile mcap weighted portfolio weights \n",
    "    df['mcap_sum']   = df.groupby(['week_idx', 'tertile']).usd_mcap.transform('sum')\n",
    "    df['mcap_wght']  = df.usd_mcap / df.mcap_sum\n",
    "    \n",
    "    # assign prtfl weight that is 0 in bottom, 1/6 in middle, and 5/6 in top\n",
    "    df.loc[df.tertile == 1, 'prtfl_wght'] = df.mcap_wght*0\n",
    "    df.loc[df.tertile == 2, 'prtfl_wght'] = df.mcap_wght*1/6\n",
    "    df.loc[df.tertile == 3, 'prtfl_wght'] = df.mcap_wght*5/6\n",
    "    \n",
    "    # confirm portfolio weights roughly sum to 1 for each week\n",
    "    assert(len(np.unique(df.week_idx)) == \n",
    "           np.sum(np.isclose(df.groupby(['week_idx']).prtfl_wght.sum(), 1,\n",
    "                             rtol=1e-2, atol=1e-2)))\n",
    "    \n",
    "    # add weekly returns to the data frame\n",
    "    df['r'] = df.prtfl_wght*df.r_tplus7\n",
    "    df['r'] = df.groupby(['week_idx']).r.transform(sum)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "987a0381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAnnualTransactionCosts(df):\n",
    "    # merge on the previous week's holdings to the new holdings\n",
    "    temp_df = df.copy()\n",
    "    temp_df = temp_df[temp_df.week_idx<np.max(temp_df.week_idx)]\n",
    "    temp_df['week_idx'] = temp_df.week_idx+1\n",
    "    temp_df = temp_df[['week_idx', 'asset', 'prtfl_wght']]\n",
    "    temp_df = temp_df.rename(columns={'prtfl_wght': 'prtfl_wght_tm7'})\n",
    "    df = df.merge(temp_df,\n",
    "                  on=['week_idx', 'asset'],\n",
    "                  how='outer',\n",
    "                  validate='one_to_one')\n",
    "\n",
    "    # calc weekly turnover and ensure it has the appropriate range\n",
    "    df['asset_to'] = np.abs(df.prtfl_wght - df.prtfl_wght_tm7)\n",
    "    to_df = df.groupby('week_idx')[['asset_to']].sum().reset_index()\n",
    "    assert((np.min(to_df.asset_to)>=0) & (np.max(to_df.asset_to<=2)))\n",
    "\n",
    "    # correct the first and last week valid for buying the initial port and liquidating\n",
    "    to_df.loc[to_df.week_idx==106, 'asset_to'] = 1\n",
    "    to_df = pd.concat((to_df, pd.DataFrame(data={'week_idx': [262],\n",
    "                                                 'asset_to': 1})))\n",
    "    to_df = to_df.reset_index(drop=True)\n",
    "\n",
    "    # add transaction costs assuming maker and taker fee of 20 bps each\n",
    "    to_df['tc'] = to_df.asset_to*0.002\n",
    "\n",
    "    # return annualize transaction cost\n",
    "    return -np.sum(to_df.tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dce70ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPortfolioSharpe(df):\n",
    "    wkly_sharpe = np.mean(df.r.values)/np.std(df.r.values)\n",
    "    annl_sharpe = wkly_sharpe*np.sqrt(52.18)\n",
    "    return annl_sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccbd54b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_draw_down(df):\n",
    "    cumulative_ret=(df.r+1).cumprod()\n",
    "    roll_max=cumulative_ret.rolling(len(cumulative_ret), min_periods=1).max()\n",
    "    daily_drawdown=cumulative_ret/roll_max\n",
    "    max_daily_drawdown=daily_drawdown.min() - 1\n",
    "    return max_daily_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf5d0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_1_month_loss(df):\n",
    "    max_loss=(df['r']+1).rolling(4).apply(np.prod)\n",
    "    max_loss_minus=max_loss.min()-1\n",
    "    return max_loss_minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "panel_train_fp = '../3-data/clean/panel_train.pkl'\n",
    "asset_uni_fp   = '../3-data/clean/asset_universe_dates_and_lists.pkl'\n",
    "mcap_fp = '../3-data/clean/raw_panel.pkl'\n",
    "test_fp = '../3-data/clean/panel_oos.pkl'\n",
    "mcap_df = pd.read_pickle(mcap_fp)\n",
    "mcap_df = mcap_df[['date', 'asset', 'usd_mcap']]\n",
    "train_df = pd.read_pickle(panel_train_fp)\n",
    "nrows    = train_df.shape[0]\n",
    "train_df = mcap_df.merge(train_df,\n",
    "                         on=['date', 'asset'],\n",
    "                         how='inner',\n",
    "                         validate='one_to_one')\n",
    "assert(nrows==train_df.shape[0])\n",
    "with open(asset_uni_fp, 'rb') as handle:\n",
    "    asset_universe_dict = pickle.load(handle)\n",
    "test_df  = pd.read_pickle(test_fp)\n",
    "\n",
    "# clean up test data\n",
    "test_df = test_df[test_df.week_idx >= 262]\n",
    "test_df = mcap_df.merge(test_df,\n",
    "                        on=['date', 'asset'],\n",
    "                        how='inner',\n",
    "                        validate='one_to_one')\n",
    "    \n",
    "# subset data to relevant rows and cols\n",
    "train_df = subsetToAssetUniverse(train_df, asset_universe_dict, train_or_test='train')\n",
    "train_df = subsetColumnsToAssetCovariates(train_df)\n",
    "test_df  = subsetToAssetUniverse(test_df, asset_universe_dict, train_or_test='test')\n",
    "\n",
    "# form weekly univariate tertile rankings to use throughout\n",
    "covariates = list(train_df.columns.values)\n",
    "covariates.remove('asset')\n",
    "covariates.remove('r_tplus7')\n",
    "covariates.remove('usd_mcap')\n",
    "for covar in covariates:\n",
    "    train_df = labelUnivariateFactorSortedPortfolios(train_df, covar, calc_corr=True)\n",
    "    \n",
    "# rank covars on 3 minus 1 sorted portfolio return to find best one factor model\n",
    "univar_results_df = calcFactorPerformance(train_df, covariates, factors=[])\n",
    "factor1 = univar_results_df.covariate.values[0]\n",
    "\n",
    "# rank covars on 3 minus 1 sorted portfolio return from two factor model\n",
    "covariates.remove(factor1)\n",
    "bivar_results_df = calcFactorPerformance(train_df, covariates, factors=[factor1])\n",
    "factor2 = bivar_results_df.covariate.values[0]\n",
    "\n",
    "# rank covars on 3 minus 1 sorted portfolio return from three factor model\n",
    "covariates.remove(factor2)\n",
    "trivar_results_df = calcFactorPerformance(train_df, covariates, factors=[factor1, factor2])\n",
    "factor3 = trivar_results_df.covariate.values[0]\n",
    "\n",
    "# generate validation results\n",
    "factors = []\n",
    "for factor in [factor1, factor2, factor3]:\n",
    "    factors  += [factor]\n",
    "    print('validation period (2018-2020) results for factor model containing')\n",
    "    print(factors)\n",
    "    train_df = labelMultivarFactorSortedPortfolio(train_df, covars=factors)\n",
    "    val_df   = train_df[train_df.index>=106].reset_index() # 2018 and onward for val period\n",
    "    val_df   = val_df[['week_idx', 'asset', 'r_tplus7', 'usd_mcap', 'tertile']]\n",
    "    val_df   = labelPortfolioWeightsAndReturns(val_df)\n",
    "    annl_tc  = calcAnnualTransactionCosts(val_df)\n",
    "    print('annual transaction costs in simple return terms: ' + str(np.round(annl_tc, 4)))\n",
    "    r_df     = val_df[['week_idx', 'r']].drop_duplicates()\n",
    "    annl_ret = calcPortfolioReturn(r_df)\n",
    "    annl_sharpe = calcPortfolioSharpe(r_df)\n",
    "    print('annual simple return before trans costs: ' + str(np.round(annl_ret, 4)))\n",
    "    print('annual sharpe: '+str(np.round(annl_sharpe, 2)))\n",
    "    print('\\n')\n",
    "    \n",
    "# generate test period results\n",
    "test_df = test_df[['week_idx', 'date', 'asset', 'r_tplus7', 'usd_mcap', factor1, factor2, factor3]]\n",
    "for factor in [factor1, factor2, factor3]:\n",
    "    test_df = labelUnivariateFactorSortedPortfolios(test_df, factor, calc_corr=True)\n",
    "    \n",
    "factors = []\n",
    "num_factors = 0\n",
    "for factor in [factor1, factor2, factor3]:\n",
    "    factors  += [factor]\n",
    "    num_factors += 1\n",
    "    print('test period (2021) results for factor model containing')\n",
    "    print(factors)\n",
    "    oos_df = labelMultivarFactorSortedPortfolio(test_df, covars=factors)\n",
    "    oos_df = oos_df[['week_idx', 'asset', 'r_tplus7', 'usd_mcap', 'tertile']]\n",
    "    oos_df = labelPortfolioWeightsAndReturns(oos_df)\n",
    "    annl_tc  = calcAnnualTransactionCosts(oos_df)\n",
    "    print('annual transaction costs in simple return terms: ' + str(np.round(annl_tc, 4)))\n",
    "    r_df     = oos_df[['week_idx', 'r']].drop_duplicates()\n",
    "    annl_ret = calcPortfolioReturn(r_df)\n",
    "    annl_sharpe = calcPortfolioSharpe(r_df)\n",
    "    print('annual simple return before trans costs: ' + str(np.round(annl_ret, 4)))\n",
    "    print('annual sharpe: '+str(np.round(annl_sharpe, 2)))\n",
    "    max_dd = max_draw_down(r_df)\n",
    "    print('max drawdown : '+str(np.round(max_dd, 2)))\n",
    "    max_1mo_loss = max_1_month_loss(r_df)\n",
    "    print('max one month loss : '+str(np.round(max_1mo_loss, 2)))\n",
    "    print('\\n')\n",
    "\n",
    "# output equal weight benchmark\n",
    "print('test period (2021) results for equal-weighted portfolio')\n",
    "r_df = test_df.copy()\n",
    "r_df['counts'] = 1\n",
    "r_df['assets_per_week'] = r_df.groupby('week_idx').counts.transform('sum')\n",
    "r_df['prtfl_wght'] = 1/r_df.assets_per_week\n",
    "r_df = r_df.drop(['counts', 'assets_per_week'], axis=1)\n",
    "annl_tc  = calcAnnualTransactionCosts(r_df)\n",
    "print('annual transaction costs in simple return terms: ' + str(np.round(annl_tc, 4)))\n",
    "r_df = r_df.groupby('week_idx')[['r_tplus7']].mean()\n",
    "r_df = r_df.rename(columns={'r_tplus7': 'r'})\n",
    "annl_ret = calcPortfolioReturn(r_df)\n",
    "annl_sharpe = calcPortfolioSharpe(r_df)\n",
    "print('annual simple return before trans costs: ' + str(np.round(annl_ret, 4)))\n",
    "print('annual sharpe: '+str(np.round(annl_sharpe, 2)))\n",
    "max_dd = max_draw_down(r_df)\n",
    "print('max drawdown : '+str(np.round(max_dd, 2)))\n",
    "max_1mo_loss = max_1_month_loss(r_df)\n",
    "print('max one month loss : '+str(np.round(max_1mo_loss, 2)))\n",
    "print('\\n')\n",
    "\n",
    "# output mcap-weighted benchmark\n",
    "print('test period (2021) results for mcap-weighted portfolio')\n",
    "r_df = test_df.copy()\n",
    "r_df['mcap_sum']  = r_df.groupby(['week_idx']).usd_mcap.transform('sum')\n",
    "r_df['prtfl_wght'] = r_df.usd_mcap / r_df.mcap_sum\n",
    "# confirm portfolio weights roughly sum to 1 for each week\n",
    "assert(len(np.unique(r_df.week_idx)) == \n",
    "       np.sum(np.isclose(r_df.groupby(['week_idx']).prtfl_wght.sum(), 1,\n",
    "                         rtol=1e-2, atol=1e-2)))\n",
    "r_df = r_df.drop(['mcap_sum'], axis=1)\n",
    "annl_tc  = calcAnnualTransactionCosts(r_df)\n",
    "print('annual transaction costs in simple return terms: ' + str(np.round(annl_tc, 4)))\n",
    "r_df['r'] = r_df.prtfl_wght * r_df.r_tplus7\n",
    "r_df = r_df.groupby('week_idx')[['r']].sum()\n",
    "annl_ret = calcPortfolioReturn(r_df)\n",
    "annl_sharpe = calcPortfolioSharpe(r_df)\n",
    "print('annual simple return before trans costs: ' + str(np.round(annl_ret, 4)))\n",
    "print('annual sharpe: '+str(np.round(annl_sharpe, 2)))\n",
    "max_dd = max_draw_down(r_df)\n",
    "print('max drawdown : '+str(np.round(max_dd, 2)))\n",
    "max_1mo_loss = max_1_month_loss(r_df)\n",
    "print('max one month loss : '+str(np.round(max_1mo_loss, 2)))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7571a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO SCOPE OLD SCRIPT FOR ACTUAL NUMBERS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
