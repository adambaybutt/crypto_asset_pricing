{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9201ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO UPDATE THIS OLD MESSY SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676420d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# FOR CLEANING SCRIPT:\n",
    "\n",
    "# ensure each asset does not appear before first date nor after last date\n",
    "# cmc_ids = np.unique(panel_df.cmc_id.values)\n",
    "# for cmc_id in cmc_ids:\n",
    "#     print(cmc_id)\n",
    "#     first_date = cw_df[cw_df.cmc_id==cmc_id].first_date_cmc.values[0]\n",
    "#     last_date  = cw_df[cw_df.cmc_id==cmc_id].last_date_cmc.values[0]\n",
    "#     assert(0==panel_df[(panel_df.cmc_id==cmc_id)&(panel_df.date<first_date)].shape[0])\n",
    "#     assert(0==panel_df[(panel_df.cmc_id==cmc_id)&(panel_df.date>last_date)].shape[0])\n",
    "\n",
    "# ensure each asset has consecutive data, interpolate where needed with forward fill\n",
    "\n",
    "# group the data by cmc_id to loop over\n",
    "grouped = panel_df.groupby('cmc_id')\n",
    "\n",
    "# interate through each cmc_id\n",
    "dfs = []\n",
    "for name, group in grouped:\n",
    "    # find the first and last dates for the current id\n",
    "    first_date = group['date'].min()\n",
    "    last_date  = group['date'].max()\n",
    "\n",
    "    # create a new dataframe with all the possible combinations of cmc_id and date\n",
    "    dates = pd.date_range(first_date, last_date)\n",
    "    index = pd.MultiIndex.from_product([[name], dates], names=['cmc_id', 'date'])\n",
    "    full_df = pd.DataFrame(index=index).reset_index()\n",
    "\n",
    "    # merge the full dataframe with the original dataframe to fill in missing values with NaNs\n",
    "    merged_df = pd.merge(full_df, group, on=['cmc_id', 'date'], how='left')\n",
    "\n",
    "    # interpolate the missing values using forward fill for up to 7 consecutive observations\n",
    "    interpolated_df = merged_df.fillna(method='ffill', limit=21)\n",
    "\n",
    "    # Check if there are any missing values in the remaining columns for the current id and date range\n",
    "    if interpolated_df.isnull().values.any():\n",
    "        print(f\"ID {name} has missing values in the given date range, precisely: {int(interpolated_df.isnull().sum().sum()/3)}.\")\n",
    "        break\n",
    "\n",
    "    # combine    \n",
    "    dfs.append(interpolated_df)\n",
    "\n",
    "# Combine all the dataframes and drop the 'cmc_id' index level\n",
    "result_df = pd.concat(dfs).reset_index()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04dece7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86f36585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DATA\n",
    "cw_df = pd.read_csv('../3-data/raw/cmc_token_universe.csv')\n",
    "cmc_df   = pd.read_csv('../3-data/raw/cmc_token_covars_panel.csv')\n",
    "panel_df = pd.read_csv('../3-data/raw/cmc_price_vol_mcap_panel.csv')\n",
    "macro_df = pd.read_csv('../3-data/raw/cmc_macro_timeseries.csv')\n",
    "ex_df    = pd.read_csv('../3-data/raw/cmc_exchange_panel.csv')\n",
    "ex_covar_df = pd.read_csv('../3-data/raw/cmc_exchange_covar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "364570c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN TOKEN COVARS\n",
    "\n",
    "# Merge token covars from crosswalk data onto the cmc df\n",
    "cmc_df = cmc_df.merge(cw_df[['cmc_id', 'cmc_first_date', 'cmc_last_date', 'platform_cmc_slug']],\n",
    "                      on='cmc_id',\n",
    "                      how='outer',\n",
    "                      validate='many_to_one')\n",
    "\n",
    "# Rename columns to standard convention (with data source name in it)\n",
    "cmc_df   = cmc_df.rename(columns = {'num_market_pairs': 'num_market_pairs_cmc', \n",
    "                                    'max_supply': 'max_supply_cmc',\n",
    "                                    'circulating_supply': 'circulating_supply_cmc',\n",
    "                                    'total_supply': 'total_supply_cmc',\n",
    "                                    'cmc_rank': 'rank_cmc',\n",
    "                                    'cmc_first_date': 'first_date_cmc',\n",
    "                                    'cmc_last_date': 'last_date_cmc'})\n",
    "\n",
    "# Obtain unique list of all tags in tags column\n",
    "all_tags = []\n",
    "for tags in cmc_df.tags.values:\n",
    "    tags = tags.strip('\\'][\\'').split(', ')\n",
    "    tags = [tag.replace('\\'', '') for tag in tags]\n",
    "    all_tags.append(tags)\n",
    "unique_tags = list(set([tag for tags in all_tags for tag in tags]))\n",
    "\n",
    "# Determine the number of appearances of each tag\n",
    "tag_counts_dict = {}\n",
    "for tag in unique_tags:\n",
    "    tag_counts_dict[tag] = 0\n",
    "for tag in cmc_df.tags.values:\n",
    "    tag_list = tag.strip('\\'][\\'').split(', ')\n",
    "    if len(tag_list) >= 1:\n",
    "        tag_list = [tag.replace('\\'', '') for tag in tag_list]\n",
    "        for tag in tag_list:\n",
    "            tag_counts_dict[tag] += 1\n",
    "    \n",
    "# Create a tag to column name dictionary\n",
    "tag_col_dict = {'platform': 'platform_cmc',\n",
    "                'mineable': 'mineable_cmc',\n",
    "                'pow': 'pow_cmc',\n",
    "                'powt': 'pow_cmc',\n",
    "                'hybrid-dpow-pow': 'pow_cmc',\n",
    "                'hybrid-pos-lpos': 'pos_cmc',\n",
    "                'pos': 'pos_cmc',\n",
    "                'hybrid-pos-pop': 'pos_cmc',\n",
    "                'dpos': 'pos_cmc',\n",
    "                'rpos': 'pos_cmc',\n",
    "                'placeholder-ventures-portfolio': 'portfolio_placeholder_cmc',\n",
    "                'dragonfly-capital-portfolio': 'portfolio_dragonfly_cmc',\n",
    "                'three-arrows-capital-portfolio': 'portfolio_3arrows_cmc',\n",
    "                'electric-capital-portfolio': 'portfolio_electric_cap_cmc',\n",
    "                'coinbase-ventures-portfolio': 'portfolio_coinbase_cmc',\n",
    "                'winklevoss-capital-portfolio': 'portfolio_winklevoss_cmc',\n",
    "                'winklevoss-capital': 'portfolio_winklevoss_cmc',\n",
    "                'a16z-portfolio': 'portfolio_a16z_cmc',\n",
    "                'multicoin-capital-portfolio': 'portfolio_multicoin_cap_cmc',\n",
    "                'polychain-capital-portfolio': 'portfolio_polychain_cmc',\n",
    "                'pantera-capital-portfolio': 'portfolio_pantera_cmc',\n",
    "                'dcg-portfolio': 'portfolio_dcg_cmc',\n",
    "                'alameda-research-portfolio': 'portfolio_alameda_cmc',\n",
    "                'paradigm-portfolio': 'portfolio_paradigm_cmc',\n",
    "                'galaxy-digital-portfolio': 'portfolio_galaxy_digital_cmc',\n",
    "                'usv-portfolio': 'portfolio_usv_cmc',\n",
    "                'ethereum': 'ecosystem_eth_cmc',\n",
    "                'ethereum-ecosystem': 'ecosystem_eth_cmc',\n",
    "                'algorand-ecosystem': 'ecosystem_algorand_cmc',\n",
    "                'polkadot': 'ecosystem_polkadot_cmc',\n",
    "                'cosmos': 'ecosystem_cosmos_cmc',\n",
    "                'cosmos-ecosystem': 'ecosystem_cosmos_cmc',\n",
    "                'terra-ecosystem': 'ecosystem_terra_cmc',\n",
    "                'solana-ecosystem': 'ecosystem_solana_cmc',\n",
    "                'binance-smart-chain-ecosystem': 'ecosystem_binance_cmc',\n",
    "                'polygon-ecosystem': 'ecosystem_polygon_cmc',\n",
    "                'cardano-ecosystem': 'ecosystem_cardano_cmc',\n",
    "                'avalanche-ecosystem': 'ecosystem_avalanche_cmc',\n",
    "                'near-protocol-ecosystem': 'ecosystem_near_cmc',\n",
    "                'stablecoin-asset-backed': 'sector_stablecoin_cmc',\n",
    "                'asset-backed-stablecoin': 'sector_stablecoin_cmc',\n",
    "                'stablecoin-algorithmically-stabilized': 'sector_stablecoin_cmc',\n",
    "                'algorithmic-stablecoin': 'sector_stablecoin_cmc',\n",
    "                'stablecoin': 'sector_stablecoin_cmc',\n",
    "                'derivatives': 'sector_defi_cmc',\n",
    "                'defi-index': 'sector_defi_cmc',\n",
    "                'options': 'sector_defi_cmc',\n",
    "                'yield-aggregator': 'sector_defi_cmc',\n",
    "                'lending-borowing': 'sector_defi_cmc',\n",
    "                'yield-farming': 'sector_defi_cmc',\n",
    "                'asset-management': 'sector_defi_cmc',\n",
    "                'defi': 'sector_defi_cmc',\n",
    "                'dao': 'sector_dao_cmc',\n",
    "                'atomic-swaps': 'sector_payments_cmc',\n",
    "                'payments': 'sector_payments_cmc',\n",
    "                'layer-2': 'sector_infastructure_cmc',\n",
    "                'oracles': 'sector_infrastructure_cmc',\n",
    "                'interoperability': 'sector_infrastructure_cmc',\n",
    "                'rollups': 'sector_infastructure_cmc',\n",
    "                'zero-knowledge-proofs': 'sector_infastructure_cmc',\n",
    "                'scaling': 'sector_infastructure_cmc',\n",
    "                'wallet': 'sector_infastructure_cmc',\n",
    "                'smart-contracts': 'sector_infastructure_cmc',\n",
    "                'staking': 'sector_infastructure_cmc',\n",
    "                'identity': 'sector_infrastructure_cmc',\n",
    "                'fan-token': 'sector_social_cmc',\n",
    "                'social-money': 'sector_social_cmc',\n",
    "                'social-token': 'sector_social_cmc',\n",
    "                'communications-social-media': 'sector_social_cmc',\n",
    "                'distributed-computing': 'sector_computing_cmc',\n",
    "                'storage': 'sector_computing_cmc',\n",
    "                'enterprise-solutions': 'sector_enterprise_cmc',\n",
    "                'privacy': 'sector_privacy_cmc',\n",
    "                'agriculture': 'sector_agriculture_cmc',\n",
    "                'sports': 'sector_games_cmc',\n",
    "                'gaming': 'sector_games_cmc',\n",
    "                'play-to-earn': 'sector_games_cmc',\n",
    "                'gambling': 'sector_games_cmc',\n",
    "                'energy': 'sector_energy_cmc',\n",
    "                'cybersecurity': 'sector_cybersecurity_cmc',\n",
    "                'store-of-value': 'sector_sov_cmc',\n",
    "                'ai-big-data': 'sector_ai_cmc',\n",
    "                'crowdsourcing': 'sector_crowdsourcing_cmc', \n",
    "                'crowdfunding': 'sector_crowdsourcing_cmc',\n",
    "                'prediction-markets': 'sector_crowdsourcing_cmc',\n",
    "                'memes': 'sector_memes_cmc',\n",
    "                'entertainment': 'sector_media_cmc',\n",
    "                'media': 'sector_media_cmc',\n",
    "                'music': 'sector_media_cmc',\n",
    "                'marketplace': 'sector_market_cmc',\n",
    "                'e-commerce': 'sector_market_cmc',\n",
    "                'centralized-exchange': 'sector_cex_cmc',\n",
    "                'medium-of-exchange': 'sector_moe_cmc',\n",
    "                'dex': 'sector_dex_cmc',\n",
    "                'decentralized-exchange ': 'sector_dex_cmc',\n",
    "                'amm': 'sector_dex_cmc',\n",
    "                'collectibles-nfts': 'sector_nft_cmc',\n",
    "                'real-estate': 'sector_real_estate_cmc',\n",
    "                'metaverse': 'sector_metaverse_cmc',\n",
    "                'education': 'sector_education_cmc'}\n",
    "\n",
    "# Add the values in the dictionary as new columns with zeros\n",
    "cmc_df = cmc_df.reindex(columns=[*cmc_df.columns.tolist(), \n",
    "                                 *list(set(tag_col_dict.values()))], fill_value=0)\n",
    "\n",
    "# Update the new columns with 1 if contained in tags column\n",
    "n = cmc_df.shape[0]\n",
    "keys = list(tag_col_dict.keys())\n",
    "for i in range(n):\n",
    "    # Obtain tags\n",
    "    tags = all_tags[i]\n",
    "    \n",
    "    # Update columns\n",
    "    if tags != ['']:\n",
    "        for tag in tags:\n",
    "            if tag in keys:\n",
    "                col = tag_col_dict[tag]\n",
    "                cmc_df.at[i, col] = 1\n",
    "                \n",
    "# Drop tags column\n",
    "cmc_df = cmc_df.drop('tags', axis=1)\n",
    "\n",
    "# Convert columns to correct data type\n",
    "cmc_df['date'] = pd.to_datetime(cmc_df.date, format='%Y-%m-%d', utc=False)\n",
    "cmc_df['first_date_cmc'] = pd.to_datetime(cmc_df.first_date_cmc, format='%Y-%m-%d', utc=False).dt.date\n",
    "cmc_df['last_date_cmc'] = pd.to_datetime(cmc_df.last_date_cmc, format='%Y-%m-%d', utc=False).dt.date\n",
    "\n",
    "# Use platform slug column to update platform values\n",
    "cmc_df.loc[cmc_df.platform_cmc_slug == 'polygon', 'ecosystem_polygon_cmc'] = 1\n",
    "cmc_df.loc[cmc_df.platform_cmc_slug == 'cardano', 'ecosystem_cardano_cmc'] = 1\n",
    "cmc_df.loc[cmc_df.platform_cmc_slug == 'bnb', 'ecosystem_binance_cmc'] = 1\n",
    "cmc_df.loc[cmc_df.platform_cmc_slug == 'solana', 'ecosystem_solana_cmc'] = 1\n",
    "cmc_df.loc[cmc_df.platform_cmc_slug == 'avalanche', 'ecosystem_avalanche_cmc'] = 1\n",
    "cmc_df.loc[cmc_df.platform_cmc_slug == 'terra-luna', 'ecosystem_terra_cmc'] = 1\n",
    "cmc_df.loc[cmc_df.platform_cmc_slug == 'algorand', 'ecosystem_algorand_cmc'] = 1\n",
    "cmc_df.loc[cmc_df.platform_cmc_slug == 'arbitrum-ethereum', 'ecosystem_eth_cmc'] =1\n",
    "cmc_df.loc[cmc_df.platform_cmc_slug == 'cosmos', 'ecosystem_cosmos_cmc'] = 1\n",
    "\n",
    "# Drop platform slug column\n",
    "cmc_df = cmc_df.drop('platform_cmc_slug', axis=1)\n",
    "\n",
    "# Form list of data columns to work with\n",
    "data_cols = list(cmc_df.columns.values)\n",
    "data_cols.remove('date')\n",
    "data_cols.remove('cmc_id')\n",
    "\n",
    "# Set column order\n",
    "cmc_df = cmc_df[['date', 'cmc_id'] + data_cols]\n",
    "\n",
    "# Drop rows\n",
    "cmc_df = cmc_df[(cmc_df.date.dt.year >= 2015) & (cmc_df.date <= '2022-01-02')]\n",
    "\n",
    "# Trim values\n",
    "cmc_df.loc[cmc_df.max_supply_cmc < 0, 'max_supply_cmc'] = np.nan\n",
    "cmc_df.loc[cmc_df.max_supply_cmc < 0, 'max_supply_cmc'] = np.nan\n",
    "\n",
    "# Drop duplicated rows across id columns\n",
    "cmc_df = cmc_df.drop_duplicates(subset=['date', 'cmc_id'])\n",
    "\n",
    "# Sort values and reset index\n",
    "cmc_df = cmc_df.sort_values(by=['date', 'cmc_id'], \n",
    "                            ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0603d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN PANEL\n",
    "\n",
    "# Rename columns to standard convention (with data source name in it)\n",
    "panel_df = panel_df.rename(columns = {'usd_per_token': 'usd_per_token_cmc',\n",
    "                                      'usd_mcap': 'usd_mcap_cmc',\n",
    "                                      'usd_volume_24h': 'usd_volume_24h_cmc'})\n",
    "\n",
    "# Convert columns to correct data type\n",
    "panel_df['date'] = pd.to_datetime(panel_df.date, format='%Y-%m-%d', utc=False)\n",
    "\n",
    "# Set column order\n",
    "panel_df = panel_df[['date', 'cmc_id', 'usd_per_token_cmc', 'usd_mcap_cmc', 'usd_volume_24h_cmc']]\n",
    "\n",
    "# Drop rows\n",
    "panel_df = panel_df[(panel_df.date.dt.year >= 2015) & (panel_df.date <= '2022-01-02')]\n",
    "panel_df = panel_df[panel_df.index.isin(panel_df[['usd_per_token_cmc', \n",
    "                                                  'usd_mcap_cmc', \n",
    "                                                  'usd_volume_24h_cmc']].dropna(how='all').index.values)]\n",
    "\n",
    "# Confirm no missings in the df\n",
    "assert(panel_df.isnull().sum().values.sum() == 0)\n",
    "\n",
    "# Form list of data columns to work with\n",
    "data_cols = list(panel_df.columns.values)\n",
    "data_cols.remove('date')\n",
    "data_cols.remove('cmc_id')\n",
    "\n",
    "# Set negative values to missing and too large values to missing\n",
    "for col in data_cols:\n",
    "    panel_df.loc[panel_df[col] < 0, col] = np.nan\n",
    "    panel_df.loc[panel_df[col] > 2e12, col] = np.nan\n",
    "\n",
    "# Confirm no negative values nor too large values\n",
    "for col in data_cols:\n",
    "    assert(0 <= np.nanmin(panel_df[col].values))\n",
    "    assert(2e12 >= np.nanmax(panel_df[col].values))\n",
    "\n",
    "# Drop duplicated rows across id columns\n",
    "panel_df = panel_df.drop_duplicates(subset=['date', 'cmc_id'])\n",
    "\n",
    "# Sort values and reset index\n",
    "panel_df = panel_df.sort_values(by=['date', 'cmc_id'], \n",
    "                                ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "999675b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE\n",
    "panel_df = panel_df.merge(cmc_df,\n",
    "                          on=['date', 'cmc_id'],\n",
    "                          how='left',\n",
    "                          validate='one_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "91596266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN CW\n",
    "\n",
    "# Convert column names\n",
    "cw_df = cw_df.rename(columns = {'cmc_symbol': 'symbol_cmc',\n",
    "                                'name': 'name_cmc',\n",
    "                                'cmc_slug': 'slug_cmc'})\n",
    "\n",
    "# Drop columns from crosswalk\n",
    "cw_df = cw_df[['cmc_id', 'symbol_cmc', 'name_cmc', 'slug_cmc']]\n",
    "\n",
    "# Confirm ID column is unique\n",
    "assert(cw_df.shape[0] == len(np.unique(cw_df.cmc_id.values)))\n",
    "\n",
    "# Sort values and reset index\n",
    "cw_df = cw_df.sort_values(by='cmc_id', ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "682d5a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN MACRO VARS\n",
    "\n",
    "# Clean date column\n",
    "ex_df['date'] = pd.to_datetime(ex_df.date, format='%Y-%m-%d', utc=False).dt.date\n",
    "macro_df['date'] = pd.to_datetime(macro_df.date, format='%Y-%m-%d', utc=False).dt.date\n",
    "\n",
    "# Reshape exchange volume and market pairs from long to wide\n",
    "us_ex = ['binance-us', 'coinbase-exchange', 'ftx-us',  'gemini', 'kraken', 'kucoin']\n",
    "ex_df = ex_df[~((ex_df.exchange_volume_24h == -1) & (ex_df.num_market_pairs == -1))].reset_index(drop=True)\n",
    "\n",
    "ex_df = ex_df.merge(ex_covar_df[['exchange_id', 'exchange_slug']],\n",
    "                    how='inner',\n",
    "                    on='exchange_id',\n",
    "                    validate='many_to_one')\n",
    "ex_df = ex_df.drop('exchange_id', axis=1)\n",
    "ex_df = ex_df[ex_df.exchange_slug.isin(us_ex)]\n",
    "ex_df = ex_df.rename(columns={'exchange_volume_24h': 'volume_24h'})\n",
    "ex_df = ex_df[~ex_df.exchange_slug.isin(['b2bx', 'dodo', 'demex'])]\n",
    "ex_vol_df = ex_df.pivot(index='date', columns='exchange_slug', values='volume_24h').reset_index()\n",
    "ex_pairs_df = ex_df.pivot(index='date', columns='exchange_slug', values='num_market_pairs').reset_index()\n",
    "ex_vol_df = ex_vol_df.rename(columns={'binance-us': 'exchange_volume_binance_us_cmc',\n",
    "                                      'coinbase-exchange': 'exchange_volume_coinbase_cmc',\n",
    "                                      'ftx-us': 'exchange_volume_ftx_us_cmc',\n",
    "                                      'gemini': 'exchange_volume_gemini_cmc',\n",
    "                                      'kraken': 'exchange_volume_kraken_cmc',\n",
    "                                      'kucoin': 'exchange_volume_kucoin_cmc'})\n",
    "ex_pairs_df = ex_pairs_df.rename(columns={'binance-us':        'exchange_pairs_binance_us_cmc',\n",
    "                                          'coinbase-exchange': 'exchange_pairs_coinbase_cmc',\n",
    "                                          'ftx-us': 'exchange_pairs_ftx_us_cmc',\n",
    "                                          'gemini': 'exchange_pairs_gemini_cmc',\n",
    "                                          'kraken': 'exchange_pairs_kraken_cmc',\n",
    "                                          'kucoin': 'exchange_pairs_kucoin_cmc'})\n",
    "ex_final_df = ex_vol_df.merge(ex_pairs_df,\n",
    "                              on='date', \n",
    "                              how='outer',\n",
    "                              validate='one_to_one')\n",
    "\n",
    "# Add CMC to macro column names\n",
    "col_names = list(macro_df.columns.values)\n",
    "col_names.remove('date')\n",
    "for col in col_names:\n",
    "    macro_df = macro_df.rename(columns={col:col+'_cmc'})\n",
    "    \n",
    "# Merge together\n",
    "final_macro_df = macro_df.merge(ex_final_df,\n",
    "                                on='date',\n",
    "                                how='outer',\n",
    "                                validate='one_to_one')\n",
    "\n",
    "# Confirm no rows are missing all observations\n",
    "assert(final_macro_df.shape[0] == final_macro_df.dropna(how='all').shape[0])\n",
    "\n",
    "# Confirm it is unique on date\n",
    "assert(len(np.unique(final_macro_df.date.values)) == final_macro_df.shape[0])\n",
    "\n",
    "# Convert date column\n",
    "final_macro_df['date'] = pd.to_datetime(final_macro_df.date, format='%Y-%m-%d', utc=False)\n",
    "\n",
    "# Drop earlier than 2015 or later than 2021\n",
    "final_macro_df = final_macro_df[final_macro_df.date.dt.year >= 2015]\n",
    "final_macro_df = final_macro_df[final_macro_df.date.dt.year <= 2021]\n",
    "\n",
    "# Sort and reset index\n",
    "final_macro_df = final_macro_df.sort_values(by='date', ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2a9a50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE PANEL AND CW DATA TO DERIVED\n",
    "panel_df.to_pickle('../3-data/derived/cmc_panel.pkl')\n",
    "cw_df.to_pickle('../3-data/derived/cmc_cw.pkl')\n",
    "final_macro_df.to_pickle('../3-data/derived/cmc_macro.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02d2ac1",
   "metadata": {},
   "source": [
    "## (2) Clean CMC BTC and ETH data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f6e8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f6572669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN DATA\n",
    "\n",
    "df            = pd.read_csv('../3-data/raw/cmc_price_vol_mcap_btceth.csv')\n",
    "cmc_covars_df = pd.read_csv('../3-data/raw/cmc_token_covars_btceth.csv')\n",
    "macro_df      = pd.read_csv('../3-data/raw/cmc_macro_timeseries_btceth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b0657535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_153159/2930331424.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  btc_df[col] = btc_df[col].interpolate(limit_direction='forward', axis=0, method='cubic')\n",
      "/tmp/ipykernel_153159/2930331424.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eth_df[col] = eth_df[col].interpolate(limit_direction='forward', axis=0, method='cubic')\n"
     ]
    }
   ],
   "source": [
    "# CLEAN PANEL \n",
    "\n",
    "# Make panel data unique on the ID columns\n",
    "df = df[df.index.isin(df[['date', 'cmc_id']].drop_duplicates().index)]\n",
    "cmc_covars_df = cmc_covars_df[cmc_covars_df.index.isin(cmc_covars_df[['date', 'cmc_id']].drop_duplicates().index)]\n",
    "\n",
    "# Merge panel data together\n",
    "cmc_df = df.merge(cmc_covars_df,\n",
    "                  on=['date', 'cmc_id'],\n",
    "                  how='outer',\n",
    "                  validate='one_to_one')\n",
    "\n",
    "# Rename columns to standard convention (with data source name in it)\n",
    "cmc_df   = cmc_df.rename(columns = {'usd_per_token': 'usd_per_token_cmc',\n",
    "                                    'usd_mcap': 'usd_mcap_cmc',\n",
    "                                    'usd_volume_24h': 'usd_volume_24h_cmc',\n",
    "                                    'num_market_pairs': 'num_market_pairs_cmc', \n",
    "                                    'circulating_supply': 'circulating_supply_cmc'})\n",
    "\n",
    "# Ensure data has all dates and token IDs\n",
    "first_date = np.min(cmc_df.date)\n",
    "last_date  = np.max(cmc_df.date)\n",
    "dates = list(pd.date_range(first_date, last_date, freq='D').strftime('%Y-%m-%d'))\n",
    "ids   = np.repeat(np.array([1, 1027]), len(cmc_df)/2)\n",
    "full_id_df = pd.DataFrame(data={'date': np.concatenate((dates, dates)), 'cmc_id': ids})\n",
    "cmc_df = cmc_df.merge(full_id_df,\n",
    "                      on=['date', 'cmc_id'],\n",
    "                      how='outer', \n",
    "                      validate='one_to_one')\n",
    "\n",
    "# Sort values and reset index\n",
    "cmc_df = cmc_df.sort_values(by=['date', 'cmc_id'], \n",
    "                            ignore_index=True)\n",
    "\n",
    "# Ensure correct date type\n",
    "cmc_df['date'] = pd.to_datetime(cmc_df['date'], format='%Y-%m-%d', utc=False)\n",
    "\n",
    "# Clean missing values\n",
    "btc_df = cmc_df[cmc_df.cmc_id==1]\n",
    "btc_df.loc[btc_df.date==np.min(btc_df.date), 'num_market_pairs_cmc'] = 1000\n",
    "eth_df = cmc_df[cmc_df.cmc_id==1027]\n",
    "eth_df.loc[eth_df.date==np.min(eth_df.date), 'num_market_pairs_cmc'] = 1000\n",
    "cols = list(cmc_df.columns.values)\n",
    "cols.remove('date')\n",
    "cols.remove('cmc_id')\n",
    "for col in cols:\n",
    "    btc_df[col] = btc_df[col].interpolate(limit_direction='forward', axis=0, method='cubic')\n",
    "    eth_df[col] = eth_df[col].interpolate(limit_direction='forward', axis=0, method='cubic')\n",
    "cmc_df = pd.concat((btc_df, eth_df))\n",
    "cmc_df = cmc_df.sort_values(by=['date', 'cmc_id'])\n",
    "\n",
    "# Confirm no missings in the df\n",
    "assert(cmc_df.isnull().sum().values.sum() == 0)\n",
    "\n",
    "# Set column order\n",
    "cmc_df = cmc_df[['date', 'cmc_id', \n",
    "                 'usd_per_token_cmc', 'usd_mcap_cmc', 'usd_volume_24h_cmc',\n",
    "                 'num_market_pairs_cmc', 'circulating_supply_cmc']]\n",
    "\n",
    "# Sort values and reset index\n",
    "cmc_df = cmc_df.sort_values(by=['date', 'cmc_id'], \n",
    "                            ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "afa601b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN MACRO VARS\n",
    "\n",
    "# Clean date column\n",
    "macro_df['date'] = pd.to_datetime(macro_df.date, format='%Y-%m-%d', utc=False)\n",
    "\n",
    "# Add CMC to macro column names\n",
    "col_names = list(macro_df.columns.values)\n",
    "col_names.remove('date')\n",
    "for col in col_names:\n",
    "    macro_df = macro_df.rename(columns={col:col+'_cmc'})\n",
    "    \n",
    "# Ensure it has all dates\n",
    "first_date = np.min(macro_df.date)\n",
    "last_date  = np.max(macro_df.date)\n",
    "dates = list(pd.date_range(first_date, last_date, freq='D'))\n",
    "dates_df = pd.DataFrame(data={'date': dates})\n",
    "macro_df   = macro_df.merge(dates_df,\n",
    "                            on=['date'],\n",
    "                            how='outer', \n",
    "                            validate='one_to_one')\n",
    "macro_df = macro_df.sort_values('date').reset_index(drop=True)\n",
    "cols = list(macro_df.columns.values)\n",
    "cols.remove('date')\n",
    "for col in cols:\n",
    "    macro_df[col] = macro_df[col].interpolate(limit_direction='forward', axis=0, method='cubic')\n",
    "    \n",
    "# Confirm no missings in the df\n",
    "assert(macro_df.isnull().sum().values.sum() == 0)\n",
    "\n",
    "# Confirm it is unique on date\n",
    "assert(len(np.unique(macro_df.date.values)) == macro_df.shape[0])\n",
    "\n",
    "# Sort and reset index\n",
    "macro_df = macro_df.sort_values(by='date', ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c13c7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE PANEL AND CW DATA TO DERIVED\n",
    "cmc_df.to_pickle('../3-data/derived/cmc_btceth_panel.pkl')\n",
    "macro_df.to_pickle('../3-data/derived/cmc_btceth_macro.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
