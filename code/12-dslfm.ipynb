{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab026fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to use the quantools, due to my crap path names have to add to sys path\n",
    "import sys\n",
    "sys.path.insert(0, '/home/adam/Dropbox/2-creations/2-crafts/7-buidl/0-utils/quant_tools/code')\n",
    "\n",
    "# IMPORT PACKAGES\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.decomposition import PCA\n",
    "from typing import Dict, List, Tuple\n",
    "from joblib import Parallel, delayed\n",
    "import pandas_datareader as pdr\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from tools import QuantTools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44edf457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsetAndNormalizeChars(df: pd.DataFrame, lhs_col: str, first_year: int) -> pd.DataFrame:\n",
    "   # drop unneeded data to reduce T\n",
    "   df = df[df.date.dt.year >= first_year].copy()\n",
    "\n",
    "   # Set characteristics of interest  \n",
    "   selected_rhs = ['char_tx_volume_tm7',\n",
    "      'char_addr_active_tm7',\n",
    "      'char_age_destroyed_tm7',\n",
    "      'char_delta_flow_dist_tm7',\n",
    "      'char_delta_holders_dist_tm7',\n",
    "      'char_prct_supply_in_profit_t',\n",
    "      'char_exchange_inflow_tm7',\n",
    "      'char_exchange_outflow_tm7',\n",
    "      'char_num_pairs_t',\n",
    "      'char_social_volume_tm7',\n",
    "      'char_social_volume_reddit_tm7',\n",
    "      'char_social_volume_twitter_tm7',\n",
    "      'char_sent_pos_reddit_tm7',\n",
    "      'char_sent_pos_twitter_tm7',\n",
    "      'char_sent_neg_reddit_tm7',\n",
    "      'char_sent_neg_twitter_tm7',\n",
    "      'char_r_tm7',\n",
    "      'char_r_tm14',\n",
    "      'char_r_tm90',\n",
    "      'char_r_tm90_tm30',\n",
    "      'char_r_ath_t',\n",
    "      'char_r_atl_t',\n",
    "      'char_r_industry_tm30',\n",
    "      'char_r_industry_tm60',\n",
    "      'char_trades_sum_tm7',\n",
    "      'char_volume_sum_tm7',\n",
    "      'char_spread_bps_t',\n",
    "      'char_ask_size_t',\n",
    "      'char_bid_size_t',\n",
    "      'char_illiq_tm7',\n",
    "      'char_turnover_tm7',\n",
    "      'char_size_t',\n",
    "      'char_alpha_tm7',\n",
    "      'char_alpha_tm30',\n",
    "      'char_beta_tm7',\n",
    "      'char_beta_tm30',\n",
    "      'char_coskew_tm30',\n",
    "      'char_iskew_tm30',\n",
    "      'char_shortfall5_tm7',\n",
    "      'char_var5_tm7',\n",
    "      'char_vol_tm7',\n",
    "      'char_vol_tm30',\n",
    "      'char_vol_tm90']\n",
    "\n",
    "   # Cut to characteristics columns of interest\n",
    "   df = df[['date', 'asset', lhs_col]+selected_rhs]\n",
    "\n",
    "   # Normalize characteristics to be between 0 and 1.\n",
    "   for col in selected_rhs:\n",
    "      df[col] = (df.groupby('date')[col].rank() - 1) / (df.groupby('date')[col].transform('count') - 1)\n",
    "   assert 0 == df[selected_rhs].min().min()\n",
    "   assert 1 == df[selected_rhs].max().max()\n",
    "\n",
    "   return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b145887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLasso(Y: np.ndarray, X: np.ndarray, penalty: float) -> np.ndarray:\n",
    "    # perform lasso\n",
    "    lasso = Lasso(alpha = penalty)\n",
    "    lasso.fit(X, Y)\n",
    "    \n",
    "    # return fitted coefficients\n",
    "    return lasso.coef_\n",
    "\n",
    "def calcPenaltyBCCH(Y: np.ndarray, X: np.ndarray, c: float) -> float:\n",
    "    ''' This function applies Belloni, Chen, Chernozhukov, Hansen 2012 ECMA\n",
    "        closed-form solution for selecting Lasso penalty parmaeter.\n",
    "\n",
    "    Args: \n",
    "        X (np.ndarray): RHS variables with rows of obs and covar_cols of covars.\n",
    "                        These data include a constant but have yet to be\n",
    "                        normalized for lasso.\n",
    "        Y (np.ndarray): LHS variable with rows of obs and single column.\n",
    "        c (float):    scalar constant from theory; usually ~1.\n",
    "\n",
    "    Returns:\n",
    "        penalty (float): BCCH penalty parameter.\n",
    "    '''\n",
    "    # Bickel Ritov Tsybakov constant parameter selection\n",
    "    a = 0.1\n",
    "\n",
    "    # calc pilot penalty parameter\n",
    "    N = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    max_moment_xy = np.max(np.mean((X**2)*(Y**2), axis =0)**0.5) \n",
    "    penalty_pilot = 2*c*norm.ppf(1-a/(2*p))*max_moment_xy/np.sqrt(N)\n",
    "\n",
    "    # run lasso with pilot penalty parameter\n",
    "    beta_hat = runLasso(Y, X, penalty_pilot)\n",
    "    \n",
    "    # set BCCH penalty parameter\n",
    "    residuals = Y - np.matmul(X, beta_hat).reshape(-1,1)\n",
    "    max_moment_xepi = np.max(np.mean((X**2)*(residuals**2), axis =0)**0.5) \n",
    "    penalty = 2*c*norm.ppf(1-a/(2*p))*max_moment_xepi/np.sqrt(N)\n",
    "\n",
    "    return penalty\n",
    "\n",
    "def runOLS(Y: np.ndarray, X: np.ndarray) -> np.ndarray:\n",
    "    ''' Runs OLS of Y on X to return fitted coefficients.\n",
    "\n",
    "    Args: \n",
    "        X (np.ndarray): RHS--assumes contains constant--with rows of obs and covar_cols of covars.\n",
    "        Y (np.ndarray): LHS variable with rows of obs and single column.\n",
    "\n",
    "    Returns:\n",
    "        beta_hat (np.ndarray): vector of fitted coefficients.\n",
    "    '''\n",
    "    if np.linalg.matrix_rank(X) < min(X.shape):\n",
    "        num_cols_to_drop = int(X.shape[1] * 0.5)\n",
    "        X = X[:, :-num_cols_to_drop]\n",
    "        \n",
    "        if np.linalg.matrix_rank(X) < min(X.shape):\n",
    "            num_cols_to_drop = int(X.shape[1] * 0.5)\n",
    "            X = X[:, :-num_cols_to_drop]\n",
    "            if np.linalg.matrix_rank(X) < min(X.shape):\n",
    "                print(X.shape)\n",
    "\n",
    "                raise ValueError(\"Matrix is still singular after dropping columns.\")\n",
    "    \n",
    "    return np.matmul(np.linalg.inv(np.matmul(np.transpose(X), X)),\n",
    "                        np.matmul(np.transpose(X), Y))\n",
    "\n",
    "def runDoubleSelectionLasso(Y: np.ndarray, D: np.ndarray, X: np.ndarray, c: float,\n",
    "    selected_prct_upper: float=0.3, selected_prct_lower: float=0.05) -> float:\n",
    "    ''' Runs Double Selection Lasso from Belloni et al (2014).\n",
    "\n",
    "    Args: \n",
    "        Y (np.ndarray): LHS variable with rows of obs and single column.\n",
    "        D (np.ndarray): RHS target variable with rows of obs and single column.\n",
    "        X (np.ndarray): RHS controls with rows of obs and p cols of characteristics.\n",
    "        c (float): scalar constant from theory; usually ~1.\n",
    "        selected_prct_upper (float): upper bound on number of columns selected.\n",
    "        selected_prct_lower (float): lower bound on number of columns selected.\n",
    "    \n",
    "    Returns:\n",
    "        alpha_hat (float): estimated target coefficient.\n",
    "    '''\n",
    "    # initialize a percent selected outside range\n",
    "    selected_prct_cols = 1\n",
    "\n",
    "    while ((selected_prct_cols > selected_prct_upper) \n",
    "        | (selected_prct_cols < selected_prct_lower)):\n",
    "        # update scalar constant\n",
    "        if (selected_prct_cols > selected_prct_upper):\n",
    "            c = 1.1*c\n",
    "        else:\n",
    "            c = 0.9*c\n",
    "\n",
    "        # lasso of Y on D and X to select elements of X, I_1_hat\n",
    "        X_all = np.hstack((D,X))\n",
    "        beta_hat_1 = runLasso(Y, X_all, penalty=calcPenaltyBCCH(Y, X_all, c=c))\n",
    "\n",
    "        # lasso of D on X to select elements of X, I_2_hat\n",
    "        beta_hat_2 = runLasso(D, X, penalty=calcPenaltyBCCH(D, X, c=c))\n",
    "\n",
    "        # form union of I_1_hat and I_2_hat\n",
    "        i_1_hat = list(np.nonzero(beta_hat_1)[0] -1 ) # NOTE: subtracting 1 as we added the treatment var to RHS\n",
    "        if -1 in i_1_hat: i_1_hat.remove(-1) # remove treatment variable if it was included\n",
    "        i_2_hat = list(np.nonzero(beta_hat_2)[0])\n",
    "        i_hat   = list(set(i_1_hat).union(set(i_2_hat)))\n",
    "\n",
    "        # update percent of columns that were selected\n",
    "        selected_prct_cols = len(i_hat) / X.shape[1]\n",
    "\n",
    "    # OLS of Y on D plus included Xs\n",
    "    X_sel    = X[:,i_hat]\n",
    "    X_all    = np.hstack((D, X_sel))\n",
    "    beta_hat = runOLS(Y, X_all)\n",
    "    alpha_hat = beta_hat[0,0]\n",
    "\n",
    "    # return target parameter on D\n",
    "    return alpha_hat\n",
    "\n",
    "def fitBaiPCA(\n",
    "    matrix: np.ndarray, T: int, k: int, p: int\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # Calculate the scaling factor\n",
    "    scaling_factor = 1 / (T * p)\n",
    "\n",
    "    # Form the target, symmetric, positive semi-definite matrix\n",
    "    target_matrix = scaling_factor * (matrix @ matrix.T)\n",
    "\n",
    "    # Calculate eigenvalues and vectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(target_matrix)\n",
    "\n",
    "    # Calculate factors and loadings\n",
    "    factors = np.sqrt(T) * eigenvectors[:, -k:][:, ::-1]\n",
    "    loadings = (matrix.T @ factors) / T\n",
    "\n",
    "    # Confirm factors are scaled appropriately\n",
    "    identity = (factors.T @ factors) / T\n",
    "    assert(np.isclose(k, np.sum(np.abs(np.diagonal(identity)))))\n",
    "\n",
    "    return factors, loadings\n",
    "\n",
    "def softThresholdRows(matrix, sparse_prct=0.2):\n",
    "    \"\"\" Implement ell_1 soft thresholding across rows of the given matrix. \"\"\"\n",
    "    dim2 = matrix.shape[1]\n",
    "    ell_1_norm_rows = np.sum(np.abs(matrix), axis=1)\n",
    "    lmbd = np.quantile(ell_1_norm_rows, 1-sparse_prct)\n",
    "    row_mask = 1*(ell_1_norm_rows > lmbd)\n",
    "    mat_mask = np.repeat(row_mask, dim2).reshape(-1, dim2)\n",
    "    return matrix*mat_mask\n",
    "\n",
    "def fitDSLFM(R: List[np.ndarray], Z: List[np.ndarray],\n",
    "    k: int, p: int, c: float, num_cpus: int, sparse_prct: float=0.2) -> tuple:\n",
    "    # Figure out number cpus to use for outer and inner loops assuming we have at least 4\n",
    "    assert(num_cpus >= 4)\n",
    "    n_jobs_outer = int(num_cpus / 4)\n",
    "    n_jobs_inner = 4\n",
    "\n",
    "    # Determine number of time periods\n",
    "    T = len(R)\n",
    "\n",
    "    def runForEachCharacteristic(j):\n",
    "        # form indices\n",
    "        minus_j = list(range(p))\n",
    "        minus_j.remove(j)\n",
    "        \n",
    "        def runForEachTimePeriod(t):\n",
    "            # form, for this rhs var j, this time periods LHS, target, and controls\n",
    "            Y = R[t].reshape(-1,1)\n",
    "            D = Z[t][:,j].reshape(-1,1)\n",
    "            X = Z[t][:,minus_j]\n",
    "\n",
    "            # estimate c_{t,j}, i.e. target coef\n",
    "            c_t_j = runDoubleSelectionLasso(Y, D, X, c)\n",
    "\n",
    "            return c_t_j\n",
    "\n",
    "        C_t_hat = Parallel(n_jobs=n_jobs_inner)(delayed(runForEachTimePeriod)(t) for t in range(T))\n",
    "        \n",
    "        return C_t_hat\n",
    "\n",
    "    # Estimate C hat matrix\n",
    "    C_hat = Parallel(n_jobs=n_jobs_outer)(delayed(runForEachCharacteristic)(j) for j in range(p))\n",
    "    C_hat = np.array(C_hat).transpose()\n",
    "\n",
    "    # Demean C_hat for this version of the estimators\n",
    "    C_hat_d = C_hat - np.mean(C_hat, axis=0)\n",
    "\n",
    "    # Use PCA to decompose C_hat into estimated factors and loadings\n",
    "    factors_hat, loadings_hat = fitBaiPCA(C_hat, T, k, p)\n",
    "    Gamma_beta_hat = loadings_hat\n",
    "\n",
    "    # Use PCA to decompose C_hat_d into estimated factors V and loadings \\G_\\b^d\n",
    "    factors_v_hat, loadings_d_hat = fitBaiPCA(C_hat_d, T, k, p)\n",
    "\n",
    "    # Soft threshold Gamma beta hat and Gamma_beta_d_hat\n",
    "    Gamma_beta_check = softThresholdRows(Gamma_beta_hat, sparse_prct)\n",
    "\n",
    "    return Gamma_beta_hat, factors_hat, Gamma_beta_check, factors_v_hat\n",
    "\n",
    "def predictDSLFM(df: pd.DataFrame, lhs_col: str, char_cols: List[str], oos_date: str, window: int,\n",
    "    gamma_beta_check: np.ndarray, factors_hat: np.ndarray):\n",
    "    # Confirm parameters are valid\n",
    "    assert (window <= len(factors_hat)) # rolling avg window is less than length of factors\n",
    "\n",
    "    # Build rhs\n",
    "    z = df[df.date==oos_date][char_cols].values\n",
    "    lambda_hat = factors_hat[-window:,:].mean(axis=0)\n",
    "\n",
    "    # Predict\n",
    "    yhats = z @ gamma_beta_check @ lambda_hat\n",
    "\n",
    "    # Build output data\n",
    "    out_df = df[df.date == oos_date][['date', 'asset', lhs_col]]\n",
    "    out_df['yhats'] = yhats\n",
    "\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a88773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvDSLFM(df: pd.DataFrame, lhs_col: str, val_start_date: str, test_start_date: str,\n",
    "    num_factors: int, asset_universe_dict: Dict[str, str], num_cpus: int,\n",
    "    periods_in_year: int, num_qntls_prtls: int, cv_out_fp: str) -> List[dict]:\n",
    "    # Obtain char col names and set p\n",
    "    cols = list(df.columns.values)\n",
    "    for col in ['date', 'asset', lhs_col]:\n",
    "        cols.remove(col)\n",
    "    char_cols = cols.copy()\n",
    "    p = len(char_cols)\n",
    "\n",
    "    # Remove unneeded data\n",
    "    df = df[df.date < test_start_date].copy()\n",
    "\n",
    "    # Initilize cv results object\n",
    "    cv_results_lst = []\n",
    "\n",
    "    # Determine val datetimes to loop over\n",
    "    val_dates = list(df[df.date >= val_start_date].date.unique())\n",
    "\n",
    "    # Form hps to iterate over\n",
    "    hp_grid = {'C': [0.05], \n",
    "        'window': [20, 25, 30, 35],\n",
    "        'st': [0.05, 0.1, 0.15, 0.2, 0.25]}\n",
    "\n",
    "    # Loop over hp combinations\n",
    "    keys = hp_grid.keys()\n",
    "    values = hp_grid.values()\n",
    "    hp_combos = list(itertools.product(*values))\n",
    "    for hps in hp_combos:\n",
    "        # Start the timer\n",
    "        tic = time.perf_counter()\n",
    "\n",
    "        # Create hp dictionary and other objects for this iteration\n",
    "        hps_dict = dict(zip(keys, hps))\n",
    "        hps_results_dict = hps_dict.copy()\n",
    "        val_y_yhats_df = pd.DataFrame()\n",
    "\n",
    "        # Report on progress\n",
    "        print(hps_dict)\n",
    "\n",
    "        # Loop over val dates\n",
    "        for val_date in val_dates:\n",
    "            # Monitor progress\n",
    "            print(val_date)\n",
    "\n",
    "            # Obtain all train dates before this val date\n",
    "            train_datetimes = list(df[df.date < val_date].date.unique())\n",
    "\n",
    "            # Form appropriate asset universe\n",
    "            first_day_of_month_for_current_val_dt = np.datetime_as_string(val_date, unit='M')+'-01'\n",
    "            asset_universe = asset_universe_dict[first_day_of_month_for_current_val_dt]\n",
    "\n",
    "            # Subset to asset universe\n",
    "            val_df = df[df.asset.isin(asset_universe)].copy()\n",
    "\n",
    "            # Form necessary matrices of data to fit and predict on\n",
    "            R = []\n",
    "            Z = []\n",
    "            for train_date in train_datetimes:\n",
    "                R.append(val_df[val_df.date==train_date][lhs_col].values)\n",
    "                Z.append(val_df[val_df.date==train_date][char_cols].values)\n",
    "\n",
    "            # Fit DSLFM\n",
    "            (gamma_beta_hat, factors_hat, gamma_beta_check, factors_v_hat) = fitDSLFM(\n",
    "                R, Z, num_factors, p, hps_dict['C'], num_cpus, hps_dict['st'])\n",
    "            \n",
    "            # Predict DSLFM \n",
    "            temp_y_yhats_df = predictDSLFM(val_df, lhs_col, char_cols, val_date, hps_dict['window'], gamma_beta_check, factors_hat)\n",
    "\n",
    "            # Save this week's results\n",
    "            val_y_yhats_df = pd.concat([val_y_yhats_df, temp_y_yhats_df])\n",
    "        \n",
    "        # Stop the timer after this hp grid point is completed\n",
    "        toc = time.perf_counter()\n",
    "\n",
    "        # Obtain validation period results\n",
    "        val_yhats      = val_y_yhats_df.yhats.values\n",
    "        val_ys         = val_y_yhats_df[lhs_col].values\n",
    "        val_y_yhats_pos_df = QuantTools.formPortfolioWeightsByQuantile(val_y_yhats_df, num_qntls_prtls)\n",
    "        val_y_yhats_pos_df['returns'] = val_y_yhats_pos_df.prtfl_wght_hml*val_y_yhats_pos_df[lhs_col]\n",
    "        returns = (val_y_yhats_pos_df.groupby('date')['returns'].sum().values)\n",
    "\n",
    "        # Add results to dict\n",
    "        hps_results_dict['train-start_year']    = np.min(df.date.dt.year)\n",
    "        hps_results_dict['num_factors']    = num_factors\n",
    "        hps_results_dict['runtime']        = round((toc - tic)/60, 0)\n",
    "        hps_results_dict['val_mse']        = QuantTools.calcMSE(val_ys, val_yhats)\n",
    "        hps_results_dict['val_r2_pred']    = QuantTools.calcR2Pred(val_ys, val_yhats)\n",
    "        hps_results_dict['geom_mean']      = QuantTools.calcGeomAvg(returns)\n",
    "        hps_results_dict['sharpe_annual']  = QuantTools.calcSharpe(returns, periods_in_year=periods_in_year)\n",
    "        hps_results_dict['sd_annual']      = QuantTools.calcSD(returns, periods_in_year=periods_in_year)\n",
    "        \n",
    "        # Save results to return\n",
    "        cv_results_lst.append(hps_results_dict)\n",
    "\n",
    "        # For this hp, save results to csv\n",
    "        cv_df = pd.DataFrame(cv_results_lst)\n",
    "        timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        fp = cv_out_fp + '-' + timestr + '.csv'\n",
    "        cv_df.to_csv(fp, index=False)\n",
    "\n",
    "    return cv_results_lst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5553684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectOptHps(cv_results_lst: List[dict]) -> dict:\n",
    "    best_sharpe = -2\n",
    "    for hps_dict in cv_results_lst:\n",
    "        if hps_dict['sharpe_annual'] > best_sharpe:\n",
    "            best_sharpe = hps_dict['sharpe_annual']\n",
    "            opt_hps_dict = hps_dict\n",
    "\n",
    "    return opt_hps_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "956f2879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOOS(df: pd.DataFrame, lhs_col: str, test_start_date: str, num_factors: int,\n",
    "    asset_universe_dict: dict, num_cpus: int, opt_hps_dict: dict) -> tuple:\n",
    "    # Initialize objects for results\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    # Obtain char col names\n",
    "    cols = list(df.columns.values)\n",
    "    for col in ['date', 'asset', lhs_col]:\n",
    "        cols.remove(col)\n",
    "    char_cols = cols.copy()\n",
    "\n",
    "    # Set p\n",
    "    p = len(char_cols)\n",
    "\n",
    "    # Determine test dates to loop over\n",
    "    test_dates = list(df[df.date >= test_start_date].date.unique())\n",
    "\n",
    "    # Loop over test dates\n",
    "    for test_date in test_dates:\n",
    "        # Monitor progress\n",
    "        print(test_date)\n",
    "        \n",
    "        # Obtain all train dates before this test date\n",
    "        train_datetimes = list(df[df.date < test_date].date.unique())\n",
    "\n",
    "        # Form appropriate asset universe\n",
    "        first_day_of_month_for_current_val_dt = np.datetime_as_string(test_date, unit='M')+'-01'\n",
    "        asset_universe = asset_universe_dict[first_day_of_month_for_current_val_dt]\n",
    "\n",
    "        # Subset to asset universe\n",
    "        oos_df = df[df.asset.isin(asset_universe)].copy()\n",
    "\n",
    "        # Form necessary matrices of data to fit and predict on\n",
    "        R = []\n",
    "        Z = []\n",
    "        for train_date in train_datetimes:\n",
    "            R.append(oos_df[oos_df.date==train_date][lhs_col].values)\n",
    "            Z.append(oos_df[oos_df.date==train_date][char_cols].values)\n",
    "        \n",
    "        # Fit DSLFM\n",
    "        (gamma_beta_hat, factors_hat, gamma_beta_check, factors_v_hat) = fitDSLFM(\n",
    "            R, Z, num_factors, p, opt_hps_dict['C'], num_cpus)\n",
    "        \n",
    "        # Predict DSLFM \n",
    "        temp_y_yhats_df = predictDSLFM(oos_df, lhs_col, char_cols, test_date, opt_hps_dict['window'], gamma_beta_check, factors_hat)\n",
    "        \n",
    "        # Save this week's results\n",
    "        test_df = pd.concat([test_df, temp_y_yhats_df])\n",
    "\n",
    "    return test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2e7a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reportOOSResults(\n",
    "    df: pd.DataFrame, lhs_col: str,\n",
    "    num_factors: int, num_qntls_prtls: int, periods_in_year: int, model_prefix: str,\n",
    "    out_fp: str, out_sheet: str, mcap_weighted: bool\n",
    "    ) -> None:\n",
    "    # Initialize results to return\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    # Generate results for each model\n",
    "    for num_factor in range(1,1+num_factors):\n",
    "        # Rename model's yhats and name\n",
    "        df = df.rename(columns={'yhats_'+str(num_factor)+'_factors': 'yhats'})\n",
    "        model_name =  model_prefix+str(num_factor)\n",
    "\n",
    "        # Generate this model's portfolio statistics\n",
    "        temp_results_df = QuantTools.calcPortfolioStatistics(\n",
    "            df, lhs_col, 'yhats', 'macro_cmkt_tp7', model_name, \n",
    "            num_qntls_prtls, periods_in_year, mcap_weighted\n",
    "        )\n",
    "\n",
    "        # Append results\n",
    "        results_df = pd.concat([results_df, temp_results_df])\n",
    "        \n",
    "        # Update yhat labels for next iteration\n",
    "        df = df.rename(columns={'yhats': 'yhats_'+str(num_factor)+'_factors'})\n",
    "\n",
    "    # Save the results\n",
    "    with pd.ExcelWriter(out_fp, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer: \n",
    "        results_df.to_excel(writer, sheet_name=out_sheet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e862625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genBootstrapCharImportResults(df: pd.DataFrame, \n",
    "    lhs_col: str, asset_universe_dict: dict, opt_hps_dict: dict, \n",
    "    out_fp: str, num_cpus: int, num_bs_samps: int=200) -> None:\n",
    "    # Obtain hps\n",
    "    num_factors = opt_hps_dict['num_factors']\n",
    "    C = opt_hps_dict['C']\n",
    "\n",
    "    # Obtain char col names\n",
    "    cols = list(df.columns.values)\n",
    "    for col in ['date', 'asset', lhs_col]:\n",
    "        cols.remove(col)\n",
    "    char_cols = cols.copy()\n",
    "\n",
    "    # Prepare data\n",
    "    p = len(char_cols)\n",
    "    asset_universe = asset_universe_dict['2022-12-01']\n",
    "    df = df[df.asset.isin(asset_universe)]\n",
    "    train_datetimes = list(df.date.unique())\n",
    "    R = []\n",
    "    Z = []\n",
    "    for train_date in train_datetimes:\n",
    "        R.append(df[df.date==train_date][lhs_col].values)\n",
    "        Z.append(df[df.date==train_date][char_cols].values)\n",
    "\n",
    "    # gen given number of bootstrap samples\n",
    "    gamma_beta_hats = []\n",
    "    for bs in range(num_bs_samps):\n",
    "        # Randomly sample what dates to fit on\n",
    "        np.random.seed(bs)\n",
    "        bs_weeks_indices = np.random.randint(0, len(train_datetimes), len(train_datetimes))\n",
    "        R_bs = [R[i] for i in bs_weeks_indices]\n",
    "        Z_bs = [Z[i] for i in bs_weeks_indices]\n",
    "\n",
    "        # Fit DSLFM\n",
    "        (gamma_beta_hat, factors_hat, gamma_beta_check, factors_v_hat) = fitDSLFM(\n",
    "            R_bs, Z_bs, num_factors, p, C, num_cpus)\n",
    "        \n",
    "        # Save results\n",
    "        gamma_beta_hats.append(gamma_beta_hat)\n",
    "\n",
    "    # form results df\n",
    "    results_df = pd.DataFrame(data={'char': char_cols})\n",
    "\n",
    "    # calc point est\n",
    "    summed_chars_gamma_beta_hats = [np.sum(np.square(gamma_beta_hat), axis=1) \n",
    "                                for gamma_beta_hat in gamma_beta_hats]\n",
    "    point_ests_per_bs = np.vstack(summed_chars_gamma_beta_hats)\n",
    "    assert (num_bs_samps == point_ests_per_bs.shape[0])\n",
    "    estimates_arr = np.mean(point_ests_per_bs, axis=0)\n",
    "        \n",
    "    # calc se\n",
    "    ses_arr = np.std(point_ests_per_bs, axis=0)\n",
    "\n",
    "    # format estimate for output\n",
    "    t_stat_arr = estimates_arr / ses_arr\n",
    "    estimates_list = []\n",
    "    for i in range(len(estimates_arr)):\n",
    "        t_stat = t_stat_arr[i]\n",
    "        if np.abs(t_stat) > 2.576:\n",
    "            estimate_str = str(estimates_arr[i])+\"***\"\n",
    "        elif np.abs(t_stat) > 1.96:\n",
    "            estimate_str = str(estimates_arr[i])+\"**\"\n",
    "        elif np.abs(t_stat) > 1.645:\n",
    "            estimate_str = str(estimates_arr[i])+\"*\"\n",
    "        else:\n",
    "            estimate_str = str(estimates_arr[i])    \n",
    "        estimates_list.append(estimate_str)\n",
    "\n",
    "    # add results\n",
    "    results_df['est'] = estimates_list\n",
    "    results_df['se'] = ses_arr\n",
    "\n",
    "    # sort\n",
    "    results_df = results_df.sort_values('est', ascending=False)\n",
    "\n",
    "    # save results\n",
    "    with pd.ExcelWriter(out_fp, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer: \n",
    "        results_df.to_excel(writer, sheet_name='raw_char_imp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff6f9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtainExpInflationDf(week_dts: np.ndarray, inf_col: str='EXPINF10YR') -> pd.DataFrame:\n",
    "    # obtain data\n",
    "    ei_df = pdr.DataReader(inf_col, 'fred', '2017-01-01').reset_index()\n",
    "\n",
    "    # clean up data\n",
    "    ei_df = ei_df.rename(columns={'DATE': 'date'})\n",
    "\n",
    "    # convert to weekly rate from annual\n",
    "    ei_df[inf_col] = (1+ei_df[inf_col]/100)**(1/52)-1 \n",
    "\n",
    "    # convert to weekly freq and interpolate to fill missing\n",
    "    ei_df = ei_df.merge(pd.DataFrame(data={'date': week_dts}),\n",
    "                on='date', how='outer', validate='one_to_one')\n",
    "    ei_df = ei_df.sort_values(by='date', ascending=True)\n",
    "    ei_df[inf_col] = ei_df[inf_col].interpolate(method='linear')\n",
    "\n",
    "    # keep only dts in og data\n",
    "    ei_df = ei_df[ei_df.date.isin(list(week_dts))]\n",
    "\n",
    "    # convert to pct change\n",
    "    ei_df = ei_df.set_index('date')\n",
    "    ei_df = ei_df.pct_change()\n",
    "    ei_df = ei_df.fillna(0)\n",
    "    ei_df = ei_df.reset_index()\n",
    "\n",
    "    return ei_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "164f2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAsympVar(Z: list, Z_bar: np.ndarray, ob_factor: np.ndarray, factors_v_hat: np.ndarray,\n",
    "    gamma_beta_hat: np.ndarray, gamma_hat: np.ndarray, eta_hat: np.ndarray, \n",
    "    T: int, k: int, p: int):\n",
    "    # Reshape\n",
    "    gamma_hat = gamma_hat.reshape(-1, 1)\n",
    "    eta_hat   = eta_hat.reshape(-1, 1)\n",
    "    \n",
    "    # Calculate the residuals from the time series OLS\n",
    "    residuals = ob_factor.reshape(-1,1) - np.matmul(factors_v_hat, eta_hat)\n",
    "\n",
    "    # Calculate the Z_t_j_jprime scalar\n",
    "    Z_tjjp = np.zeros((T,p,p))\n",
    "    for t in range(T):\n",
    "        for j in range(p):\n",
    "            zitj_bar = np.mean(Z[t][:,j])\n",
    "            Z_tjjp[t, j, :] = (Z[t]*zitj_bar).mean(axis=0)\n",
    "            Z_tjjp[t, j, :] *= (Z[t].shape[0])**(-1)\n",
    "\n",
    "    Z_tjjp *= (T)**(-1)\n",
    "\n",
    "    # Calculate the Pi_t scalar\n",
    "    Pi = np.zeros((T,k,k))\n",
    "    for t in range(T):\n",
    "        Pi_t = 0\n",
    "        for j in range(p):\n",
    "            for jp in range(p):\n",
    "                gamma_beta_jp = gamma_beta_hat[jp,:]\n",
    "                gamma_beta_j  = gamma_beta_hat[j,:]\n",
    "                Pi_t += gamma_beta_jp @ gamma_beta_j.T * Z_tjjp[t,j,jp]\n",
    "        Pi[t] = Pi_t\n",
    "\n",
    "    # Calc the components of asymp matrix\n",
    "    Phi_11 = T**(-1) * (factors_v_hat.T @ residuals) @ (residuals.T @ factors_v_hat)\n",
    "\n",
    "    Phi_22 = np.zeros((k,k))\n",
    "    for t in range(T):\n",
    "        for tp in range(T):\n",
    "            Phi_22 += Pi[t,:,:] @ factors_v_hat[t,:] * factors_v_hat[tp,:].T @ Pi[tp,:,:].T\n",
    "    Phi_22 *= T**(-1)\n",
    "\n",
    "    Phi_12 = np.zeros((k,k))\n",
    "    for t in range(T):\n",
    "        for tp in range(T):\n",
    "            Phi_12 += factors_v_hat[t,:] * residuals[t] * factors_v_hat[tp,:].T @ Pi[tp,:,:].T\n",
    "    Phi_12 *= T**(-1)\n",
    "\n",
    "    # Calc design matrices\n",
    "    A = (factors_v_hat.T @ factors_v_hat) / T\n",
    "\n",
    "    B = (gamma_beta_hat.T @ Z_bar.T @ Z_bar @ gamma_beta_hat) / Z_bar.shape[0]\n",
    "\n",
    "    # Calculate the target variance\n",
    "    gamma_hat = gamma_hat.reshape(-1, 1)\n",
    "    eta_hat   = eta_hat.reshape(-1, 1)\n",
    "    sigma_g_2 = (gamma_hat.T @ np.linalg.inv(A) @ Phi_11 @ np.linalg.inv(A.T) @ gamma_hat\n",
    "                    + eta_hat.T @ np.linalg.inv(B) @ Phi_22 @ np.linalg.inv(B.T) @ eta_hat\n",
    "                    + gamma_hat.T @ np.linalg.inv(A) @ Phi_12 @ np.linalg.inv(B.T) @ eta_hat\n",
    "                    + eta_hat.T @ np.linalg.inv(B) @ Phi_12.T @ np.linalg.inv(A.T) @ gamma_hat)\n",
    "\n",
    "    return sigma_g_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc15b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infRiskPremium(df: pd.DataFrame, asset_universe_dict: dict,\n",
    "    lhs_col: str, inf_col: str, opt_hps_dict: dict, num_cpus: int) -> None:\n",
    "    # Obtain observable factor\n",
    "    week_dts = df.date.unique()\n",
    "    ob_df = obtainExpInflationDf(week_dts, inf_col)\n",
    "\n",
    "    # Obtain char col names and set p\n",
    "    cols = list(df.columns.values)\n",
    "    for col in ['date', 'asset', lhs_col]:\n",
    "        cols.remove(col)\n",
    "    char_cols = cols.copy()\n",
    "\n",
    "    # Set params\n",
    "    T = len(df.date.unique())\n",
    "    p = len(char_cols)\n",
    "    k = opt_hps_dict['num_factors']\n",
    "    C = opt_hps_dict['C']\n",
    "    soft_threshold_prct = opt_hps_dict['st']\n",
    "\n",
    "    # Calc Z bar\n",
    "    z_bar_list = []\n",
    "    assets = list(df.asset.unique())\n",
    "    for asset in assets:\n",
    "        asset_z_df = df[df.asset==asset][char_cols].values\n",
    "        asset_z_bar = np.mean(asset_z_df, axis=0)\n",
    "        z_bar_list.append(asset_z_bar)\n",
    "    Z_bar = np.vstack(z_bar_list)\n",
    "\n",
    "    # Obtain datetimes to fit over\n",
    "    train_datetimes = list(df.date.unique())\n",
    "\n",
    "    # Subset to asset universe\n",
    "    asset_universe = asset_universe_dict['2022-12-01']\n",
    "    train_df = df[df.asset.isin(asset_universe)].copy()\n",
    "\n",
    "    # Form necessary matrices of data to fit on\n",
    "    R = []\n",
    "    Z = []\n",
    "    for train_date in train_datetimes:\n",
    "        R.append(train_df[train_df.date==train_date][lhs_col].values)\n",
    "        Z.append(train_df[train_df.date==train_date][char_cols].values)\n",
    "\n",
    "    # Fit DSLFM\n",
    "    (gamma_beta_hat, factors_hat, gamma_beta_check, factors_v_hat) = fitDSLFM(\n",
    "        R, Z, k, p, C, num_cpus, soft_threshold_prct)\n",
    "\n",
    "    # Estimate risk premium\n",
    "    G = ob_df[inf_col].values\n",
    "    gamma_hat   = factors_hat.mean(axis=0)\n",
    "    eta_hat     = runOLS(G, factors_hat-gamma_hat)\n",
    "    gamma_g_hat = np.dot(eta_hat, gamma_hat)\n",
    "    gamma_g_var = calcAsympVar(Z, Z_bar, G, factors_hat-gamma_hat, gamma_beta_hat, gamma_hat, eta_hat, T, k, p)\n",
    "\n",
    "    # Output results\n",
    "    print(f\"Inflation risk premium: {gamma_g_hat}\")\n",
    "    print(f\"Standard error: {np.sqrt(gamma_g_var[0][0])}\")\n",
    "    print(f\"Number of time periods: {len(ob_df)}\")\n",
    "    print(f\"Number of assets: {Z_bar.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19b6bfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adam/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inflation risk premium: 0.00013824213421103075\n",
      "Standard error: 9.675459918701172e-08\n",
      "Number of time periods: 156\n",
      "Number of assets: 210\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # set args\n",
    "    IN_FP           = '../data/clean/panel_weekly.pkl'\n",
    "    ASSET_IN_FP     = '../data/clean/asset_universe_dict.pickle'\n",
    "    CV_OUT_FP       = '../output/high_dim_fm/dslfm_cv'\n",
    "    OUT_FP          = '../output/high_dim_fm/dslfm.xlsx'\n",
    "    LHS_COL         = 'r_ex_tp7'\n",
    "    VAL_START_DATE  = '2022-01-01'\n",
    "    TEST_START_DATE = '2022-07-01'\n",
    "    PERIODS_IN_YEAR = 52\n",
    "    NUM_QNTLS_PRTLS = 5\n",
    "    NUM_FACTORS     = 5\n",
    "    NUM_CPUS        = 20\n",
    "\n",
    "    # read in data\n",
    "    with open(ASSET_IN_FP, \"rb\") as f:\n",
    "        asset_universe_dict = pickle.load(f)\n",
    "    all_df = pd.read_pickle(IN_FP)\n",
    "\n",
    "    # subset to relevant data\n",
    "    df = subsetAndNormalizeChars(all_df, LHS_COL, 2020)\n",
    "\n",
    "    # form dataframe to use for reporting results\n",
    "    cmkt_df = all_df[['date', 'macro_cmkt_tm7']].drop_duplicates().copy()\n",
    "    cmkt_df['macro_cmkt_tp7'] = cmkt_df.macro_cmkt_tm7.shift(-1)\n",
    "    cmkt_df = cmkt_df.drop('macro_cmkt_tm7', axis=1)\n",
    "    mcap_df = all_df[['date', 'asset', 'char_mcap_t']].copy()\n",
    "    mcap_df = mcap_df[mcap_df.date >= TEST_START_DATE]\n",
    "    mcap_df = mcap_df.rename(columns={'char_mcap_t': 'mcap'})\n",
    "    aux_df = mcap_df.merge(cmkt_df, on=['date'], how='left', validate='many_to_one')\n",
    "    aux_df = aux_df.fillna(0.003) # NOTE: cmkt return last week of 2022\n",
    "    \n",
    "    # gen results for given number of factors\n",
    "    yhats_df = pd.DataFrame()\n",
    "    opt_hps_dicts = []\n",
    "    for num_factors in range(1,NUM_FACTORS+1):\n",
    "        # cv dslfm for optimal penalty param and predict oos\n",
    "        cv_results_lst = cvDSLFM(df, LHS_COL, VAL_START_DATE, TEST_START_DATE,\n",
    "            num_factors, asset_universe_dict, NUM_CPUS, PERIODS_IN_YEAR, NUM_QNTLS_PRTLS, CV_OUT_FP)\n",
    "        \n",
    "        # select optimal hp point\n",
    "        opt_hps_dict = selectOptHps(cv_results_lst)\n",
    "        opt_hps_dicts.append(opt_hps_dict)\n",
    "        \n",
    "        # gen oos results\n",
    "        test_df = predictOOS(df, LHS_COL, TEST_START_DATE, num_factors, asset_universe_dict, NUM_CPUS, opt_hps_dict)\n",
    "\n",
    "        # format oos results\n",
    "        test_df = test_df.rename(columns={'yhats': 'yhats_'+str(num_factors)+'_factors'})\n",
    "        if num_factors == 1:\n",
    "            yhats_df = test_df.copy()\n",
    "        else:\n",
    "            test_df = test_df.drop(LHS_COL, axis=1)\n",
    "            yhats_df = yhats_df.merge(test_df, on=['date', 'asset'], how='inner', validate='one_to_one')\n",
    "\n",
    "    # add aux data to yhats\n",
    "    yhats_df = yhats_df.merge(aux_df, on=['date', 'asset'], how='inner', validate='one_to_one')\n",
    "\n",
    "    # Report oos results\n",
    "    reportOOSResults(\n",
    "        yhats_df, LHS_COL, \n",
    "        NUM_FACTORS, NUM_QNTLS_PRTLS, PERIODS_IN_YEAR, \n",
    "        'dslfm_mcap_', OUT_FP, 'raw_oos_mcap', True)\n",
    "    reportOOSResults(\n",
    "        yhats_df, LHS_COL, \n",
    "        NUM_FACTORS, NUM_QNTLS_PRTLS, PERIODS_IN_YEAR, \n",
    "        'dslfm_equal_', OUT_FP, 'raw_oos_equal', False)\n",
    "    \n",
    "    # Obtain optimal results across factors\n",
    "    opt_hps_dict = selectOptHps(opt_hps_dicts)\n",
    "\n",
    "    # Gen char import\n",
    "    genBootstrapCharImportResults(df, LHS_COL, asset_universe_dict, opt_hps_dict, OUT_FP, NUM_CPUS) # NOTE: 1 HOUR RUNTIME\n",
    "\n",
    "    # Calculate inflation risk premium\n",
    "    infRiskPremium(df, asset_universe_dict, LHS_COL, 'EXPINF10YR', opt_hps_dict, NUM_CPUS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f14a76dcff07d5b93f2c0fc65ce65c8ac7788ddb1ef5c63daa3feefa016fa519"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
