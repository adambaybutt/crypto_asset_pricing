{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60883846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from coinmetrics.api_client import CoinMetricsClient\n",
    "import time\n",
    "import pickle\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import Dict, List\n",
    "import logging\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e16fe93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCmApiCall(base_url: str, endpoint: str, params: Dict[str, str], num_retries: int = 3) -> requests.Response:\n",
    "    \"\"\"\n",
    "    Makes an API call to the given endpoint with the given parameters.\n",
    "\n",
    "    Args:\n",
    "    - base_url (str): string representing the base URL for the API.\n",
    "    - endpoint (str): string representing the endpoint to call.\n",
    "    - params (Dict): dictionary containing the parameters for the API call.\n",
    "    - num_retries (int): integer representing the number of times to retry the API call in case of an error.\n",
    "\n",
    "    Returns:\n",
    "    - response (requests.Response): the response object from the API call.\n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/{endpoint}\"\n",
    "    retries = 0\n",
    "    while retries < num_retries:\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            if response.status_code == 403:\n",
    "                try:\n",
    "                    return params['metrics']\n",
    "                except:\n",
    "                    raise Exception(f\"Failed to make API call with response {response.status_code}.\")\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "        except requests.exceptions.Timeout as e:\n",
    "            logging.warning(f\"Timeout error occurred: {e}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.warning(f\"Request error occurred: {e}\")\n",
    "        retries += 1\n",
    "        if retries == 1:\n",
    "            time.sleep(1)\n",
    "        elif retries == 2:\n",
    "            time.sleep(20)\n",
    "    raise Exception(f\"Failed to make API call after {num_retries} retries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ca2afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formCoinmetricsAssetUniverse(client: CoinMetricsClient, cmc_assets_fp: str) -> pd.DataFrame:\n",
    "    \"\"\" map cmc universe to coinmetrics universe. \n",
    "    (1) pull all cm assets and open my universe of cmc assets.\n",
    "    (2) adjust cm asset names so they match to my cmc assets.\n",
    "    (3) merge asset ids together on both the cm asset id and the full name.\n",
    "    (4) clean the merged data.\n",
    "    (5) add assets from cm that should be in the universe but aren't in cmc.\n",
    "    (6) remove stablecoins and derivatives.\n",
    "\n",
    "    Args:\n",
    "        client (CoinMetricsClient): cm client object for pinging api.\n",
    "        cmc_assets_fp (str): filepath to cmc asset universe pickle.\n",
    "    \n",
    "    Returns:\n",
    "        merged_df (pd.DataFrame): dataframe of crosswalk between cmc id and cm id.    \n",
    "    \"\"\"\n",
    "    # import cmc token universe\n",
    "    with open(cmc_assets_fp, 'rb') as f:\n",
    "        cmc_asset_universe_dict = pickle.load(f)\n",
    "\n",
    "    # form unique cmc asset df\n",
    "    cmc_assets = []\n",
    "    for k, v in cmc_asset_universe_dict.items():\n",
    "        cmc_assets.extend(v)\n",
    "    cmc_assets = list(np.unique(np.array(cmc_assets)))\n",
    "    cmc_assets_df = pd.DataFrame(data={'asset_cmc': cmc_assets})\n",
    "\n",
    "    # pull all cm assets\n",
    "    full_asset_catalog = client.catalog_full_assets()\n",
    "    cm_assets_df = pd.DataFrame(full_asset_catalog)\n",
    "\n",
    "    # Check that the \"asset\" column is unique in both dataframes\n",
    "    assert (cmc_assets_df[\"asset_cmc\"].is_unique \n",
    "            and cm_assets_df[\"full_name\"].is_unique \n",
    "            and cm_assets_df['asset'].is_unique)\n",
    "\n",
    "    # remove duplicated cm asset; they have a data error\n",
    "    cm_assets_df = cm_assets_df[~cm_assets_df.asset.isin(['seed', 'tree', 'aurora'])]\n",
    "\n",
    "    # change cm full names before merge so they match cmc for known nonmatches\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='aave', 'full_name'] = 'aave-old'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='alpha', 'full_name'] = 'alpha-finance-lab'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='mco', 'full_name'] = 'crypto-com'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='fet', 'full_name'] = 'fetch'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='clv', 'full_name'] = 'clover'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='gno', 'full_name'] = 'gnosis-gno'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='glm', 'full_name'] = 'golem-network-tokens'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='hive', 'full_name'] = 'hive-blockchain'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='rook', 'full_name'] = 'keeperdao'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='yffii', 'full_name'] = 'yearn-finance-ii'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='btt', 'full_name'] = 'bittorrent'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='idex', 'full_name'] = 'aurora'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='egld', 'full_name'] = 'multiversx-egld'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='cfx', 'full_name'] = 'confluxnetwork'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='xch', 'full_name'] = 'chia-network'\n",
    "    cm_assets_df.loc[cm_assets_df.asset=='syn', 'full_name'] = 'synapse2'\n",
    "\n",
    "    # clean the asset names to just low case letters and numbers and merge\n",
    "    cmc_assets_df[\"asset_clean\"] = cmc_assets_df[\"asset_cmc\"].str.lower().str.replace(r\"[^a-zA-Z0-9]\", \"\")\n",
    "    cm_assets_df[\"asset_clean\"] = cm_assets_df[\"full_name\"].str.lower().str.replace(r\"[^a-zA-Z0-9]\", \"\")\n",
    "    merged_df = pd.merge(cmc_assets_df, cm_assets_df, \n",
    "                        on=\"asset_clean\", how='inner',\n",
    "                        validate='one_to_one')\n",
    "\n",
    "    # repeat but use the unique asset abbreviation id from cm\n",
    "    cm_assets_df[\"asset_clean\"] = cm_assets_df[\"asset\"].str.lower().str.replace(r\"[^a-zA-Z0-9]\", \"\")\n",
    "    merged_df2 = pd.merge(cmc_assets_df, cm_assets_df, \n",
    "                        on=\"asset_clean\", how='inner',\n",
    "                        validate='one_to_one')\n",
    "\n",
    "    # remove duplicated assets from the two merged dataframes and put them together\n",
    "    merged_df2 = merged_df2[~merged_df2.asset.isin(list(merged_df.asset.values))]\n",
    "    merged_df = pd.concat((merged_df, merged_df2))\n",
    "    assert merged_df.asset.is_unique\n",
    "\n",
    "    # clean up the merged data\n",
    "    merged_df = merged_df[['asset_cmc', 'asset']]\n",
    "    merged_df = merged_df.rename(columns={'asset': 'asset_cm'})\n",
    "    merged_df = merged_df.reset_index(drop=True)\n",
    "\n",
    "    # manually add to my universe of cm assets these assets to consider\n",
    "    assets_to_add = ['ape', 'apt', 'arpa', 'badger', 'bal', 'cake', 'cel', 'comp', 'cvx',\n",
    "        'dot', 'etc', 'fil', 'flr', 'flux', 'ftt', 'fun', 'gmx', 'grin', 'hnt',\n",
    "        'inv', 'knc', 'krl', 'luna', 'luna2', 'mir', 'multi', 'nft', 'nu', 'ocean', 'ohm',\n",
    "        'op', 'poly', 'qi', 'rndr', 'rpl', 'skl', 'snt', 'theta', 'tru', 'xdc', 'zrx']\n",
    "    merged_df = pd.concat((merged_df, pd.DataFrame(data={'asset_cmc': np.repeat(np.nan, len(assets_to_add)),\n",
    "                                                        'asset_cm': assets_to_add})))\n",
    "\n",
    "    # manually remove stables and derivatives\n",
    "    merged_df = merged_df[~merged_df.asset_cm.isin(['steth', 'wbtc', 'tusd', 'gusd', 'usdd', 'btcb'])]\n",
    "\n",
    "    # manually add in both aave old and new\n",
    "    merged_df = pd.concat((merged_df, pd.DataFrame(data={'asset_cmc': ['aave'],\n",
    "                                                        'asset_cm': ['aave']}))).reset_index(drop=True)\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a9aca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullAssetMetrics(client: CoinMetricsClient, base_url: str, base_params: dict, \n",
    "    cm_asset_universe: list, target_asset_metrics: list, num_retries=3):\n",
    "    \"\"\"\n",
    "    Pulls asset metrics for assets in the given asset universe using the given base URL and parameters.\n",
    "\n",
    "    Args:\n",
    "    - client (CoinMetricsClient): client object for interacting with the CM API.\n",
    "    - base_url: string representing the base URL for the API.\n",
    "    - base_params: dictionary containing the base parameters for the API call.\n",
    "    - cm_asset_universe: list of strings representing the assets to pull metrics for.\n",
    "    - target_asset_metrics: list of strings of asset metrics of interest.\n",
    "    - num_retries: integer representing the number of times to retry the API call in case of an error.\n",
    "\n",
    "    Returns:\n",
    "    - results_df: Pandas DataFrame containing the asset metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize dataframe to return results\n",
    "    results_df = pd.DataFrame(data={'asset': [], 'time': []})\n",
    "\n",
    "    # Pull all the metrics for all assets\n",
    "    asset_metrics_df = pd.DataFrame(client.catalog_full_assets())\n",
    "\n",
    "    # Cut down to CM universe\n",
    "    asset_metrics_df = asset_metrics_df[asset_metrics_df.asset.isin(cm_asset_universe)]\n",
    "    assert asset_metrics_df.asset.is_unique\n",
    "    assert asset_metrics_df.shape[0] == len(cm_asset_universe)\n",
    "    \n",
    "    # Define endpoint and parameters\n",
    "    endpoint = 'timeseries/asset-metrics'\n",
    "    params = base_params.copy()\n",
    "    params['page_size'] = 10000\n",
    "\n",
    "    # For every asset, pull all metrics available for this asset\n",
    "    for i in range(len(cm_asset_universe)):\n",
    "        # Update asset\n",
    "        asset = cm_asset_universe[i]\n",
    "\n",
    "        # Monitor progress\n",
    "        print(f\"Processing the {i+1}th asset ({(i+1)/len(cm_asset_universe)*100:.2f}%): {asset}\")\n",
    "\n",
    "        # Initialize object for this asset results\n",
    "        asset_results_df = pd.DataFrame(data={'asset': [], 'time': []})\n",
    "\n",
    "        # update parameters for this asset\n",
    "        params['assets'] = asset\n",
    "\n",
    "        # determine all metrics for this asset (skip if there aren't metrics for this asset)\n",
    "        metrics = asset_metrics_df[asset_metrics_df.asset==asset].metrics.values[0]\n",
    "        if type(metrics) is not list:\n",
    "            continue\n",
    "        metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "        # pull data for each metric\n",
    "        assert metrics_df.metric.is_unique\n",
    "        for metric in list(metrics_df.metric.values):\n",
    "            # Skip if not a metric of interest\n",
    "            if metric not in target_asset_metrics:\n",
    "                continue\n",
    "\n",
    "            # Print out the metric we are doing\n",
    "            print(f\"Working on metric: {metric}.\")\n",
    "\n",
    "            # form dataframe of the different frequency options for this metric\n",
    "            metric_options_df = pd.DataFrame(metrics_df[metrics_df.metric==metric].frequencies.values[0])\n",
    "\n",
    "            # Set frequency to 1d but report if it does not have a one day option and stop execution\n",
    "            if '1d' in list(metric_options_df.frequency.values):\n",
    "                frequency = '1d'\n",
    "            else:\n",
    "                print(metric_options_df)\n",
    "                print(f\"The metric {metric} for asset {asset} does not have a 1d frequency option.\")\n",
    "                continue\n",
    "        \n",
    "            # Set the start and end time for this frequency\n",
    "            start_time = metric_options_df[metric_options_df.frequency==frequency].min_time.values[0]\n",
    "            end_time = metric_options_df[metric_options_df.frequency==frequency].max_time.values[0]\n",
    "\n",
    "            # Update params for this metric and frequency\n",
    "            params['metrics'] = metric\n",
    "            params['frequency'] = frequency\n",
    "            params['start_time'] = start_time\n",
    "            params['end_time'] = end_time\n",
    "\n",
    "            # Make the API request\n",
    "            response = makeCmApiCall(base_url, endpoint, params)\n",
    "            if type(response)==str:\n",
    "                print(f'The metric {metric} is not available for my API key.')\n",
    "                continue\n",
    "            data = response.json()['data']\n",
    "            asset_df = pd.DataFrame(data)\n",
    "\n",
    "            # Confirm we obtained the expected number of obs\n",
    "            start_datetime = datetime.fromisoformat(start_time[:-7] + '+00:00')\n",
    "            end_datetime = datetime.fromisoformat(end_time[:-7]+ '+00:00')\n",
    "            num_days = (end_datetime - start_datetime).days\n",
    "            if asset_df.shape[0] < (num_days-1):\n",
    "                print(f\"Did not obtain expected number of days for {asset} {metric}; there were {num_days-asset_df.shape[0]} fewer days than expected.\")\n",
    "\n",
    "            # Add data to master dataframe\n",
    "            asset_results_df = asset_results_df.merge(asset_df, \n",
    "                                                        on=['asset', 'time'], \n",
    "                                                        how='outer', \n",
    "                                                        validate='one_to_one')\n",
    "            \n",
    "            # Space out the calls\n",
    "            time.sleep(5)\n",
    "\n",
    "        # Add this asset's results to the overall df\n",
    "        results_df = pd.concat((results_df, asset_results_df))\n",
    "\n",
    "        # Space out the calls across assets\n",
    "        time.sleep(10)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9951c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullFirstTradeDates(base_url: str, base_params: dict, \n",
    "    cm_asset_universe: list, legit_exchanges: list, num_retries: int=3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get the date of the first tradable market date for each asset in the given asset universe on legitimate exchanges.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_url: str\n",
    "        The base URL of the API endpoint to use.\n",
    "\n",
    "    base_params: dict\n",
    "        A dictionary containing the parameters to include in the API calls.\n",
    "\n",
    "    cm_asset_universe: list\n",
    "        A list of assets to find the first tradable market dates for.\n",
    "\n",
    "    legit_exchanges: list\n",
    "        A list of legitimate exchanges to include.\n",
    "\n",
    "    num_retries: int, default=3\n",
    "        The number of times to retry an API call if it fails.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the date of the first tradable market for each asset in the given asset universe on legitimate exchanges.\n",
    "    \"\"\"\n",
    "    # initialize dataframe to track these data with manually calc'ed dates for btc eth and usdt\n",
    "    asset_ft_df = pd.DataFrame(data={'asset': ['btc', 'eth', 'usdt'],\n",
    "                                    'date_first_tradable': ['2013-01-14', '2015-08-07', '2015-02-01']})\n",
    "\n",
    "    # initiate params for coming calls\n",
    "    params = base_params.copy()\n",
    "    endpoint = \"catalog-all/markets\"\n",
    "\n",
    "    for i in range(len(cm_asset_universe)):\n",
    "        # Update asset\n",
    "        asset = cm_asset_universe[i]\n",
    "\n",
    "        # Monitor progress\n",
    "        print(f\"Processing the {i+1}th asset ({(i+1)/len(cm_asset_universe)*100:.2f}%): {asset}\")\n",
    "\n",
    "        # skip if btc, eth, or usdt as too many markets; i did manually\n",
    "        if asset in ['btc', 'eth', 'usdt']:\n",
    "            continue\n",
    "\n",
    "        # determine the markets for this asset\n",
    "        asset_markets = asset_metrics_df[asset_metrics_df.asset==asset].markets.values[0]\n",
    "\n",
    "        # determine relevant markets that are spot and on relevant exchanges for this asset\n",
    "        rel_asset_markets = [m for m in asset_markets if (m.split(\"-\")[0] in legit_exchanges) & ('spot' in m)]\n",
    "\n",
    "        # obtain the market info for all of these markets\n",
    "        if len(rel_asset_markets) > 0:\n",
    "            # obtain the market info\n",
    "            params['markets'] = rel_asset_markets\n",
    "            response = makeCmApiCall(base_url, endpoint, params)\n",
    "            markets_info = response.json()['data']\n",
    "\n",
    "            # calculate the minimum date across these markets\n",
    "            min_date = datetime.utcnow().replace(tzinfo=pytz.utc)\n",
    "            for market in markets_info:\n",
    "                market_min_date = datetime.fromisoformat(market['min_time'][:-7] + '+00:00')\n",
    "                if market_min_date.year < 2012: # some dates are just straight wrong so try to avoid them here\n",
    "                    continue\n",
    "                if market_min_date < min_date:\n",
    "                    min_date = market_min_date\n",
    "            \n",
    "            # append this data\n",
    "            asset_ft_df = pd.concat((asset_ft_df, pd.DataFrame(data={'asset': [asset], \n",
    "                                                                    'date_first_tradable': [min_date.strftime('%Y-%m-%d')]})))\n",
    "                \n",
    "            # space out the calls\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # return\n",
    "    return asset_ft_df.sort_values(by='asset', ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee9e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # set parameters\n",
    "    cmc_assets_fp = \"../data/raw/cmc_asset_universe.pkl\"\n",
    "    cm_api_fp = '../../admin/coinmetrics.txt'\n",
    "    cw_fp = \"../data/raw/coinmetrics_cmc_cw.pkl\"\n",
    "    cm_asset_first_tradable_fp = '../data/raw/coinmetrics_assets_first_tradable.pkl'\n",
    "    panel_fp = \"../data/raw/coinmetrics_initial_panel.pkl\"\n",
    "    base_url = 'https://api.coinmetrics.io/v4/'\n",
    "    cm_assets_wo_markets = ['atb', 'bcy', 'bits_bitswift', 'botx', 'bps', 'btcd', 'btcp', 'bz', 'drop', 'dtb', 'gam', 'golos', 'inb',\n",
    "        'ino', 'ipc', 'lky', 'lmc', 'lrg', 'mcap', 'msp', 'net_nimiqexchangetoken', 'nxm', 'pnt_pnetwork', 'qau', 'qbit', 'rhoc', 'sjcx', \n",
    "        'thr', 'tio', 'tnc_tnccoin', 'usnbt', 'vrm', 'xbc', 'yoc']\n",
    "    cm_assets_wo_markets.extend(['1st', '2give', 'aby', 'adk', 'adt', 'aeon', 'banca', 'bay', 'bitb', 'bitcny',\n",
    "        'blk', 'block', 'bmc', 'bnk', 'brc', 'brk', 'bscpad', 'bsd_bitsend', 'bta',\n",
    "        'bto', 'btu', 'btx', 'c20', 'ccxx', 'cfi', 'cnx', 'con', 'cosm', 'cpx', 'crw',\n",
    "        'cure', 'dad', 'dcn', 'dct', 'ddd', 'dope', 'dpy', 'drg', 'dtr', 'dvi',\n",
    "        'eauric', 'eca', 'edr_endorprotocol', 'egc', 'elama', 'emc', 'eosdac', 'etz',\n",
    "        'excl', 'exp', 'fei', 'fldc', 'ftc', 'gard', 'geo', 'glc', 'gny', 'grc', 'hmq',\n",
    "        'hmr', 'hns', 'hoge', 'hst', 'html', 'hyn', 'idh', 'incnt', 'ink', 'ioc',\n",
    "        'ion', 'iop', 'ipx', 'jnt', 'kbc', 'krt', 'la', 'lbtc_lightningbitcoin',\n",
    "        'lcc', 'maro', 'med', 'min', 'mix', 'mnx', 'morph', 'mue', 'music', 'mxm',\n",
    "        'myst', 'nanj', 'next', 'nlc2', 'nlg', 'nvt', 'nxc', 'odn', 'ohm', 'ok', 'otn',\n",
    "        'part', 'peak', 'pink', 'plbt', 'plf', 'plr', 'pltc', 'pot', 'ppp', 'ptoy',\n",
    "        'qbt_qbao', 'qc', 'qrl', 'qwark', 'ret', 'rise', 'rox', 'rvr', 'safemoon',\n",
    "        'sent', 'shift', 'sib', 'slr', 'sls', 'smart', 'soul_phantasma', 'sphtx',\n",
    "        'ssx', 'stq', 'stx_stox', 'swt', 'swth', 'taas', 'taboo', 'ten', 'thc', 'tips',\n",
    "        'tix', 'tnc', 'tpay', 'tshp', 'tx', 'ubq', 'ukg', 'upp', 'val', 'vitae', 'vrc',\n",
    "        'xaur', 'xdn', 'xel', 'xmy', 'xsgd', 'xst', 'xtp', 'xwc', 'yffii', 'zcl', 'zlw',\n",
    "        'zrc', 'zsc', 'zyn'])\n",
    "    initial_asset_metrics = ['SplyAct1yr', 'SplyActEver', 'SplyCur', 'SplyFF', \n",
    "        'CapMrktCurUSD', 'CapMrktEstUSD', 'CapMrktFFUSD', 'CapRealUSD', 'ReferenceRateUSD']\n",
    "    legit_exchanges = ['binance', 'binance.us', 'bitfinex', 'coinbase', 'crypto.com', 'ftx', 'ftx.us',\n",
    "                   'gemini', 'huobi', 'kraken', 'kucoin', 'mt.gox', 'okex', 'poloniex', 'uniswap_v2_eth']\n",
    "\n",
    "    # TODO ONLY USE THESE EXCHANGES \n",
    "    LEGIT_US_EXCHANGES = ['BINANCEUS', 'BITSTAMP', 'COINBASE', 'CRYPTOCOM', 'FTXUS', \n",
    "                          'GEMINI', 'KRAKEN', 'KUCOIN', 'OKCOINUSD']\n",
    "    \n",
    "    # initialize client class\n",
    "    with open(cm_api_fp) as f:\n",
    "        API_KEY = f.readlines()\n",
    "        API_KEY = API_KEY[0].strip()\n",
    "    client = CoinMetricsClient(API_KEY)\n",
    "\n",
    "    # set up base parameters\n",
    "    base_params = {'api_key': API_KEY}\n",
    "\n",
    "    # obtain coinmetrics assets\n",
    "    cw_df = formCoinmetricsAssetUniverse(client, cmc_assets_fp)\n",
    "    cw_df.to_pickle(cw_fp)\n",
    "    cm_asset_universe = list(np.unique(cw_df[~cw_df.asset_cm.isnull()].asset_cm.values))\n",
    "    cm_asset_universe = [a for a in cm_asset_universe if a not in cm_assets_wo_markets]\n",
    "\n",
    "    # pull price, mcap, and supply metrics for assets in universe\n",
    "    asset_metrics_df = pullAssetMetrics(client, base_url, base_params, cm_asset_universe, initial_asset_metrics)\n",
    "    asset_metrics_df.to_pickle(panel_fp)\n",
    "\n",
    "    # pull first date for assets\n",
    "    asset_df = pullFirstTradeDates(base_url, base_params, cm_asset_universe, legit_exchanges)\n",
    "    asset_df.to_pickle(cm_asset_first_tradable_fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295cd38c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Jun  1 2022, 11:38:51) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e428bc405edc59f3352e9792cab27c5e28560f7efb4b47308a6c6ea38cd15df2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
