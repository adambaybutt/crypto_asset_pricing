{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from typing import List, Dict, Optional\n",
    "from helper_functions import Helper\n",
    "import requests\n",
    "from itertools import chain\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateYearlyCalendarYearDateList(time_start: str, time_end: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generates a list of dates in the format '%Y-%m-%d' representing the first day of each year between \n",
    "    the given start and end dates (inclusive).\n",
    "\n",
    "    Args:\n",
    "    - time_start (str): start date in the format '%Y-%m-%d'.\n",
    "    - time_end (str): end date in the format '%Y-%m-%d'.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: a list of dates in the format '%Y-%m-%d' representing the first day of each year \n",
    "      between the given start and end dates (inclusive).\n",
    "    \"\"\"\n",
    "    # Convert start and end dates to datetime objects\n",
    "    start_date = datetime.strptime(time_start, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(time_end, '%Y-%m-%d')\n",
    "\n",
    "    # Calculate the difference between the years of the start and end dates\n",
    "    year_diff = end_date.year - start_date.year\n",
    "\n",
    "    # Generate list of dates based on the difference in years\n",
    "    if year_diff == 0:\n",
    "        dates = [time_start, time_end]\n",
    "    elif year_diff > 0:\n",
    "        dates = [time_start]\n",
    "        for i in range(year_diff):\n",
    "            dates.append(datetime(start_date.year + 1 + i, 1, 1).strftime('%Y-%m-%d'))\n",
    "        dates.append(time_end)\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findUniqueAssets(asset_universe_dict: Dict[str, List[str]]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Determine the unique assets in the universe and return them as a sorted list.\n",
    "\n",
    "    Args:\n",
    "        asset_universe_dict (dict): A dictionary where the keys are the first date of each month\n",
    "            in the study period and and the values are lists of assets for that month.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of unique assets.\n",
    "    \"\"\"\n",
    "    # Flatten the lists of assets and create a set to ensure uniqueness.\n",
    "    unique_assets = set(chain.from_iterable(asset_universe_dict.values()))\n",
    "\n",
    "    # Convert the set to a list and sort it.\n",
    "    sorted_unique_assets = sorted(list(unique_assets))\n",
    "\n",
    "    return sorted_unique_assets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullMarketInfo(base_url: str, base_headers: Dict[str, str], target_exchanges: List[str], target_assets: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame containing information about coinapi markets that are on a target exchange with\n",
    "        USD or stablecoin quote asset.\n",
    "\n",
    "    Args:\n",
    "        base_url: A string representing the base URL of the CoinAPI service.\n",
    "        base_headers: A dictionary representing the headers to be sent with the API request.\n",
    "        target_exchanges: A list of strings with the target exchanges for this study.\n",
    "        target_assets: A list of strings with the target assets for this study.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame containing information about cryptocurrency markets.\n",
    "    \"\"\"\n",
    "    # Build target URL\n",
    "    target_url = 'symbols'\n",
    "    url        = f\"{base_url}{target_url}\"\n",
    "    headers    = base_headers.copy()\n",
    "\n",
    "    # Call API and convert to DataFrame\n",
    "    response_json = Helper.makeApiCall(url, headers=headers)\n",
    "    df = pd.DataFrame(response_json)\n",
    "\n",
    "    # subset to exchanges of interest\n",
    "    df = df[df.exchange_id.isin(target_exchanges)]\n",
    "\n",
    "    # clean columns\n",
    "    df['data_start'] = pd.to_datetime(df.data_start)\n",
    "    df['data_end'] = pd.to_datetime(df.data_end)\n",
    "    df['duration_days'] = (df.data_end - df.data_start).dt.days\n",
    "\n",
    "    # subset to assets of interest\n",
    "    df = df[df.symbol_type=='SPOT'] # spot markets\n",
    "    df = df[df.asset_id_quote.isin(['USD', 'USDC', 'USDT'])] # quote asset is fiat USD or stablecoin USD\n",
    "    df = df.dropna(subset=['data_start', 'data_end'])  # have data\n",
    "    df = df[df.duration_days > 120] # have at least four months of data\n",
    "    target_date = pd.Timestamp('2022-09-01')\n",
    "    df = df[df.data_start <= target_date] # have at least four months of data in target window\n",
    "\n",
    "    # remove symbols that are derivatives of other symbols or stablecoins\n",
    "    assets_to_remove = ['WBTC', 'WLUNA', 'WNXM', 'TBTC', 'CUSD', 'MUSD', 'NUSD', 'DAI', 'BUSD', 'CUSDT', \n",
    "        'GUSD', 'LUSD', 'OUSD', 'USDJ', 'USDK', 'USDN', 'USDT', 'USDC', 'AOA', 'AUSD', 'ERN', 'KRW', 'MTL', \n",
    "        'TUSD', 'SUSD', 'USDD', 'UST', 'USTC', 'EUR', 'AUD', 'GBP', 'CAD', 'CBETH', 'LBP', 'SOS']\n",
    "    df = df[~df.asset_id_base.isin(assets_to_remove)]\n",
    "    df = df[~df.asset_id_base.str.contains('3L|3S')]\n",
    "\n",
    "    # subset to target assets if list is given\n",
    "    if target_assets is not None:\n",
    "        df = df[df.asset_id_base.isin(target_assets)]\n",
    "\n",
    "    return df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullExchangeRates(base_url: str, base_headers: Dict[str, str], target_assets: List[str],\n",
    "                      target_freq: str, time_start: str, time_end: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame containing prices of usdc and usdt.\n",
    "\n",
    "    Args:\n",
    "        base_url: A string representing the base URL of the CoinAPI service.\n",
    "        base_headers: A dictionary representing the headers to be sent with the API request.\n",
    "        target_assets: A list of strings of assets included in this study.\n",
    "        target_freq: A string of the frequency to pull data for; either '1DAY' or '1HRS'.\n",
    "        time_start: A string of format '%Y-%m-%d' of the date for the study start.\n",
    "        time_end: A string of format '%Y-%m-%d' of the date for the study end.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame containing usdt and usdc price timeserieses.\n",
    "    \"\"\"\n",
    "    # set params\n",
    "    assert target_freq in ['1HRS', '1DAY']\n",
    "    headers = base_headers.copy()\n",
    "    params = {'period_id': target_freq, 'limit': 10000}\n",
    "\n",
    "    # initialize data frame for the results\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # loop over assets to pull\n",
    "    for i in range(len(target_assets)):\n",
    "        # update asset to pull\n",
    "        asset = target_assets[i]\n",
    "\n",
    "        # report how many assets completed\n",
    "        print(f\"Processing asset #{i+1} ({(i+1)/len(target_assets)*100:.2f}%): {asset}\")\n",
    "\n",
    "        # make the call\n",
    "        url = url = f\"{base_url}exchangerate/{asset}/USD/history\"\n",
    "        if target_freq == '1DAY': # if the request is at daily level then make it\n",
    "            params['time_start'] = time_start\n",
    "            params['time_end'] = time_end\n",
    "            response_json = Helper.makeApiCall(url, headers=headers, params=params)\n",
    "            asset_df = pd.DataFrame(response_json)\n",
    "        elif target_freq == '1HRS': # if at hourly level break into calendar year requests and append\n",
    "            asset_df = pd.DataFrame()\n",
    "            time_list = generateYearlyCalendarYearDateList(time_start, time_end)\n",
    "            for j in range(len(time_list)-1):\n",
    "                params['time_start'] = time_list[j]\n",
    "                params['time_end']   = time_list[j+1]\n",
    "                response_json = Helper.makeApiCall(url, headers=headers, params=params)\n",
    "                temp_df = pd.DataFrame(response_json)\n",
    "                asset_df = pd.concat((asset_df, temp_df))\n",
    "\n",
    "        # clean the exchange rate df for the given asset\n",
    "        asset_df = asset_df[asset_df.rate_close!=0] # remove invalid prices\n",
    "        asset_df = asset_df[asset_df.time_period_end.str[:2]=='20'] # remove broken dates\n",
    "        asset_df['date'] = pd.to_datetime(asset_df.time_period_end, utc=True).dt.tz_localize(None)\n",
    "        asset_df['usd_per_token_ref'] = asset_df.rate_close\n",
    "        asset_df = asset_df[['date', 'usd_per_token_ref']]\n",
    "\n",
    "        # ensure asset data is present for all dates \n",
    "        asset_df.set_index('date', inplace=True)\n",
    "        if target_freq == '1DAY':\n",
    "            date_range = pd.date_range(start=asset_df.index.min(), end=asset_df.index.max(), freq='D')\n",
    "        elif target_freq == '1HRS':\n",
    "            date_range = pd.date_range(start=asset_df.index.min(), end=asset_df.index.max(), freq='H')\n",
    "        asset_df = asset_df.reindex(date_range)\n",
    "        asset_df['usd_per_token_ref'] = asset_df.usd_per_token_ref.ffill()\n",
    "\n",
    "        # ensure stablecoins are in valid range \n",
    "        if asset in ['USDC', 'USDT']:\n",
    "            asset_df.loc[asset_df.usd_per_token_ref>2, 'usd_per_token_ref'] = np.nan\n",
    "            asset_df.loc[asset_df.usd_per_token_ref<0.5, 'usd_per_token_ref'] = np.nan\n",
    "            asset_df['usd_per_token_ref'] = asset_df.usd_per_token_ref.ffill()\n",
    "\n",
    "        # final clean\n",
    "        asset_df = asset_df.reset_index()\n",
    "        asset_df = asset_df.rename(columns={'index': 'date'})\n",
    "        asset_df['asset'] = asset\n",
    "        asset_df = asset_df[['date', 'asset', 'usd_per_token_ref']]\n",
    "\n",
    "        # ensure no missing values\n",
    "        assert 0 == asset_df.isnull().sum().sum()\n",
    "\n",
    "        # append\n",
    "        df = pd.concat((df, asset_df))\n",
    "\n",
    "    return df.sort_values(by='date', ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullMarketData(base_url: str, base_headers: Dict[str, str], markets_list: List[str], macro_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a panel DataFrame containing market prices, volumes, and trade counts.\n",
    "\n",
    "    Args:\n",
    "        base_url: A string representing the base URL of the CoinAPI service.\n",
    "        base_headers: A dictionary representing the headers to be sent with the API request.\n",
    "        markets_list: A list of strings of market names to pull.\n",
    "        macro_df: A Pandas DataFrame containing usdt and usdc price timeserieses.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame panel of dates and markets with their usd_per_token prices, \n",
    "            usd_volume_per_24h, and trades.\n",
    "    \"\"\"\n",
    "    # set up object to store all\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # set up args\n",
    "    params = {'period_id': '1DAY', \n",
    "              'time_start': '2015-01-01T00:00:00',\n",
    "              'time_end': '2023-02-02T00:00:00',\n",
    "              'include_empty_items': True,\n",
    "              'limit': 4000}\n",
    "\n",
    "    # pull all markets\n",
    "    for i in range(len(markets_list)):\n",
    "        # update market to pull\n",
    "        market = markets_list[i]\n",
    "\n",
    "        # monitor progress\n",
    "        print(f\"Processing market #{i+1} ({(i+1)/len(markets_list)*100:.2f}%): {market}\")\n",
    "\n",
    "        # make the call\n",
    "        url = f\"{base_url}ohlcv/{market}/history\"\n",
    "        headers = base_headers.copy()\n",
    "        response_json = Helper.makeApiCall(url, headers=headers, params=params)\n",
    "\n",
    "        # catch if there is no data\n",
    "        try:\n",
    "            # clean the market_df\n",
    "            market_df = pd.DataFrame(response_json)\n",
    "            market_df['symbol_id'] = market\n",
    "            market_df = market_df[['symbol_id', 'time_period_end', 'price_close', 'volume_traded', 'trades_count']]\n",
    "\n",
    "            # save data\n",
    "            df = pd.concat((df, market_df))\n",
    "        except:\n",
    "            print(f\"{market} did not have data\")\n",
    "            continue\n",
    "\n",
    "    # remove asset-dates where there is a missing price and zero volume\n",
    "    df = df[~(df.price_close.isnull() & (df.volume_traded==0) & (df.trades_count==0))]\n",
    "\n",
    "    # extract names of exchange, base asset, and quote asset\n",
    "    df['exchange'] = df['symbol_id'].str.split('_', n=4, expand=True)[0]\n",
    "    df['asset_id'] = df['symbol_id'].str.split('_', n=4, expand=True)[2]\n",
    "    df['quote_id'] = df['symbol_id'].str.split('_', n=4, expand=True)[3]\n",
    "\n",
    "    # form the date column\n",
    "    df['date'] = pd.to_datetime(df.time_period_end, format='%Y-%m-%d').dt.date\n",
    "    df = df.drop(columns='time_period_end', axis=1)\n",
    "\n",
    "    # merge on usdt and usdc prices\n",
    "    df = df.merge(macro_df, on='date', how='left', validate='many_to_one')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # form the price column\n",
    "    df.loc[df.quote_id=='USD', 'usd_per_token_coinapi'] = df.loc[df.quote_id=='USD', 'price_close']\n",
    "    df.loc[df.quote_id=='USDC', 'usd_per_token_coinapi'] = df.loc[df.quote_id=='USDC', 'price_close']*df.loc[df.quote_id=='USDC', 'usd_per_usdc']\n",
    "    df.loc[df.quote_id=='USDT', 'usd_per_token_coinapi'] = df.loc[df.quote_id=='USDT', 'price_close']*df.loc[df.quote_id=='USDT', 'usd_per_usdt']\n",
    "    assert 0 == df.usd_per_token_coinapi.isnull().sum()\n",
    "\n",
    "    # form volume column\n",
    "    df['usd_volume_per_24h_coinapi'] = df.volume_traded*df.usd_per_token_coinapi\n",
    "    assert 0 == df.usd_volume_per_24h_coinapi.isnull().sum()\n",
    "\n",
    "    # collapse to the asset date level\n",
    "    df.loc[df.usd_volume_per_24h_coinapi==0, 'usd_volume_per_24h_coinapi'] = 1\n",
    "    grouped = df.groupby(['date', 'asset_id'])\n",
    "    weighted_avg = grouped.apply(lambda x: (x['usd_per_token_coinapi'] * x['usd_volume_per_24h_coinapi']).sum() / x['usd_volume_per_24h_coinapi'].sum())\n",
    "    total_volume = grouped['usd_volume_per_24h_coinapi'].sum()\n",
    "    total_trades = grouped['trades_count'].sum()\n",
    "    df = pd.DataFrame({'usd_per_token_coinapi': weighted_avg, \n",
    "                       'usd_volume_per_24h_coinapi': total_volume, \n",
    "                       'trades_count': total_trades}).reset_index()\n",
    "    df.loc[df.usd_volume_per_24h_coinapi==1, 'usd_volume_per_24h_coinapi'] = 0\n",
    "\n",
    "    # check for valid ranges and dtypes\n",
    "    assert 0 == df.usd_per_token_coinapi.isnull().sum()\n",
    "    assert 0 == df.usd_volume_per_24h_coinapi.isnull().sum()\n",
    "    df = df[(df['usd_per_token_coinapi'] >= 0) & (df['usd_per_token_coinapi'] < 1e9)]\n",
    "    df = df[(df['usd_volume_per_24h_coinapi'] >= 0) & (df['usd_volume_per_24h_coinapi'] < 1e11)]\n",
    "    df = df[(df['trades_count'] >= 0) & (df['trades_count'] < 1e9)]\n",
    "\n",
    "    # ensure dtypes are set\n",
    "    df['usd_per_token_coinapi'] = df['usd_per_token_coinapi'].astype('float32')\n",
    "    df['usd_volume_per_24h_coinapi'] = df['usd_volume_per_24h_coinapi'].astype('float32')\n",
    "    df['trades_count'] = df['trades_count'].astype('float32')\n",
    "\n",
    "    # ensure panel is sorted\n",
    "    df = df.sort_values(by=['date', 'asset_id'], ignore_index=True)\n",
    "    df['date'] = pd.to_datetime(df.date)\n",
    "\n",
    "    # initialize a new df\n",
    "    final_df = pd.DataFrame(data={'date': [], 'asset_id': [], 'usd_per_token_coinapi': [], 'usd_volume_per_24h_coinapi': [], 'trades_count': []})\n",
    "\n",
    "    # loop over all assets to add missing days\n",
    "    assets = list(np.unique(df.asset_id.values))\n",
    "    for asset in assets:\n",
    "        # subset to asset of interest\n",
    "        asset_df = df[df.asset_id==asset].copy()\n",
    "\n",
    "        # determine the date gaps\n",
    "        date_gaps = []\n",
    "        dates = asset_df.date.values\n",
    "        for i in range(1, len(dates)):\n",
    "            date_gaps.append(np.timedelta64(dates[i]-dates[i-1], 'D').astype(int))\n",
    "\n",
    "        # determine new days to add\n",
    "        indices_to_expand = [i for i in range(len(date_gaps)) if (date_gaps[i] > 1) & (date_gaps[i] < 32)]\n",
    "        num_days_to_add = [date_gaps[i] for i in range(len(date_gaps)) if (date_gaps[i] > 1) & (date_gaps[i] < 32)]\n",
    "        start_days = dates[indices_to_expand]\n",
    "        new_days = []\n",
    "        for i in range(len(start_days)):\n",
    "            start_day = start_days[i]\n",
    "            days_to_add = num_days_to_add[i]\n",
    "            for j in range(1, days_to_add):\n",
    "                new_days.append(start_day+np.timedelta64(24*(j), 'h'))\n",
    "        \n",
    "        # add the new days to the asset df\n",
    "        new_asset_df = pd.DataFrame(data={'date': new_days})\n",
    "        new_asset_df['asset_id'] = asset\n",
    "        asset_df = pd.concat((asset_df, new_asset_df))\n",
    "        asset_df = asset_df.sort_values(by='date', ignore_index=True)\n",
    "\n",
    "        # forward fill the price column\n",
    "        asset_df['usd_per_token_coinapi'] = asset_df.usd_per_token_coinapi.ffill()\n",
    "\n",
    "        # replace volume and trades with zeros\n",
    "        asset_df.loc[asset_df.usd_volume_per_24h_coinapi.isnull(), 'usd_volume_per_24h_coinapi'] = 0\n",
    "        asset_df.loc[asset_df.trades_count.isnull(), 'trades_count'] = 0\n",
    "\n",
    "        # add data to master df\n",
    "        final_df = pd.concat((final_df, asset_df))\n",
    "\n",
    "    # final clean\n",
    "    df = final_df.copy()\n",
    "    df = df.rename(columns={'trades_count': 'trades_coinapi'})\n",
    "    df = df.sort_values(by=['date', 'asset_id'], ignore_index=True)\n",
    "    assert not df.duplicated(subset=['date', 'asset_id']).any()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperateMacroAndAssetRefPrices(prices_df: pd.DataFrame) -> tuple:\n",
    "    \"\"\" Separate macro and asset reference prices from a given DataFrame.\n",
    "\n",
    "    Args:\n",
    "        prices_df: A pandas DataFrame containing asset prices and asset types.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of two pandas DataFrames containing macro reference prices and\n",
    "        asset reference prices respectively.\n",
    "    \"\"\"\n",
    "    # Separate stablecoin DataFrames and remaining asset DataFrame\n",
    "    usdc_df = prices_df[prices_df.asset=='USDC']\n",
    "    usdt_df = prices_df[prices_df.asset=='USDT']\n",
    "    prices_df = prices_df[~prices_df.asset.isin(['USDT', 'USDC'])]\n",
    "\n",
    "    # Rename columns and drop 'asset' column from stablecoin DataFrames\n",
    "    usdc_df = usdc_df.rename(columns={'usd_per_token_ref': 'usd_per_usdc'})\n",
    "    usdt_df = usdt_df.rename(columns={'usd_per_token_ref': 'usd_per_usdt'})\n",
    "    usdc_df = usdc_df.drop(columns=['asset'], axis=1)\n",
    "    usdt_df = usdt_df.drop(columns=['asset'], axis=1)\n",
    "\n",
    "    # Merge stablecoins into a macro DataFrame\n",
    "    macro_df = usdc_df.merge(usdt_df, on='date', how='outer', validate='one_to_one')\n",
    "\n",
    "    # Sort DataFrames by date and reset index\n",
    "    prices_df = prices_df.sort_values(by=['date', 'asset'], ignore_index=True)\n",
    "    macro_df = macro_df.sort_values(by='date', ignore_index=True)\n",
    "\n",
    "    return macro_df, prices_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '2023-03-17', 'requests': 11800, 'apicalls': 249}, {'date': '2023-03-15', 'requests': 85274, 'apicalls': 2851}, {'date': '2023-03-14', 'requests': 87973, 'apicalls': 2943}, {'date': '2023-03-08', 'requests': 101011, 'apicalls': 3378}, {'date': '2023-03-07', 'requests': 35546, 'apicalls': 1208}, {'date': '2023-03-06', 'requests': 65646, 'apicalls': 2194}]\n",
      "Processing asset #1 (0.36%): USDC\n",
      "credits used out of 100k:\n",
      "11800\n",
      "Processing asset #2 (0.72%): USDT\n",
      "credits used out of 100k:\n",
      "574\n",
      "Processing asset #3 (1.08%): 1INCH\n",
      "credits used out of 100k:\n",
      "1104\n",
      "Processing asset #4 (1.44%): AAVE\n",
      "credits used out of 100k:\n",
      "1104\n",
      "Processing asset #5 (1.80%): ACA\n",
      "credits used out of 100k:\n",
      "1104\n",
      "Processing asset #6 (2.16%): ACH\n",
      "credits used out of 100k:\n",
      "1104\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # import api key\n",
    "    API_KEY_FP = '../../admin/coinapi.txt'\n",
    "    with open(API_KEY_FP) as f:\n",
    "        API_KEY = f.readlines()[0].strip()\n",
    "\n",
    "    # Set args\n",
    "    CW_IN_FP = '../data/derived/cm_to_coinapi_cw.pkl'\n",
    "    ASSET_IN_FP = '../data/clean/asset_universe_dict.pickle'\n",
    "    BASE_URL   = 'https://rest.coinapi.io/v1/'\n",
    "    BASE_HEADERS = {'X-CoinAPI-Key': API_KEY}\n",
    "    LEGIT_US_EXCHANGES = ['BINANCEUS', 'BITSTAMP', 'COINBASE', 'CRYPTOCOM', 'FTXUS', \n",
    "        'GEMINI', 'KRAKEN', 'KUCOIN']\n",
    "    TARGET_FREQ = '1HRS'\n",
    "    TIME_START = '2016-07-01'\n",
    "    TIME_END = '2023-01-02'\n",
    "\n",
    "    # confirm api is working\n",
    "    url = 'https://www.coinapi.io/api/subscriptions/usage/rest/history'\n",
    "    response = requests.get(url, headers=BASE_HEADERS)\n",
    "    print(response.json())    \n",
    "\n",
    "    # Import asset universe and cw\n",
    "    cw_df = pd.read_pickle(CW_IN_FP)\n",
    "    with open(ASSET_IN_FP, \"rb\") as f:\n",
    "        asset_universe_dict = pickle.load(f)\n",
    "    asset_universe_cm = findUniqueAssets(asset_universe_dict)\n",
    "    asset_universe = list(cw_df[cw_df.asset_cm.isin(asset_universe_cm)].asset_coinapi.values)\n",
    "\n",
    "    # pull relevant markets\n",
    "    markets_df = pullMarketInfo(BASE_URL, BASE_HEADERS, LEGIT_US_EXCHANGES, asset_universe)\n",
    "\n",
    "    # pull coinapi aggregated prices\n",
    "    prices_df = pullExchangeRates(BASE_URL, BASE_HEADERS, ['USDC', 'USDT'] + asset_universe,\n",
    "                    TARGET_FREQ, TIME_START, TIME_END)\n",
    "    macro_df, prices_df = seperateMacroAndAssetRefPrices(prices_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO pull market data function but need to adjust to work either for daily level or hourly level;  specificied assets as well\n",
    "# -pull all markets in those three stables for all my assets to get prices, volume, and trades at HOURLY freq\n",
    "# --so check first if the market offers hourly freq?\n",
    "# TODO build the panel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO figure out how to pully hourly bid and ask for those markets to add to the panel as well\n",
    "\n",
    "url = 'https://rest.coinapi.io/v1/quotes/BITSTAMP_SPOT_BTC_USD/history?time_start=2016-01-01T00:00:00'\n",
    "\n",
    "\n",
    "time_start = 1\n",
    "time_end = 2\n",
    "limit = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO move functions to the helper function call\n",
    "\n",
    "# TODO adjust the OG script to see if they work for it too\n",
    "# --will need to adjust a bit for the changes to make the functions more general\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e428bc405edc59f3352e9792cab27c5e28560f7efb4b47308a6c6ea38cd15df2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
