{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab026fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 09:15:36.278957: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-18 09:15:36.334189: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-18 09:15:37.193887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# To be able to use the quantools, due to my crap path names have to add to sys path\n",
    "import sys\n",
    "sys.path.insert(0, '/home/adam/Dropbox/2-creations/2-crafts/7-buidl/0-utils/quant_tools/code')\n",
    "\n",
    "# IMPORT PACKAGES\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "from tools import QuantTools\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "import time\n",
    "import gc\n",
    "\n",
    "keras.mixed_precision.set_global_policy(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b00e177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsetRowsAndColumns(\n",
    "    df: pd.DataFrame, lhs_col: str\n",
    "    ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    ''' Subset relevant rows and columns to form needed dataframes.\n",
    "\n",
    "    Parameters:\n",
    "        df      (pd.DataFrame): The original DataFrame containing the data.\n",
    "        lhs_col (str):          The name of lhs column.\n",
    "\n",
    "    Notes:\n",
    "        - Kept characteristics based on what are most raw characteristics and \n",
    "            what work well as univariate factor to gen large spread in returns\n",
    "            in pre 2h 2022 data.\n",
    "        - Kept matching number of macro cols up to integer scalar which have\n",
    "            high corr to avg LHS after taking out variabilitity of previous\n",
    "            chosen columns.\n",
    "        - Keep also previous returns as a separate dataframe for the factor\n",
    "            side of the network.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing four DataFrames:\n",
    "            y_df: A DataFrame with relevant rows and lhs column.\n",
    "            char_df: A DataFrame with raw characteristics.\n",
    "            ts_df: A DataFrame containing previous returns.\n",
    "            weight_df: A DataFrame containing columns for weighting asset-dates in obj func.\n",
    "    '''\n",
    "    # Set column lists that I manually constructed\n",
    "    char_cols_to_keep = ['char_addr_active_tm1h',\n",
    "        'char_addr_new_log_delta_tm2_tm1',\n",
    "        'char_alpha_tm7',\n",
    "        'char_delta_flow_dist_tm1h',\n",
    "        'char_delta_holders_dist_tm7',\n",
    "        'char_mvrv_t',\n",
    "        'char_prct_supply_in_profit_t',\n",
    "        'char_r_ath_t',\n",
    "        'char_r_atl_t',\n",
    "        'char_r_industry_tm6h',\n",
    "        'char_r_tm1',\n",
    "        'char_r_tm14',\n",
    "        'char_r_tm1h',\n",
    "        'char_r_tm2h',\n",
    "        'char_shortfall5_tm1',\n",
    "        'char_size_t',\n",
    "        'char_trades_t',\n",
    "        'char_var5_tm90',\n",
    "        'char_vol_tm6h',\n",
    "        'char_volume_t']\n",
    "\n",
    "    macro_cols_to_keep = ['macro_avg_vel_cur_1yr_t',\n",
    "        'macro_btc_momr_t',\n",
    "        'macro_btc_ser_t',\n",
    "        'macro_btc_sopr_t',\n",
    "        'macro_btc_sply_act_30d_t',\n",
    "        'macro_btc_tx_tfr_cnt_t',\n",
    "        'macro_btc_utxo_prof_unreal_usd_t',\n",
    "        'macro_btc_vel_act_1yr_t',\n",
    "        'macro_cpiaucsl_t',\n",
    "        'macro_dgs1mo_t',\n",
    "        'macro_eth_roi_t',\n",
    "        'macro_eth_rvt_adj_t',\n",
    "        'macro_ex_open_interest_future_usd_t',\n",
    "        'macro_expinf1yr_t',\n",
    "        'macro_m2sl_t',\n",
    "        'macro_mvrv_med_t',\n",
    "        'macro_t10yie_t',\n",
    "        'macro_us_ex_volume_future_usd_t', \n",
    "        'macro_us_ex_volume_spot_usd_t',\n",
    "        'macro_vixclsx_t']\n",
    "\n",
    "    # Dropping some data if we want to up the ratio of real to fake data\n",
    "    df = df[df.date >= '2019-01-01'].copy()\n",
    "\n",
    "    # Form dataframe of all dates and assets and merge back on df to ensure obs for all assets\n",
    "    unique_dates  = df.date.unique()\n",
    "    unique_assets = df.asset.unique()\n",
    "    cross_product = list(itertools.product(unique_dates, unique_assets))\n",
    "    cross_df      = pd.DataFrame(cross_product, columns=['date', 'asset'])\n",
    "    df            = df.merge(\n",
    "        cross_df, on=['date', 'asset'], how='outer', validate='one_to_one')\n",
    "    df            = df.sort_values(by=['date', 'asset'], ignore_index=True)\n",
    "    assert(len(df) == (len(np.unique(df.date))*len(np.unique(df.asset))))\n",
    "\n",
    "    # Form lhs dataframe\n",
    "    y_df = df[['date', 'asset', lhs_col]].copy()\n",
    "    y_df = y_df.sort_values(by=['date', 'asset'], ignore_index=True)\n",
    "\n",
    "    # Form characteristic dataframe\n",
    "    char_df = df[['date', 'asset']+char_cols_to_keep].copy()\n",
    "    char_df = char_df.sort_values(by=['date', 'asset'], ignore_index=True)\n",
    "\n",
    "    # Form previous return dataframe by extracting from char_df and reshaping wide\n",
    "    r_df         = char_df[['date', 'asset', 'char_r_tm1h']].copy()\n",
    "    r_df         = r_df.pivot(index='date', columns='asset', values='char_r_tm1h').reset_index()\n",
    "    r_df.columns = (['date'] \n",
    "        + ['asset_r_' + str(col) + '_t1h' for col in r_df.columns if col != 'date'])\n",
    "\n",
    "    # Form ts_df as the macro columns plus the previous return columns\n",
    "    macro_df = df[df.asset=='btc'][['date']+macro_cols_to_keep].copy()\n",
    "    assert(set(macro_df.date)==set(r_df.date))\n",
    "    ts_df    = macro_df.merge(r_df, on='date', how='inner', validate='one_to_one')\n",
    "    ts_df    = ts_df.sort_values(by='date', ignore_index=True)\n",
    "\n",
    "    # Form weight dataframe containing columns to form for weighting asset dates in obj func\n",
    "    weight_df = df[['date', 'asset', 'char_mcap_t', 'char_volume_t']].copy()\n",
    "    weight_df = weight_df.rename(columns={'char_mcap_t': 'mcap',\n",
    "                                        'char_volume_t': 'volume'})\n",
    "\n",
    "    # Run final checks\n",
    "    assert(set(y_df.date)==set(char_df.date))\n",
    "    assert(set(y_df.date)==set(ts_df.date))\n",
    "    assert(set(y_df.date)==set(weight_df.date))\n",
    "    assert(0 == ((len(macro_cols_to_keep) \n",
    "                / len(char_cols_to_keep)) % 1)) # macro cols are some multiple of # char cols\n",
    "\n",
    "    return y_df, char_df, ts_df, weight_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e7a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeAndFillMissing(df: pd.DataFrame, \n",
    "        lhs_col: Optional[str] = None, lhs_pad: float = -2, rhs_pad: float = -2,\n",
    "        ignore_cols: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize all numeric columns of a DataFrame to be between -1 and 1 based on rank,\n",
    "    and set missing values to given lhs and rhs pad values.\n",
    "\n",
    "    Parameters:\n",
    "    df          (pd.DataFrame):        Input DataFrame to normalize.\n",
    "    lhs_col     (str, optional):       Column name to fill missing values with lhs_pad.\n",
    "    lhs_pad     (float, optional):     Value to replace missing values in lhs_col.\n",
    "    rhs_pad     (float, optional):     Value to replace missing values in other columns.\n",
    "    ignore_cols (List[str], optional): List of column names to ignore during normalization.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Normalized DataFrame.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If any column to normalize is not numeric.\n",
    "    \"\"\"\n",
    "    # If ignore_cols is not provided, use an empty list\n",
    "    if ignore_cols is None:\n",
    "        ignore_cols = []\n",
    "\n",
    "    # Get the columns to normalize\n",
    "    cols_to_normalize = [col for col in df.columns if col not in ignore_cols]\n",
    "\n",
    "    # Check if all columns to normalize are numeric\n",
    "    if not all(dtype.kind in 'biufc' for dtype in df[cols_to_normalize].dtypes):\n",
    "        raise ValueError(\"All columns to normalize must be numeric\")\n",
    "\n",
    "    # Check for constant columns and raise a warning\n",
    "    constant_columns = df[cols_to_normalize].columns[df[cols_to_normalize].nunique() <= 1]\n",
    "    if len(constant_columns) > 0:\n",
    "        print(f\"Warning: Columns {constant_columns} have constant values and will result in NaN after normalization.\")\n",
    "\n",
    "    # Find out how many missing in the cols to normalize \n",
    "    missing_per_column = df[cols_to_normalize].isnull().sum()\n",
    "\n",
    "    # Rank the values in each column \n",
    "    #    -where we first rank normalize\n",
    "    #    -but then add noise and \n",
    "    #         re rank normalize to ensure unique values with \n",
    "    #         even coverage of RHS latent space\n",
    "    if len(cols_to_normalize) > 0:\n",
    "        # Rank normalization\n",
    "        df[cols_to_normalize] = df[cols_to_normalize].rank() / (len(df) - missing_per_column)\n",
    "\n",
    "        # Add small random noise\n",
    "        df[cols_to_normalize] += np.random.uniform(-1e-6, 1e-6, (len(df), len(cols_to_normalize)))\n",
    "\n",
    "        # Re-rank after adding noise\n",
    "        df[cols_to_normalize] = df[cols_to_normalize].rank() / (len(df) - missing_per_column)\n",
    "\n",
    "        # Scale to the range [-128, 127]\n",
    "        df[cols_to_normalize] = (df[cols_to_normalize] * 255) - 128\n",
    "\n",
    "        # Confirm ranges\n",
    "        assert(-128 <= df[cols_to_normalize].min().min())\n",
    "        assert(127 >= df[cols_to_normalize].max().max())\n",
    "\n",
    "    # Replace missing LHS and RHS with given buffer values\n",
    "    if lhs_col is not None and lhs_col in df.columns:\n",
    "        df[lhs_col].fillna(lhs_pad, inplace=True)\n",
    "        df[lhs_col] = df[lhs_col].astype(np.float32)\n",
    "        assert np.allclose(0, df[lhs_col].isnull().sum())\n",
    "    df.fillna(rhs_pad, inplace=True)\n",
    "    assert 0 == df.isnull().sum().sum()\n",
    "\n",
    "    # Reduce data memory usage, resort, and reset index\n",
    "    for col in df.select_dtypes(include=[np.float64]).columns:\n",
    "        df[col] = df[col].astype(np.int8)\n",
    "    if 'asset' in df.columns:\n",
    "        df      = df.sort_values(by=['date', 'asset'], ignore_index=True)\n",
    "    else:\n",
    "        df      = df.sort_values(by=['date'], ignore_index=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f6ef756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formLhsAndRhsTensors(rel_y_df: pd.DataFrame, rel_char_df: pd.DataFrame, rel_ts_df: pd.DataFrame,\n",
    "                            datetimes_window: List[pd.Timestamp], prev_asset_ret_cols: List[str],\n",
    "                            macro_cols: List[str], lhs_col: str, num_lags: int, num_assets: int,\n",
    "                            num_chars: int) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "    \"\"\"\n",
    "    Form tensors for loading input, factor input, and output for machine learning model.\n",
    "\n",
    "    Parameters:\n",
    "        rel_y_df            (pd.DataFrame):       DataFrame containing target variable (response) data.\n",
    "        rel_char_df         (pd.DataFrame):       DataFrame containing characteristics data.\n",
    "        rel_ts_df           (pd.DataFrame):       DataFrame containing time series data (factors).\n",
    "        datetimes_window    (List[pd.Timestamp]): List of datetime values for which to form tensors.\n",
    "        prev_asset_ret_cols (List[str]):          List of column names for previous asset returns in `rel_ts_df`.\n",
    "        macro_cols          (List[str]):          List of column names for macroeconomic data in `rel_ts_df`.\n",
    "        lhs_col             (str):                The column name in `rel_y_df` representing the target variable.\n",
    "        num_lags            (int):                Number of lagged time steps to consider.\n",
    "        num_assets          (int):                Number of assets (entities).\n",
    "        num_chars           (int):                Number of characteristics.\n",
    "        batch_size          (int):                Number of observations per batch.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[tf.Tensor, tf.Tensor, tf.Tensor]: A tuple containing three tensors:\n",
    "            - `loading_input`: Tensor containing the concatenated characteristics and macro data.\n",
    "            - `factor_input`: Tensor containing previous asset return data.\n",
    "            - `output`: Tensor containing the target returns.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input data shapes are not as expected.\n",
    "    \"\"\"\n",
    "    # Initialize lists to return\n",
    "    loading_input_list = []\n",
    "    factor_input_list  = []\n",
    "    output_list        = []\n",
    "\n",
    "    # Loop over all datetimes to form LHS and RHS for\n",
    "    for i, datetime in enumerate(datetimes_window):\n",
    "        # Form the beginning datetime for this observation given the number of lags to step back\n",
    "        datetime_input_start = datetime - pd.Timedelta(hours=num_lags - 1)\n",
    "\n",
    "        # Obtain output data\n",
    "        output_list.append(rel_y_df.loc[rel_y_df.date == datetime, lhs_col].values)\n",
    "\n",
    "        # Obtain input data\n",
    "        rel_char_filtered = rel_char_df[\n",
    "            (rel_char_df.date >= datetime_input_start) & (rel_char_df.date <= datetime)\n",
    "            ].drop(columns=['date', 'asset'])\n",
    "\n",
    "        char_data = rel_char_filtered.values.reshape(\n",
    "                        (num_lags, num_assets, num_chars)\n",
    "                        ).transpose((0, 2, 1))\n",
    "\n",
    "        rel_ts_filtered = rel_ts_df[\n",
    "            (rel_ts_df.date >= datetime_input_start) & (rel_ts_df.date <= datetime)]\n",
    "\n",
    "        if len(rel_ts_filtered) < num_lags:\n",
    "            raise ValueError(\"Not enough data points for the given number of lags.\")\n",
    "\n",
    "        macro_data = rel_ts_filtered[macro_cols].values.reshape((num_lags, num_chars, -1))\n",
    "\n",
    "        # Append to lists of input data\n",
    "        loading_input_list.append(np.concatenate((char_data, macro_data), axis=2))\n",
    "        factor_input_list.append(rel_ts_filtered[prev_asset_ret_cols].values)\n",
    "\n",
    "    # Convert validation data lists to tensors\n",
    "    loading_input = tf.convert_to_tensor(np.array(loading_input_list), dtype=tf.int8)\n",
    "    factor_input  = tf.convert_to_tensor(np.array(factor_input_list), dtype=tf.int8)\n",
    "    output        = tf.convert_to_tensor(np.array(output_list), dtype=tf.float32)\n",
    "\n",
    "    return loading_input, factor_input, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "430d5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, num_heads: int, hidden_dim: int, dropout_pct: float,\n",
    "                 dense_dim: int, l2_penalty: float, **kwargs):\n",
    "        \"\"\"\n",
    "        TransformerEncoder layer.\n",
    "\n",
    "        Parameters:\n",
    "            num_heads   (int):   Number of attention heads in the multi-head attention layer.\n",
    "            hidden_dim  (int):   Dimension of the hidden layers.\n",
    "            dropout_pct (float): Dropout rate as a percentage.\n",
    "            dense_dim   (int):   Dimension of the dense layers.\n",
    "            l2_penalty  (float): L2 regularization penalty.\n",
    "            **kwargs: Additional arguments for the base Layer class.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads   = num_heads\n",
    "        self.hidden_dim  = hidden_dim\n",
    "        self.dropout_pct = dropout_pct\n",
    "        self.dense_dim   = dense_dim\n",
    "        self.l2_penalty  = l2_penalty\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=hidden_dim,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            bias_initializer='random_uniform',\n",
    "            dropout = dropout_pct,\n",
    "            kernel_regularizer=regularizers.l2(l2=l2_penalty))\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation='gelu',\n",
    "                        kernel_initializer='glorot_uniform',\n",
    "                        bias_initializer='random_uniform',\n",
    "                        kernel_regularizer=regularizers.l2(l2=l2_penalty)),\n",
    "                layers.Dropout(dropout_pct),\n",
    "                layers.Dense(hidden_dim, activation='linear',\n",
    "                            kernel_initializer='glorot_uniform',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            kernel_regularizer=regularizers.l2(l2=l2_penalty)),\n",
    "                layers.Dropout(dropout_pct),\n",
    "                ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        attention_output = self.attention(query=inputs, key=inputs, value=inputs)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_heads\":  self.num_heads,\n",
    "            \"hidden_dim\": self.hidden_dim,\n",
    "            \"dropout_pct\": self.dropout_pct,\n",
    "            \"dense_dim\":  self.dense_dim,\n",
    "            \"l2_penalty\": self.l2_penalty,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def buildLoadingOutputs(inputs: Layer, num_assets: int, hidden_dim: int, l2_penalty: float,\n",
    "                        dropout_pct: float, num_heads: int, dense_dim: int, num_factors: int) -> Layer:\n",
    "    \"\"\"\n",
    "    Build loading outputs for the Transformer model.\n",
    "\n",
    "    Parameters:\n",
    "        inputs      (Layer): Input layer for the encoder.\n",
    "        num_assets  (int):   Number of assets (entities).\n",
    "        hidden_dim  (int):   Dimension of the hidden layers.\n",
    "        l2_penalty  (float): L2 regularization penalty.\n",
    "        dropout_pct (float): Dropout rate as a percentage.\n",
    "        num_heads   (int):   Number of attention heads.\n",
    "        dense_dim   (int):   Dimension of the dense layers.\n",
    "        num_factors (int):   Number of factors in the model.\n",
    "\n",
    "    Returns:\n",
    "        Layer: Output layer of the loading outputs.\n",
    "    \"\"\"\n",
    "\n",
    "    encoder_outputs = []\n",
    "    for _ in range(num_assets):\n",
    "        encoder_output = layers.Dense(hidden_dim, activation='linear',\n",
    "                                    kernel_initializer='glorot_uniform',\n",
    "                                    bias_initializer='random_uniform',\n",
    "                                    kernel_regularizer=regularizers.l2(l2=l2_penalty))(inputs)\n",
    "        encoder_output = layers.Dropout(dropout_pct)(encoder_output)\n",
    "        encoder_output = TransformerEncoder(num_heads, hidden_dim, dropout_pct, dense_dim, l2_penalty)(encoder_output)\n",
    "        encoder_output = layers.GlobalAveragePooling2D()(encoder_output)\n",
    "        encoder_output = layers.Dense(num_factors, activation='linear',\n",
    "                                    kernel_initializer='glorot_uniform',\n",
    "                                    bias_initializer='random_uniform',\n",
    "                                    kernel_regularizer=regularizers.l2(l2=l2_penalty))(encoder_output)\n",
    "        encoder_outputs.append(encoder_output)\n",
    "\n",
    "    # Stack the outputs and reshape to a matrix of dim num_assets by num_factors\n",
    "    outputs = layers.Concatenate(axis=1)(encoder_outputs)  \n",
    "    output  = layers.Reshape((num_assets, num_factors))(outputs)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def buildFactorOutputs(inputs: Layer, hidden_dim: int, l2_penalty: float, dropout_pct: float,\n",
    "                        num_heads: int, dense_dim: int, num_factors: int) -> Layer:\n",
    "    \"\"\"\n",
    "    Build factor outputs for the Transformer model.\n",
    "\n",
    "    Parameters:\n",
    "        inputs      (Layer): Input layer for the encoder.\n",
    "        hidden_dim  (int):   Dimension of the hidden layers.\n",
    "        l2_penalty  (float): L2 regularization penalty.\n",
    "        dropout_pct (float): Dropout rate as a percentage.\n",
    "        num_heads   (int):   Number of attention heads.\n",
    "        dense_dim   (int):   Dimension of the dense layers.\n",
    "        num_factors (int):   Number of factors in the model.\n",
    "\n",
    "    Returns:\n",
    "        Layer: Output layer of the factor outputs.\n",
    "    \"\"\"\n",
    "    encoder_output = layers.Dense(hidden_dim, activation='linear',\n",
    "                                kernel_initializer='glorot_uniform',\n",
    "                                bias_initializer='random_uniform',\n",
    "                                kernel_regularizer=regularizers.l2(l2=l2_penalty))(inputs)\n",
    "    encoder_output = layers.Dropout(dropout_pct)(encoder_output)\n",
    "    encoder_output = TransformerEncoder(num_heads, hidden_dim, dropout_pct, dense_dim, l2_penalty)(encoder_output)\n",
    "    encoder_output = layers.GlobalAveragePooling1D()(encoder_output)\n",
    "    output = layers.Dense(num_factors, activation='linear',\n",
    "                        kernel_initializer='glorot_uniform',\n",
    "                        bias_initializer='random_uniform')(encoder_output)\n",
    "    return output\n",
    "\n",
    "def buildTransformer(num_chars: int, num_macro_vectors: int, \n",
    "    num_assets: int, num_training_obs: int, \n",
    "    hps_dict: Dict, rel_weight_df: pd.DataFrame) -> keras.Model:\n",
    "    \"\"\"\n",
    "    Build and compile a Transformer model.\n",
    "\n",
    "    Parameters:\n",
    "        num_chars (int): Number of characteristics.\n",
    "        num_macro_vectors (int): Number of macroeconomic vectors.\n",
    "        num_assets (int): Number of assets (entities).\n",
    "        num_training_obs (ints): Number of observations in the training data for this model.\n",
    "        hps_dict (Dict): hyperparameter values.\n",
    "        rel_weight_df (pd.DataFrame): DataFrame containing columns for wieghting obj. func.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: Compiled Transformer model.\n",
    "    \"\"\"\n",
    "    # Set dense dim to be two times that of hidden dimension\n",
    "    dense_dim = int(hps_dict['hidden_dim']*2)\n",
    "\n",
    "    # Build inputs\n",
    "    input_loadings = keras.Input(shape=(hps_dict['num_lags'], num_chars, num_assets + num_macro_vectors))\n",
    "    input_factors = keras.Input(shape=(hps_dict['num_lags'], num_assets))\n",
    "\n",
    "    # Build mappings to outputs\n",
    "    output_loadings = buildLoadingOutputs(\n",
    "        input_loadings, num_assets, hps_dict['hidden_dim'],\n",
    "        hps_dict['l2_penalty'], hps_dict['dropout_pct'], \n",
    "        hps_dict['num_heads'], dense_dim, hps_dict['number_factors'])\n",
    "    output_factors = buildFactorOutputs(\n",
    "        input_factors, hps_dict['hidden_dim'],\n",
    "        hps_dict['l2_penalty'], hps_dict['dropout_pct'], \n",
    "        hps_dict['num_heads'], dense_dim, hps_dict['number_factors'])\n",
    "    output = layers.Dot(axes=[2, 1])([output_loadings, output_factors])\n",
    "\n",
    "    # Build optimizer\n",
    "    decay_steps = int(num_training_obs / hps_dict['batch_size'])\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        hps_dict['initial_learning_rate'],\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=hps_dict['learning_decay_rate'],\n",
    "        staircase=False)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule,\n",
    "        beta_1=hps_dict['adam_beta_1'], beta_2=hps_dict['adam_beta_2'], \n",
    "        clipnorm=hps_dict['adam_clipnorm'])\n",
    "    \n",
    "    # Create weights for the loss function for each asset in the output\n",
    "    # remove data from weights that is before we have suff num of lags before\n",
    "    w_df = rel_weight_df[int(num_assets*(hps_dict['num_lags']-1)):].reset_index(drop=True).copy()\n",
    "\n",
    "    # fill missings in weight matrix of mcap and volume with min value so they get downweighted\n",
    "    for col in ['mcap', 'volume']:\n",
    "        median_values = w_df.groupby('date')[col].transform('min')\n",
    "        w_df[col].fillna(median_values, inplace=True)\n",
    "\n",
    "    # calc mcap weights\n",
    "    total_mcap = w_df.groupby('date')['mcap'].transform('sum')\n",
    "    w_df['mcap_weight'] = w_df['mcap'] / total_mcap\n",
    "\n",
    "    # calc volume weights\n",
    "    total_volume = w_df.groupby('date')['volume'].transform('sum')\n",
    "    w_df['volume_weight'] = w_df['volume'] / total_volume\n",
    "\n",
    "    # calc final weight column\n",
    "    w_df['weight'] = (w_df.mcap_weight + w_df.volume_weight)/2\n",
    "\n",
    "    # form the weighting matrix from mcap and volume\n",
    "    training_weight_matrix = w_df.weight.values.reshape(-1,num_assets)\n",
    "    training_weight_matrix = tf.cast(training_weight_matrix, tf.float32)\n",
    "\n",
    "    # form weighing array for each asset\n",
    "    loss_weights = tf.cast(tf.reduce_mean(training_weight_matrix, axis=0), tf.float32)\n",
    "    loss_weights = list(loss_weights.numpy())\n",
    "    \n",
    "    # Build and compile model\n",
    "    model = keras.Model(inputs=[input_loadings, input_factors], outputs=output)\n",
    "    model.compile(optimizer=optimizer, \n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mse'],\n",
    "        weighted_metrics=['mse'])\n",
    "    #     loss_weights=loss_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50baeb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitTransformer(model: keras.Model,\n",
    "        train_loading_input: tf.Tensor, train_factor_input: tf.Tensor, train_output: tf.Tensor, \n",
    "        rel_y_df: pd.DataFrame, lhs_col: str, lhs_pad: int, tc_per_hour: float, num_prtfl_qntls: int,\n",
    "        train_datetimes: List[np.datetime64], num_assets: int, \n",
    "        hps_dict: Dict,\n",
    "        val_loading_input: tf.Tensor = None, val_factor_input: tf.Tensor = None, val_output: tf.Tensor = None, \n",
    "    ) -> Tuple[keras.Model, int, float, float]:\n",
    "    \"\"\"\n",
    "    Fit the Transformer model.\n",
    "\n",
    "    Parameters: \n",
    "        model (keras.Model): The Transformer model to be trained.\n",
    "        train_loading_input (tf.Tensor): Training loading input tensor.\n",
    "        train_factor_input (tf.Tensor): Training factor input tensor.\n",
    "        train_output (tf.Tensor): Training output tensor.\n",
    "        rel_y_df (pd.DataFrame): lhs data.\n",
    "        lhs_col (str): Name of LHS column.\n",
    "        lhs_pad (int): The padded value for the lhs to signify missing.\n",
    "        tc_per_hour (float): Transaction costs per hour in simple return.\n",
    "        num_prtfl_qntls (int): Number of quantiles for long-short portfolio construction.\n",
    "        train_datetimes (List[np.datetime64]): date at which validation period begins.\n",
    "        num_assets (int): Number of assets (entities).\n",
    "        hps_dict (Dict): hyperparameter values.\n",
    "        val_loading_input (tf.Tensor, optional): Validation loading input tensor.\n",
    "        val_factor_input (tf.Tensor, optional): Validation factor input tensor.\n",
    "        val_output (tf.Tensor, optional): Validation output tensor.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple: A tuple containing the trained model, number of epochs trained for the best epoch,\n",
    "                training r^2 predictive, and training geometric average return.\n",
    "    \"\"\"\n",
    "    # Build additional obj func weights using number of missing assets\n",
    "    missing_asset_matrix = tf.cast(train_output != lhs_pad, dtype=tf.int16)\n",
    "    missing_asset_weight_array = np.sum(missing_asset_matrix, axis=1) / num_assets\n",
    "    missing_asset_weight_array = missing_asset_weight_array / missing_asset_weight_array.sum()\n",
    "    sample_weight_array = tf.cast(missing_asset_weight_array, dtype=tf.float32)\n",
    "\n",
    "    # Build early stopping and model checkpoint callbacks and checkpoint objects and val data, if given.\n",
    "    callbacks = []\n",
    "    if hps_dict['early_stopping']:\n",
    "        es = EarlyStopping(monitor='val_mse', mode='min', verbose=1, patience=hps_dict['patience'])\n",
    "        model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "        callbacks += [es, model_checkpoint]\n",
    "\n",
    "    if val_loading_input is not None and val_factor_input is not None and val_output is not None:\n",
    "        validation_data = ([val_loading_input, val_factor_input], val_output)\n",
    "    else:\n",
    "        validation_data = None\n",
    "\n",
    "    # Fit the model.    \n",
    "    model.fit(x=[train_loading_input, train_factor_input],\n",
    "                y=train_output,\n",
    "                batch_size=hps_dict['batch_size'], epochs=hps_dict['num_epochs'], verbose=1, callbacks=callbacks,\n",
    "                validation_data=validation_data,\n",
    "                sample_weight=sample_weight_array)\n",
    "    \n",
    "    # If we did early stopping, load the best model and update number of epochs.xtract the best epoch.\n",
    "    if hps_dict['early_stopping']:\n",
    "        model.load_weights('best_model.h5')\n",
    "        if (es.stopped_epoch > 0):\n",
    "            best_epoch_train = es.stopped_epoch - hps_dict['patience']\n",
    "        else:\n",
    "            best_epoch_train = hps_dict['num_epochs']\n",
    "    else:\n",
    "        best_epoch_train = hps_dict['num_epochs']\n",
    "\n",
    "    # Predict on the training data to return the training r^2_pred for obs with nonmissing return\n",
    "    train_yhats = model.predict([train_loading_input, train_factor_input])\n",
    "    train_mask = train_output != lhs_pad\n",
    "    train_mse     = QuantTools.calcMSE(train_output[train_mask], train_yhats[train_mask])\n",
    "    train_r2_pred = QuantTools.calcR2Pred(train_output[train_mask], train_yhats[train_mask])\n",
    "\n",
    "    # Form array of training yhats\n",
    "    train_yhats_array = tf.reshape(train_yhats, [-1]).numpy()\n",
    "\n",
    "    # Form DataFrame of y and yhat values for nonmissing returns in training window\n",
    "    train_pos_df = rel_y_df[rel_y_df.date.isin(train_datetimes)].copy()\n",
    "    train_pos_df['yhats'] = train_yhats_array\n",
    "    train_pos_df = train_pos_df[train_pos_df[lhs_col] != lhs_pad].reset_index(drop=True)\n",
    "\n",
    "    # Calculate the geom avg return of given quantile long short portfolios\n",
    "    train_pos_df = QuantTools.formPortfolioWeightsByQuantile(\n",
    "            train_pos_df, num_prtfl_qntls)\n",
    "    train_pos_df['returns'] = train_pos_df.prtfl_wght_hml*train_pos_df[lhs_col]\n",
    "    train_returns = train_pos_df.groupby('date')['returns'].sum().values - tc_per_hour\n",
    "    train_geom_mean_rtrn = QuantTools.calcGeomAvg(train_returns)\n",
    "    \n",
    "    return model, best_epoch_train, train_mse, train_r2_pred, train_geom_mean_rtrn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "291af01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runCV(y_df: pd.DataFrame, char_df: pd.DataFrame, ts_df: pd.DataFrame, weight_df: pd.DataFrame,\n",
    "    aux_df: pd.DataFrame, asset_universe_dict: Dict[str, List],\n",
    "    val_start_date: str, val_end_date: str, test_start_date: str, lhs_col: str,\n",
    "    lhs_pad: int, rhs_pad: int, num_prtfl_qntls: int, tc_per_hour: float,\n",
    "    hp_grid: Dict[str, list], periods_in_year: int, \n",
    "    cv_out_fp: str, arch_name: str,\n",
    "    restrict_shortable_uni: bool=False, shortable_asset_uni: List[str]=[], \n",
    "    restrict_tradable_volume: bool=False, prct_volume_threshold: float=0.05, total_trade_volume_per_hour: int=1e6\n",
    "    ) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Run custom step forward cross-validation.\n",
    "\n",
    "    This function evaluates the performance of the Transformer-based factor model. \n",
    "    It uses the input data and hyperparameter grid to train multiple models with \n",
    "    different hyperparameter combinations and evaluates their performance using \n",
    "    step-forward cross-validation. The function outputs the results to a csv and\n",
    "    returns a list of dictionaries containing the evaluation results for each model.\n",
    "\n",
    "    Parameters:\n",
    "        y_df (pd.DataFrame): DataFrame containing the target variable data.\n",
    "        char_df (pd.DataFrame): DataFrame containing the characteristic data.\n",
    "        ts_df (pd.DataFrame): DataFrame containing the previous return data.\n",
    "        weight_df (pd.DataFrame): DataFrame containing columns for wieghting obj. func.\n",
    "        aux_df (pd.DataFrame): DataFrame containing date asset mcap and volume_tp1 columns.\n",
    "        asset_universe_dict (Dict[str, List]): Dictionary containing the asset universe \n",
    "                                                for each month in the study period.\n",
    "        val_start_date (str): Start date of the validation period in 'YYYY-MM-DD' format.\n",
    "        val_end_date (str): End date of the validation period in 'YYYY-MM-DD' format.\n",
    "        test_start_date (str): Start date of the test period in 'YYYY-MM-DD' format.\n",
    "        lhs_col (str): The name of the target variable (lhs) column in y_df.\n",
    "        lhs_pad (int): The value to pad missing lhs values with.\n",
    "        rhs_pad (int): The value to pad missing rhs values with.\n",
    "        num_prtfl_qntls (int): Number of quantiles for long-short portfolio construction.\n",
    "        tc_per_hour (float): Transaction cost per hour for calculating returns.\n",
    "        hp_grid (Dict[str, list]): Hyperparameter grid to search for the best model.\n",
    "        periods_in_year (int): Number of periods in a year for annualization.\n",
    "        cv_out_fp (str): Filepath to save the cross-validation results in CSV format.\n",
    "        arch_name (str): Name of the architecture/model being tested.\n",
    "        restrict_shortable_uni (bool): If True, restrict shortable assets to those listed.\n",
    "        shortable_asset_uni (List): assets that are shortable.\n",
    "        restrict_tradable_volume (bool): If True, restrict volume to specified percentage.\n",
    "        prct_volume_threshold (float): Fraction of datetime-asset volume that is tradable.\n",
    "        total_trade_volume_per_hour (int): total dollar trade volume to place in long and short\n",
    "            positions used to calculate what fraction of datetime-asset volume is traded.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: A list of dictionaries containing evaluation results for each model \n",
    "            in the hyperparameter grid. Each dictionary includes the model's hyperparameters, \n",
    "            evaluation metrics, and other relevant information.\n",
    "    \"\"\"\n",
    "    # Subset the LHS and RHS to remove test period\n",
    "    y_df = y_df[y_df.date < test_start_date].copy()\n",
    "    char_df = char_df[char_df.date < test_start_date].copy()\n",
    "    ts_df = ts_df[ts_df.date < test_start_date].copy()\n",
    "    weight_df = weight_df[weight_df.date < test_start_date].copy()\n",
    "\n",
    "    # Initialize cv result objects\n",
    "    results_list = []\n",
    "\n",
    "    # Determine RHS column names\n",
    "    char_cols = list(char_df.columns.values)\n",
    "    char_cols.remove('date')\n",
    "    char_cols.remove('asset')\n",
    "    macro_cols = [col for col in ts_df.columns if 'macro' in col]\n",
    "\n",
    "    # Determine number of RHS values\n",
    "    num_chars  = len(char_cols)\n",
    "    num_macro_vectors = int(len(macro_cols)/len(char_cols))\n",
    "\n",
    "    # Determine validation datetimes to loop over and datetimes to refit at\n",
    "    val_dts_dict = {}\n",
    "    val_sun_midnights = np.unique(y_df[(y_df.date>=val_start_date) \n",
    "        & (y_df.date.dt.hour==0) & (y_df.date.dt.day_of_week==6)].date.values)\n",
    "\n",
    "    # Check if first val date is sunday midnight, if not then add the dates\n",
    "    first_val_date = np.min(y_df[(y_df.date==val_start_date)].date.values)\n",
    "    day_of_week_of_first_val_datetime = (first_val_date.astype('datetime64[D]').view('int64') - 4) % 7\n",
    "    if day_of_week_of_first_val_datetime != 6:\n",
    "        val_dts_dict[first_val_date] = np.unique(y_df[(y_df.date>=first_val_date) & (y_df.date<val_sun_midnights[0])].date.values)\n",
    "\n",
    "    # Complete the dictionary with all the sundays as keys as the dates until the next sunday as the values\n",
    "    for val_sun_midnight in val_sun_midnights:\n",
    "        next_sun_midnight = val_sun_midnight + np.timedelta64(7, 'D')\n",
    "        val_dts_dict[val_sun_midnight] = np.unique(y_df[(y_df.date>=val_sun_midnight) \n",
    "                                            & (y_df.date<next_sun_midnight)\n",
    "                                            & (y_df.date<test_start_date)].date.values)\n",
    "\n",
    "    # Loop over hp combinations\n",
    "    keys = hp_grid.keys()\n",
    "    values = hp_grid.values()\n",
    "    hp_combos = list(itertools.product(*values))\n",
    "    for hps in hp_combos:\n",
    "        # Start the timer\n",
    "        tic = time.perf_counter()\n",
    "\n",
    "        # Create hp dictionary and other objects for this iteration\n",
    "        hps_dict = dict(zip(keys, hps))\n",
    "        hps_results_dict = hps_dict.copy()\n",
    "        val_y_yhats_df = pd.DataFrame()\n",
    "\n",
    "        # Report on progress\n",
    "        print(hps_dict)\n",
    "\n",
    "        # Initiate lists for results and start the loop over the val dates to fit and predict\n",
    "        num_epochs_trained_list   = []\n",
    "        train_mse_list            = []\n",
    "        train_r2_pred_list        = []\n",
    "        train_geom_mean_rtrn_list = []\n",
    "        train_num_assets_list     = []\n",
    "        num_model_params_list     = []\n",
    "        yhats_spread_list         = []\n",
    "        for val_datetime_start in list(val_dts_dict.keys()): \n",
    "            print(val_datetime_start)\n",
    "            # form training and validation datetime objects\n",
    "            train_datetimes = list(ts_df[ts_df.date < val_datetime_start].date.values)[hps_dict['num_lags']-1:]\n",
    "            val_datetimes_window = val_dts_dict[val_datetime_start]\n",
    "            val_datetime_end = np.max(val_datetimes_window)\n",
    "\n",
    "            # form appropriate asset universe\n",
    "            first_day_of_month_for_current_val_dt = np.datetime_as_string(val_datetime_start, unit='M')+'-01'\n",
    "            asset_universe = asset_universe_dict[first_day_of_month_for_current_val_dt]\n",
    "\n",
    "            # figure out what assets are not included in this asset universe to drop from previous return df\n",
    "            prev_ret_cols_to_drop = [col for col in ts_df.columns \n",
    "                                        if (col != 'date') & ('asset_r_' in col) \n",
    "                                        if col.split('_')[2] not in asset_universe]\n",
    "\n",
    "            # for all dfs, cut down assets and form relevant dataframes of up to end of current val week\n",
    "            rel_y_df    = y_df[(y_df.asset.isin(asset_universe))\n",
    "                                & ((y_df.date <= val_datetime_end))].copy()\n",
    "            rel_char_df = char_df[(char_df.asset.isin(asset_universe))\n",
    "                                & (char_df.date <= val_datetime_end)].copy()\n",
    "            rel_ts_df   = ts_df[(ts_df.date <= val_datetime_end)].drop(columns=prev_ret_cols_to_drop, axis=1)\n",
    "            rel_weight_df = weight_df[(weight_df.asset.isin(asset_universe))\n",
    "                                    & (weight_df.date < val_datetime_start)].copy()\n",
    "\n",
    "            # form rel prev asset return col names\n",
    "            prev_asset_ret_cols = [col for col in rel_ts_df.columns if 'asset_r_' in col]\n",
    "\n",
    "            # Update asset universe with intersection of what we have and what we should have!\n",
    "            lhs_asset_uni = set(rel_y_df[rel_y_df.date>=val_datetime_start].asset.unique())\n",
    "            char_asset_uni = set(rel_char_df[rel_char_df.date>=val_datetime_start].asset.unique())\n",
    "            assert(len(lhs_asset_uni) == len(char_asset_uni)),\"LHS and RHS dont have same assets!\"\n",
    "            assert(len(lhs_asset_uni) == len(prev_asset_ret_cols)), \"LHS and prev ret dont have same assets!\"\n",
    "            asset_universe = set(asset_universe).intersection(lhs_asset_uni)\n",
    "            assert(len(asset_universe) == len(char_asset_uni))\n",
    "\n",
    "            # Set number of assets to consider\n",
    "            num_assets = len(asset_universe)\n",
    "\n",
    "            # normalize rhs data (note: this takes 2-15 min given big df's)\n",
    "            rel_char_df = normalizeAndFillMissing(rel_char_df, lhs_col,\n",
    "                            lhs_pad, rhs_pad, ignore_cols=['date', 'asset'])\n",
    "            rel_ts_df = normalizeAndFillMissing(rel_ts_df, lhs_col, \n",
    "                            lhs_pad, rhs_pad, ignore_cols='date')\n",
    "\n",
    "            # form training and validation data\n",
    "            train_loading_input, train_factor_input, train_output = formLhsAndRhsTensors(rel_y_df, rel_char_df, rel_ts_df,\n",
    "                                                                        train_datetimes, prev_asset_ret_cols, macro_cols,\n",
    "                                                                        lhs_col, hps_dict['num_lags'], num_assets, num_chars)\n",
    "            val_loading_input, val_factor_input, val_output = formLhsAndRhsTensors(rel_y_df, rel_char_df, rel_ts_df,\n",
    "                                                                        val_datetimes_window, prev_asset_ret_cols, macro_cols,\n",
    "                                                                        lhs_col, hps_dict['num_lags'], num_assets, num_chars)\n",
    "\n",
    "            # Fit and predict\n",
    "            num_training_obs = train_output.shape[0]\n",
    "            model = buildTransformer(\n",
    "                num_chars, num_macro_vectors, num_assets, num_training_obs, hps_dict, rel_weight_df)\n",
    "            model, num_epochs_trained, train_mse, train_r2_pred, train_geom_mean_rtrn = fitTransformer(\n",
    "                model, train_loading_input, train_factor_input, train_output,\n",
    "                rel_y_df, lhs_col, lhs_pad, tc_per_hour, num_prtfl_qntls, \n",
    "                train_datetimes, num_assets, hps_dict,\n",
    "                val_loading_input, val_factor_input, val_output)\n",
    "            val_yhats = model.predict([val_loading_input, val_factor_input])\n",
    "            val_yhats_array = tf.reshape(val_yhats, [-1]).numpy()\n",
    "\n",
    "            # Save this val week returns\n",
    "            num_epochs_trained_list.append(num_epochs_trained)\n",
    "            train_mse_list.append(train_mse)\n",
    "            train_r2_pred_list.append(train_r2_pred)\n",
    "            train_geom_mean_rtrn_list.append(train_geom_mean_rtrn)\n",
    "            train_num_assets_list.append(num_assets)\n",
    "            num_model_params_list.append(model.count_params())\n",
    "            temp_yhats_df = rel_y_df[rel_y_df.date >= val_datetime_start].reset_index(drop=True).copy()\n",
    "            temp_yhats_df['yhats'] = val_yhats_array\n",
    "            val_y_yhats_df = pd.concat([val_y_yhats_df, temp_yhats_df])\n",
    "\n",
    "            # Save this week's yhat stat: avg diff across assets of the within asset 95th and 5th quantiles of yhats\n",
    "            quantiles = temp_yhats_df.groupby('asset')['yhats'].quantile([0.05, 0.95]).unstack()\n",
    "            quantiles['diff'] = quantiles[0.95] - quantiles[0.05]\n",
    "            yhats_spread = quantiles['diff'].mean()\n",
    "            yhats_spread_list.append(yhats_spread)\n",
    "        \n",
    "            # Output this week's results\n",
    "            if True:\n",
    "                val_week_df = val_y_yhats_df[(val_y_yhats_df.date>=val_datetime_start) \n",
    "                                        & (val_y_yhats_df.date<=val_datetime_end)].copy()\n",
    "                val_week_df = val_week_df.sort_values(by=['date', 'asset'], ignore_index=True)\n",
    "                val_week_y = val_week_df[lhs_col].values\n",
    "                val_week_yhats = val_week_df['yhats'].values\n",
    "                val_week_r_2_pred = QuantTools.calcR2Pred(val_week_y, val_week_yhats)\n",
    "                print(f'\\n this week r 2 pred: {val_week_r_2_pred}')\n",
    "                val_week_df = QuantTools.formPortfolioWeightsByQuantile(val_week_df, num_prtfl_qntls, False, 'yhats')\n",
    "                val_week_df['returns'] = val_week_df.prtfl_wght_hml*val_week_df[lhs_col]\n",
    "                val_week_returns = (val_week_df.groupby('date')['returns'].sum().values - tc_per_hour)\n",
    "                print(f'this week eq wght unrestricted geom avg ret {QuantTools.calcGeomAvg(val_week_returns)} \\n')\n",
    "                val_week_df = val_y_yhats_df[(val_y_yhats_df.date>=val_datetime_start) \n",
    "                                        & (val_y_yhats_df.date<=val_datetime_end)].copy()\n",
    "                val_week_df = val_week_df.merge(aux_df, on=['date', 'asset'], how='left', validate='one_to_one')\n",
    "                val_week_df = val_week_df.sort_values(by=['date', 'asset'], ignore_index=True)\n",
    "                val_week_mcap_df = QuantTools.formPortfolioWeightsByQuantile(val_week_df, num_prtfl_qntls, mcap_weighted=True)\n",
    "                val_week_mcap_df['returns'] = val_week_mcap_df.prtfl_wght_hml * val_week_mcap_df[lhs_col]\n",
    "                val_week_returns_mcap = (val_week_mcap_df.groupby('date')['returns'].sum().values - tc_per_hour)\n",
    "                print(f'this week mcap wght geom avg ret {QuantTools.calcGeomAvg(val_week_returns_mcap)} \\n')\n",
    "                val_week_df = val_y_yhats_df[(val_y_yhats_df.date>=val_datetime_start) \n",
    "                                        & (val_y_yhats_df.date<=val_datetime_end)].copy()\n",
    "                val_week_df = val_week_df.merge(aux_df, on=['date', 'asset'], how='left', validate='one_to_one')\n",
    "                val_week_df = val_week_df.sort_values(by=['date', 'asset'], ignore_index=True)\n",
    "                val_week_mcap_df = QuantTools.formPortfolioWeightsByQuantile(val_week_df, num_prtfl_qntls, True, 'yhats',\n",
    "                    restrict_shortable_uni, shortable_asset_uni, \n",
    "                    restrict_tradable_volume, prct_volume_threshold, total_trade_volume_per_hour)\n",
    "                val_week_mcap_df['returns'] = val_week_mcap_df.prtfl_wght_hml * val_week_mcap_df[lhs_col]\n",
    "                val_week_returns_mcap = (val_week_mcap_df.groupby('date')['returns'].sum().values - tc_per_hour)\n",
    "                print(f'this week mcap wght shortable and volume restricted geom avg ret {QuantTools.calcGeomAvg(val_week_returns_mcap)} \\n')\n",
    "\n",
    "                # Skip to next hp point if this week val r2 is negative\n",
    "                if True:\n",
    "                    if val_week_r_2_pred < 0:\n",
    "                        break\n",
    "                        \n",
    "        # Stop the timer after this hp grid point is completed\n",
    "        toc = time.perf_counter()\n",
    "\n",
    "        # For this hp point, add metadata to the results dict\n",
    "        hps_results_dict['arch_name'] = arch_name\n",
    "        hps_results_dict['val_start_date'] = val_start_date\n",
    "        hps_results_dict['val_end_date'] = val_end_date\n",
    "        hps_results_dict['runtime'] = round((toc - tic)/60, 0) \n",
    "\n",
    "        # Add training period statistics\n",
    "        hps_results_dict['avg_epochs_trained'] = np.mean(num_epochs_trained_list)\n",
    "        hps_results_dict['avg_num_assets'] = np.mean(train_num_assets_list)\n",
    "        hps_results_dict['avg_num_model_params'] = np.mean(num_model_params_list)\n",
    "        hps_results_dict['train_mse_min'] = np.min(train_mse_list)\n",
    "        hps_results_dict['train_mse_mean'] = np.mean(train_mse_list)\n",
    "        hps_results_dict['train_mse_max'] = np.max(train_mse_list)\n",
    "        hps_results_dict['train_r2_pred_min'] = np.min(train_r2_pred_list)\n",
    "        hps_results_dict['train_r2_pred_mean'] = np.mean(train_r2_pred_list)\n",
    "        hps_results_dict['train_r2_pred_max'] = np.max(train_r2_pred_list)\n",
    "        hps_results_dict['train_geom_mean_rtrn_min'] = np.min(train_geom_mean_rtrn_list)\n",
    "        hps_results_dict['train_geom_mean_rtrn_mean'] = np.mean(train_geom_mean_rtrn_list)\n",
    "        hps_results_dict['train_geom_mean_rtrn_max'] = np.max(train_geom_mean_rtrn_list)\n",
    "\n",
    "        # Obtain validation period results\n",
    "        assert(0 == val_y_yhats_df.isnull().sum().sum()), \"Missing observations in the validation period.\"\n",
    "        val_y_yhats_df = val_y_yhats_df.sort_values(by=['date', 'asset'], ignore_index=True)\n",
    "        val_y_yhats_eq_df = val_y_yhats_df.copy()\n",
    "        val_yhats      = val_y_yhats_df.yhats.values\n",
    "        val_ys         = val_y_yhats_df[lhs_col].values\n",
    "        assert len(val_yhats) == len(val_ys)\n",
    "        val_y_yhats_pos_df = QuantTools.formPortfolioWeightsByQuantile(val_y_yhats_eq_df, num_prtfl_qntls)\n",
    "        val_y_yhats_pos_df['returns'] = val_y_yhats_pos_df.prtfl_wght_hml*val_y_yhats_pos_df[lhs_col]\n",
    "        returns = (val_y_yhats_pos_df.groupby('date')['returns'].sum().values - tc_per_hour)\n",
    "\n",
    "        # Obtain validation period results, by MCAP!\n",
    "        nrows_before = val_y_yhats_df.shape[0]\n",
    "        val_y_yhats_mcap_df = val_y_yhats_df.copy()\n",
    "        val_y_yhats_mcap_df = val_y_yhats_mcap_df.merge(aux_df, on=['date', 'asset'], how='left', validate='one_to_one')\n",
    "        assert(nrows_before == val_y_yhats_mcap_df.shape[0])\n",
    "        val_y_yhats_pos_mcap_df = QuantTools.formPortfolioWeightsByQuantile(val_y_yhats_mcap_df, num_prtfl_qntls, mcap_weighted=True)\n",
    "        val_y_yhats_pos_mcap_df['returns'] = val_y_yhats_pos_mcap_df.prtfl_wght_hml*val_y_yhats_pos_mcap_df[lhs_col]\n",
    "        returns_mcap = (val_y_yhats_pos_mcap_df.groupby('date')['returns'].sum().values - tc_per_hour)\n",
    "\n",
    "        # Obtain validation period results, by mcap with volume and shortable restrictions\n",
    "        nrows_before = val_y_yhats_df.shape[0]\n",
    "        val_y_yhats_mcap_restrict_df = val_y_yhats_df.copy()\n",
    "        val_y_yhats_mcap_restrict_df = val_y_yhats_mcap_restrict_df.merge(aux_df, on=['date', 'asset'], how='left', validate='one_to_one')\n",
    "        assert(nrows_before == val_y_yhats_mcap_restrict_df.shape[0])\n",
    "        val_y_yhats_pos_mcap_restrict_df = QuantTools.formPortfolioWeightsByQuantile(val_y_yhats_mcap_restrict_df, num_prtfl_qntls, True, 'yhats',\n",
    "            restrict_shortable_uni, shortable_asset_uni, \n",
    "            restrict_tradable_volume, prct_volume_threshold, total_trade_volume_per_hour)\n",
    "        val_y_yhats_pos_mcap_restrict_df['returns'] = (val_y_yhats_pos_mcap_restrict_df.prtfl_wght_hml\n",
    "            * val_y_yhats_pos_mcap_restrict_df[lhs_col])\n",
    "        returns_mcap_restricted = (val_y_yhats_pos_mcap_restrict_df.groupby('date')['returns'].sum().values - tc_per_hour)\n",
    "\n",
    "        # Form validation period statistics\n",
    "        hps_results_dict['val_mse']        = QuantTools.calcMSE(val_ys, val_yhats)\n",
    "        hps_results_dict['val_r2_pred']    = QuantTools.calcR2Pred(val_ys, val_yhats)\n",
    "        hps_results_dict['val_yhat_min']   = np.min(val_yhats)\n",
    "        hps_results_dict['val_yhat_q1']    = np.quantile(val_yhats, q=0.25)\n",
    "        hps_results_dict['val_yhat_q2']    = np.quantile(val_yhats, q=0.5)\n",
    "        hps_results_dict['val_yhat_mean']  = np.mean(val_yhats)\n",
    "        hps_results_dict['val_yhat_q3']    = np.quantile(val_yhats, q=0.75)\n",
    "        hps_results_dict['val_yhat_max']   = np.max(val_yhats)\n",
    "        hps_results_dict['geom_mean_1h']   = QuantTools.calcGeomAvg(returns)\n",
    "        hps_results_dict['sharpe_annual']  = QuantTools.calcSharpe(returns, periods_in_year=periods_in_year)\n",
    "        hps_results_dict['sortino_annual'] = QuantTools.calcSortino(returns, periods_in_year=periods_in_year)\n",
    "        hps_results_dict['sd_annual']      = QuantTools.calcSD(returns, periods_in_year=periods_in_year)\n",
    "        hps_results_dict['max_dd']         = QuantTools.calcMaxDrawdown(returns)\n",
    "        hps_results_dict['avg_turnover']   = QuantTools.calcTSAvgTurnover(val_y_yhats_pos_df, 'prtfl_wght_hml')\n",
    "        hps_results_dict['mcap_geom_mean_1h']   = QuantTools.calcGeomAvg(returns_mcap)\n",
    "        hps_results_dict['mcap_sharpe_annual']  = QuantTools.calcSharpe(returns_mcap, periods_in_year=periods_in_year)\n",
    "        hps_results_dict['mcap_sd_annual']      = QuantTools.calcSD(returns_mcap, periods_in_year=periods_in_year)\n",
    "        hps_results_dict['mcap_max_dd']         = QuantTools.calcMaxDrawdown(returns_mcap)\n",
    "        hps_results_dict['mcap_avg_turnover']   = QuantTools.calcTSAvgTurnover(val_y_yhats_pos_mcap_df, 'prtfl_wght_hml')\n",
    "        hps_results_dict['mcap_restrict_geom_mean_1h']   = QuantTools.calcGeomAvg(returns_mcap_restricted)\n",
    "        hps_results_dict['mcap_restrict_sharpe_annual']  = QuantTools.calcSharpe(returns_mcap_restricted, periods_in_year=periods_in_year)\n",
    "        hps_results_dict['mcap_restrict_sd_annual']      = QuantTools.calcSD(returns_mcap_restricted, periods_in_year=periods_in_year)\n",
    "        hps_results_dict['mcap_restrict_max_dd']         = QuantTools.calcMaxDrawdown(returns_mcap_restricted)\n",
    "        hps_results_dict['mcap_restrict_avg_turnover']   = QuantTools.calcTSAvgTurnover(val_y_yhats_pos_mcap_restrict_df, 'prtfl_wght_hml')\n",
    "        hps_results_dict['avg_over_val_wks_ast_95_m_5_quntl_yhats'] = np.mean(yhats_spread_list)\n",
    "\n",
    "        # Add other information to the results\n",
    "        meta_data_dict = {'num_rhs': num_chars,\n",
    "            'lhs_pad': lhs_pad,\n",
    "            'rhs_pad': rhs_pad,\n",
    "            'num_qntls_prtls': num_prtfl_qntls,\n",
    "            'tc_per_hour': tc_per_hour\n",
    "        }\n",
    "        hps_results_dict = {**meta_data_dict, **hps_results_dict}\n",
    "\n",
    "        # Add the final datatime for the val period actually predicted in\n",
    "        hps_results_dict['val_datetime_end'] = val_datetime_end\n",
    "\n",
    "        # Save results to return\n",
    "        results_list.append(hps_results_dict)\n",
    "\n",
    "        # For this hp, save results to csv\n",
    "        cv_df = pd.DataFrame(results_list)\n",
    "        timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        fp = cv_out_fp + '-' + arch_name + '-' + timestr + '.csv'\n",
    "        cv_df.to_csv(fp, index=False)\n",
    "    \n",
    "    # Return cv results\n",
    "    return results_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "435b753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitAndPredictOOS(y_df: pd.DataFrame, char_df: pd.DataFrame, ts_df: pd.DataFrame, weight_df: pd.DataFrame,\n",
    "    aux_df: pd.DataFrame, asset_universe_dict: Dict[str, List], hps_dict: Dict,\n",
    "    oos_start_date: str, oos_end_date: str, \n",
    "    lhs_col: str, lhs_pad: int, rhs_pad: int, num_prtfl_qntls: int, tc_per_hour: float,\n",
    "    oos_out_fp: str,\n",
    "    restrict_shortable_uni: bool=False, shortable_asset_uni: List[str]=[], \n",
    "    restrict_tradable_volume: bool=False, prct_volume_threshold: float=0.05, total_trade_volume_per_hour: int=1e6) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Predicts out-of-sample (OOS) returns for the test period cross section by \n",
    "        recursively refitting in each subsequent week of data.\n",
    "\n",
    "    :param y_df: Dataframe containing the future returns, indexed by date and asset.\n",
    "    :param char_df: Dataframe containing characteristic data, indexed by date and asset.\n",
    "    :param ts_df: Dataframe containing time-series data, indexed by date.\n",
    "    :param weight_df: DataFrame containing panel of mcap and volume data to use to weight obj func.\n",
    "    :param aux_df: DataFrame containing date asset mcap and volume_tp1 columns.\n",
    "    :param asset_universe_dict: Dictionary containing lists of asset identifiers for specific date string keys.\n",
    "    :param hps_grid: Hyperparameter grid to be used in model fitting.\n",
    "    :param oos_start_date: The start date for the OOS period.\n",
    "    :param oos_end_date: The end date for the OOS period.\n",
    "    :param lhs_col: The left-hand-side column name to be used in the model.\n",
    "    :param lhs_pad: Padding value for missing values in the left-hand-side column.\n",
    "    :param rhs_pad: Padding value for missing values in the right-hand-side columns.\n",
    "    :param num_prtfl_qntls: Number of portfolio quantiles to be used.\n",
    "    :param tc_per_hour: Transaction cost per hour.\n",
    "    :param oos_out_fp: Filepath for saving the out-of-sample predictions.\n",
    "    :param restrict_shortable_uni (bool): If True, restrict shortable assets to those listed.\n",
    "    :param shortable_asset_uni (List): assets that are shortable.\n",
    "    :param restrict_tradable_volume (bool): If True, restrict volume to specified percentage.\n",
    "    :param prct_volume_threshold (float): Fraction of datetime-asset volume that is tradable.\n",
    "    :param total_trade_volume_per_hour (int): total dollar trade volume to place in long and short\n",
    "    :param positions used to calculate what fraction of datetime-asset volume is traded.\n",
    "    \n",
    "    :return: Dataframe containing OOS predictions, list of training R^2 prediction values, \n",
    "                list of training geometric mean returns, and a list of the number of model parameters.\n",
    "    \"\"\"\n",
    "    # Form the fp to save yhats\n",
    "    yyyymmdd1 = oos_start_date.replace('-', '')\n",
    "    yyyymmdd2 = oos_end_date.replace('-', '')\n",
    "    out_fp    = oos_out_fp+'_'+yyyymmdd1+'_'+yyyymmdd2+'.pkl'\n",
    "\n",
    "    # Determine RHS columns\n",
    "    char_cols = list(char_df.columns.values)\n",
    "    char_cols.remove('date')\n",
    "    char_cols.remove('asset')\n",
    "    macro_cols = [col for col in ts_df.columns if 'macro' in col]\n",
    "\n",
    "    # Determine number of RHS values\n",
    "    num_chars  = len(char_cols)\n",
    "    num_macro_vectors = int(len(macro_cols)/len(char_cols))\n",
    "\n",
    "    # Determine oos period datetimes to loop over and datetimes to refit at\n",
    "    oos_dts_dict = {}\n",
    "    oos_sun_midnights = np.unique(y_df[(y_df.date>=oos_start_date) \n",
    "        & (y_df.date.dt.hour==0) & (y_df.date.dt.day_of_week==6)].date.values)\n",
    "\n",
    "    # Check if first oos date is sunday midnight, if not then add the dates\n",
    "    first_oos_datetime = np.min(y_df[(y_df.date==oos_start_date)].date.values)\n",
    "    day_of_week_of_first_oos_datetime = (first_oos_datetime.astype('datetime64[D]').view('int64') - 4) % 7\n",
    "    if day_of_week_of_first_oos_datetime != 6:\n",
    "        oos_dts_dict[first_oos_datetime] = np.unique(y_df[(y_df.date>=first_oos_datetime) \n",
    "                                                    & (y_df.date<oos_sun_midnights[0])].date.values)\n",
    "\n",
    "    # Complete the dictionary with all the sundays as keys as the dates until the next sunday as the values\n",
    "    for oos_sun_midnight in oos_sun_midnights:\n",
    "        next_sun_midnight = oos_sun_midnight + np.timedelta64(7, 'D')\n",
    "        oos_dts_dict[oos_sun_midnight] = np.unique(y_df[(y_df.date>=oos_sun_midnight) \n",
    "                                            & (y_df.date<next_sun_midnight)].date.values)\n",
    "        \n",
    "    # Create result objects to return\n",
    "    oos_y_yhats_df            = pd.DataFrame()\n",
    "    train_r2_pred_list        = []\n",
    "    train_geom_mean_rtrn_list = []\n",
    "    train_mse_list            = []\n",
    "    num_model_params_list     = []\n",
    "\n",
    "    # Loop over all the datetimes in the oos period where we want to refit the model\n",
    "    for oos_datetime_start in list(oos_dts_dict.keys()):\n",
    "        # Monitor progress\n",
    "        print('Currently fitting and predicting for the week starting: ')\n",
    "        print(oos_datetime_start)\n",
    "\n",
    "        # form training and oos datetime objects\n",
    "        train_datetimes = list(ts_df[ts_df.date < oos_datetime_start].date.values)[hps_dict['num_lags']-1:]\n",
    "        oos_datetimes_window = oos_dts_dict[oos_datetime_start]\n",
    "        oos_datetime_end = np.max(oos_datetimes_window)\n",
    "\n",
    "        # form appropriate asset universe and update num asset parameter\n",
    "        first_day_of_month_for_current_oos_dt = np.datetime_as_string(oos_datetime_start, unit='M')+'-01'\n",
    "        asset_universe = asset_universe_dict[first_day_of_month_for_current_oos_dt]\n",
    "\n",
    "        # figure out what assets are not included in this asset universe to drop from previous return df\n",
    "        prev_ret_cols_to_drop = [col for col in ts_df.columns \n",
    "                                if (col != 'date') & ('asset_r_' in col) \n",
    "                                if col.split('_')[2] not in asset_universe]\n",
    "\n",
    "        # for all dfs, cut down assets and form relevant dataframes of up to end of current oos week\n",
    "        rel_y_df    = y_df[(y_df.asset.isin(asset_universe))\n",
    "                            & ((y_df.date <= oos_datetime_end))].copy()\n",
    "        rel_char_df = char_df[(char_df.asset.isin(asset_universe))\n",
    "                            & (char_df.date <= oos_datetime_end)].copy()\n",
    "        rel_ts_df   = ts_df[(ts_df.date <= oos_datetime_end)].drop(columns=prev_ret_cols_to_drop, axis=1)\n",
    "        rel_weight_df = weight_df[(weight_df.asset.isin(asset_universe))\n",
    "                            & (weight_df.date < oos_datetime_start)].copy()\n",
    "\n",
    "        # form rel prev asset return col names\n",
    "        prev_asset_ret_cols = [col for col in rel_ts_df.columns if 'asset_r_' in col]\n",
    "\n",
    "        # Update asset universe with intersection of what we have and what we should have!\n",
    "        lhs_asset_uni = set(rel_y_df[rel_y_df.date>=oos_datetime_start].asset.unique())\n",
    "        char_asset_uni = set(rel_char_df[rel_char_df.date>=oos_datetime_start].asset.unique())\n",
    "        assert(len(lhs_asset_uni) == len(char_asset_uni)),\"LHS and RHS dont have same assets!\"\n",
    "        assert(len(lhs_asset_uni) == len(prev_asset_ret_cols)), \"LHS and prev ret dont have same assets!\"\n",
    "        asset_universe = set(asset_universe).intersection(lhs_asset_uni)\n",
    "        assert(len(asset_universe) == len(char_asset_uni))\n",
    "\n",
    "        # Set number of assets to consider\n",
    "        num_assets = len(asset_universe)\n",
    "\n",
    "        # normalize rhs data (note: this takes 2-15 min given big df's)\n",
    "        rel_char_df = normalizeAndFillMissing(rel_char_df, lhs_col,\n",
    "                        lhs_pad, rhs_pad, ignore_cols=['date', 'asset'])\n",
    "        rel_ts_df = normalizeAndFillMissing(rel_ts_df, lhs_col, \n",
    "                        lhs_pad, rhs_pad, ignore_cols='date')\n",
    "\n",
    "        # form training and oos data\n",
    "        train_loading_input, train_factor_input, train_output = formLhsAndRhsTensors(rel_y_df, rel_char_df, rel_ts_df,\n",
    "            train_datetimes, prev_asset_ret_cols, macro_cols, lhs_col, hps_dict['num_lags'], num_assets, num_chars)\n",
    "        oos_loading_input, oos_factor_input, oos_output = formLhsAndRhsTensors(rel_y_df, rel_char_df, rel_ts_df,\n",
    "            oos_datetimes_window, prev_asset_ret_cols, macro_cols, lhs_col, hps_dict['num_lags'], num_assets, num_chars)\n",
    "        \n",
    "        # Fit and predict\n",
    "        num_training_obs = train_output.shape[0]\n",
    "        model = buildTransformer(\n",
    "            num_chars, num_macro_vectors, num_assets, num_training_obs, hps_dict, rel_weight_df)\n",
    "        model, num_epochs_trained, train_mse, train_r2_pred, train_geom_mean_rtrn = fitTransformer(\n",
    "            model, train_loading_input, train_factor_input, train_output,\n",
    "            rel_y_df, lhs_col, lhs_pad, tc_per_hour, num_prtfl_qntls, \n",
    "            train_datetimes, num_assets, hps_dict)\n",
    "        oos_yhats = model.predict([oos_loading_input, oos_factor_input])\n",
    "        oos_yhats_array = tf.reshape(oos_yhats, [-1]).numpy()\n",
    "        \n",
    "        # Save this OOS week results\n",
    "        train_r2_pred_list.append(train_r2_pred)\n",
    "        train_geom_mean_rtrn_list.append(train_geom_mean_rtrn)\n",
    "        train_mse_list.append(train_mse)\n",
    "        num_model_params_list.append(model.count_params())\n",
    "        temp_y_yhats_df = rel_y_df[rel_y_df.date >= oos_datetime_start].reset_index(drop=True).copy()\n",
    "        temp_y_yhats_df['yhats'] = oos_yhats_array\n",
    "        oos_y_yhats_df = pd.concat([oos_y_yhats_df, temp_y_yhats_df])\n",
    "\n",
    "        # Display this week's results\n",
    "        if True:\n",
    "            oos_week_df = oos_y_yhats_df[(oos_y_yhats_df.date>=oos_datetime_start) \n",
    "                                    & (oos_y_yhats_df.date<=oos_datetime_end)].copy()\n",
    "            oos_week_df = oos_week_df.sort_values(by=['date', 'asset'], ignore_index=True)\n",
    "            oos_week_y = oos_week_df[lhs_col].values\n",
    "            oos_week_yhats = oos_week_df['yhats'].values\n",
    "            oos_week_r_2_pred = QuantTools.calcR2Pred(oos_week_y, oos_week_yhats)\n",
    "            print(f'\\n this week r 2 pred: {oos_week_r_2_pred}')\n",
    "            oos_week_eq_df = oos_week_df.copy()\n",
    "            oos_week_eq_df = QuantTools.formPortfolioWeightsByQuantile(oos_week_eq_df, num_prtfl_qntls)\n",
    "            oos_week_eq_df['returns'] = oos_week_eq_df.prtfl_wght_hml*oos_week_eq_df[lhs_col]\n",
    "            oos_week_returns_eq = (oos_week_eq_df.groupby('date')['returns'].sum().values - tc_per_hour)\n",
    "            print(f'this week eq wght unrestricted geom avg ret {QuantTools.calcGeomAvg(oos_week_returns_eq)} \\n')\n",
    "            oos_week_mcap_df = oos_week_df.copy()\n",
    "            oos_week_mcap_df = oos_week_mcap_df.merge(aux_df, on=['date', 'asset'], how='left', validate='one_to_one')\n",
    "            oos_week_mcap_df = QuantTools.formPortfolioWeightsByQuantile(oos_week_mcap_df, num_prtfl_qntls, mcap_weighted=True)\n",
    "            oos_week_mcap_df['returns'] = oos_week_mcap_df.prtfl_wght_hml*oos_week_mcap_df[lhs_col]\n",
    "            oos_week_returns_mcap = (oos_week_mcap_df.groupby('date')['returns'].sum().values - tc_per_hour)\n",
    "            print(f'this week mcap wght geom avg ret {QuantTools.calcGeomAvg(oos_week_returns_mcap)} \\n')\n",
    "            oos_week_mcap_restrict_df = oos_week_df.copy()\n",
    "            oos_week_mcap_restrict_df = oos_week_mcap_restrict_df.merge(aux_df, on=['date', 'asset'], how='left', validate='one_to_one')\n",
    "            oos_week_mcap_restrict_df = QuantTools.formPortfolioWeightsByQuantile(oos_week_mcap_restrict_df, num_prtfl_qntls, True, 'yhats',\n",
    "                restrict_shortable_uni, shortable_asset_uni, \n",
    "                restrict_tradable_volume, prct_volume_threshold, total_trade_volume_per_hour)\n",
    "            oos_week_mcap_restrict_df['returns'] = oos_week_mcap_restrict_df.prtfl_wght_hml*oos_week_mcap_restrict_df[lhs_col]\n",
    "            oos_week_returns_mcap_restrict = (oos_week_mcap_restrict_df.groupby('date')['returns'].sum().values - tc_per_hour)\n",
    "            print(f'this week mcap wght shortable and volume restricted geom avg ret {QuantTools.calcGeomAvg(oos_week_returns_mcap_restrict)} \\n')\n",
    "\n",
    "        # Try to clear out memory, which is kinda unclear how this works...lol.\n",
    "        del model\n",
    "        del train_loading_input, train_factor_input, train_output\n",
    "        del oos_loading_input, oos_factor_input, oos_output\n",
    "        gc.collect()\n",
    "\n",
    "        # Save the file in case this breaks part way through\n",
    "        oos_y_yhats_df.to_pickle(out_fp)\n",
    "\n",
    "    return oos_y_yhats_df, train_r2_pred_list, train_geom_mean_rtrn_list, num_model_params_list, train_mse_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6953a300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently fitting and predicting for the week starting: \n",
      "2022-07-03T00:00:00.000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 09:25:45.011311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5234 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 09:27:28.028698: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-10-18 09:27:46.861782: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-18 09:27:47.088271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-10-18 09:27:47.215701: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x45627e60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-18 09:27:47.215725: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Ti, Compute Capability 8.6\n",
      "2023-10-18 09:27:47.221432: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-18 09:27:47.412207: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 229s 198ms/step - loss: 2.5688 - mse: 0.1858 - weighted_mse: 0.1837\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 48s 198ms/step - loss: 0.7269 - mse: 0.0446 - weighted_mse: 0.0431\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 46s 192ms/step - loss: 0.1329 - mse: 0.0103 - weighted_mse: 0.0098\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 43s 180ms/step - loss: 0.0110 - mse: 0.0022 - weighted_mse: 0.0022\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 46s 192ms/step - loss: 3.7617e-04 - mse: 4.2980e-04 - weighted_mse: 4.4040e-04\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 48s 201ms/step - loss: 1.0282e-05 - mse: 1.6484e-04 - weighted_mse: 1.8494e-04\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 48s 199ms/step - loss: 1.1397e-08 - mse: 1.6743e-04 - weighted_mse: 1.8844e-04\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 47s 197ms/step - loss: 5.8652e-09 - mse: 1.5212e-04 - weighted_mse: 1.7199e-04\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 46s 194ms/step - loss: 5.5808e-09 - mse: 1.4683e-04 - weighted_mse: 1.6624e-04\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 49s 206ms/step - loss: 5.4729e-09 - mse: 1.4372e-04 - weighted_mse: 1.6280e-04\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 47s 198ms/step - loss: 5.4884e-09 - mse: 1.4209e-04 - weighted_mse: 1.6096e-04\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 47s 197ms/step - loss: 5.5236e-09 - mse: 1.4180e-04 - weighted_mse: 1.6065e-04\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 46s 191ms/step - loss: 5.4900e-09 - mse: 1.4128e-04 - weighted_mse: 1.6009e-04\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 47s 194ms/step - loss: 5.5176e-09 - mse: 1.4154e-04 - weighted_mse: 1.6039e-04\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 47s 195ms/step - loss: 5.5084e-09 - mse: 1.4164e-04 - weighted_mse: 1.6051e-04\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 48s 199ms/step - loss: 5.4906e-09 - mse: 1.4145e-04 - weighted_mse: 1.6026e-04\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 47s 198ms/step - loss: 5.4871e-09 - mse: 1.4121e-04 - weighted_mse: 1.6000e-04\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 48s 199ms/step - loss: 5.5174e-09 - mse: 1.4120e-04 - weighted_mse: 1.6000e-04\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 46s 190ms/step - loss: 5.5089e-09 - mse: 1.4104e-04 - weighted_mse: 1.5982e-04\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 46s 190ms/step - loss: 5.5004e-09 - mse: 1.4129e-04 - weighted_mse: 1.6015e-04\n",
      "960/960 [==============================] - 49s 44ms/step\n",
      "6/6 [==============================] - 0s 47ms/step\n",
      "\n",
      " this week r 2 pred: 0.14003771543502808\n",
      "this week eq wght unrestricted geom avg ret -0.00036713564708712454 \n",
      "\n",
      "this week mcap wght geom avg ret 1.816705394697138e-05 \n",
      "\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.00024038483670030253 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-07-10T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 09:55:35.077415: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_1/dropout_84/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 221s 193ms/step - loss: 2.5617 - mse: 0.1520 - weighted_mse: 0.1470\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 49s 202ms/step - loss: 0.7148 - mse: 0.0390 - weighted_mse: 0.0375\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 48s 199ms/step - loss: 0.1273 - mse: 0.0105 - weighted_mse: 0.0103\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 47s 195ms/step - loss: 0.0101 - mse: 0.0023 - weighted_mse: 0.0023\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 42s 173ms/step - loss: 3.4472e-04 - mse: 4.4240e-04 - weighted_mse: 4.4591e-04\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 47s 193ms/step - loss: 7.7613e-06 - mse: 1.8899e-04 - weighted_mse: 2.0901e-04\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 47s 191ms/step - loss: 8.6352e-09 - mse: 1.7376e-04 - weighted_mse: 1.9442e-04\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 51s 212ms/step - loss: 6.3053e-09 - mse: 1.5956e-04 - weighted_mse: 1.7961e-04\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 46s 191ms/step - loss: 5.6960e-09 - mse: 1.4967e-04 - weighted_mse: 1.6911e-04\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 46s 190ms/step - loss: 5.4268e-09 - mse: 1.4494e-04 - weighted_mse: 1.6387e-04\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 47s 193ms/step - loss: 5.4005e-09 - mse: 1.4275e-04 - weighted_mse: 1.6143e-04\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 47s 194ms/step - loss: 5.4728e-09 - mse: 1.4186e-04 - weighted_mse: 1.6044e-04\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 48s 201ms/step - loss: 5.4640e-09 - mse: 1.4105e-04 - weighted_mse: 1.5946e-04\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 47s 194ms/step - loss: 5.4440e-09 - mse: 1.4086e-04 - weighted_mse: 1.5923e-04\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 50s 206ms/step - loss: 5.5367e-09 - mse: 1.4097e-04 - weighted_mse: 1.5939e-04\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 45s 187ms/step - loss: 5.4379e-09 - mse: 1.4078e-04 - weighted_mse: 1.5917e-04\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 47s 196ms/step - loss: 5.4370e-09 - mse: 1.4073e-04 - weighted_mse: 1.5914e-04\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 47s 193ms/step - loss: 5.4665e-09 - mse: 1.4092e-04 - weighted_mse: 1.5938e-04\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 44s 182ms/step - loss: 5.4454e-09 - mse: 1.4046e-04 - weighted_mse: 1.5881e-04\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 48s 197ms/step - loss: 5.4493e-09 - mse: 1.4041e-04 - weighted_mse: 1.5871e-04\n",
      "965/965 [==============================] - 59s 48ms/step\n",
      "6/6 [==============================] - 0s 53ms/step\n",
      "\n",
      " this week r 2 pred: 0.13377785682678223\n",
      "this week eq wght unrestricted geom avg ret 0.0003189894332280563 \n",
      "\n",
      "this week mcap wght geom avg ret 0.0003811316870241388 \n",
      "\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.0003614925877146735 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-07-17T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 10:23:32.013234: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_2/dropout_168/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 221s 200ms/step - loss: 2.5614 - mse: 0.1210 - weighted_mse: 0.1168\n",
      "Epoch 2/20\n",
      "243/243 [==============================] - 47s 195ms/step - loss: 0.7118 - mse: 0.0305 - weighted_mse: 0.0299\n",
      "Epoch 3/20\n",
      "243/243 [==============================] - 45s 184ms/step - loss: 0.1258 - mse: 0.0084 - weighted_mse: 0.0082\n",
      "Epoch 4/20\n",
      "243/243 [==============================] - 45s 186ms/step - loss: 0.0099 - mse: 0.0020 - weighted_mse: 0.0019\n",
      "Epoch 5/20\n",
      "243/243 [==============================] - 50s 206ms/step - loss: 3.5589e-04 - mse: 4.2430e-04 - weighted_mse: 4.2546e-04\n",
      "Epoch 6/20\n",
      "243/243 [==============================] - 47s 192ms/step - loss: 8.9036e-06 - mse: 1.7928e-04 - weighted_mse: 1.9830e-04\n",
      "Epoch 7/20\n",
      "243/243 [==============================] - 44s 183ms/step - loss: 8.4135e-09 - mse: 1.6208e-04 - weighted_mse: 1.8185e-04\n",
      "Epoch 8/20\n",
      "243/243 [==============================] - 50s 205ms/step - loss: 5.7501e-09 - mse: 1.4858e-04 - weighted_mse: 1.6764e-04\n",
      "Epoch 9/20\n",
      "243/243 [==============================] - 49s 202ms/step - loss: 5.5213e-09 - mse: 1.4272e-04 - weighted_mse: 1.6130e-04\n",
      "Epoch 10/20\n",
      "243/243 [==============================] - 47s 193ms/step - loss: 5.4572e-09 - mse: 1.4048e-04 - weighted_mse: 1.5865e-04\n",
      "Epoch 11/20\n",
      "243/243 [==============================] - 46s 187ms/step - loss: 5.4324e-09 - mse: 1.4082e-04 - weighted_mse: 1.5895e-04\n",
      "Epoch 12/20\n",
      "243/243 [==============================] - 48s 197ms/step - loss: 5.4137e-09 - mse: 1.4074e-04 - weighted_mse: 1.5882e-04\n",
      "Epoch 13/20\n",
      "243/243 [==============================] - 50s 204ms/step - loss: 5.3625e-09 - mse: 1.4034e-04 - weighted_mse: 1.5838e-04\n",
      "Epoch 14/20\n",
      "243/243 [==============================] - 46s 191ms/step - loss: 5.3932e-09 - mse: 1.4087e-04 - weighted_mse: 1.5899e-04\n",
      "Epoch 15/20\n",
      "243/243 [==============================] - 48s 197ms/step - loss: 5.3517e-09 - mse: 1.4007e-04 - weighted_mse: 1.5808e-04\n",
      "Epoch 16/20\n",
      "243/243 [==============================] - 46s 190ms/step - loss: 5.3890e-09 - mse: 1.4014e-04 - weighted_mse: 1.5811e-04\n",
      "Epoch 17/20\n",
      "243/243 [==============================] - 48s 195ms/step - loss: 5.3912e-09 - mse: 1.3989e-04 - weighted_mse: 1.5789e-04\n",
      "Epoch 18/20\n",
      "243/243 [==============================] - 47s 193ms/step - loss: 5.4128e-09 - mse: 1.4057e-04 - weighted_mse: 1.5861e-04\n",
      "Epoch 19/20\n",
      "243/243 [==============================] - 46s 188ms/step - loss: 5.4009e-09 - mse: 1.4017e-04 - weighted_mse: 1.5811e-04\n",
      "Epoch 20/20\n",
      "243/243 [==============================] - 48s 199ms/step - loss: 5.3937e-09 - mse: 1.4018e-04 - weighted_mse: 1.5819e-04\n",
      "970/970 [==============================] - 54s 45ms/step\n",
      "6/6 [==============================] - 0s 32ms/step\n",
      "\n",
      " this week r 2 pred: 0.04690772294998169\n",
      "this week eq wght unrestricted geom avg ret 0.0006226367381232389 \n",
      "\n",
      "this week mcap wght geom avg ret 0.00013163420409201265 \n",
      "\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.00030990573319655823 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-07-24T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 10:51:37.496705: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_3/dropout_252/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 223s 192ms/step - loss: 2.5559 - mse: 0.0983 - weighted_mse: 0.0961\n",
      "Epoch 2/20\n",
      "244/244 [==============================] - 47s 192ms/step - loss: 0.7051 - mse: 0.0237 - weighted_mse: 0.0222\n",
      "Epoch 3/20\n",
      "244/244 [==============================] - 47s 194ms/step - loss: 0.1226 - mse: 0.0057 - weighted_mse: 0.0053\n",
      "Epoch 4/20\n",
      "244/244 [==============================] - 48s 196ms/step - loss: 0.0091 - mse: 0.0013 - weighted_mse: 0.0013\n",
      "Epoch 5/20\n",
      "244/244 [==============================] - 49s 203ms/step - loss: 2.6971e-04 - mse: 3.4842e-04 - weighted_mse: 3.5829e-04\n",
      "Epoch 6/20\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 5.4375e-06 - mse: 1.7471e-04 - weighted_mse: 1.9281e-04\n",
      "Epoch 7/20\n",
      "244/244 [==============================] - 50s 203ms/step - loss: 7.1968e-09 - mse: 1.6446e-04 - weighted_mse: 1.8393e-04\n",
      "Epoch 8/20\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 5.8392e-09 - mse: 1.5236e-04 - weighted_mse: 1.7139e-04\n",
      "Epoch 9/20\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 5.4922e-09 - mse: 1.4610e-04 - weighted_mse: 1.6462e-04\n",
      "Epoch 10/20\n",
      "244/244 [==============================] - 47s 192ms/step - loss: 5.3316e-09 - mse: 1.4223e-04 - weighted_mse: 1.6040e-04\n",
      "Epoch 11/20\n",
      "244/244 [==============================] - 46s 189ms/step - loss: 5.3322e-09 - mse: 1.4048e-04 - weighted_mse: 1.5842e-04\n",
      "Epoch 12/20\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 5.3460e-09 - mse: 1.3983e-04 - weighted_mse: 1.5760e-04\n",
      "Epoch 13/20\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 5.3614e-09 - mse: 1.4005e-04 - weighted_mse: 1.5783e-04\n",
      "Epoch 14/20\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 5.3589e-09 - mse: 1.4007e-04 - weighted_mse: 1.5784e-04\n",
      "Epoch 15/20\n",
      "244/244 [==============================] - 47s 191ms/step - loss: 5.4020e-09 - mse: 1.4055e-04 - weighted_mse: 1.5842e-04\n",
      "Epoch 16/20\n",
      "244/244 [==============================] - 47s 192ms/step - loss: 5.2907e-09 - mse: 1.3977e-04 - weighted_mse: 1.5745e-04\n",
      "Epoch 17/20\n",
      "244/244 [==============================] - 48s 199ms/step - loss: 5.3606e-09 - mse: 1.4026e-04 - weighted_mse: 1.5808e-04\n",
      "Epoch 18/20\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 5.3070e-09 - mse: 1.3982e-04 - weighted_mse: 1.5754e-04\n",
      "Epoch 19/20\n",
      "244/244 [==============================] - 47s 191ms/step - loss: 5.3251e-09 - mse: 1.3987e-04 - weighted_mse: 1.5759e-04\n",
      "Epoch 20/20\n",
      "244/244 [==============================] - 48s 195ms/step - loss: 5.3276e-09 - mse: 1.3961e-04 - weighted_mse: 1.5732e-04\n",
      "975/975 [==============================] - 37s 30ms/step\n",
      "6/6 [==============================] - 10s 66ms/step\n",
      "\n",
      " this week r 2 pred: 0.044119298458099365\n",
      "this week eq wght unrestricted geom avg ret -5.4853810686150695e-05 \n",
      "\n",
      "this week mcap wght geom avg ret 0.0005449998141653367 \n",
      "\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.0006660788176029442 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-07-31T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 11:19:51.862494: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_4/dropout_336/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 224s 191ms/step - loss: 2.5459 - mse: 0.1909 - weighted_mse: 0.1841\n",
      "Epoch 2/20\n",
      "246/246 [==============================] - 47s 191ms/step - loss: 0.6929 - mse: 0.0397 - weighted_mse: 0.0386\n",
      "Epoch 3/20\n",
      "246/246 [==============================] - 49s 201ms/step - loss: 0.1175 - mse: 0.0085 - weighted_mse: 0.0085\n",
      "Epoch 4/20\n",
      "246/246 [==============================] - 49s 198ms/step - loss: 0.0085 - mse: 0.0019 - weighted_mse: 0.0020\n",
      "Epoch 5/20\n",
      "246/246 [==============================] - 48s 194ms/step - loss: 2.5672e-04 - mse: 3.8155e-04 - weighted_mse: 3.9207e-04\n",
      "Epoch 6/20\n",
      "246/246 [==============================] - 49s 197ms/step - loss: 4.7545e-06 - mse: 1.7619e-04 - weighted_mse: 1.9450e-04\n",
      "Epoch 7/20\n",
      "246/246 [==============================] - 48s 195ms/step - loss: 6.7438e-09 - mse: 1.6079e-04 - weighted_mse: 1.7949e-04\n",
      "Epoch 8/20\n",
      "246/246 [==============================] - 49s 197ms/step - loss: 5.4490e-09 - mse: 1.4236e-04 - weighted_mse: 1.5991e-04\n",
      "Epoch 9/20\n",
      "246/246 [==============================] - 48s 193ms/step - loss: 5.3236e-09 - mse: 1.3979e-04 - weighted_mse: 1.5722e-04\n",
      "Epoch 10/20\n",
      "246/246 [==============================] - 50s 202ms/step - loss: 5.3214e-09 - mse: 1.4039e-04 - weighted_mse: 1.5793e-04\n",
      "Epoch 11/20\n",
      "246/246 [==============================] - 47s 193ms/step - loss: 5.2724e-09 - mse: 1.4034e-04 - weighted_mse: 1.5788e-04\n",
      "Epoch 12/20\n",
      "246/246 [==============================] - 48s 197ms/step - loss: 5.2868e-09 - mse: 1.4032e-04 - weighted_mse: 1.5780e-04\n",
      "Epoch 13/20\n",
      "246/246 [==============================] - 49s 200ms/step - loss: 5.3013e-09 - mse: 1.4038e-04 - weighted_mse: 1.5789e-04\n",
      "Epoch 14/20\n",
      "246/246 [==============================] - 49s 198ms/step - loss: 5.2563e-09 - mse: 1.4008e-04 - weighted_mse: 1.5756e-04\n",
      "Epoch 15/20\n",
      "246/246 [==============================] - 50s 202ms/step - loss: 5.2852e-09 - mse: 1.3973e-04 - weighted_mse: 1.5721e-04\n",
      "Epoch 16/20\n",
      "246/246 [==============================] - 50s 201ms/step - loss: 5.2871e-09 - mse: 1.3945e-04 - weighted_mse: 1.5684e-04\n",
      "Epoch 17/20\n",
      "246/246 [==============================] - 45s 183ms/step - loss: 5.3314e-09 - mse: 1.4033e-04 - weighted_mse: 1.5784e-04\n",
      "Epoch 18/20\n",
      "246/246 [==============================] - 51s 209ms/step - loss: 5.2614e-09 - mse: 1.3932e-04 - weighted_mse: 1.5664e-04\n",
      "Epoch 19/20\n",
      "246/246 [==============================] - 49s 199ms/step - loss: 5.3026e-09 - mse: 1.4047e-04 - weighted_mse: 1.5800e-04\n",
      "Epoch 20/20\n",
      "246/246 [==============================] - 48s 195ms/step - loss: 5.2744e-09 - mse: 1.4003e-04 - weighted_mse: 1.5752e-04\n",
      "981/981 [==============================] - 55s 48ms/step\n",
      "6/6 [==============================] - 0s 55ms/step\n",
      "\n",
      " this week r 2 pred: 0.10799604654312134\n",
      "this week eq wght unrestricted geom avg ret 0.0006733242487895197 \n",
      "\n",
      "this week mcap wght geom avg ret 0.0009393700630013768 \n",
      "\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.0012315879402724494 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-08-07T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 11:46:50.534188: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_5/dropout_420/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/247 [==============================] - 170s 154ms/step - loss: 1.8552 - mse: 0.0994 - weighted_mse: 0.0968\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 38s 152ms/step - loss: 0.5091 - mse: 0.0241 - weighted_mse: 0.0234\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 38s 154ms/step - loss: 0.0895 - mse: 0.0063 - weighted_mse: 0.0062\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 39s 157ms/step - loss: 0.0075 - mse: 0.0015 - weighted_mse: 0.0015\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 34s 139ms/step - loss: 2.6633e-04 - mse: 3.2945e-04 - weighted_mse: 3.5060e-04\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 38s 153ms/step - loss: 4.4877e-06 - mse: 1.6162e-04 - weighted_mse: 1.8536e-04\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 38s 155ms/step - loss: 5.9496e-09 - mse: 1.4727e-04 - weighted_mse: 1.7083e-04\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 38s 155ms/step - loss: 5.4726e-09 - mse: 1.4272e-04 - weighted_mse: 1.6631e-04\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 38s 152ms/step - loss: 5.2307e-09 - mse: 1.3728e-04 - weighted_mse: 1.6039e-04\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 38s 155ms/step - loss: 5.1774e-09 - mse: 1.3521e-04 - weighted_mse: 1.5808e-04\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 37s 151ms/step - loss: 5.1601e-09 - mse: 1.3365e-04 - weighted_mse: 1.5633e-04\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 37s 151ms/step - loss: 5.1527e-09 - mse: 1.3293e-04 - weighted_mse: 1.5553e-04\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 37s 149ms/step - loss: 5.1374e-09 - mse: 1.3206e-04 - weighted_mse: 1.5452e-04\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 39s 156ms/step - loss: 5.1834e-09 - mse: 1.3256e-04 - weighted_mse: 1.5520e-04\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 38s 153ms/step - loss: 5.1387e-09 - mse: 1.3192e-04 - weighted_mse: 1.5445e-04\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 38s 154ms/step - loss: 5.1676e-09 - mse: 1.3197e-04 - weighted_mse: 1.5452e-04\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 35s 140ms/step - loss: 5.1763e-09 - mse: 1.3228e-04 - weighted_mse: 1.5487e-04\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 38s 154ms/step - loss: 5.1653e-09 - mse: 1.3213e-04 - weighted_mse: 1.5470e-04\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 39s 156ms/step - loss: 5.1706e-09 - mse: 1.3216e-04 - weighted_mse: 1.5478e-04\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 36s 144ms/step - loss: 5.1584e-09 - mse: 1.3237e-04 - weighted_mse: 1.5499e-04\n",
      "986/986 [==============================] - 43s 38ms/step\n",
      "6/6 [==============================] - 0s 43ms/step\n",
      "\n",
      " this week r 2 pred: 0.06244319677352905\n",
      "this week eq wght unrestricted geom avg ret 2.0623062380931145e-05 \n",
      "\n",
      "this week mcap wght geom avg ret -1.170864808552885e-05 \n",
      "\n",
      "Of a total 168 datetimes, 12.0% have insufficient volume to trade, or not shortable.\n",
      "Of a total 168 datetimes, 12.0% have insufficient volume to trade.\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.0002974873018188884 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-08-14T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 12:09:41.100722: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_483/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 171s 150ms/step - loss: 1.8444 - mse: 0.1207 - weighted_mse: 0.1149\n",
      "Epoch 2/20\n",
      "248/248 [==============================] - 40s 161ms/step - loss: 0.5027 - mse: 0.0317 - weighted_mse: 0.0298\n",
      "Epoch 3/20\n",
      "248/248 [==============================] - 40s 160ms/step - loss: 0.0871 - mse: 0.0079 - weighted_mse: 0.0076\n",
      "Epoch 4/20\n",
      "248/248 [==============================] - 37s 149ms/step - loss: 0.0070 - mse: 0.0016 - weighted_mse: 0.0016\n",
      "Epoch 5/20\n",
      "248/248 [==============================] - 39s 156ms/step - loss: 2.0817e-04 - mse: 3.0850e-04 - weighted_mse: 3.2414e-04\n",
      "Epoch 6/20\n",
      "248/248 [==============================] - 41s 163ms/step - loss: 2.5916e-06 - mse: 1.5394e-04 - weighted_mse: 1.7638e-04\n",
      "Epoch 7/20\n",
      "248/248 [==============================] - 34s 136ms/step - loss: 5.6488e-09 - mse: 1.4181e-04 - weighted_mse: 1.6468e-04\n",
      "Epoch 8/20\n",
      "248/248 [==============================] - 35s 143ms/step - loss: 5.1291e-09 - mse: 1.3230e-04 - weighted_mse: 1.5447e-04\n",
      "Epoch 9/20\n",
      "248/248 [==============================] - 38s 153ms/step - loss: 5.1209e-09 - mse: 1.3096e-04 - weighted_mse: 1.5299e-04\n",
      "Epoch 10/20\n",
      "248/248 [==============================] - 35s 142ms/step - loss: 5.1954e-09 - mse: 1.3138e-04 - weighted_mse: 1.5344e-04\n",
      "Epoch 11/20\n",
      "248/248 [==============================] - 39s 158ms/step - loss: 5.1453e-09 - mse: 1.3134e-04 - weighted_mse: 1.5341e-04\n",
      "Epoch 12/20\n",
      "248/248 [==============================] - 38s 153ms/step - loss: 5.1548e-09 - mse: 1.3155e-04 - weighted_mse: 1.5367e-04\n",
      "Epoch 13/20\n",
      "248/248 [==============================] - 39s 156ms/step - loss: 5.1243e-09 - mse: 1.3128e-04 - weighted_mse: 1.5330e-04\n",
      "Epoch 14/20\n",
      "248/248 [==============================] - 37s 151ms/step - loss: 5.1456e-09 - mse: 1.3132e-04 - weighted_mse: 1.5336e-04\n",
      "Epoch 15/20\n",
      "248/248 [==============================] - 38s 155ms/step - loss: 5.1365e-09 - mse: 1.3157e-04 - weighted_mse: 1.5366e-04\n",
      "Epoch 16/20\n",
      "248/248 [==============================] - 37s 150ms/step - loss: 5.1476e-09 - mse: 1.3185e-04 - weighted_mse: 1.5400e-04\n",
      "Epoch 17/20\n",
      "248/248 [==============================] - 35s 142ms/step - loss: 5.1399e-09 - mse: 1.3177e-04 - weighted_mse: 1.5389e-04\n",
      "Epoch 18/20\n",
      "248/248 [==============================] - 40s 160ms/step - loss: 5.1331e-09 - mse: 1.3139e-04 - weighted_mse: 1.5343e-04\n",
      "Epoch 19/20\n",
      "248/248 [==============================] - 38s 153ms/step - loss: 5.1447e-09 - mse: 1.3189e-04 - weighted_mse: 1.5409e-04\n",
      "Epoch 20/20\n",
      "248/248 [==============================] - 35s 141ms/step - loss: 5.1000e-09 - mse: 1.3181e-04 - weighted_mse: 1.5396e-04\n",
      "991/991 [==============================] - 46s 36ms/step\n",
      "6/6 [==============================] - 0s 36ms/step\n",
      "\n",
      " this week r 2 pred: 0.07195639610290527\n",
      "this week eq wght unrestricted geom avg ret -0.00015553179222038693 \n",
      "\n",
      "this week mcap wght geom avg ret -0.0006022945005412783 \n",
      "\n",
      "Of a total 168 datetimes, 4.0% have insufficient volume to trade, or not shortable.\n",
      "Of a total 168 datetimes, 4.0% have insufficient volume to trade.\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.0002237447071240517 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-08-21T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 12:30:46.060913: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/dropout_546/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 108s 100ms/step - loss: 1.8437 - mse: 0.1320 - weighted_mse: 0.1317\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 0.4993 - mse: 0.0308 - weighted_mse: 0.0307\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 0.0855 - mse: 0.0073 - weighted_mse: 0.0074\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 25s 99ms/step - loss: 0.0067 - mse: 0.0015 - weighted_mse: 0.0015\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 1.9667e-04 - mse: 2.8593e-04 - weighted_mse: 3.0657e-04\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 2.3530e-06 - mse: 1.6390e-04 - weighted_mse: 1.8713e-04\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 5.5635e-09 - mse: 1.4455e-04 - weighted_mse: 1.6750e-04\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 25s 101ms/step - loss: 5.1095e-09 - mse: 1.3484e-04 - weighted_mse: 1.5712e-04\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 5.0800e-09 - mse: 1.3179e-04 - weighted_mse: 1.5374e-04\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 5.1113e-09 - mse: 1.3115e-04 - weighted_mse: 1.5293e-04\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 25s 99ms/step - loss: 5.0966e-09 - mse: 1.3068e-04 - weighted_mse: 1.5233e-04\n",
      "Epoch 12/20\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 5.1208e-09 - mse: 1.3145e-04 - weighted_mse: 1.5328e-04\n",
      "Epoch 13/20\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 5.0974e-09 - mse: 1.3158e-04 - weighted_mse: 1.5344e-04\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 5.0554e-09 - mse: 1.3118e-04 - weighted_mse: 1.5294e-04\n",
      "Epoch 15/20\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 5.0925e-09 - mse: 1.3078e-04 - weighted_mse: 1.5247e-04\n",
      "Epoch 16/20\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 5.1166e-09 - mse: 1.3151e-04 - weighted_mse: 1.5337e-04\n",
      "Epoch 17/20\n",
      "249/249 [==============================] - 25s 99ms/step - loss: 5.0723e-09 - mse: 1.3150e-04 - weighted_mse: 1.5333e-04\n",
      "Epoch 18/20\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 5.0751e-09 - mse: 1.3119e-04 - weighted_mse: 1.5300e-04\n",
      "Epoch 19/20\n",
      "249/249 [==============================] - 25s 101ms/step - loss: 5.0613e-09 - mse: 1.3110e-04 - weighted_mse: 1.5290e-04\n",
      "Epoch 20/20\n",
      "249/249 [==============================] - 25s 101ms/step - loss: 5.0743e-09 - mse: 1.3107e-04 - weighted_mse: 1.5280e-04\n",
      "996/996 [==============================] - 31s 27ms/step\n",
      "6/6 [==============================] - 4s 40ms/step\n",
      "\n",
      " this week r 2 pred: 0.06923556327819824\n",
      "this week eq wght unrestricted geom avg ret 0.00021151425602461416 \n",
      "\n",
      "this week mcap wght geom avg ret -0.0003298614256425081 \n",
      "\n",
      "Of a total 168 datetimes, 10.0% have insufficient volume to trade, or not shortable.\n",
      "Of a total 168 datetimes, 10.0% have insufficient volume to trade.\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.0002658245776305801 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-08-28T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 12:46:26.381605: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_8/dropout_609/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 124s 135ms/step - loss: 1.8338 - mse: 0.0931 - weighted_mse: 0.0864\n",
      "Epoch 2/20\n",
      "251/251 [==============================] - 34s 135ms/step - loss: 0.4914 - mse: 0.0188 - weighted_mse: 0.0183\n",
      "Epoch 3/20\n",
      "251/251 [==============================] - 33s 133ms/step - loss: 0.0828 - mse: 0.0046 - weighted_mse: 0.0045\n",
      "Epoch 4/20\n",
      "251/251 [==============================] - 34s 134ms/step - loss: 0.0064 - mse: 0.0010 - weighted_mse: 0.0010\n",
      "Epoch 5/20\n",
      "251/251 [==============================] - 34s 134ms/step - loss: 1.8597e-04 - mse: 2.6019e-04 - weighted_mse: 2.7474e-04\n",
      "Epoch 6/20\n",
      "251/251 [==============================] - 34s 134ms/step - loss: 2.2806e-06 - mse: 1.5880e-04 - weighted_mse: 1.8136e-04\n",
      "Epoch 7/20\n",
      "251/251 [==============================] - 34s 134ms/step - loss: 5.6729e-09 - mse: 1.4792e-04 - weighted_mse: 1.7060e-04\n",
      "Epoch 8/20\n",
      "251/251 [==============================] - 34s 135ms/step - loss: 5.3430e-09 - mse: 1.4037e-04 - weighted_mse: 1.6293e-04\n",
      "Epoch 9/20\n",
      "251/251 [==============================] - 34s 135ms/step - loss: 5.0944e-09 - mse: 1.3412e-04 - weighted_mse: 1.5592e-04\n",
      "Epoch 10/20\n",
      "251/251 [==============================] - 34s 135ms/step - loss: 5.0741e-09 - mse: 1.3299e-04 - weighted_mse: 1.5472e-04\n",
      "Epoch 11/20\n",
      "251/251 [==============================] - 34s 134ms/step - loss: 5.0223e-09 - mse: 1.3153e-04 - weighted_mse: 1.5301e-04\n",
      "Epoch 12/20\n",
      "251/251 [==============================] - 34s 134ms/step - loss: 4.9951e-09 - mse: 1.3103e-04 - weighted_mse: 1.5248e-04\n",
      "Epoch 13/20\n",
      "251/251 [==============================] - 34s 134ms/step - loss: 5.0043e-09 - mse: 1.3105e-04 - weighted_mse: 1.5246e-04\n",
      "Epoch 14/20\n",
      "251/251 [==============================] - 34s 134ms/step - loss: 5.0015e-09 - mse: 1.3092e-04 - weighted_mse: 1.5228e-04\n",
      "Epoch 15/20\n",
      "251/251 [==============================] - 34s 135ms/step - loss: 5.0331e-09 - mse: 1.3144e-04 - weighted_mse: 1.5289e-04\n",
      "Epoch 16/20\n",
      "251/251 [==============================] - 34s 136ms/step - loss: 4.9953e-09 - mse: 1.3137e-04 - weighted_mse: 1.5285e-04\n",
      "Epoch 17/20\n",
      "251/251 [==============================] - 34s 135ms/step - loss: 4.9831e-09 - mse: 1.3108e-04 - weighted_mse: 1.5245e-04\n",
      "Epoch 18/20\n",
      "251/251 [==============================] - 34s 135ms/step - loss: 4.9739e-09 - mse: 1.3093e-04 - weighted_mse: 1.5230e-04\n",
      "Epoch 19/20\n",
      "251/251 [==============================] - 34s 135ms/step - loss: 4.9863e-09 - mse: 1.3096e-04 - weighted_mse: 1.5233e-04\n",
      "Epoch 20/20\n",
      "251/251 [==============================] - 34s 134ms/step - loss: 4.9943e-09 - mse: 1.3109e-04 - weighted_mse: 1.5244e-04\n",
      "1002/1002 [==============================] - 44s 40ms/step\n",
      "6/6 [==============================] - 0s 40ms/step\n",
      "\n",
      " this week r 2 pred: 0.06792277097702026\n",
      "this week eq wght unrestricted geom avg ret 0.00020280375511427806 \n",
      "\n",
      "this week mcap wght geom avg ret 0.0008236731561461763 \n",
      "\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.001110688255844039 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-09-04T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 13:05:30.749343: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_9/dropout_672/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 136s 147ms/step - loss: 2.0285 - mse: 0.1545 - weighted_mse: 0.1498\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 37s 146ms/step - loss: 0.5375 - mse: 0.0346 - weighted_mse: 0.0331\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 37s 145ms/step - loss: 0.0882 - mse: 0.0082 - weighted_mse: 0.0080\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 37s 145ms/step - loss: 0.0064 - mse: 0.0018 - weighted_mse: 0.0017\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 37s 146ms/step - loss: 2.0179e-04 - mse: 3.7161e-04 - weighted_mse: 3.6099e-04\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 37s 146ms/step - loss: 2.5966e-06 - mse: 1.6403e-04 - weighted_mse: 1.8428e-04\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 37s 146ms/step - loss: 5.2631e-09 - mse: 1.3469e-04 - weighted_mse: 1.5422e-04\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 37s 145ms/step - loss: 4.3432e-09 - mse: 1.1806e-04 - weighted_mse: 1.3594e-04\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 37s 145ms/step - loss: 4.2049e-09 - mse: 1.1397e-04 - weighted_mse: 1.3124e-04\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 37s 147ms/step - loss: 4.2368e-09 - mse: 1.1173e-04 - weighted_mse: 1.2848e-04\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 37s 146ms/step - loss: 4.2205e-09 - mse: 1.1154e-04 - weighted_mse: 1.2816e-04\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 37s 146ms/step - loss: 4.2516e-09 - mse: 1.1134e-04 - weighted_mse: 1.2789e-04\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 37s 146ms/step - loss: 4.2194e-09 - mse: 1.1146e-04 - weighted_mse: 1.2802e-04\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 37s 145ms/step - loss: 4.2340e-09 - mse: 1.1158e-04 - weighted_mse: 1.2818e-04\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 37s 146ms/step - loss: 4.2567e-09 - mse: 1.1159e-04 - weighted_mse: 1.2821e-04\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 37s 146ms/step - loss: 4.2153e-09 - mse: 1.1133e-04 - weighted_mse: 1.2784e-04\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 37s 146ms/step - loss: 4.2384e-09 - mse: 1.1138e-04 - weighted_mse: 1.2793e-04\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 37s 146ms/step - loss: 4.2151e-09 - mse: 1.1150e-04 - weighted_mse: 1.2814e-04\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 37s 145ms/step - loss: 4.2133e-09 - mse: 1.1132e-04 - weighted_mse: 1.2791e-04\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 37s 145ms/step - loss: 4.2258e-09 - mse: 1.1132e-04 - weighted_mse: 1.2788e-04\n",
      "1007/1007 [==============================] - 47s 43ms/step\n",
      "6/6 [==============================] - 0s 42ms/step\n",
      "\n",
      " this week r 2 pred: 0.09121567010879517\n",
      "this week eq wght unrestricted geom avg ret 0.0002027078785660219 \n",
      "\n",
      "this week mcap wght geom avg ret 0.0001766293844411848 \n",
      "\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.000501469929780507 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-09-11T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 13:25:44.030025: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_10/dropout_741/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253/253 [==============================] - 134s 146ms/step - loss: 2.0201 - mse: 0.1788 - weighted_mse: 0.1731\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 37s 146ms/step - loss: 0.5311 - mse: 0.0321 - weighted_mse: 0.0312\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 37s 144ms/step - loss: 0.0856 - mse: 0.0071 - weighted_mse: 0.0070\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 37s 144ms/step - loss: 0.0060 - mse: 0.0016 - weighted_mse: 0.0016\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 36s 144ms/step - loss: 1.6261e-04 - mse: 3.2275e-04 - weighted_mse: 3.1636e-04\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 36s 144ms/step - loss: 1.9207e-06 - mse: 1.3901e-04 - weighted_mse: 1.5661e-04\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 36s 144ms/step - loss: 4.3123e-09 - mse: 1.1907e-04 - weighted_mse: 1.3629e-04\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 36s 144ms/step - loss: 4.1138e-09 - mse: 1.1351e-04 - weighted_mse: 1.3035e-04\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 36s 143ms/step - loss: 4.1416e-09 - mse: 1.1165e-04 - weighted_mse: 1.2800e-04\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 36s 144ms/step - loss: 4.1789e-09 - mse: 1.1163e-04 - weighted_mse: 1.2788e-04\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 36s 144ms/step - loss: 4.1703e-09 - mse: 1.1142e-04 - weighted_mse: 1.2772e-04\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 36s 144ms/step - loss: 4.1735e-09 - mse: 1.1156e-04 - weighted_mse: 1.2782e-04\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 36s 144ms/step - loss: 4.1639e-09 - mse: 1.1136e-04 - weighted_mse: 1.2760e-04\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 36s 144ms/step - loss: 4.1813e-09 - mse: 1.1175e-04 - weighted_mse: 1.2811e-04\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 36s 144ms/step - loss: 4.1468e-09 - mse: 1.1139e-04 - weighted_mse: 1.2757e-04\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 37s 145ms/step - loss: 4.1706e-09 - mse: 1.1133e-04 - weighted_mse: 1.2752e-04\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 36s 144ms/step - loss: 4.1511e-09 - mse: 1.1103e-04 - weighted_mse: 1.2716e-04\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 36s 143ms/step - loss: 4.1760e-09 - mse: 1.1132e-04 - weighted_mse: 1.2750e-04\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 36s 144ms/step - loss: 4.1715e-09 - mse: 1.1140e-04 - weighted_mse: 1.2766e-04\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 36s 144ms/step - loss: 4.1479e-09 - mse: 1.1119e-04 - weighted_mse: 1.2736e-04\n",
      "1012/1012 [==============================] - 48s 43ms/step\n",
      "6/6 [==============================] - 0s 42ms/step\n",
      "\n",
      " this week r 2 pred: 0.048821985721588135\n",
      "this week eq wght unrestricted geom avg ret 0.0005730488665676159 \n",
      "\n",
      "this week mcap wght geom avg ret 0.00048487367345240173 \n",
      "\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.0005899218282714447 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-09-18T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 13:45:52.421685: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_11/dropout_810/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255/255 [==============================] - 135s 142ms/step - loss: 2.0129 - mse: 0.1638 - weighted_mse: 0.1493\n",
      "Epoch 2/20\n",
      "255/255 [==============================] - 36s 141ms/step - loss: 0.5212 - mse: 0.0287 - weighted_mse: 0.0269\n",
      "Epoch 3/20\n",
      "255/255 [==============================] - 36s 141ms/step - loss: 0.0815 - mse: 0.0062 - weighted_mse: 0.0060\n",
      "Epoch 4/20\n",
      "255/255 [==============================] - 36s 141ms/step - loss: 0.0053 - mse: 0.0013 - weighted_mse: 0.0012\n",
      "Epoch 5/20\n",
      "255/255 [==============================] - 36s 141ms/step - loss: 1.2736e-04 - mse: 2.8533e-04 - weighted_mse: 2.8949e-04\n",
      "Epoch 6/20\n",
      "255/255 [==============================] - 36s 141ms/step - loss: 1.2119e-06 - mse: 1.3507e-04 - weighted_mse: 1.5247e-04\n",
      "Epoch 7/20\n",
      "255/255 [==============================] - 36s 141ms/step - loss: 4.2844e-09 - mse: 1.1791e-04 - weighted_mse: 1.3456e-04\n",
      "Epoch 8/20\n",
      "255/255 [==============================] - 36s 141ms/step - loss: 4.1445e-09 - mse: 1.1234e-04 - weighted_mse: 1.2849e-04\n",
      "Epoch 9/20\n",
      "255/255 [==============================] - 36s 141ms/step - loss: 4.1402e-09 - mse: 1.1134e-04 - weighted_mse: 1.2735e-04\n",
      "Epoch 10/20\n",
      "255/255 [==============================] - 36s 141ms/step - loss: 4.1321e-09 - mse: 1.1092e-04 - weighted_mse: 1.2677e-04\n",
      "Epoch 11/20\n",
      "255/255 [==============================] - 36s 140ms/step - loss: 4.1512e-09 - mse: 1.1080e-04 - weighted_mse: 1.2656e-04\n",
      "Epoch 12/20\n",
      "255/255 [==============================] - 36s 141ms/step - loss: 4.1329e-09 - mse: 1.1082e-04 - weighted_mse: 1.2665e-04\n",
      "Epoch 13/20\n",
      "255/255 [==============================] - 36s 141ms/step - loss: 4.1574e-09 - mse: 1.1095e-04 - weighted_mse: 1.2677e-04\n",
      "Epoch 14/20\n",
      "255/255 [==============================] - 36s 142ms/step - loss: 4.1253e-09 - mse: 1.1071e-04 - weighted_mse: 1.2654e-04\n",
      "Epoch 15/20\n",
      "255/255 [==============================] - 37s 144ms/step - loss: 4.1506e-09 - mse: 1.1100e-04 - weighted_mse: 1.2689e-04\n",
      "Epoch 16/20\n",
      "255/255 [==============================] - 36s 142ms/step - loss: 4.1335e-09 - mse: 1.1075e-04 - weighted_mse: 1.2662e-04\n",
      "Epoch 17/20\n",
      "255/255 [==============================] - 36s 142ms/step - loss: 4.1223e-09 - mse: 1.1071e-04 - weighted_mse: 1.2653e-04\n",
      "Epoch 18/20\n",
      "255/255 [==============================] - 37s 144ms/step - loss: 4.1414e-09 - mse: 1.1076e-04 - weighted_mse: 1.2656e-04\n",
      "Epoch 19/20\n",
      "255/255 [==============================] - 36s 142ms/step - loss: 4.1402e-09 - mse: 1.1104e-04 - weighted_mse: 1.2693e-04\n",
      "Epoch 20/20\n",
      "255/255 [==============================] - 36s 142ms/step - loss: 4.1336e-09 - mse: 1.1090e-04 - weighted_mse: 1.2680e-04\n",
      "1017/1017 [==============================] - 33s 29ms/step\n",
      "6/6 [==============================] - 5s 42ms/step\n",
      "\n",
      " this week r 2 pred: 0.08785879611968994\n",
      "this week eq wght unrestricted geom avg ret -0.00023776592333502045 \n",
      "\n",
      "this week mcap wght geom avg ret -0.0003583174564151248 \n",
      "\n",
      "Of a total 168 datetimes, 2.0% have insufficient volume to trade, or not shortable.\n",
      "Of a total 168 datetimes, 2.0% have insufficient volume to trade.\n",
      "this week mcap wght shortable and volume restricted geom avg ret -0.0003042637165940887 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-09-25T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 14:05:56.488354: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_12/dropout_879/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 140s 147ms/step - loss: 2.0079 - mse: 0.1583 - weighted_mse: 0.1541\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 37s 146ms/step - loss: 0.5168 - mse: 0.0353 - weighted_mse: 0.0338\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 37s 145ms/step - loss: 0.0799 - mse: 0.0085 - weighted_mse: 0.0078\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 37s 145ms/step - loss: 0.0051 - mse: 0.0017 - weighted_mse: 0.0015\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 37s 144ms/step - loss: 1.2187e-04 - mse: 3.1841e-04 - weighted_mse: 2.8747e-04\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 37s 143ms/step - loss: 1.1043e-06 - mse: 1.3153e-04 - weighted_mse: 1.4843e-04\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 37s 144ms/step - loss: 4.2744e-09 - mse: 1.1894e-04 - weighted_mse: 1.3544e-04\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 37s 144ms/step - loss: 4.1254e-09 - mse: 1.1421e-04 - weighted_mse: 1.3032e-04\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 37s 144ms/step - loss: 4.0978e-09 - mse: 1.1186e-04 - weighted_mse: 1.2764e-04\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 37s 143ms/step - loss: 4.1062e-09 - mse: 1.1093e-04 - weighted_mse: 1.2652e-04\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 37s 144ms/step - loss: 4.0771e-09 - mse: 1.1058e-04 - weighted_mse: 1.2616e-04\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 37s 144ms/step - loss: 4.1208e-09 - mse: 1.1100e-04 - weighted_mse: 1.2671e-04\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 37s 143ms/step - loss: 4.0767e-09 - mse: 1.1046e-04 - weighted_mse: 1.2602e-04\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 37s 144ms/step - loss: 4.1004e-09 - mse: 1.1070e-04 - weighted_mse: 1.2629e-04\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 37s 144ms/step - loss: 4.0802e-09 - mse: 1.1060e-04 - weighted_mse: 1.2613e-04\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 37s 144ms/step - loss: 4.0977e-09 - mse: 1.1091e-04 - weighted_mse: 1.2655e-04\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 37s 144ms/step - loss: 4.0850e-09 - mse: 1.1070e-04 - weighted_mse: 1.2625e-04\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 37s 145ms/step - loss: 4.0775e-09 - mse: 1.1051e-04 - weighted_mse: 1.2607e-04\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 37s 144ms/step - loss: 4.1034e-09 - mse: 1.1089e-04 - weighted_mse: 1.2656e-04\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 37s 144ms/step - loss: 4.0839e-09 - mse: 1.1060e-04 - weighted_mse: 1.2615e-04\n",
      "1023/1023 [==============================] - 48s 43ms/step\n",
      "6/6 [==============================] - 0s 43ms/step\n",
      "\n",
      " this week r 2 pred: 0.04704552888870239\n",
      "this week eq wght unrestricted geom avg ret 0.0002371767616469178 \n",
      "\n",
      "this week mcap wght geom avg ret -0.00015378314071456956 \n",
      "\n",
      "this week mcap wght shortable and volume restricted geom avg ret -4.091691064855851e-06 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-10-02T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 14:26:00.070773: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_13/dropout_948/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 120s 131ms/step - loss: 1.7302 - mse: 0.1183 - weighted_mse: 0.1142\n",
      "Epoch 2/20\n",
      "257/257 [==============================] - 33s 129ms/step - loss: 0.4469 - mse: 0.0238 - weighted_mse: 0.0220\n",
      "Epoch 3/20\n",
      "257/257 [==============================] - 33s 128ms/step - loss: 0.0703 - mse: 0.0062 - weighted_mse: 0.0056\n",
      "Epoch 4/20\n",
      "257/257 [==============================] - 33s 128ms/step - loss: 0.0048 - mse: 0.0015 - weighted_mse: 0.0014\n",
      "Epoch 5/20\n",
      "257/257 [==============================] - 33s 128ms/step - loss: 1.1659e-04 - mse: 3.0904e-04 - weighted_mse: 3.1720e-04\n",
      "Epoch 6/20\n",
      "257/257 [==============================] - 33s 128ms/step - loss: 8.8553e-07 - mse: 1.7589e-04 - weighted_mse: 1.9531e-04\n",
      "Epoch 7/20\n",
      "257/257 [==============================] - 33s 129ms/step - loss: 5.6633e-09 - mse: 1.6039e-04 - weighted_mse: 1.7948e-04\n",
      "Epoch 8/20\n",
      "257/257 [==============================] - 33s 128ms/step - loss: 5.5016e-09 - mse: 1.5390e-04 - weighted_mse: 1.7263e-04\n",
      "Epoch 9/20\n",
      "257/257 [==============================] - 33s 129ms/step - loss: 5.5118e-09 - mse: 1.5282e-04 - weighted_mse: 1.7139e-04\n",
      "Epoch 10/20\n",
      "257/257 [==============================] - 33s 129ms/step - loss: 5.4831e-09 - mse: 1.5307e-04 - weighted_mse: 1.7164e-04\n",
      "Epoch 11/20\n",
      "257/257 [==============================] - 33s 129ms/step - loss: 5.5087e-09 - mse: 1.5269e-04 - weighted_mse: 1.7123e-04\n",
      "Epoch 12/20\n",
      "257/257 [==============================] - 33s 129ms/step - loss: 5.5185e-09 - mse: 1.5299e-04 - weighted_mse: 1.7159e-04\n",
      "Epoch 13/20\n",
      "257/257 [==============================] - 33s 129ms/step - loss: 5.5089e-09 - mse: 1.5281e-04 - weighted_mse: 1.7137e-04\n",
      "Epoch 14/20\n",
      "257/257 [==============================] - 33s 130ms/step - loss: 5.5093e-09 - mse: 1.5323e-04 - weighted_mse: 1.7187e-04\n",
      "Epoch 15/20\n",
      "257/257 [==============================] - 33s 129ms/step - loss: 5.4889e-09 - mse: 1.5266e-04 - weighted_mse: 1.7119e-04\n",
      "Epoch 16/20\n",
      "257/257 [==============================] - 33s 128ms/step - loss: 5.5219e-09 - mse: 1.5294e-04 - weighted_mse: 1.7150e-04\n",
      "Epoch 17/20\n",
      "257/257 [==============================] - 33s 129ms/step - loss: 5.4845e-09 - mse: 1.5246e-04 - weighted_mse: 1.7101e-04\n",
      "Epoch 18/20\n",
      "257/257 [==============================] - 33s 128ms/step - loss: 5.4960e-09 - mse: 1.5277e-04 - weighted_mse: 1.7136e-04\n",
      "Epoch 19/20\n",
      "257/257 [==============================] - 33s 129ms/step - loss: 5.5175e-09 - mse: 1.5296e-04 - weighted_mse: 1.7154e-04\n",
      "Epoch 20/20\n",
      "257/257 [==============================] - 33s 129ms/step - loss: 5.4960e-09 - mse: 1.5289e-04 - weighted_mse: 1.7148e-04\n",
      "1028/1028 [==============================] - 44s 38ms/step\n",
      "6/6 [==============================] - 0s 39ms/step\n",
      "\n",
      " this week r 2 pred: 0.03438788652420044\n",
      "this week eq wght unrestricted geom avg ret -5.4096575447304396e-05 \n",
      "\n",
      "this week mcap wght geom avg ret 1.5819468193400965e-05 \n",
      "\n",
      "Of a total 168 datetimes, 1.0% have insufficient volume to trade, or not shortable.\n",
      "Of a total 168 datetimes, 1.0% have insufficient volume to trade.\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.00023137214156920827 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-10-09T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 14:44:31.629749: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_14/dropout_1008/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259/259 [==============================] - 120s 133ms/step - loss: 1.7127 - mse: 0.1596 - weighted_mse: 0.1580\n",
      "Epoch 2/20\n",
      "259/259 [==============================] - 34s 132ms/step - loss: 0.4349 - mse: 0.0371 - weighted_mse: 0.0358\n",
      "Epoch 3/20\n",
      "259/259 [==============================] - 34s 132ms/step - loss: 0.0664 - mse: 0.0097 - weighted_mse: 0.0094\n",
      "Epoch 4/20\n",
      "259/259 [==============================] - 34s 131ms/step - loss: 0.0044 - mse: 0.0020 - weighted_mse: 0.0020\n",
      "Epoch 5/20\n",
      "259/259 [==============================] - 34s 132ms/step - loss: 1.0188e-04 - mse: 3.4327e-04 - weighted_mse: 3.5380e-04\n",
      "Epoch 6/20\n",
      "259/259 [==============================] - 34s 132ms/step - loss: 7.1980e-07 - mse: 1.7060e-04 - weighted_mse: 1.8956e-04\n",
      "Epoch 7/20\n",
      "259/259 [==============================] - 34s 131ms/step - loss: 5.4549e-09 - mse: 1.5908e-04 - weighted_mse: 1.7776e-04\n",
      "Epoch 8/20\n",
      "259/259 [==============================] - 34s 130ms/step - loss: 5.3684e-09 - mse: 1.5535e-04 - weighted_mse: 1.7390e-04\n",
      "Epoch 9/20\n",
      "259/259 [==============================] - 34s 130ms/step - loss: 5.4112e-09 - mse: 1.5324e-04 - weighted_mse: 1.7161e-04\n",
      "Epoch 10/20\n",
      "259/259 [==============================] - 34s 132ms/step - loss: 5.4249e-09 - mse: 1.5248e-04 - weighted_mse: 1.7074e-04\n",
      "Epoch 11/20\n",
      "259/259 [==============================] - 34s 130ms/step - loss: 5.4470e-09 - mse: 1.5202e-04 - weighted_mse: 1.7022e-04\n",
      "Epoch 12/20\n",
      "259/259 [==============================] - 34s 131ms/step - loss: 5.4762e-09 - mse: 1.5239e-04 - weighted_mse: 1.7062e-04\n",
      "Epoch 13/20\n",
      "259/259 [==============================] - 34s 131ms/step - loss: 5.4375e-09 - mse: 1.5272e-04 - weighted_mse: 1.7101e-04\n",
      "Epoch 14/20\n",
      "259/259 [==============================] - 34s 130ms/step - loss: 5.4316e-09 - mse: 1.5240e-04 - weighted_mse: 1.7065e-04\n",
      "Epoch 15/20\n",
      "259/259 [==============================] - 34s 131ms/step - loss: 5.4569e-09 - mse: 1.5289e-04 - weighted_mse: 1.7122e-04\n",
      "Epoch 16/20\n",
      "259/259 [==============================] - 34s 132ms/step - loss: 5.4108e-09 - mse: 1.5289e-04 - weighted_mse: 1.7124e-04\n",
      "Epoch 17/20\n",
      "259/259 [==============================] - 34s 131ms/step - loss: 5.4343e-09 - mse: 1.5287e-04 - weighted_mse: 1.7119e-04\n",
      "Epoch 18/20\n",
      "259/259 [==============================] - 34s 131ms/step - loss: 5.4162e-09 - mse: 1.5235e-04 - weighted_mse: 1.7061e-04\n",
      "Epoch 19/20\n",
      "259/259 [==============================] - 34s 132ms/step - loss: 5.4314e-09 - mse: 1.5232e-04 - weighted_mse: 1.7053e-04\n",
      "Epoch 20/20\n",
      "259/259 [==============================] - 34s 131ms/step - loss: 5.4496e-09 - mse: 1.5284e-04 - weighted_mse: 1.7119e-04\n",
      "1033/1033 [==============================] - 44s 38ms/step\n",
      "6/6 [==============================] - 0s 38ms/step\n",
      "\n",
      " this week r 2 pred: 0.05856281518936157\n",
      "this week eq wght unrestricted geom avg ret 0.00021809003634731816 \n",
      "\n",
      "this week mcap wght geom avg ret 0.0002713941456573554 \n",
      "\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.00032425116414969146 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-10-16T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 15:03:13.663002: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_15/dropout_1068/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/260 [==============================] - 118s 128ms/step - loss: 1.7097 - mse: 0.1545 - weighted_mse: 0.1500\n",
      "Epoch 2/20\n",
      "260/260 [==============================] - 33s 128ms/step - loss: 0.4312 - mse: 0.0297 - weighted_mse: 0.0289\n",
      "Epoch 3/20\n",
      "260/260 [==============================] - 33s 127ms/step - loss: 0.0649 - mse: 0.0064 - weighted_mse: 0.0062\n",
      "Epoch 4/20\n",
      "260/260 [==============================] - 33s 127ms/step - loss: 0.0042 - mse: 0.0013 - weighted_mse: 0.0013\n",
      "Epoch 5/20\n",
      "260/260 [==============================] - 33s 127ms/step - loss: 9.5433e-05 - mse: 2.6366e-04 - weighted_mse: 2.7623e-04\n",
      "Epoch 6/20\n",
      "260/260 [==============================] - 33s 127ms/step - loss: 5.8771e-07 - mse: 1.6969e-04 - weighted_mse: 1.8804e-04\n",
      "Epoch 7/20\n",
      "260/260 [==============================] - 33s 127ms/step - loss: 5.3980e-09 - mse: 1.5842e-04 - weighted_mse: 1.7664e-04\n",
      "Epoch 8/20\n",
      "260/260 [==============================] - 33s 127ms/step - loss: 5.3004e-09 - mse: 1.5354e-04 - weighted_mse: 1.7148e-04\n",
      "Epoch 9/20\n",
      "260/260 [==============================] - 33s 126ms/step - loss: 5.3425e-09 - mse: 1.5192e-04 - weighted_mse: 1.6977e-04\n",
      "Epoch 10/20\n",
      "260/260 [==============================] - 33s 127ms/step - loss: 5.3748e-09 - mse: 1.5272e-04 - weighted_mse: 1.7073e-04\n",
      "Epoch 11/20\n",
      "260/260 [==============================] - 33s 127ms/step - loss: 5.3528e-09 - mse: 1.5207e-04 - weighted_mse: 1.6999e-04\n",
      "Epoch 12/20\n",
      "260/260 [==============================] - 33s 126ms/step - loss: 5.3589e-09 - mse: 1.5231e-04 - weighted_mse: 1.7022e-04\n",
      "Epoch 13/20\n",
      "260/260 [==============================] - 33s 126ms/step - loss: 5.3549e-09 - mse: 1.5234e-04 - weighted_mse: 1.7025e-04\n",
      "Epoch 14/20\n",
      "260/260 [==============================] - 33s 126ms/step - loss: 5.3558e-09 - mse: 1.5214e-04 - weighted_mse: 1.7004e-04\n",
      "Epoch 15/20\n",
      "260/260 [==============================] - 33s 126ms/step - loss: 5.3687e-09 - mse: 1.5193e-04 - weighted_mse: 1.6985e-04\n",
      "Epoch 16/20\n",
      "260/260 [==============================] - 33s 126ms/step - loss: 5.3529e-09 - mse: 1.5219e-04 - weighted_mse: 1.7012e-04\n",
      "Epoch 17/20\n",
      "260/260 [==============================] - 33s 127ms/step - loss: 5.3674e-09 - mse: 1.5242e-04 - weighted_mse: 1.7040e-04\n",
      "Epoch 18/20\n",
      "260/260 [==============================] - 33s 127ms/step - loss: 5.3298e-09 - mse: 1.5239e-04 - weighted_mse: 1.7033e-04\n",
      "Epoch 19/20\n",
      "260/260 [==============================] - 33s 127ms/step - loss: 5.3336e-09 - mse: 1.5231e-04 - weighted_mse: 1.7026e-04\n",
      "Epoch 20/20\n",
      "260/260 [==============================] - 33s 127ms/step - loss: 5.3417e-09 - mse: 1.5236e-04 - weighted_mse: 1.7035e-04\n",
      "1038/1038 [==============================] - 30s 26ms/step\n",
      "6/6 [==============================] - 4s 38ms/step\n",
      "\n",
      " this week r 2 pred: 0.033099353313446045\n",
      "this week eq wght unrestricted geom avg ret 0.0006202409043547519 \n",
      "\n",
      "this week mcap wght geom avg ret 0.00042369508457684724 \n",
      "\n",
      "Of a total 168 datetimes, 1.0% have insufficient volume to trade, or not shortable.\n",
      "Of a total 168 datetimes, 1.0% have insufficient volume to trade.\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.0003923777226872982 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-10-23T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 15:21:29.622002: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_16/dropout_1128/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 120s 133ms/step - loss: 1.7048 - mse: 0.1484 - weighted_mse: 0.1411\n",
      "Epoch 2/20\n",
      "261/261 [==============================] - 34s 132ms/step - loss: 0.4268 - mse: 0.0305 - weighted_mse: 0.0291\n",
      "Epoch 3/20\n",
      "261/261 [==============================] - 34s 131ms/step - loss: 0.0635 - mse: 0.0069 - weighted_mse: 0.0067\n",
      "Epoch 4/20\n",
      "261/261 [==============================] - 34s 131ms/step - loss: 0.0041 - mse: 0.0014 - weighted_mse: 0.0013\n",
      "Epoch 5/20\n",
      "261/261 [==============================] - 34s 132ms/step - loss: 1.0095e-04 - mse: 2.8417e-04 - weighted_mse: 2.9238e-04\n",
      "Epoch 6/20\n",
      "261/261 [==============================] - 34s 131ms/step - loss: 5.8463e-07 - mse: 1.6281e-04 - weighted_mse: 1.8087e-04\n",
      "Epoch 7/20\n",
      "261/261 [==============================] - 34s 131ms/step - loss: 5.4655e-09 - mse: 1.5640e-04 - weighted_mse: 1.7439e-04\n",
      "Epoch 8/20\n",
      "261/261 [==============================] - 34s 130ms/step - loss: 5.3491e-09 - mse: 1.5166e-04 - weighted_mse: 1.6922e-04\n",
      "Epoch 9/20\n",
      "261/261 [==============================] - 34s 131ms/step - loss: 5.3446e-09 - mse: 1.5131e-04 - weighted_mse: 1.6891e-04\n",
      "Epoch 10/20\n",
      "261/261 [==============================] - 34s 131ms/step - loss: 5.3241e-09 - mse: 1.5083e-04 - weighted_mse: 1.6843e-04\n",
      "Epoch 11/20\n",
      "261/261 [==============================] - 34s 131ms/step - loss: 5.3270e-09 - mse: 1.5116e-04 - weighted_mse: 1.6874e-04\n",
      "Epoch 12/20\n",
      "261/261 [==============================] - 34s 131ms/step - loss: 5.3417e-09 - mse: 1.5144e-04 - weighted_mse: 1.6909e-04\n",
      "Epoch 13/20\n",
      "261/261 [==============================] - 34s 131ms/step - loss: 5.3106e-09 - mse: 1.5115e-04 - weighted_mse: 1.6877e-04\n",
      "Epoch 14/20\n",
      "261/261 [==============================] - 34s 132ms/step - loss: 5.3244e-09 - mse: 1.5142e-04 - weighted_mse: 1.6905e-04\n",
      "Epoch 15/20\n",
      "261/261 [==============================] - 34s 130ms/step - loss: 5.3021e-09 - mse: 1.5083e-04 - weighted_mse: 1.6839e-04\n",
      "Epoch 16/20\n",
      "261/261 [==============================] - 34s 130ms/step - loss: 5.3271e-09 - mse: 1.5075e-04 - weighted_mse: 1.6834e-04\n",
      "Epoch 17/20\n",
      "261/261 [==============================] - 34s 131ms/step - loss: 5.3446e-09 - mse: 1.5122e-04 - weighted_mse: 1.6884e-04\n",
      "Epoch 18/20\n",
      "261/261 [==============================] - 34s 132ms/step - loss: 5.3207e-09 - mse: 1.5135e-04 - weighted_mse: 1.6899e-04\n",
      "Epoch 19/20\n",
      "261/261 [==============================] - 34s 132ms/step - loss: 5.2904e-09 - mse: 1.5098e-04 - weighted_mse: 1.6857e-04\n",
      "Epoch 20/20\n",
      "261/261 [==============================] - 34s 131ms/step - loss: 5.3068e-09 - mse: 1.5088e-04 - weighted_mse: 1.6843e-04\n",
      "1044/1044 [==============================] - 44s 38ms/step\n",
      "6/6 [==============================] - 0s 39ms/step\n",
      "\n",
      " this week r 2 pred: 0.08055883646011353\n",
      "this week eq wght unrestricted geom avg ret -0.0004199763282427549 \n",
      "\n",
      "this week mcap wght geom avg ret 0.00035039179260465403 \n",
      "\n",
      "Of a total 168 datetimes, 1.0% have insufficient volume to trade, or not shortable.\n",
      "Of a total 168 datetimes, 1.0% have insufficient volume to trade.\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.0004232193946132057 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-10-30T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 15:40:25.757339: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_17/dropout_1188/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 121s 131ms/step - loss: 1.7000 - mse: 0.1482 - weighted_mse: 0.1470\n",
      "Epoch 2/20\n",
      "263/263 [==============================] - 34s 131ms/step - loss: 0.4219 - mse: 0.0311 - weighted_mse: 0.0299\n",
      "Epoch 3/20\n",
      "263/263 [==============================] - 34s 131ms/step - loss: 0.0622 - mse: 0.0074 - weighted_mse: 0.0070\n",
      "Epoch 4/20\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 0.0040 - mse: 0.0015 - weighted_mse: 0.0014\n",
      "Epoch 5/20\n",
      "263/263 [==============================] - 34s 131ms/step - loss: 9.9375e-05 - mse: 2.9223e-04 - weighted_mse: 2.9521e-04\n",
      "Epoch 6/20\n",
      "263/263 [==============================] - 34s 131ms/step - loss: 5.5487e-07 - mse: 1.6588e-04 - weighted_mse: 1.8365e-04\n",
      "Epoch 7/20\n",
      "263/263 [==============================] - 34s 131ms/step - loss: 5.2218e-09 - mse: 1.5502e-04 - weighted_mse: 1.7258e-04\n",
      "Epoch 8/20\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 5.2338e-09 - mse: 1.5237e-04 - weighted_mse: 1.6982e-04\n",
      "Epoch 9/20\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 5.2243e-09 - mse: 1.5093e-04 - weighted_mse: 1.6827e-04\n",
      "Epoch 10/20\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 5.2575e-09 - mse: 1.5085e-04 - weighted_mse: 1.6818e-04\n",
      "Epoch 11/20\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 5.2585e-09 - mse: 1.5087e-04 - weighted_mse: 1.6813e-04\n",
      "Epoch 12/20\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 5.2622e-09 - mse: 1.5103e-04 - weighted_mse: 1.6830e-04\n",
      "Epoch 13/20\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 5.2776e-09 - mse: 1.5128e-04 - weighted_mse: 1.6864e-04\n",
      "Epoch 14/20\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 5.2389e-09 - mse: 1.5144e-04 - weighted_mse: 1.6885e-04\n",
      "Epoch 15/20\n",
      "263/263 [==============================] - 34s 131ms/step - loss: 5.2156e-09 - mse: 1.5129e-04 - weighted_mse: 1.6865e-04\n",
      "Epoch 16/20\n",
      "263/263 [==============================] - 34s 131ms/step - loss: 5.2301e-09 - mse: 1.5099e-04 - weighted_mse: 1.6828e-04\n",
      "Epoch 17/20\n",
      "263/263 [==============================] - 34s 131ms/step - loss: 5.2977e-09 - mse: 1.5121e-04 - weighted_mse: 1.6860e-04\n",
      "Epoch 18/20\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 5.2401e-09 - mse: 1.5090e-04 - weighted_mse: 1.6823e-04\n",
      "Epoch 19/20\n",
      "263/263 [==============================] - 34s 131ms/step - loss: 5.2326e-09 - mse: 1.5098e-04 - weighted_mse: 1.6830e-04\n",
      "Epoch 20/20\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 5.2248e-09 - mse: 1.5097e-04 - weighted_mse: 1.6832e-04\n",
      "1049/1049 [==============================] - 45s 39ms/step\n",
      "6/6 [==============================] - 0s 39ms/step\n",
      "\n",
      " this week r 2 pred: 0.011583387851715088\n",
      "this week eq wght unrestricted geom avg ret 7.613726491717543e-06 \n",
      "\n",
      "this week mcap wght geom avg ret 0.0005897451877714399 \n",
      "\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.000867074943283308 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-11-06T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 15:59:07.056002: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_18/dropout_1248/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 110s 120ms/step - loss: 1.5120 - mse: 0.1293 - weighted_mse: 0.1307\n",
      "Epoch 2/20\n",
      "264/264 [==============================] - 31s 118ms/step - loss: 0.3724 - mse: 0.0257 - weighted_mse: 0.0249\n",
      "Epoch 3/20\n",
      "264/264 [==============================] - 31s 119ms/step - loss: 0.0541 - mse: 0.0060 - weighted_mse: 0.0056\n",
      "Epoch 4/20\n",
      "264/264 [==============================] - 31s 119ms/step - loss: 0.0034 - mse: 0.0013 - weighted_mse: 0.0012\n",
      "Epoch 5/20\n",
      "264/264 [==============================] - 31s 119ms/step - loss: 7.6708e-05 - mse: 2.4888e-04 - weighted_mse: 2.6633e-04\n",
      "Epoch 6/20\n",
      "264/264 [==============================] - 31s 119ms/step - loss: 3.3421e-07 - mse: 1.6517e-04 - weighted_mse: 1.8926e-04\n",
      "Epoch 7/20\n",
      "264/264 [==============================] - 31s 118ms/step - loss: 5.4937e-09 - mse: 1.5602e-04 - weighted_mse: 1.7983e-04\n",
      "Epoch 8/20\n",
      "264/264 [==============================] - 31s 119ms/step - loss: 5.4288e-09 - mse: 1.5231e-04 - weighted_mse: 1.7572e-04\n",
      "Epoch 9/20\n",
      "264/264 [==============================] - 31s 119ms/step - loss: 5.4604e-09 - mse: 1.5178e-04 - weighted_mse: 1.7523e-04\n",
      "Epoch 10/20\n",
      "264/264 [==============================] - 31s 119ms/step - loss: 5.4535e-09 - mse: 1.5199e-04 - weighted_mse: 1.7545e-04\n",
      "Epoch 11/20\n",
      "264/264 [==============================] - 31s 118ms/step - loss: 5.4416e-09 - mse: 1.5197e-04 - weighted_mse: 1.7546e-04\n",
      "Epoch 12/20\n",
      "264/264 [==============================] - 31s 118ms/step - loss: 5.4314e-09 - mse: 1.5183e-04 - weighted_mse: 1.7528e-04\n",
      "Epoch 13/20\n",
      "264/264 [==============================] - 31s 117ms/step - loss: 5.4521e-09 - mse: 1.5170e-04 - weighted_mse: 1.7514e-04\n",
      "Epoch 14/20\n",
      "264/264 [==============================] - 31s 118ms/step - loss: 5.4514e-09 - mse: 1.5159e-04 - weighted_mse: 1.7494e-04\n",
      "Epoch 15/20\n",
      "264/264 [==============================] - 31s 118ms/step - loss: 5.4418e-09 - mse: 1.5174e-04 - weighted_mse: 1.7519e-04\n",
      "Epoch 16/20\n",
      "264/264 [==============================] - 31s 118ms/step - loss: 5.4535e-09 - mse: 1.5184e-04 - weighted_mse: 1.7527e-04\n",
      "Epoch 17/20\n",
      "264/264 [==============================] - 31s 118ms/step - loss: 5.4431e-09 - mse: 1.5174e-04 - weighted_mse: 1.7517e-04\n",
      "Epoch 18/20\n",
      "264/264 [==============================] - 31s 118ms/step - loss: 5.4385e-09 - mse: 1.5173e-04 - weighted_mse: 1.7514e-04\n",
      "Epoch 19/20\n",
      "264/264 [==============================] - 31s 118ms/step - loss: 5.4341e-09 - mse: 1.5179e-04 - weighted_mse: 1.7522e-04\n",
      "Epoch 20/20\n",
      "264/264 [==============================] - 31s 118ms/step - loss: 5.4499e-09 - mse: 1.5182e-04 - weighted_mse: 1.7521e-04\n",
      "1054/1054 [==============================] - 41s 35ms/step\n",
      "6/6 [==============================] - 0s 35ms/step\n",
      "\n",
      " this week r 2 pred: 0.1071922779083252\n",
      "this week eq wght unrestricted geom avg ret 0.0004381831907547262 \n",
      "\n",
      "this week mcap wght geom avg ret 0.000607477325550887 \n",
      "\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.0008046338766172223 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-11-13T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 16:16:43.282762: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_19/dropout_1302/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 109s 121ms/step - loss: 1.5145 - mse: 0.1307 - weighted_mse: 0.1226\n",
      "Epoch 2/20\n",
      "265/265 [==============================] - 32s 121ms/step - loss: 0.3705 - mse: 0.0303 - weighted_mse: 0.0285\n",
      "Epoch 3/20\n",
      "265/265 [==============================] - 32s 120ms/step - loss: 0.0531 - mse: 0.0059 - weighted_mse: 0.0057\n",
      "Epoch 4/20\n",
      "265/265 [==============================] - 32s 121ms/step - loss: 0.0033 - mse: 0.0011 - weighted_mse: 0.0011\n",
      "Epoch 5/20\n",
      "265/265 [==============================] - 32s 121ms/step - loss: 6.8830e-05 - mse: 2.3869e-04 - weighted_mse: 2.6011e-04\n",
      "Epoch 6/20\n",
      "265/265 [==============================] - 31s 117ms/step - loss: 2.4023e-07 - mse: 1.7092e-04 - weighted_mse: 1.9589e-04\n",
      "Epoch 7/20\n",
      "265/265 [==============================] - 31s 117ms/step - loss: 5.6763e-09 - mse: 1.6057e-04 - weighted_mse: 1.8491e-04\n",
      "Epoch 8/20\n",
      "265/265 [==============================] - 32s 119ms/step - loss: 5.5426e-09 - mse: 1.5484e-04 - weighted_mse: 1.7862e-04\n",
      "Epoch 9/20\n",
      "265/265 [==============================] - 32s 120ms/step - loss: 5.4983e-09 - mse: 1.5197e-04 - weighted_mse: 1.7545e-04\n",
      "Epoch 10/20\n",
      "265/265 [==============================] - 32s 120ms/step - loss: 5.4590e-09 - mse: 1.5178e-04 - weighted_mse: 1.7511e-04\n",
      "Epoch 11/20\n",
      "265/265 [==============================] - 32s 120ms/step - loss: 5.4609e-09 - mse: 1.5151e-04 - weighted_mse: 1.7484e-04\n",
      "Epoch 12/20\n",
      "265/265 [==============================] - 32s 121ms/step - loss: 5.4882e-09 - mse: 1.5268e-04 - weighted_mse: 1.7618e-04\n",
      "Epoch 13/20\n",
      "265/265 [==============================] - 32s 120ms/step - loss: 5.4262e-09 - mse: 1.5168e-04 - weighted_mse: 1.7507e-04\n",
      "Epoch 14/20\n",
      "265/265 [==============================] - 32s 120ms/step - loss: 5.4595e-09 - mse: 1.5196e-04 - weighted_mse: 1.7530e-04\n",
      "Epoch 15/20\n",
      "265/265 [==============================] - 32s 120ms/step - loss: 5.4398e-09 - mse: 1.5172e-04 - weighted_mse: 1.7510e-04\n",
      "Epoch 16/20\n",
      "265/265 [==============================] - 32s 120ms/step - loss: 5.4738e-09 - mse: 1.5186e-04 - weighted_mse: 1.7524e-04\n",
      "Epoch 17/20\n",
      "265/265 [==============================] - 33s 123ms/step - loss: 5.4304e-09 - mse: 1.5179e-04 - weighted_mse: 1.7516e-04\n",
      "Epoch 18/20\n",
      "265/265 [==============================] - 33s 124ms/step - loss: 5.4606e-09 - mse: 1.5161e-04 - weighted_mse: 1.7492e-04\n",
      "Epoch 19/20\n",
      "265/265 [==============================] - 33s 123ms/step - loss: 5.4757e-09 - mse: 1.5217e-04 - weighted_mse: 1.7560e-04\n",
      "Epoch 20/20\n",
      "265/265 [==============================] - 32s 122ms/step - loss: 5.4394e-09 - mse: 1.5219e-04 - weighted_mse: 1.7565e-04\n",
      "1059/1059 [==============================] - 29s 24ms/step\n",
      "6/6 [==============================] - 4s 35ms/step\n",
      "\n",
      " this week r 2 pred: 0.09894543886184692\n",
      "this week eq wght unrestricted geom avg ret 0.0003836521644557944 \n",
      "\n",
      "this week mcap wght geom avg ret 0.0009670300140383059 \n",
      "\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.0011636226399371896 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-11-20T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 16:35:24.628183: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_20/dropout_1356/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 120s 122ms/step - loss: 1.5061 - mse: 0.2159 - weighted_mse: 0.2173\n",
      "Epoch 2/20\n",
      "267/267 [==============================] - 33s 123ms/step - loss: 0.3633 - mse: 0.0497 - weighted_mse: 0.0476\n",
      "Epoch 3/20\n",
      "267/267 [==============================] - 33s 122ms/step - loss: 0.0507 - mse: 0.0095 - weighted_mse: 0.0092\n",
      "Epoch 4/20\n",
      "267/267 [==============================] - 33s 122ms/step - loss: 0.0029 - mse: 0.0016 - weighted_mse: 0.0016\n",
      "Epoch 5/20\n",
      "267/267 [==============================] - 33s 123ms/step - loss: 5.0924e-05 - mse: 2.5567e-04 - weighted_mse: 2.7673e-04\n",
      "Epoch 6/20\n",
      "267/267 [==============================] - 33s 123ms/step - loss: 1.6146e-07 - mse: 1.6071e-04 - weighted_mse: 1.8384e-04\n",
      "Epoch 7/20\n",
      "267/267 [==============================] - 33s 123ms/step - loss: 5.3850e-09 - mse: 1.5133e-04 - weighted_mse: 1.7419e-04\n",
      "Epoch 8/20\n",
      "267/267 [==============================] - 33s 122ms/step - loss: 5.3798e-09 - mse: 1.5150e-04 - weighted_mse: 1.7449e-04\n",
      "Epoch 9/20\n",
      "267/267 [==============================] - 33s 123ms/step - loss: 5.4089e-09 - mse: 1.5170e-04 - weighted_mse: 1.7474e-04\n",
      "Epoch 10/20\n",
      "267/267 [==============================] - 33s 123ms/step - loss: 5.3891e-09 - mse: 1.5180e-04 - weighted_mse: 1.7486e-04\n",
      "Epoch 11/20\n",
      "267/267 [==============================] - 33s 122ms/step - loss: 5.3832e-09 - mse: 1.5142e-04 - weighted_mse: 1.7442e-04\n",
      "Epoch 12/20\n",
      "267/267 [==============================] - 33s 123ms/step - loss: 5.4244e-09 - mse: 1.5187e-04 - weighted_mse: 1.7488e-04\n",
      "Epoch 13/20\n",
      "267/267 [==============================] - 33s 123ms/step - loss: 5.3686e-09 - mse: 1.5172e-04 - weighted_mse: 1.7477e-04\n",
      "Epoch 14/20\n",
      "267/267 [==============================] - 33s 122ms/step - loss: 5.4059e-09 - mse: 1.5160e-04 - weighted_mse: 1.7460e-04\n",
      "Epoch 15/20\n",
      "267/267 [==============================] - 33s 124ms/step - loss: 5.3931e-09 - mse: 1.5187e-04 - weighted_mse: 1.7501e-04\n",
      "Epoch 16/20\n",
      "267/267 [==============================] - 33s 122ms/step - loss: 5.3914e-09 - mse: 1.5168e-04 - weighted_mse: 1.7473e-04\n",
      "Epoch 17/20\n",
      "267/267 [==============================] - 33s 123ms/step - loss: 5.3892e-09 - mse: 1.5195e-04 - weighted_mse: 1.7505e-04\n",
      "Epoch 18/20\n",
      "267/267 [==============================] - 33s 123ms/step - loss: 5.3991e-09 - mse: 1.5188e-04 - weighted_mse: 1.7497e-04\n",
      "Epoch 19/20\n",
      "267/267 [==============================] - 33s 123ms/step - loss: 5.3936e-09 - mse: 1.5205e-04 - weighted_mse: 1.7517e-04\n",
      "Epoch 20/20\n",
      "267/267 [==============================] - 33s 123ms/step - loss: 5.3600e-09 - mse: 1.5185e-04 - weighted_mse: 1.7495e-04\n",
      "1065/1065 [==============================] - 40s 33ms/step\n",
      "6/6 [==============================] - 0s 33ms/step\n",
      "\n",
      " this week r 2 pred: -0.48987627029418945\n",
      "this week eq wght unrestricted geom avg ret -0.0013941219775478464 \n",
      "\n",
      "this week mcap wght geom avg ret -0.001649355185548651 \n",
      "\n",
      "this week mcap wght shortable and volume restricted geom avg ret -0.0018335461980441004 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-11-27T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 16:54:19.826423: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_21/dropout_1410/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 110s 119ms/step - loss: 1.5034 - mse: 0.1468 - weighted_mse: 0.1380\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 31s 117ms/step - loss: 0.3620 - mse: 0.0284 - weighted_mse: 0.0263\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 0.0502 - mse: 0.0057 - weighted_mse: 0.0053\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 0.0029 - mse: 0.0011 - weighted_mse: 0.0011\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 5.2845e-05 - mse: 2.4065e-04 - weighted_mse: 2.6226e-04\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 1.3560e-07 - mse: 1.6195e-04 - weighted_mse: 1.8557e-04\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 5.3359e-09 - mse: 1.5408e-04 - weighted_mse: 1.7730e-04\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 5.3409e-09 - mse: 1.5105e-04 - weighted_mse: 1.7383e-04\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 5.3729e-09 - mse: 1.5108e-04 - weighted_mse: 1.7387e-04\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 5.3597e-09 - mse: 1.5100e-04 - weighted_mse: 1.7375e-04\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 5.3594e-09 - mse: 1.5124e-04 - weighted_mse: 1.7403e-04\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 5.3307e-09 - mse: 1.5113e-04 - weighted_mse: 1.7390e-04\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 5.3391e-09 - mse: 1.5130e-04 - weighted_mse: 1.7410e-04\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 5.3499e-09 - mse: 1.5125e-04 - weighted_mse: 1.7404e-04\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 5.3385e-09 - mse: 1.5115e-04 - weighted_mse: 1.7394e-04\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 5.3182e-09 - mse: 1.5047e-04 - weighted_mse: 1.7311e-04\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 5.3636e-09 - mse: 1.5110e-04 - weighted_mse: 1.7381e-04\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 5.3354e-09 - mse: 1.5094e-04 - weighted_mse: 1.7370e-04\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 5.3511e-09 - mse: 1.5105e-04 - weighted_mse: 1.7384e-04\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 31s 118ms/step - loss: 5.3434e-09 - mse: 1.5135e-04 - weighted_mse: 1.7413e-04\n",
      "1070/1070 [==============================] - 41s 35ms/step\n",
      "6/6 [==============================] - 0s 35ms/step\n",
      "\n",
      " this week r 2 pred: 0.06907325983047485\n",
      "this week eq wght unrestricted geom avg ret 8.472690216909662e-05 \n",
      "\n",
      "this week mcap wght geom avg ret 0.00022012416524175293 \n",
      "\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.00019382332767925448 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-12-04T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 17:12:04.593443: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_22/dropout_1464/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 110s 120ms/step - loss: 1.4896 - mse: 0.1288 - weighted_mse: 0.1185\n",
      "Epoch 2/20\n",
      "269/269 [==============================] - 33s 121ms/step - loss: 0.3557 - mse: 0.0201 - weighted_mse: 0.0185\n",
      "Epoch 3/20\n",
      "269/269 [==============================] - 32s 120ms/step - loss: 0.0489 - mse: 0.0041 - weighted_mse: 0.0039\n",
      "Epoch 4/20\n",
      "269/269 [==============================] - 32s 120ms/step - loss: 0.0028 - mse: 8.6908e-04 - weighted_mse: 8.5349e-04\n",
      "Epoch 5/20\n",
      "269/269 [==============================] - 32s 119ms/step - loss: 4.8204e-05 - mse: 1.7124e-04 - weighted_mse: 1.8552e-04\n",
      "Epoch 6/20\n",
      "269/269 [==============================] - 32s 120ms/step - loss: 1.1142e-07 - mse: 1.2951e-04 - weighted_mse: 1.4386e-04\n",
      "Epoch 7/20\n",
      "269/269 [==============================] - 32s 119ms/step - loss: 4.1279e-09 - mse: 1.2452e-04 - weighted_mse: 1.3873e-04\n",
      "Epoch 8/20\n",
      "269/269 [==============================] - 32s 120ms/step - loss: 4.1122e-09 - mse: 1.2148e-04 - weighted_mse: 1.3541e-04\n",
      "Epoch 9/20\n",
      "269/269 [==============================] - 32s 120ms/step - loss: 4.1309e-09 - mse: 1.2086e-04 - weighted_mse: 1.3458e-04\n",
      "Epoch 10/20\n",
      "269/269 [==============================] - 32s 120ms/step - loss: 4.1482e-09 - mse: 1.2074e-04 - weighted_mse: 1.3440e-04\n",
      "Epoch 11/20\n",
      "269/269 [==============================] - 32s 119ms/step - loss: 4.1180e-09 - mse: 1.2092e-04 - weighted_mse: 1.3464e-04\n",
      "Epoch 12/20\n",
      "269/269 [==============================] - 32s 120ms/step - loss: 4.1160e-09 - mse: 1.2092e-04 - weighted_mse: 1.3458e-04\n",
      "Epoch 13/20\n",
      "269/269 [==============================] - 32s 120ms/step - loss: 4.1377e-09 - mse: 1.2053e-04 - weighted_mse: 1.3410e-04\n",
      "Epoch 14/20\n",
      "269/269 [==============================] - 32s 120ms/step - loss: 4.1363e-09 - mse: 1.2050e-04 - weighted_mse: 1.3414e-04\n",
      "Epoch 15/20\n",
      "269/269 [==============================] - 32s 120ms/step - loss: 4.1181e-09 - mse: 1.2040e-04 - weighted_mse: 1.3398e-04\n",
      "Epoch 16/20\n",
      "269/269 [==============================] - 32s 120ms/step - loss: 4.1308e-09 - mse: 1.2039e-04 - weighted_mse: 1.3399e-04\n",
      "Epoch 17/20\n",
      "269/269 [==============================] - 32s 120ms/step - loss: 4.1261e-09 - mse: 1.2050e-04 - weighted_mse: 1.3412e-04\n",
      "Epoch 18/20\n",
      "269/269 [==============================] - 32s 120ms/step - loss: 4.1316e-09 - mse: 1.2076e-04 - weighted_mse: 1.3443e-04\n",
      "Epoch 19/20\n",
      "269/269 [==============================] - 32s 120ms/step - loss: 4.1127e-09 - mse: 1.2027e-04 - weighted_mse: 1.3383e-04\n",
      "Epoch 20/20\n",
      "269/269 [==============================] - 32s 120ms/step - loss: 4.1167e-09 - mse: 1.1987e-04 - weighted_mse: 1.3340e-04\n",
      "1075/1075 [==============================] - 42s 36ms/step\n",
      "6/6 [==============================] - 0s 34ms/step\n",
      "\n",
      " this week r 2 pred: 0.08774739503860474\n",
      "this week eq wght unrestricted geom avg ret -7.410754272441089e-05 \n",
      "\n",
      "this week mcap wght geom avg ret 0.0003118786879270363 \n",
      "\n",
      "Of a total 168 datetimes, 1.0% have insufficient volume to trade, or not shortable.\n",
      "Of a total 168 datetimes, 2.0% have insufficient volume to trade.\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.00019235275883189296 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-12-11T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 17:30:06.176769: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_23/dropout_1518/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 97s 90ms/step - loss: 1.5031 - mse: 0.1148 - weighted_mse: 0.1102\n",
      "Epoch 2/20\n",
      "270/270 [==============================] - 24s 91ms/step - loss: 0.3570 - mse: 0.0208 - weighted_mse: 0.0197\n",
      "Epoch 3/20\n",
      "270/270 [==============================] - 24s 90ms/step - loss: 0.0485 - mse: 0.0044 - weighted_mse: 0.0041\n",
      "Epoch 4/20\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 0.0027 - mse: 7.9660e-04 - weighted_mse: 7.6480e-04\n",
      "Epoch 5/20\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 4.4411e-05 - mse: 2.1653e-04 - weighted_mse: 2.1977e-04\n",
      "Epoch 6/20\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 8.9409e-08 - mse: 1.3107e-04 - weighted_mse: 1.4496e-04\n",
      "Epoch 7/20\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 4.0498e-09 - mse: 1.2477e-04 - weighted_mse: 1.3858e-04\n",
      "Epoch 8/20\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 3.9823e-09 - mse: 1.2296e-04 - weighted_mse: 1.3675e-04\n",
      "Epoch 9/20\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 3.9570e-09 - mse: 1.2202e-04 - weighted_mse: 1.3575e-04\n",
      "Epoch 10/20\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 4.0070e-09 - mse: 1.2088e-04 - weighted_mse: 1.3441e-04\n",
      "Epoch 11/20\n",
      "270/270 [==============================] - 24s 90ms/step - loss: 4.1039e-09 - mse: 1.2081e-04 - weighted_mse: 1.3427e-04\n",
      "Epoch 12/20\n",
      "270/270 [==============================] - 24s 91ms/step - loss: 4.0283e-09 - mse: 1.2024e-04 - weighted_mse: 1.3364e-04\n",
      "Epoch 13/20\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 4.0905e-09 - mse: 1.2045e-04 - weighted_mse: 1.3385e-04\n",
      "Epoch 14/20\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 4.0668e-09 - mse: 1.2028e-04 - weighted_mse: 1.3366e-04\n",
      "Epoch 15/20\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 4.0761e-09 - mse: 1.2037e-04 - weighted_mse: 1.3373e-04\n",
      "Epoch 16/20\n",
      "270/270 [==============================] - 24s 90ms/step - loss: 4.0684e-09 - mse: 1.2031e-04 - weighted_mse: 1.3364e-04\n",
      "Epoch 17/20\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 4.0751e-09 - mse: 1.2023e-04 - weighted_mse: 1.3357e-04\n",
      "Epoch 18/20\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 4.0718e-09 - mse: 1.2021e-04 - weighted_mse: 1.3354e-04\n",
      "Epoch 19/20\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 4.0740e-09 - mse: 1.1989e-04 - weighted_mse: 1.3318e-04\n",
      "Epoch 20/20\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 4.0746e-09 - mse: 1.2012e-04 - weighted_mse: 1.3345e-04\n",
      "1080/1080 [==============================] - 30s 26ms/step\n",
      "6/6 [==============================] - 4s 35ms/step\n",
      "\n",
      " this week r 2 pred: 0.041448235511779785\n",
      "this week eq wght unrestricted geom avg ret -9.681147252293965e-05 \n",
      "\n",
      "this week mcap wght geom avg ret 0.0005051446572765794 \n",
      "\n",
      "Of a total 168 datetimes, 6.0% have insufficient volume to trade.\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.0006131146917904839 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-12-18T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 17:45:25.134280: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_24/dropout_1572/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 110s 122ms/step - loss: 1.4988 - mse: 0.1643 - weighted_mse: 0.1653\n",
      "Epoch 2/20\n",
      "272/272 [==============================] - 33s 121ms/step - loss: 0.3508 - mse: 0.0332 - weighted_mse: 0.0317\n",
      "Epoch 3/20\n",
      "272/272 [==============================] - 33s 120ms/step - loss: 0.0464 - mse: 0.0062 - weighted_mse: 0.0059\n",
      "Epoch 4/20\n",
      "272/272 [==============================] - 33s 120ms/step - loss: 0.0025 - mse: 9.6447e-04 - weighted_mse: 9.2957e-04\n",
      "Epoch 5/20\n",
      "272/272 [==============================] - 33s 120ms/step - loss: 4.0834e-05 - mse: 1.9671e-04 - weighted_mse: 2.0340e-04\n",
      "Epoch 6/20\n",
      "272/272 [==============================] - 33s 121ms/step - loss: 5.8801e-08 - mse: 1.3303e-04 - weighted_mse: 1.4687e-04\n",
      "Epoch 7/20\n",
      "272/272 [==============================] - 33s 121ms/step - loss: 4.0704e-09 - mse: 1.2352e-04 - weighted_mse: 1.3712e-04\n",
      "Epoch 8/20\n",
      "272/272 [==============================] - 33s 121ms/step - loss: 4.0585e-09 - mse: 1.1983e-04 - weighted_mse: 1.3304e-04\n",
      "Epoch 9/20\n",
      "272/272 [==============================] - 33s 121ms/step - loss: 4.0658e-09 - mse: 1.1975e-04 - weighted_mse: 1.3285e-04\n",
      "Epoch 10/20\n",
      "272/272 [==============================] - 33s 121ms/step - loss: 4.0366e-09 - mse: 1.1994e-04 - weighted_mse: 1.3310e-04\n",
      "Epoch 11/20\n",
      "272/272 [==============================] - 33s 120ms/step - loss: 4.0615e-09 - mse: 1.1984e-04 - weighted_mse: 1.3296e-04\n",
      "Epoch 12/20\n",
      "272/272 [==============================] - 33s 121ms/step - loss: 4.0352e-09 - mse: 1.1979e-04 - weighted_mse: 1.3294e-04\n",
      "Epoch 13/20\n",
      "272/272 [==============================] - 33s 121ms/step - loss: 4.0505e-09 - mse: 1.2001e-04 - weighted_mse: 1.3316e-04\n",
      "Epoch 14/20\n",
      "272/272 [==============================] - 33s 120ms/step - loss: 4.0387e-09 - mse: 1.1963e-04 - weighted_mse: 1.3273e-04\n",
      "Epoch 15/20\n",
      "272/272 [==============================] - 33s 120ms/step - loss: 4.0407e-09 - mse: 1.1991e-04 - weighted_mse: 1.3302e-04\n",
      "Epoch 16/20\n",
      "272/272 [==============================] - 33s 120ms/step - loss: 4.0339e-09 - mse: 1.1978e-04 - weighted_mse: 1.3289e-04\n",
      "Epoch 17/20\n",
      "272/272 [==============================] - 33s 120ms/step - loss: 4.0478e-09 - mse: 1.1968e-04 - weighted_mse: 1.3281e-04\n",
      "Epoch 18/20\n",
      "272/272 [==============================] - 33s 120ms/step - loss: 4.0417e-09 - mse: 1.1969e-04 - weighted_mse: 1.3277e-04\n",
      "Epoch 19/20\n",
      "272/272 [==============================] - 33s 121ms/step - loss: 4.0371e-09 - mse: 1.1957e-04 - weighted_mse: 1.3262e-04\n",
      "Epoch 20/20\n",
      "272/272 [==============================] - 33s 120ms/step - loss: 4.0444e-09 - mse: 1.1977e-04 - weighted_mse: 1.3284e-04\n",
      "1086/1086 [==============================] - 42s 35ms/step\n",
      "6/6 [==============================] - 0s 35ms/step\n",
      "\n",
      " this week r 2 pred: 0.07934528589248657\n",
      "this week eq wght unrestricted geom avg ret -0.00012431510983279548 \n",
      "\n",
      "this week mcap wght geom avg ret 0.0003843903947859939 \n",
      "\n",
      "Of a total 168 datetimes, 1.0% have insufficient volume to trade, or not shortable.\n",
      "Of a total 168 datetimes, 6.0% have insufficient volume to trade.\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.0004483560870358616 \n",
      "\n",
      "Currently fitting and predicting for the week starting: \n",
      "2022-12-25T00:00:00.000000000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 18:03:41.980712: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_25/dropout_1626/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 109s 119ms/step - loss: 1.4866 - mse: 0.1347 - weighted_mse: 0.1356\n",
      "Epoch 2/20\n",
      "273/273 [==============================] - 32s 119ms/step - loss: 0.3449 - mse: 0.0270 - weighted_mse: 0.0255\n",
      "Epoch 3/20\n",
      "273/273 [==============================] - 32s 119ms/step - loss: 0.0448 - mse: 0.0063 - weighted_mse: 0.0057\n",
      "Epoch 4/20\n",
      "273/273 [==============================] - 32s 119ms/step - loss: 0.0023 - mse: 0.0012 - weighted_mse: 0.0010\n",
      "Epoch 5/20\n",
      "273/273 [==============================] - 32s 119ms/step - loss: 3.3309e-05 - mse: 2.0546e-04 - weighted_mse: 2.0864e-04\n",
      "Epoch 6/20\n",
      "273/273 [==============================] - 32s 118ms/step - loss: 5.2446e-08 - mse: 1.3120e-04 - weighted_mse: 1.4491e-04\n",
      "Epoch 7/20\n",
      "273/273 [==============================] - 32s 119ms/step - loss: 3.9903e-09 - mse: 1.2378e-04 - weighted_mse: 1.3711e-04\n",
      "Epoch 8/20\n",
      "273/273 [==============================] - 32s 118ms/step - loss: 3.9271e-09 - mse: 1.2112e-04 - weighted_mse: 1.3415e-04\n",
      "Epoch 9/20\n",
      "273/273 [==============================] - 32s 118ms/step - loss: 3.9999e-09 - mse: 1.1949e-04 - weighted_mse: 1.3237e-04\n",
      "Epoch 10/20\n",
      "273/273 [==============================] - 32s 119ms/step - loss: 3.9957e-09 - mse: 1.1897e-04 - weighted_mse: 1.3181e-04\n",
      "Epoch 11/20\n",
      "273/273 [==============================] - 32s 119ms/step - loss: 4.0251e-09 - mse: 1.1875e-04 - weighted_mse: 1.3152e-04\n",
      "Epoch 12/20\n",
      "273/273 [==============================] - 32s 118ms/step - loss: 4.0397e-09 - mse: 1.1897e-04 - weighted_mse: 1.3182e-04\n",
      "Epoch 13/20\n",
      "273/273 [==============================] - 32s 118ms/step - loss: 4.0238e-09 - mse: 1.1893e-04 - weighted_mse: 1.3176e-04\n",
      "Epoch 14/20\n",
      "273/273 [==============================] - 32s 119ms/step - loss: 4.0204e-09 - mse: 1.1903e-04 - weighted_mse: 1.3189e-04\n",
      "Epoch 15/20\n",
      "273/273 [==============================] - 33s 119ms/step - loss: 3.9932e-09 - mse: 1.1849e-04 - weighted_mse: 1.3124e-04\n",
      "Epoch 16/20\n",
      "273/273 [==============================] - 32s 119ms/step - loss: 4.0445e-09 - mse: 1.1889e-04 - weighted_mse: 1.3171e-04\n",
      "Epoch 17/20\n",
      "273/273 [==============================] - 32s 118ms/step - loss: 4.0020e-09 - mse: 1.1904e-04 - weighted_mse: 1.3191e-04\n",
      "Epoch 18/20\n",
      "273/273 [==============================] - 32s 118ms/step - loss: 4.0148e-09 - mse: 1.1894e-04 - weighted_mse: 1.3174e-04\n",
      "Epoch 19/20\n",
      "273/273 [==============================] - 32s 119ms/step - loss: 3.9959e-09 - mse: 1.1891e-04 - weighted_mse: 1.3171e-04\n",
      "Epoch 20/20\n",
      "273/273 [==============================] - 32s 117ms/step - loss: 4.0035e-09 - mse: 1.1858e-04 - weighted_mse: 1.3137e-04\n",
      "1091/1091 [==============================] - 41s 35ms/step\n",
      "6/6 [==============================] - 0s 33ms/step\n",
      "\n",
      " this week r 2 pred: 0.03308725357055664\n",
      "this week eq wght unrestricted geom avg ret 4.313770902508729e-05 \n",
      "\n",
      "this week mcap wght geom avg ret 0.00030349762214232356 \n",
      "\n",
      "Of a total 168 datetimes, 5.0% have insufficient volume to trade, or not shortable.\n",
      "Of a total 168 datetimes, 10.0% have insufficient volume to trade.\n",
      "this week mcap wght shortable and volume restricted geom avg ret 0.00022951117901937046 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # set args\n",
    "    IN_TRAIN_FP     = '../data/clean/panel_train.pkl'\n",
    "    IN_TEST_FP      = '../data/clean/panel_test.pkl'\n",
    "    ASSET_IN_FP     = '../data/clean/strict_asset_universe_hourly_dict.pickle'\n",
    "    CV_OUT_FP       = '../output/high_dim_fm/cv_results'\n",
    "    TEST_OUT_FP     = '../data/clean/test_yhats_transformer'\n",
    "    LHS_COL         = 'r_ex_tp1'\n",
    "    VAL_START_DATE  = '2022-01-01' # NOTE: A Sunday.\n",
    "    VAL_END_DATE    = '2022-07-02' # NOTE: A Saturday\n",
    "    TEST_START_DATE = '2022-07-03' # NOTE: A Sunday.\n",
    "    TEST_END_DATE   = '2023-01-01' # NOTE: A Sunday.\n",
    "    PERIODS_IN_YEAR = int(365.25*24)\n",
    "    ARCH_NAME       = 'transformer'\n",
    "    LHS_PAD         = 0\n",
    "    RHS_PAD         = 0\n",
    "    NUM_PRTFL_QNTLS = 5\n",
    "    TC_PER_HOUR     = 0\n",
    "    HP_GRID         = {'number_factors': [1], # NOTE: based on cv, seems opt for sure.\n",
    "        'num_lags': [1], # NOTE: based on cv, 1 seems opt for sure w/o doing feat selection across entire matrix.\n",
    "        'hidden_dim': [32], # NOTE: 64 or 16 may be more optimal\n",
    "        'num_heads': [1], # NOTE: 2 heads may be better\n",
    "        'l2_penalty': [1e-3],\n",
    "        'dropout_pct': [0.5], # NOTE: this seems good as other hps can accord for improved setting here; i.e. it's redundant.\n",
    "        'initial_learning_rate': [4e-4],\n",
    "        'learning_decay_rate': [0.99],\n",
    "        'adam_beta_1': [0.9],\n",
    "        'adam_beta_2': [0.99],\n",
    "        'adam_clipnorm': [100],\n",
    "        'batch_size': [128], \n",
    "        'num_epochs': [100], \n",
    "        'early_stopping': [True],\n",
    "        'patience': [5]}\n",
    "    RESTRICT_SHORTABLE_UNI = True\n",
    "    SHORTABLE_UNI = ['aave', 'algo', 'rep', 'btc', 'bch', 'ada', 'link', 'comp', 'atom', 'dash', 'doge', 'dot', \n",
    "        'eos', 'eth', 'etc', 'fil', 'flow', 'kava', 'keep', 'ksm', 'ltc', 'omg', 'matic',  \n",
    "        'sc', 'sol', 'trx', 'uni', 'xlm', 'xmr', 'xrp', 'xtz', 'zec']\n",
    "    SHORTABLE_UNI += ['ape', 'avax', 'axs', 'bat', 'crv', \n",
    "        'lrc', 'mana', 'nano', 'sand', 'sc', 'grt', 'waves'] # NOTE: Post Sept 1 2022 add in \n",
    "    RESTRICT_TRADABLE_VOLUME = True\n",
    "    PRCT_VOLUME_THRESHOLD = 0.05\n",
    "    TOTAL_TRADE_VOLUME_PER_HOUR = 1e6\n",
    "    \n",
    "    # read in data\n",
    "    with open(ASSET_IN_FP, \"rb\") as f:\n",
    "        asset_universe_dict = pickle.load(f)\n",
    "    train_df = pd.read_pickle(IN_TRAIN_FP)\n",
    "    test_df  = pd.read_pickle(IN_TEST_FP)\n",
    "    all_df = pd.concat([train_df, test_df])\n",
    "\n",
    "    # drop data beyond the test period\n",
    "    all_df = all_df[all_df.date < TEST_END_DATE]\n",
    "\n",
    "    # subset rows and columns and separate input and output data\n",
    "    # NOTE: Jan 2019 seems like optimal state date\n",
    "    y_df, char_df, ts_df, weight_df = subsetRowsAndColumns(all_df, LHS_COL)\n",
    "    gc.collect()\n",
    "\n",
    "    # prep aux data\n",
    "    mcap_df = all_df[['date', 'asset', 'char_mcap_t']].copy()\n",
    "    mcap_df = mcap_df.rename(columns={'char_mcap_t': 'mcap'})\n",
    "    volume_df = all_df[['date', 'asset', 'char_volume_t']].copy()\n",
    "    volume_df['date'] -= pd.Timedelta(hours=1)\n",
    "    volume_df = volume_df.rename(columns={'char_volume_t': 'volume_tp1'})\n",
    "    aux_df = mcap_df.merge(volume_df, on=['date', 'asset'], how='left', validate='one_to_one')\n",
    "    aux_df.loc[aux_df.volume_tp1.isnull(), 'volume_tp1'] = 1e6\n",
    "    \n",
    "    # pad the lhs data\n",
    "    y_df = normalizeAndFillMissing(y_df, \n",
    "            lhs_col=LHS_COL, lhs_pad=LHS_PAD, rhs_pad=RHS_PAD, \n",
    "            ignore_cols=['date', 'asset', LHS_COL])\n",
    "\n",
    "    # # run custom step forward cross validation\n",
    "    # cv_results_list = runCV(y_df, char_df, ts_df, weight_df, aux_df, asset_universe_dict, \n",
    "    #     VAL_START_DATE, VAL_END_DATE, TEST_START_DATE,\n",
    "    #     LHS_COL, LHS_PAD, RHS_PAD, NUM_PRTFL_QNTLS, TC_PER_HOUR,\n",
    "    #     HP_GRID, PERIODS_IN_YEAR, CV_OUT_FP, ARCH_NAME,\n",
    "    #     RESTRICT_SHORTABLE_UNI, SHORTABLE_UNI,\n",
    "    #     RESTRICT_TRADABLE_VOLUME, PRCT_VOLUME_THRESHOLD, TOTAL_TRADE_VOLUME_PER_HOUR)\n",
    "\n",
    "    # Opt HPS\n",
    "    opt_hps_dict = {'number_factors': 1,\n",
    "        'num_lags': 1,\n",
    "        'hidden_dim': 32,\n",
    "        'num_heads': 1,\n",
    "        'l2_penalty': 1e-3,\n",
    "        'dropout_pct': 0.5,\n",
    "        'initial_learning_rate': 4e-4,\n",
    "        'learning_decay_rate': 0.99,\n",
    "        'adam_beta_1': 0.9,\n",
    "        'adam_beta_2': 0.99,\n",
    "        'adam_clipnorm': 100,\n",
    "        'batch_size': 128,\n",
    "        'num_epochs': 20,\n",
    "        'early_stopping': False,\n",
    "        'patience': 5}\n",
    "    \n",
    "    # Fit and predict into test period\n",
    "    oos_y_yhats_df, train_r2_pred_list, train_geom_mean_rtrn_list, num_model_params_list, train_mse_list = fitAndPredictOOS(\n",
    "        y_df, char_df, ts_df, weight_df, aux_df, asset_universe_dict, opt_hps_dict, \n",
    "        TEST_START_DATE, TEST_END_DATE, LHS_COL, LHS_PAD, RHS_PAD, NUM_PRTFL_QNTLS, TC_PER_HOUR, TEST_OUT_FP,\n",
    "        RESTRICT_SHORTABLE_UNI, SHORTABLE_UNI,\n",
    "        RESTRICT_TRADABLE_VOLUME, PRCT_VOLUME_THRESHOLD, TOTAL_TRADE_VOLUME_PER_HOUR)\n",
    "    \n",
    "    # Save the oos training mse's after forming the fp\n",
    "    yyyymmdd1 = TEST_START_DATE.replace('-', '')\n",
    "    yyyymmdd2 = TEST_END_DATE.replace('-', '')\n",
    "    oos_train_mse_out_fp = '../data/clean/test_train_mse_transformer'\n",
    "    out_fp    = oos_train_mse_out_fp+'_'+yyyymmdd1+'_'+yyyymmdd2+'.pkl'\n",
    "    with open(out_fp, \"wb\") as f:\n",
    "        pickle.dump(train_mse_list, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "223ab8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Q3+Q4 2022 HPS\n",
    "# leverage: 3x\n",
    "# opt_hps_dict = {'number_factors': 1,\n",
    "#     'num_lags': 2,\n",
    "#     'hidden_dim': 32,\n",
    "#     'num_heads': 1,\n",
    "#     'l2_penalty': 1e-3,\n",
    "#     'dropout_pct': 0.5,\n",
    "#     'initial_learning_rate': 4e-4,\n",
    "#     'learning_decay_rate': 0.99,\n",
    "#     'adam_beta_1': 0.9,\n",
    "#     'adam_beta_2': 0.99,\n",
    "#     'adam_clipnorm': 100,\n",
    "#     'batch_size': 128,\n",
    "#     'num_epochs': 20,\n",
    "#     'early_stopping': False,\n",
    "#     'patience': 5}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f14a76dcff07d5b93f2c0fc65ce65c8ac7788ddb1ef5c63daa3feefa016fa519"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
