{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aabc20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156b39d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcGeomAvg(returns: np.array,\n",
    "    annualized: bool=False,\n",
    "    periods_in_year: int=None) -> float: \n",
    "    \"\"\" Calculate the geometric average of a vector of simple returns.\n",
    "\n",
    "    Args:\n",
    "        returns (np.array): vector of a simple returns at any frequency.\n",
    "        annualized (bool): whether to annualize the statistic.\n",
    "        periods_in_year (int): how many periods of the given frequency are in a year.\n",
    "\n",
    "    Returns:\n",
    "        (float): scalar geometric average.\n",
    "    \"\"\"\n",
    "    if annualized and periods_in_year is None:\n",
    "        raise ValueError(\"Input 'periods_in_year' must be provided if 'annualized' is True\")\n",
    "    total_return = np.prod(1 + returns)\n",
    "    if total_return < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        geom_avg_at_given_freq =  total_return** (1 / np.size(returns)) - 1\n",
    "        return (geom_avg_at_given_freq + 1)**periods_in_year - 1 if annualized else geom_avg_at_given_freq\n",
    "\n",
    "def calcArithAvg(returns: np.array,\n",
    "    annualized: bool=False,\n",
    "    periods_in_year: int=None) -> float:\n",
    "    \"\"\" Calculate the time series mean return of a vector of simple returns with option to annualize.\n",
    "\n",
    "    Args:\n",
    "        returns (np.array): vector of a simple returns at any frequency.\n",
    "        annualized (bool): whether to annualize the statistic.\n",
    "        periods_in_year (int): how many periods of the given frequency are in a year.\n",
    "\n",
    "    Returns:\n",
    "        (float): scalar time series mean return.\n",
    "    \"\"\"\n",
    "    mean_ret_at_given_freq = np.mean(returns)\n",
    "    if annualized == False:\n",
    "        return mean_ret_at_given_freq\n",
    "    else:\n",
    "        mean_ret = periods_in_year*mean_ret_at_given_freq\n",
    "        if mean_ret < -1:\n",
    "            return -1.\n",
    "        else:\n",
    "            return mean_ret\n",
    "\n",
    "def calcSD(returns: np.array,\n",
    "    annualized: bool=False,\n",
    "    periods_in_year: int=None) -> float: \n",
    "    \"\"\" Calculate the standard deviation of a vector of simple returns with option to annualize.\n",
    "\n",
    "    Args:\n",
    "        returns (np.array): vector of a simple returns at any frequency.\n",
    "        annualized (bool): whether to annualize the statistic.\n",
    "        periods_in_year (int): how many periods of the given frequency are in a year.\n",
    "\n",
    "    Returns:\n",
    "        (float): scalar standard deviation.\n",
    "    \"\"\"\n",
    "    sd_at_given_freq = np.std(returns)\n",
    "    if annualized==False:\n",
    "        return sd_at_given_freq\n",
    "    else:\n",
    "        return np.sqrt(periods_in_year)*sd_at_given_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7188ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formPortfolioSortResultsTable(df: pd.DataFrame, rhs_col: str, lhs_col: str, ts_avg_method: str, annualized: bool, periods_in_year: int) -> pd.DataFrame:\n",
    "    # Check for valid input\n",
    "    assert ts_avg_method in ['arithmetic', 'geometric'], \"Incorrect input for the ts_avg_method.\"\n",
    "    \n",
    "    # Form relevant df\n",
    "    t_df = df[['date', 'asset', lhs_col, rhs_col]].copy()\n",
    "\n",
    "    # Randomly sort all rows of the dataframe\n",
    "    t_df = t_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Sort the dataframe by 'date' and rhs_col column\n",
    "    t_df = t_df.sort_values(['date', rhs_col])\n",
    "\n",
    "    # Form tertile\n",
    "    t_df['rank_within_date'] = t_df.groupby('date')[rhs_col].rank(method='first')\n",
    "    t_df['rank_ratio'] = t_df.groupby('date')['rank_within_date'].transform(lambda x: x / x.max())\n",
    "    t_df['tertile'] = 1+pd.cut(t_df['rank_ratio'], bins=[0, 1/3, 2/3, 1], labels=False, include_lowest=True)\n",
    "    t_df = t_df.drop(columns=['rank_within_date', 'rank_ratio'])\n",
    "\n",
    "    # Calculate the average return for each tertile within each date\n",
    "    daily_avg_returns_df = t_df.groupby(['date', 'tertile'])[lhs_col].mean().reset_index()\n",
    "\n",
    "    # Calculate the time series average of each tertile's average returns\n",
    "    if ts_avg_method == 'geometric':\n",
    "        tertile_avg_returns = daily_avg_returns_df.groupby('tertile')[lhs_col].apply(lambda x: calcGeomAvg(x, annualized=annualized, periods_in_year=periods_in_year))\n",
    "    else:\n",
    "        tertile_avg_returns = daily_avg_returns_df.groupby('tertile')[lhs_col].apply(lambda x: calcArithAvg(x, annualized=annualized, periods_in_year=periods_in_year))\n",
    "\n",
    "    # Calculate the time series average for each year\n",
    "    daily_avg_returns_df['year'] = daily_avg_returns_df['date'].dt.year\n",
    "    if ts_avg_method == 'geometric':\n",
    "        yearly_avg_returns = daily_avg_returns_df.groupby(['year', 'tertile'])[lhs_col].apply(lambda x: calcGeomAvg(x, annualized=annualized, periods_in_year=periods_in_year)).unstack(level=1)\n",
    "    else:\n",
    "        yearly_avg_returns = daily_avg_returns_df.groupby(['year', 'tertile'])[lhs_col].apply(lambda x: calcArithAvg(x, annualized=annualized, periods_in_year=periods_in_year)).unstack(level=1)\n",
    "\n",
    "    # Calculate the t statistics for the overall period\n",
    "    t_stats = (daily_avg_returns_df.groupby('tertile')[lhs_col].apply(lambda x: calcArithAvg(x, annualized=annualized, periods_in_year=periods_in_year)) \n",
    "                / daily_avg_returns_df.groupby('tertile')[lhs_col].apply(lambda x: calcSD(x, annualized=annualized, periods_in_year=periods_in_year)))\n",
    "\n",
    "    # Calculate the time series average of the difference between the top and bottom tertile's average returns\n",
    "    diff_daily_avg_returns_df = daily_avg_returns_df.pivot_table(index='date', columns='tertile', values=lhs_col)\n",
    "    diff_daily_avg_returns_df['year'] = diff_daily_avg_returns_df.index.year\n",
    "    diff_daily_avg_returns_df['top_bottom_diff'] = diff_daily_avg_returns_df[3] - diff_daily_avg_returns_df[1]\n",
    "    if ts_avg_method == 'geometric':\n",
    "        top_bottom_diff_average = calcGeomAvg(diff_daily_avg_returns_df['top_bottom_diff'], annualized=annualized, periods_in_year=periods_in_year)\n",
    "    else:\n",
    "        top_bottom_diff_average = calcArithAvg(diff_daily_avg_returns_df['top_bottom_diff'], annualized=annualized, periods_in_year=periods_in_year)\n",
    "\n",
    "    # Calculate the yearly top_bottom_diff\n",
    "    if ts_avg_method == 'geometric':\n",
    "        yearly_diff_avg_returns = diff_daily_avg_returns_df.groupby('year')['top_bottom_diff'].apply(lambda x: calcGeomAvg(x, annualized=annualized, periods_in_year=periods_in_year))\n",
    "    else:\n",
    "        yearly_diff_avg_returns = diff_daily_avg_returns_df.groupby('year')['top_bottom_diff'].apply(lambda x: calcArithAvg(x, annualized=annualized, periods_in_year=periods_in_year))\n",
    "\n",
    "    # Calculate the overall t stat for the top minus bottom portfolio\n",
    "    t_stat_3_1 = (np.sqrt(len(diff_daily_avg_returns_df))*calcArithAvg(diff_daily_avg_returns_df['top_bottom_diff'], annualized=False)\n",
    "                    / calcSD(diff_daily_avg_returns_df['top_bottom_diff'], annualized=False))\n",
    "\n",
    "    # Combine results\n",
    "    results = yearly_avg_returns.copy()\n",
    "    results.loc['all'] = tertile_avg_returns\n",
    "    results.loc['t_stat'] = t_stats\n",
    "    results['3-1'] = yearly_diff_avg_returns\n",
    "    results.loc['all', '3-1'] = top_bottom_diff_average\n",
    "    results.loc['t_stat', '3-1'] = t_stat_3_1\n",
    "    results['rhs_col'] = rhs_col\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1193b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # set args\n",
    "    PANEL_IN_FP     = '../data/clean/panel_weekly.pkl' \n",
    "    OUT_FP          = '../output/classic_fm/univariate_factor_analysis.xlsx'\n",
    "    PERIODS_IN_YEAR = 52\n",
    "    TS_AVG_METHOD   = 'arithmetic'\n",
    "    LHS_COL         = 'r_ex_tp7'\n",
    "    ANNUALIZED      = False\n",
    "\n",
    "    # import\n",
    "    df = pd.read_pickle(PANEL_IN_FP)\n",
    "\n",
    "    # TODO TEMP WINDSOR\n",
    "    p1 = df[LHS_COL].quantile(0.01)\n",
    "    p99 = df[LHS_COL].quantile(0.99)\n",
    "    df.loc[df[LHS_COL] < p1, LHS_COL] = p1 \n",
    "    df.loc[df[LHS_COL] > p99, LHS_COL] = p1 \n",
    "\n",
    "    # drop columns not needed in weekly panel\n",
    "    macro_cols = [col for col in df.columns if 'macro_' in col]\n",
    "    df = df.drop(macro_cols, axis=1)\n",
    "    static_cols =['char_industry_asset_mgmt',\n",
    "        'char_industry_cex',\n",
    "        'char_industry_cloud_compute',\n",
    "        'char_industry_currency',\n",
    "        'char_industry_data_mgmt',\n",
    "        'char_industry_dex',\n",
    "        'char_industry_gaming',\n",
    "        'char_industry_infra',\n",
    "        'char_industry_interop',\n",
    "        'char_industry_lending',\n",
    "        'char_industry_media',\n",
    "        'char_industry_other_defi',\n",
    "        'char_industry_smart_contract',\n",
    "        'char_asset_usage_access',\n",
    "        'char_asset_usage_discount',\n",
    "        'char_asset_usage_dividends',\n",
    "        'char_asset_usage_payments',\n",
    "        'char_asset_usage_vote',\n",
    "        'char_asset_usage_work',\n",
    "        'char_pow',\n",
    "        'char_pos',\n",
    "        'char_ico_price',\n",
    "        'char_ico']\n",
    "    df = df.drop(static_cols, axis=1)\n",
    "    rhs_cols = list(df.columns.values)\n",
    "    rhs_cols.remove('date')\n",
    "    rhs_cols.remove('asset')\n",
    "    rhs_cols.remove(LHS_COL)\n",
    "\n",
    "    # Form results\n",
    "    results_df = pd.DataFrame()\n",
    "    for rhs_col in rhs_cols:\n",
    "        result = formPortfolioSortResultsTable(df, rhs_col, LHS_COL, TS_AVG_METHOD, ANNUALIZED, PERIODS_IN_YEAR)\n",
    "        results_df = pd.concat([results_df, result])\n",
    "\n",
    "    # Save results\n",
    "    with pd.ExcelWriter(OUT_FP, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer: \n",
    "        results_df.to_excel(writer,sheet_name='raw_univariate')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
