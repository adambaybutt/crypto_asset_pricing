{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab026fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to use the quantools, due to my crap path names have to add to sys path\n",
    "import sys\n",
    "sys.path.insert(0, '/home/adam/Dropbox/2-creations/2-crafts/7-buidl/0-utils/quant_tools/code')\n",
    "\n",
    "# IMPORT PACKAGES\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import combinations\n",
    "from datetime import datetime\n",
    "from tools import QuantTools\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3f87f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsetAndFormRhs(df: pd.DataFrame, lhs_col: str) -> pd.DataFrame:\n",
    "    # Define char columns of interest\n",
    "    char_cols = ['char_circulation_tm7',\n",
    "        'char_circulation_tm30',\n",
    "        'char_circulation_tm90',\n",
    "        'char_tx_volume_t',\n",
    "        'char_tx_volume_tm7',\n",
    "        'char_addr_new_tm1',\n",
    "        'char_addr_new_tm7',\n",
    "        'char_addr_active_tm1',\n",
    "        'char_addr_active_tm7',\n",
    "        'char_addr_new_log_delta_tm14_tm7',\n",
    "        'char_age_destroyed_tm7',\n",
    "        'char_age_mean_dollar_t',\n",
    "        'char_delta_flow_dist_tm7',\n",
    "        'char_delta_holders_dist_tm7',\n",
    "        'char_prct_supply_in_profit_t',\n",
    "        'char_exchange_prct_circ_supply_t',\n",
    "        'char_cex_prct_circ_supply_t',\n",
    "        'char_dex_prct_circ_supply_t',\n",
    "        'char_defi_prct_circ_supply_t',\n",
    "        'char_traders_prct_circ_supply_t',\n",
    "        'char_exchange_inflow_tm7',\n",
    "        'char_exchange_outflow_tm7',\n",
    "        'char_rank_cmc_t',\n",
    "        'char_tradable_t',\n",
    "        'char_social_volume_tm7',\n",
    "        'char_social_volume_reddit_tm7',\n",
    "        'char_social_volume_twitter_tm7',\n",
    "        'char_sent_neg_reddit_tm7',\n",
    "        'char_sent_neg_twitter_tm7',\n",
    "        'char_sent_pos_reddit_tm7',\n",
    "        'char_sent_pos_twitter_tm7',\n",
    "        'char_sent_volume_consumed_tm7',\n",
    "        'char_social_dom_avg_tm7',\n",
    "        'char_dev_activity_tm7',\n",
    "        'char_vc_t',\n",
    "        'char_r_tm7',\n",
    "        'char_r_tm14',\n",
    "        'char_r_tm14_tm7',\n",
    "        'char_r_tm30',\n",
    "        'char_r_tm60',\n",
    "        'char_r_tm90',\n",
    "        'char_r_max_tm7',\n",
    "        'char_r_max_tm30',\n",
    "        'char_r_ath_t',\n",
    "        'char_r_atl_t',\n",
    "        'char_trades_t',\n",
    "        'char_trades_sum_tm7',\n",
    "        'char_trades_std_tm7',\n",
    "        'char_volume_sum_tm7',\n",
    "        'char_volume_std_tm7',\n",
    "        'char_ask_t',\n",
    "        'char_bid_t',\n",
    "        'char_bidask_t',\n",
    "        'char_ask_size_t',\n",
    "        'char_bid_size_t',\n",
    "        'char_illiq_tm7',\n",
    "        'char_turnover_tm7',\n",
    "        'char_price_t',\n",
    "        'char_size_t',\n",
    "        'char_mvrv_t',\n",
    "        'char_alpha_tm7',\n",
    "        'char_alpha_tm30',\n",
    "        'char_beta_tm7',\n",
    "        'char_beta_tm30',\n",
    "        'char_beta_downside_tm30',\n",
    "        'char_coskew_tm30',\n",
    "        'char_iskew_tm30',\n",
    "        'char_shortfall5_tm7',\n",
    "        'char_shortfall5_tm90',\n",
    "        'char_var5_tm7',\n",
    "        'char_var5_tm90',\n",
    "        'char_vol_tm7',\n",
    "        'char_vol_tm30',\n",
    "        'char_ivol_tm7',\n",
    "        'char_ivol_tm30']\n",
    "    \n",
    "    # Subset to relevant columns\n",
    "    df = df[['date', 'asset', lhs_col]+char_cols].copy()\n",
    "\n",
    "    # Form new rhs of the contemporaneous return and mcap to use throughout\n",
    "    df['r_ex_tp0'] = df['char_r_tm7']\n",
    "    df['mcap'] = df['char_size_t']\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa466a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFactorsDf(in_df: pd.DataFrame, lhs_col: str, num_qntls_fctrs: int) -> pd.DataFrame:\n",
    "    # Build list of rhs variables: char and factor names\n",
    "    char_cols = list(in_df.columns.values)\n",
    "    for col in ['date', 'asset', lhs_col, 'r_ex_tp0', 'mcap']:\n",
    "        char_cols.remove(col)\n",
    "    factor_cols = ['factor_'+col[5:] for col in char_cols]\n",
    "\n",
    "    # Randomly sort all rows of the dataframe, \n",
    "    #     to handle chars that have repeated values within date\n",
    "    in_df = in_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Form factors\n",
    "    factors_df = pd.DataFrame(data={'date': []})\n",
    "    for char_col, factor_col in zip(char_cols, factor_cols):\n",
    "        # subset to relevant characteristic\n",
    "        temp_df = in_df[['date', 'r_ex_tp0', 'mcap', char_col]]\n",
    "\n",
    "        # form quantiles by char col\n",
    "        temp_df = temp_df.sort_values(by=['date', char_col])\n",
    "        temp_df['rank_within_date'] = temp_df.groupby('date')[char_col].rank(method='first')\n",
    "        temp_df['rank_ratio'] = temp_df.groupby('date')['rank_within_date'].transform(lambda x: x / x.max())\n",
    "        quantile_bins = list(np.arange(0, num_qntls_fctrs+1)/num_qntls_fctrs)\n",
    "        temp_df['quant'] = 1+pd.cut(temp_df['rank_ratio'], bins=quantile_bins, labels=False, include_lowest=True)\n",
    "        temp_df = temp_df.drop(columns=['rank_within_date', 'rank_ratio'])\n",
    "\n",
    "        # form mcap weighted average return within date-quantiles\n",
    "        temp_df['weighted_return'] = temp_df['r_ex_tp0'] * temp_df.mcap\n",
    "        grouped_df = temp_df.groupby(['date', 'quant'])[['weighted_return', 'mcap']].sum().reset_index()\n",
    "        grouped_df['r_ex_tp0'] = grouped_df['weighted_return'] / grouped_df['mcap']\n",
    "        avg_ret_by_quant_df = grouped_df[['date', 'quant', 'r_ex_tp0']].copy()\n",
    "\n",
    "        # form top minus bottom mcap weighted contemporaneous return\n",
    "        pivot_df = avg_ret_by_quant_df.pivot(index='date', columns='quant', values='r_ex_tp0')\n",
    "        pivot_df['diff'] = pivot_df[num_qntls_fctrs] - pivot_df[1]\n",
    "        factor_df = pivot_df.reset_index()[['date', 'diff']]\n",
    "        factor_df = factor_df.rename(columns={'diff': factor_col})\n",
    "\n",
    "        # combine results\n",
    "        factors_df = factors_df.merge(factor_df, on='date', how='outer', validate='one_to_one')\n",
    "\n",
    "    return factors_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5af36366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitAndPredict(lhs_df: pd.DataFrame, lhs_col: str, factors_df: pd.DataFrame, factors_combo: List[str], test_start_date_str: str) -> pd.DataFrame:\n",
    "    # Calc each asset's beta hats\n",
    "    asset_universe = list(np.unique(lhs_df[lhs_df.date<test_start_date_str].asset.values))\n",
    "    asset_beta_hats_dict = {key: None for key in asset_universe}\n",
    "    for asset in asset_universe:\n",
    "        # form relevant data\n",
    "        train_lhs_df = lhs_df[(lhs_df.asset==asset) & (lhs_df.date < test_start_date_str)][['date', lhs_col]].copy()\n",
    "        train_df = train_lhs_df.merge(factors_df, on='date', how='left', validate='one_to_one')\n",
    "        train_rhs = train_df[factors_combo]\n",
    "        train_lhs = train_df[lhs_col]\n",
    "        train_rhs = sm.add_constant(train_rhs)\n",
    "\n",
    "        # calc beta hats\n",
    "        model = sm.OLS(train_lhs, train_rhs)\n",
    "        results = model.fit()\n",
    "\n",
    "        # save beta hats\n",
    "        asset_beta_hats_dict[asset] = list(results.params.values)\n",
    "\n",
    "    # Calc avg beta hat in case we need it\n",
    "    avg_beta_hats = np.mean(list(asset_beta_hats_dict.values()), axis=0)\n",
    "\n",
    "    # Form test period rhs\n",
    "    test_rhs = factors_df[factors_df.date>=test_start_date_str]\n",
    "\n",
    "    # Calc test yhats\n",
    "    test_df = lhs_df[lhs_df.date>=test_start_date_str][['date', 'asset', lhs_col]].copy()\n",
    "    test_df = test_df.sort_values(by=['date', 'asset'], ignore_index=True)\n",
    "    test_df['yhats'] = np.zeros(len(test_df))\n",
    "    test_assets = list(np.unique(test_df.asset.values))\n",
    "    for asset in test_assets:\n",
    "        # if we did not have the test asset in training data, take average of beta hats\n",
    "        if asset not in asset_beta_hats_dict.keys():\n",
    "            asset_beta_hats = avg_beta_hats\n",
    "        else:\n",
    "            asset_beta_hats = np.array(asset_beta_hats_dict[asset])\n",
    "\n",
    "        # form asset test rhs\n",
    "        asset_test_dates = list(np.unique(test_df[test_df.asset==asset].date.values))\n",
    "        asset_test_rhs = factors_df[factors_df.date.isin(asset_test_dates)][factors_combo]\n",
    "        asset_test_rhs = sm.add_constant(asset_test_rhs)\n",
    "\n",
    "        # calc asset yhats\n",
    "        asset_yhats = np.matmul(asset_test_rhs.values, asset_beta_hats)\n",
    "\n",
    "        # save values\n",
    "        test_df.loc[test_df.asset==asset, 'yhats'] = asset_yhats\n",
    "\n",
    "    return test_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d27b833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineFirstDayOfMonthsInTestPeriod(df: pd.DataFrame, test_start_date: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Determine the first day of each month within the test period starting from the given date.\n",
    "\n",
    "    :param df: DataFrame containing the date column for determining the test period range.\n",
    "    :param test_start_date: The test start date in the format '%Y-%m-%d'.\n",
    "\n",
    "    :return: A list of dates representing the first day of each month within the test period.\n",
    "    \"\"\"\n",
    "    test_start_datetime = datetime.strptime(test_start_date, '%Y-%m-%d')\n",
    "    assert test_start_datetime.day == 1, \"Test start date does not start on first day of a month.\"\n",
    "    \n",
    "    test_period_months = []\n",
    "    max_date = np.max(df.date)\n",
    "    current_date = test_start_datetime\n",
    "    while current_date <= max_date:\n",
    "        test_period_months.append(current_date.strftime('%Y-%m-%d'))\n",
    "        current_date += pd.DateOffset(months=1)\n",
    "        \n",
    "    return test_period_months\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d61fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvFactorCombos(df: pd.DataFrame, asset_universe_dict: dict, lhs_col: str, test_start_date: str, \n",
    "    num_qntls_fctrs: int, num_cpus: int, num_factors: int) -> Tuple[list, float]:\n",
    "    \"\"\"\n",
    "    Compute optimal combination of characteristics with the maximum predicted r-squared value.\n",
    "\n",
    "    :param df: Input DataFrame with necessary columns.\n",
    "    :param asset_universe_dict: Dictionary of keys of study period months and values of lists of assets.\n",
    "    :param lhs_col: Column name in df for left-hand side variable.\n",
    "    :param test_start_date: The test start date in the format '%Y-%m-%d'.\n",
    "    :param num_qntls_fctrs: Number of quantiles for factors.\n",
    "    :param num_cpus: Number of CPU cores to use for parallel processing.\n",
    "    :param num_factors: Number of factors for combinations.\n",
    "\n",
    "    :return: A tuple containing a list of optimal characteristic combinations and the associated max r-squared value.\n",
    "    \"\"\"\n",
    "    # Build list of all the char cols\n",
    "    char_cols = [col for col in df.columns if col not in ['date', 'asset', lhs_col, 'r_ex_tp0', 'mcap']]\n",
    "\n",
    "    # Form all combinations of factors\n",
    "    char_combos = list(combinations(char_cols, num_factors))\n",
    "\n",
    "    # Determine the first day of the month for all test period months\n",
    "    test_period_months = determineFirstDayOfMonthsInTestPeriod(df, test_start_date)\n",
    "\n",
    "    # Parallel loop over all combinations of characteristics to find combo with opt r2_pred\n",
    "    def findOptCharCombo(char_combo):\n",
    "        # convert char_combo to a list and form factor names\n",
    "        char_combo = list(char_combo)\n",
    "        factors_combo = ['factor_'+col[5:] for col in char_combo]\n",
    "\n",
    "        # iterate over all months in the test period to use the appropriate assets\n",
    "        test_dfs = []\n",
    "        for test_period_month in test_period_months:\n",
    "            # form the relevant dataset\n",
    "            asset_universe = asset_universe_dict[test_period_month]\n",
    "            one_month_ahead = datetime.strptime(test_period_month, '%Y-%m-%d') + pd.DateOffset(months=1)\n",
    "            rel_df = df[(df.asset.isin(asset_universe)) \n",
    "                & (df.date < one_month_ahead)][\n",
    "                ['date', 'asset', lhs_col, 'mcap', 'r_ex_tp0']+char_combo].copy()\n",
    "\n",
    "            # form factors\n",
    "            factors_df = buildFactorsDf(rel_df, lhs_col, num_qntls_fctrs)\n",
    "\n",
    "            # fit and predict\n",
    "            lhs_df = rel_df[['date', 'asset', lhs_col]].copy()\n",
    "            test_df = fitAndPredict(lhs_df, lhs_col, factors_df, factors_combo, test_period_month)\n",
    "\n",
    "            # save results across the test months\n",
    "            test_dfs.append(test_df)\n",
    "        \n",
    "        # aggregate results across test period for this combo\n",
    "        result_df = pd.concat(test_dfs)\n",
    "\n",
    "        # calc r2 pred \n",
    "        ys = result_df[lhs_col].values\n",
    "        yhats = result_df['yhats'].values\n",
    "        r2_pred = 1-np.mean(np.square(ys-yhats))/np.mean(np.square(ys))\n",
    "\n",
    "        # return results\n",
    "        return r2_pred\n",
    "        # r2_pred_list.append(r2_pred)\n",
    "\n",
    "    # Run loop in parallel\n",
    "    r2_pred_list = Parallel(n_jobs=num_cpus)(delayed(findOptCharCombo)(char_combo) for char_combo in tqdm(char_combos))\n",
    "\n",
    "    # Determine optimal r2 pred and return it with associated combination\n",
    "    max_index = np.argmax(np.array(r2_pred_list))\n",
    "    return list(char_combos[max_index]), r2_pred_list[max_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1738e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitAndReportTestPeriod(df: pd.DataFrame, asset_universe_dict: dict, lhs_col: str, test_start_date: str, \n",
    "    num_qntls_fctrs: int, num_qntls_prtls: int, num_cpus: int, periods_in_year: int, out_fp: str,\n",
    "    opt_chars_combos_list: List[list]) -> None:\n",
    "    # Determine the first day of the month for all test period months\n",
    "    test_period_months = determineFirstDayOfMonthsInTestPeriod(df, test_start_date)\n",
    "\n",
    "    # Generate yhats for each model\n",
    "    test_df = df[df.date >= test_start_date][['date', 'asset', lhs_col, 'mcap']].reset_index(drop=True).copy()\n",
    "    for i, opt_chars_combo in enumerate(opt_chars_combos_list):\n",
    "        print(i) # TODO: REMOVE\n",
    "        # form factor names\n",
    "        factors_combo = ['factor_'+col[5:] for col in opt_chars_combo]\n",
    "        num_factors = i+1\n",
    "\n",
    "        # iterate over all the test period months to gen yhats\n",
    "        temp_dfs = []\n",
    "        for test_period_month in test_period_months:\n",
    "            # form the relevant dataset\n",
    "            asset_universe = asset_universe_dict[test_period_month]\n",
    "            one_month_ahead = datetime.strptime(test_period_month, '%Y-%m-%d') + pd.DateOffset(months=1)\n",
    "            rel_df = df[(df.asset.isin(asset_universe)) \n",
    "                & (df.date < one_month_ahead)][\n",
    "                ['date', 'asset', lhs_col, 'mcap', 'r_ex_tp0']+opt_chars_combo].copy()\n",
    "\n",
    "            # form factors\n",
    "            factors_df = buildFactorsDf(rel_df, lhs_col, num_qntls_fctrs)\n",
    "\n",
    "            # fit and predict\n",
    "            lhs_df = rel_df[['date', 'asset', lhs_col]].copy()\n",
    "            temp_df = fitAndPredict(lhs_df, lhs_col, factors_df, factors_combo, test_period_month)\n",
    "\n",
    "            # save results across the test months\n",
    "            temp_dfs.append(temp_df)\n",
    "\n",
    "        # aggregate results across the test period for this combo\n",
    "        temp_df = pd.concat(temp_dfs)\n",
    "        temp_df = temp_df.drop(lhs_col, axis=1)\n",
    "        temp_df = temp_df.rename(columns={'yhats': 'yhats_'+str(num_factors)+'_factors'})\n",
    "\n",
    "        # merge results for this combo onto the main df\n",
    "        test_df = test_df.merge(temp_df, on=['date', 'asset'], how='inner', validate='one_to_one')\n",
    "\n",
    "    # Generate the results\n",
    "    assert(num_qntls_prtls==5),\"Update results to programatically form the df.\"\n",
    "    results_df = pd.DataFrame(data = {\n",
    "        '1': [], '2': [], '3': [], '4': [], '5': [], '5-1': [], 't-stat': []\n",
    "    })\n",
    "    results_df['num_factors'] = 1+np.arange(5)\n",
    "    for num_factors in range(1,6):\n",
    "        # form relevant dataframe\n",
    "        yhat_col = 'yhats_'+str(num_factors)+'_factors'\n",
    "        t_df = test_df[['date', 'asset', lhs_col, 'mcap', yhat_col]].copy()\n",
    "\n",
    "        # randomly sort\n",
    "        t_df = t_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        # sort the dataframe by 'date' and yhats column\n",
    "        t_df = t_df.sort_values(['date', yhat_col])\n",
    "\n",
    "        # form quantiles\n",
    "        t_df['rank_within_date'] = t_df.groupby('date')[yhat_col].rank(method='first')\n",
    "        t_df['rank_ratio'] = t_df.groupby('date')['rank_within_date'].transform(lambda x: x / x.max())\n",
    "        quantile_bins = list(np.arange(0, num_qntls_prtls+1)/num_qntls_prtls)\n",
    "        t_df['quant'] = 1+pd.cut(t_df['rank_ratio'], bins=quantile_bins, labels=False, include_lowest=True)\n",
    "        t_df = t_df.drop(columns=['rank_within_date', 'rank_ratio'])\n",
    "\n",
    "        # form quantile returns\n",
    "        t_df['weighted_return'] = t_df[lhs_col] * t_df.mcap\n",
    "        grouped_df = t_df.groupby(['date', 'quant'])[['weighted_return', 'mcap']].sum().reset_index()\n",
    "        grouped_df[lhs_col] = grouped_df['weighted_return'] / grouped_df['mcap']\n",
    "        date_quantile_avg_returns_df = grouped_df[['date', 'quant', lhs_col]].copy()\n",
    "        quantile_avg_returns = date_quantile_avg_returns_df.groupby('quant')[lhs_col].apply(lambda x: QuantTools.calcTSAvgReturn(x, annualized=False))\n",
    "\n",
    "        # form ts avg of long short strat and its tstat\n",
    "        top_quantile = num_qntls_prtls\n",
    "        bottom_quantile = 1\n",
    "        diff_date_quantile_avg_returns_df = date_quantile_avg_returns_df.pivot_table(index='date', columns='quant', values=lhs_col)\n",
    "        diff_date_quantile_avg_returns_df['top_bottom_diff'] = (diff_date_quantile_avg_returns_df[top_quantile] \n",
    "                                                                - diff_date_quantile_avg_returns_df[bottom_quantile])\n",
    "        top_bottom_diff_average = QuantTools.calcTSAvgReturn(diff_date_quantile_avg_returns_df['top_bottom_diff'], annualized=False)\n",
    "        t_stat_top_bottom_diff = (np.sqrt(len(diff_date_quantile_avg_returns_df))*QuantTools.calcTSAvgReturn(diff_date_quantile_avg_returns_df['top_bottom_diff'], annualized=False)\n",
    "                        / QuantTools.calcSD(diff_date_quantile_avg_returns_df['top_bottom_diff'], annualized=False))\n",
    "\n",
    "        # format results\n",
    "        top_bottom_diff_avg_rounded = np.round(top_bottom_diff_average, 4)\n",
    "        if (np.abs(t_stat_top_bottom_diff) > 2.576):\n",
    "            top_bottom_diff_result = str(top_bottom_diff_avg_rounded)+\"***\"\n",
    "        elif (np.abs(t_stat_top_bottom_diff) > 1.96):\n",
    "            top_bottom_diff_result = str(top_bottom_diff_avg_rounded)+\"**\"\n",
    "        elif (np.abs(t_stat_top_bottom_diff) > 1.645):\n",
    "            top_bottom_diff_result = str(top_bottom_diff_avg_rounded)+\"*\"\n",
    "        else:\n",
    "            top_bottom_diff_result = str(top_bottom_diff_avg_rounded)\n",
    "\n",
    "        for i in range(1,num_qntls_prtls+1):\n",
    "            results_df.loc[results_df.num_factors==num_factors, str(i)] = np.round(quantile_avg_returns[i], 4)\n",
    "        results_df.loc[results_df.num_factors==num_factors, '5-1'] = top_bottom_diff_result\n",
    "        results_df.loc[results_df.num_factors==num_factors, 't-stat'] = np.round(t_stat_top_bottom_diff, 2)\n",
    "\n",
    "        indices = results_df.index[results_df.num_factors == num_factors]\n",
    "        for idx in indices:\n",
    "            results_df.at[idx, 'chars'] = opt_chars_combos_list[num_factors - 1]\n",
    "        \n",
    "    # Save the results\n",
    "    with pd.ExcelWriter(out_fp, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer: \n",
    "        results_df.to_excel(writer, sheet_name='raw_multi')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6953a300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1 factors validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [01:28<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected factors are: ['char_mvrv_t'] \n",
      "\n",
      "Running 2 factors validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2775/2775 [1:36:46<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected factors are: ['char_delta_holders_dist_tm7', 'char_ask_size_t'] \n",
      "\n",
      "Running 3 factors validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 27288/67525 [17:21:05<25:56:45,  2.32s/it]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # set args\n",
    "    IN_FP           = '../data/clean/panel_weekly.pkl'\n",
    "    ASSET_IN_FP     = '../data/clean/asset_universe_dict.pickle'\n",
    "    OUT_FP          = '../output/low_dim_fm/low_dim_fms.xlsx'\n",
    "    LHS_COL         = 'r_ex_tp7'\n",
    "    VAL_START_DATE  = '2021-07-01'\n",
    "    TEST_START_DATE = '2022-07-01'\n",
    "    PERIODS_IN_YEAR = 52\n",
    "    NUM_QNTLS_FCTRS = 5\n",
    "    NUM_QNTLS_PRTLS = 5\n",
    "    NUM_CPUS        = 18\n",
    "    \n",
    "    # read in data\n",
    "    with open(ASSET_IN_FP, \"rb\") as f:\n",
    "        asset_universe_dict = pickle.load(f)\n",
    "    all_df = pd.read_pickle(IN_FP)\n",
    "\n",
    "    # remove unncessary RHS columns\n",
    "    df = subsetAndFormRhs(all_df, LHS_COL)\n",
    "\n",
    "    # determine optimal chars for 1-5 factor models\n",
    "    val_df = df[df.date<TEST_START_DATE].copy()\n",
    "    opt_chars_combos_list = []\n",
    "    opt_r2_pred_list = []\n",
    "    for i in range(1,4):\n",
    "        print(f'Running {i} factors validation.')\n",
    "        opt_chars_combo, opt_r2_pred = cvFactorCombos(\n",
    "            val_df, asset_universe_dict, LHS_COL, VAL_START_DATE, \n",
    "            NUM_QNTLS_FCTRS, NUM_CPUS, i)\n",
    "        opt_chars_combos_list.append(opt_chars_combo)\n",
    "        opt_r2_pred_list.append(opt_r2_pred)\n",
    "        print(f'Selected {i} factors are: {opt_chars_combo} \\n')\n",
    "\n",
    "    # output results\n",
    "    fitAndReportTestPeriod(df, \n",
    "        LHS_COL, TEST_START_DATE, NUM_QNTLS_FCTRS, NUM_QNTLS_PRTLS, \n",
    "        NUM_CPUS, PERIODS_IN_YEAR, OUT_FP, \n",
    "        opt_chars_combos_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b58dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO run the CV func for 1, 2, 3, 4, and 5 factors to get all\n",
    "# 1 factor is ['char_mvrv_t'] \n",
    "# 2 factors are ['char_delta_holders_dist_tm7', 'char_ask_size_t'] \n",
    "# 3 factors are ['char_delta_holders_dist_tm7', 'char_ask_size_t'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10caea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO -also do a func to build the liu 3 factor model to add its yhats to report within this func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d607ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO SEE HOW RESULTS CHANGE BY WINSORIZING FIRST AND MAYBE JUST DO THIS ACROSS ALL WEEKLY PANEL STUFF\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f14a76dcff07d5b93f2c0fc65ce65c8ac7788ddb1ef5c63daa3feefa016fa519"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
