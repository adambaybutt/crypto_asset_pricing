{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets args\n",
    "cmc_asset_universe_fp = \"../data/raw/cmc_asset_universe.pkl\"\n",
    "cmc_cw_fp = \"../data/raw/cmc_cw.pkl\"\n",
    "cmc_panel_fp = \"../data/raw/cmc_price_volume_mcap_panel.pkl\"\n",
    "cg_cw_fp = \"../data/raw/coingecko_cmc_cw.pkl\"\n",
    "cg_panel_fp = \"../data/raw/coingecko_price_volume_mcap_panel.pkl\"\n",
    "cm_cw_fp = \"../data/raw/coinmetrics_cmc_cw.pkl\"\n",
    "cm_asset_info_fp = '../data/raw/coinmetrics_assets_first_tradable.pkl'\n",
    "cm_panel_fp = \"../data/raw/coinmetrics_initial_panel.pkl\"\n",
    "\n",
    "# import data\n",
    "with open(cmc_asset_universe_fp, 'rb') as f:\n",
    "    cmc_asset_universe_dict = pickle.load(f)\n",
    "cmc_cw_df =  pd.read_pickle(cmc_cw_fp)\n",
    "cmc_panel_df = pd.read_pickle(cmc_panel_fp)\n",
    "cg_cw_df =  pd.read_pickle(cg_cw_fp)\n",
    "cg_panel_df = pd.read_pickle(cg_panel_fp)\n",
    "cm_cw_df = pd.read_pickle(cm_cw_fp)\n",
    "cm_asset_df = pd.read_pickle(cm_asset_info_fp)\n",
    "cm_panel_df = pd.read_pickle(cm_panel_fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO FORM SINGLE PANEL\n",
    "\n",
    "# clean cws and panels before merge\n",
    "cm_cw_df = cm_cw_df[~cm_cw_df.asset_cm.isin(['xno'])]\n",
    "cm_cw_df = cm_cw_df[~cm_cw_df.asset_cmc.isin(['aave-old'])]\n",
    "cm_cw_df = cm_cw_df.rename(columns = {'asset_cmc': 'slug_cmc'})\n",
    "cg_cw_df = cg_cw_df[~cg_cw_df.asset_cmc.isin(['cronos', 'aave-old', 'yearn-finance-ii'])]\n",
    "cg_cw_df = cg_cw_df.rename(columns={'asset_cmc': 'slug_cmc'})\n",
    "cmc_panel_df['date'] = cmc_panel_df['date'].dt.date\n",
    "assert type(cg_panel_df.date.values[0]) == datetime.date\n",
    "cm_panel_df['time'] = pd.to_datetime(cm_panel_df['time']).dt.date\n",
    "cm_panel_df = cm_panel_df.rename(columns={'asset': 'asset_cm', 'time': 'date'})\n",
    "cm_asset_df = cm_asset_df.rename(columns={'asset': 'asset_cm'})\n",
    "\n",
    "# merge panels togethers\n",
    "panel_df = cmc_panel_df.merge(cg_cw_df,\n",
    "                              on='slug_cmc',\n",
    "                              how='left',\n",
    "                              validate='many_to_one')\n",
    "assert cmc_panel_df.shape[0]==panel_df.shape[0]\n",
    "panel_df = panel_df.merge(cg_panel_df, on=['date', 'asset_gecko'], how='outer', validate='many_to_one')\n",
    "panel_df = panel_df.merge(cm_cw_df[~cm_cw_df.slug_cmc.isnull()], on='slug_cmc', how='left', validate='many_to_one')\n",
    "panel_df = panel_df.merge(cm_panel_df, on=['date', 'asset_cm'], how='outer', validate='many_to_one')\n",
    "\n",
    "# cut down to window of interest\n",
    "panel_df = panel_df[panel_df.date.apply(lambda x: x.year) >=2015]\n",
    "\n",
    "# subset to assets with tradable market on coinmetrics and the dates after it is first tradable\n",
    "panel_df = panel_df[panel_df.asset_cm.isin(cm_asset_df.asset.values)].copy()\n",
    "assets = list(np.unique(panel_df.asset_cm.values))\n",
    "\n",
    "for asset in assets:\n",
    "    date_first_tradable = cm_asset_df[cm_asset_df.asset_cm==asset].date_first_tradable.values[0]\n",
    "    date_first_tradable = datetime.datetime.strptime(date_first_tradable, '%Y-%m-%d').date()\n",
    "    rows_before = panel_df.shape[0]\n",
    "    panel_df = panel_df[~((panel_df.asset_cm==asset) & (panel_df.date<date_first_tradable))]\n",
    "    if rows_before != panel_df.shape[0]:\n",
    "        print(f\"For {asset} we lost {(rows_before - panel_df.shape[0])} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN PRICE COLUMN\n",
    "\n",
    "# drop rows where we have no price data\n",
    "panel_df = panel_df[~(panel_df.ReferenceRateUSD.isnull() \n",
    "                    & panel_df.usd_per_token_cmc.isnull() \n",
    "                    & panel_df.usd_per_token_cg.isnull())]\n",
    "\n",
    "# form the price column\n",
    "panel_df['usd_per_token'] = np.nan\n",
    "panel_df.loc[~panel_df.ReferenceRateUSD.isnull(), 'usd_per_token'] = panel_df['ReferenceRateUSD']\n",
    "panel_df.loc[panel_df.usd_per_token.isnull(), 'usd_per_token'] = panel_df[['usd_per_token_cmc', 'usd_per_token_cg']].mean(axis=1, skipna=True)\n",
    "\n",
    "# remove rows where the price between cmc and cg is different by more than 50%\n",
    "panel_df = panel_df[~(panel_df.ReferenceRateUSD.isnull() \n",
    "                    & ~panel_df.usd_per_token_cmc.isnull() \n",
    "                    & ~panel_df.usd_per_token_cg.isnull()\n",
    "                    & (np.abs((panel_df.usd_per_token_cmc-panel_df.usd_per_token_cg)/panel_df.usd_per_token_cmc) > 0.5))]\n",
    "\n",
    "# keep just the final price\n",
    "panel_df = panel_df.drop(columns=['usd_per_token_cmc', 'usd_per_token_cg', \n",
    "                     'PriceUSD', 'ReferenceRate', 'ReferenceRateUSD'], axis=1)\n",
    "\n",
    "# convert dtype\n",
    "panel_df['usd_per_token'] = panel_df.usd_per_token.astype(float)\n",
    "\n",
    "# CLEAN MCAP COLUMN\n",
    "\n",
    "# drop if there is no mcap data\n",
    "panel_df = panel_df[~(panel_df.usd_mcap_cmc.isnull()\n",
    "                    & panel_df.usd_mcap_cg.isnull()\n",
    "                    & panel_df.CapMrktEstUSD.isnull())]\n",
    "\n",
    "# set any zeros to missing\n",
    "panel_df.loc[panel_df.CapMrktEstUSD==0, 'CapMrktEstUSD'] = np.nan\n",
    "panel_df.loc[panel_df.usd_mcap_cg==0, 'usd_mcap_cg'] = np.nan\n",
    "panel_df.loc[panel_df.usd_mcap_cmc==0, 'usd_mcap_cmc'] = np.nan\n",
    "\n",
    "# form the mcap column\n",
    "panel_df['CapMrktEstUSD'] = panel_df.CapMrktEstUSD.astype(float)\n",
    "panel_df['usd_mcap'] = panel_df[['CapMrktEstUSD', 'usd_mcap_cg', 'usd_mcap_cmc']].mean(axis=1, skipna=True)\n",
    "assert 0 == panel_df.usd_mcap.isnull().sum()\n",
    "\n",
    "# drop rows where mcaps between cg and cmc are more than order of magnitude off when we are missing CM values\n",
    "panel_df = panel_df[~(panel_df.CapMrktEstUSD.isnull() & ~panel_df.usd_mcap_cg.isnull() & ~panel_df.usd_mcap_cmc.isnull()\n",
    "                      & (np.abs((panel_df.usd_mcap_cg - panel_df.usd_mcap_cmc)/panel_df.usd_mcap_cmc) > 10))]\n",
    "\n",
    "# keep just the final price\n",
    "panel_df = panel_df.drop(columns=['usd_mcap_cmc', 'usd_mcap_cg', \n",
    "                                  'CapMrktCurUSD', 'CapMrktEstUSD', 'CapMrktFFUSD', 'CapRealUSD'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO come back to create the cm market cap measure using supply for where it is missing if useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO COINAPI\n",
    "# for a broad cm asset universe\n",
    "# pull all exchange prices from a set of legit exchanges (maybe the cm set?)\n",
    "# pull asociated volume data\n",
    "# use this as my legit volume estimate \n",
    "# pull any mcap data that they have too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use coinapi for my volume estimate of LEGIT exchanges; maybe cross check with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO subset down to date, asset, price, mcap, and volume and other useful variables\n",
    "# TODO look for continuity within asset. look at returns to see if anything crazy. look if mcap jump is way diff than price jump.\n",
    "# TODO make sure ranges of values looks good\n",
    "# TODO go scope old cleaning scripts to make sure i do all of that too\n",
    "# TODO apply the inclusion criteria on the first on each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO manually check that the universe makes sense for maybe 6-10 of the random sampling of hte first years and \n",
    "# the last 3-6 random sampling over 2-3 years?\n",
    "\n",
    "\n",
    "# TODO output the cmc, coingecko, and cm cw for this universe as well as a dictionary of the cmc ids at the start of each month\n",
    "\n",
    "# TODO convert all the code to functions with professional documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e428bc405edc59f3352e9792cab27c5e28560f7efb4b47308a6c6ea38cd15df2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
