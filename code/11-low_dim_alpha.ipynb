{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab026fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to use the quantools, due to my crap path names have to add to sys path\n",
    "import sys\n",
    "sys.path.insert(0, '/home/adam/Dropbox/2-creations/2-crafts/7-buidl/0-utils/quant_tools/code')\n",
    "\n",
    "# IMPORT PACKAGES\n",
    "from typing import List, Dict\n",
    "from tools import QuantTools\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4bd052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsetToAssetUniverse(df: pd.DataFrame, asset_universe_dict: Dict[str, List[str]]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Subset a DataFrame based on a dictionary of asset universes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The input DataFrame. Must contain columns \"date\" and \"asset\".\n",
    "    asset_universe_dict : Dict[str, List[str]]\n",
    "        A dictionary where keys are dates in 'YYYY-MM-DD' format and values are lists of asset names.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The subsetted DataFrame.\n",
    "    \"\"\"\n",
    "    # Check that the required columns are present in the DataFrame\n",
    "    if not set(['date', 'asset']).issubset(df.columns):\n",
    "        raise ValueError('Input DataFrame must contain \"date\" and \"asset\" columns.')\n",
    "\n",
    "    # Ensure that the 'date' column is of datetime type\n",
    "    if df['date'].dtype != 'datetime64[ns]':\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Loop over all months with their relevant assets\n",
    "    for key, values in asset_universe_dict.items():\n",
    "        # Extract the year and month from the key\n",
    "        year, month = key.split('-')[:2]\n",
    "\n",
    "        # Drop rows from the dataframe which match the year and month but not the assets\n",
    "        df = df[~((df.date.dt.year == int(year)) \n",
    "                    & (df.date.dt.month == int(month)) \n",
    "                    & (~df.asset.isin(values)))]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "644b05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formUniFactor(in_df: pd.DataFrame, rhs_col: str, lhs_col: str, num_quantiles: int=5) -> pd.DataFrame:\n",
    "    # Obtain factor name\n",
    "    factor_col = 'factor_'+rhs_col[5:]\n",
    "\n",
    "    # Obtain relevant data\n",
    "    t_df = in_df[['date', 'asset', lhs_col, rhs_col, 'char_mcap_t']].copy()\n",
    "    t_df = t_df.rename(columns={'char_mcap_t': 'mcap'})\n",
    "\n",
    "    # Form quantiles\n",
    "    t_df['rank_within_date'] = t_df.groupby('date')[rhs_col].rank(method='first')\n",
    "    t_df['rank_ratio'] = t_df.groupby('date')['rank_within_date'].transform(lambda x: x / x.max())\n",
    "    quantile_bins = list(np.arange(0, num_quantiles+1)/num_quantiles)\n",
    "    t_df['quant'] = 1+pd.cut(t_df['rank_ratio'], bins=quantile_bins, labels=False, include_lowest=True)\n",
    "    t_df = t_df.drop(columns=['rank_within_date', 'rank_ratio'])\n",
    "\n",
    "    # Calculate the average return for each quantile within each date\n",
    "    t_df['weighted_return'] = t_df[lhs_col] * t_df.mcap\n",
    "    grouped_df = t_df.groupby(['date', 'quant'])[['weighted_return', 'mcap']].sum().reset_index()\n",
    "    grouped_df[lhs_col] = grouped_df['weighted_return'] / grouped_df['mcap']\n",
    "    date_quantile_avg_returns_df = grouped_df[['date', 'quant', lhs_col]].copy()\n",
    "\n",
    "    # Calculate the 5-1 return time series\n",
    "    diff_date_quantile_avg_returns_df = date_quantile_avg_returns_df.pivot_table(index='date', columns='quant', values=lhs_col)\n",
    "    hml_df = pd.DataFrame(diff_date_quantile_avg_returns_df[num_quantiles] \n",
    "        - diff_date_quantile_avg_returns_df[1])\n",
    "\n",
    "    # Clean up\n",
    "    hml_df.columns = [factor_col]\n",
    "    hml_df = hml_df.reset_index()\n",
    "\n",
    "    return hml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fdea95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runContempRegAndReportResults(\n",
    "    factors_df: pd.DataFrame, models_df: pd.DataFrame, out_fp: str, out_sheet: str) -> None:\n",
    "    # obtain factors to study as lhs variables\n",
    "    factor_cols = list(factors_df.columns.values)\n",
    "    factor_cols.remove('date')\n",
    "\n",
    "    # Put together the factors and model yhats\n",
    "    reg_df = factors_df.merge(models_df, on='date', how='inner', validate='one_to_one')\n",
    "\n",
    "    # Initialize DataFrame for the results\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    # Generate results for each uni factor\n",
    "    for factor_col in factor_cols:\n",
    "        # Initialize result object for this factor\n",
    "        result_df = pd.DataFrame(index=[0, 1])\n",
    "\n",
    "        # Add factor name\n",
    "        result_df['uni_factor'] = factor_col\n",
    "\n",
    "        # Prep lhs and rhs\n",
    "        y = reg_df[factor_col].values\n",
    "        X = reg_df[['multi', 'pca', 'ipca']].copy()\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        # Run OLS\n",
    "        T = reg_df.shape[0]\n",
    "        maxlags = int(4 * (T / 100)**(2/9))\n",
    "        model = sm.OLS(y, X)\n",
    "        results = model.fit(cov_type='HAC', cov_kwds={'maxlags': maxlags})\n",
    "\n",
    "        # obtain, format, and store results\n",
    "        for i, col in zip(range(4), ['alpha', 'multi', 'pca', 'ipca']):\n",
    "            # obtain\n",
    "            coef  = results.params[i]\n",
    "            se    = results.bse[i]\n",
    "            tstat = results.tvalues[i]\n",
    "\n",
    "            # format\n",
    "            coef    = str(np.round(coef, 4))\n",
    "            se      = \"(\"+str(np.round(se, 4))+\")\"\n",
    "            \n",
    "            # add significant\n",
    "            if np.abs(tstat) >= 2.326:\n",
    "                coef = coef+\"***\"\n",
    "            elif np.abs(tstat) >= 1.96:\n",
    "                coef = coef+\"**\"\n",
    "            elif np.abs(tstat) >= 1.645:\n",
    "                coef = coef+\"*\"\n",
    "            \n",
    "            # store results\n",
    "            result_df.loc[0, col] = coef\n",
    "            result_df.loc[1, col] = se\n",
    "\n",
    "        # Obtain and store r2\n",
    "        result_df['r2'] = np.round(results.rsquared, 2)\n",
    "\n",
    "        # Append results\n",
    "        results_df = pd.concat((results_df, result_df))\n",
    "\n",
    "    # Save the results\n",
    "    with pd.ExcelWriter(out_fp, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer: \n",
    "        results_df.to_excel(writer, sheet_name=out_sheet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d441d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # set args\n",
    "    PANEL_IN_FP     = '../data/clean/panel_weekly.pkl' \n",
    "    ASSET_IN_FP     = '../data/clean/asset_universe_dict.pickle'\n",
    "    IN_MULTI_FP     = '../data/clean/test_yhats_multivariate.pkl'\n",
    "    IN_PCA_FP       = '../data/clean/test_yhats_pca.pkl'\n",
    "    IN_IPCA_FP      = '../data/clean/test_yhats_ipca.pkl'\n",
    "    OUT_FP          = '../output/low_dim_fm/low_dim_fms.xlsx'\n",
    "    OUT_SHEET       = 'raw_alpha'\n",
    "    SIG_UNI_COLS    = ['char_r_tm14',\n",
    "        'char_r_industry_tm30',\n",
    "        'char_r_industry_tm60',\n",
    "        'char_beta_tm7',\n",
    "        'char_iskew_tm30',\n",
    "        'char_illiq_tm7']\n",
    "    LHS_COL         = 'r_ex_tp7'\n",
    "\n",
    "    # read in data\n",
    "    with open(ASSET_IN_FP, \"rb\") as f:\n",
    "        asset_universe_dict = pickle.load(f)\n",
    "    all_df = pd.read_pickle(PANEL_IN_FP)\n",
    "    multi_df = pd.read_pickle(IN_MULTI_FP)\n",
    "    pca_df   = pd.read_pickle(IN_PCA_FP)\n",
    "    ipca_df  = pd.read_pickle(IN_IPCA_FP)\n",
    "    \n",
    "    # form uni factors\n",
    "    char_df = all_df[['date', 'asset', LHS_COL, 'char_mcap_t']+SIG_UNI_COLS].copy()\n",
    "    char_df = subsetToAssetUniverse(char_df, asset_universe_dict)\n",
    "    factors_df = pd.DataFrame(data={'date': []})\n",
    "    for rhs_col in SIG_UNI_COLS:\n",
    "        factor_df = formUniFactor(char_df, rhs_col, LHS_COL)\n",
    "        factors_df = factors_df.merge(factor_df, on=['date'], how='outer', validate='one_to_one')\n",
    "\n",
    "    # select best models based on low dim results and rename\n",
    "    multi_df = multi_df.rename(columns={'yhats_2_factors': 'yhats_multi'})\n",
    "    multi_df = multi_df[['date', 'asset', 'yhats_multi']].copy()\n",
    "    pca_df = pca_df.rename(columns={'yhats_4_factors': 'yhats_pca'})\n",
    "    pca_df = pca_df[['date', 'asset', 'yhats_pca']].copy()\n",
    "    ipca_df = ipca_df.rename(columns={'yhats_3_factors': 'yhats_ipca'})\n",
    "    ipca_df = ipca_df[['date', 'asset', 'yhats_ipca']].copy()\n",
    "\n",
    "    # put results together\n",
    "    df = multi_df.merge(pca_df, on=['date', 'asset'], how='inner', validate='one_to_one')\n",
    "    df = df.merge(ipca_df, on=['date', 'asset'], how='inner', validate='one_to_one')\n",
    "\n",
    "    # add lhs and mcap to low dim model yhats\n",
    "    df = df.merge(all_df[['date', 'asset', LHS_COL, 'char_mcap_t']], on=['date', 'asset'], how='inner', validate='one_to_one')\n",
    "    df = df.rename(columns={'char_mcap_t': 'mcap'})\n",
    "\n",
    "    # calc low dim returns\n",
    "    temp_df = QuantTools.formPortfolioWeightsByQuantile(df, 5, True, 'yhats_multi')\n",
    "    temp_df['return'] = temp_df.prtfl_wght_hml*temp_df[LHS_COL]\n",
    "    returns_multi = temp_df.groupby('date')[['return']].sum().values.reshape(-1)\n",
    "    temp_df = QuantTools.formPortfolioWeightsByQuantile(df, 5, True, 'yhats_pca')\n",
    "    temp_df['return'] = temp_df.prtfl_wght_hml*temp_df[LHS_COL]\n",
    "    returns_pca = temp_df.groupby('date')[['return']].sum().values.reshape(-1)\n",
    "    temp_df = QuantTools.formPortfolioWeightsByQuantile(df, 5, True, 'yhats_ipca')\n",
    "    temp_df['return'] = temp_df.prtfl_wght_hml*temp_df[LHS_COL]\n",
    "    returns_ipca = temp_df.groupby('date')[['return']].sum().values.reshape(-1)\n",
    "    models_df = pd.DataFrame(data={\n",
    "        'date': multi_df.date.unique(),\n",
    "        'multi': returns_multi,\n",
    "        'pca': returns_pca,\n",
    "        'ipca': returns_ipca\n",
    "    })\n",
    "\n",
    "    # Run and report results\n",
    "    runContempRegAndReportResults(factors_df, models_df, OUT_FP, OUT_SHEET)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f14a76dcff07d5b93f2c0fc65ce65c8ac7788ddb1ef5c63daa3feefa016fa519"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
