{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO scope diff between tradable price and global price to see if interesting to show in exploratory data analysis\n",
    "# -show how far off you'd be by using this price as opposed to the actually available price\n",
    "# -can note it'd be even worse for assets that i'm not looking as they'd be adversely selected toward lower liquidity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO CAN USE THIS FOR SCOPING UNIVARIATE CORR\n",
    "\n",
    "series2 = df.price_usd[1:].values\n",
    "for col in df.columns.values[1:-2]:\n",
    "    series1 = df[col][:-1].values\n",
    "\n",
    "    # Find indices where both series have non-missing values\n",
    "    non_missing_indices = np.logical_not(np.isnan(series1) | np.isnan(series2))\n",
    "\n",
    "    # Compute the correlation using non-missing values only\n",
    "    corr_matrix = np.corrcoef(series1[non_missing_indices], series2[non_missing_indices])\n",
    "\n",
    "    # Extract the correlation coefficient (off-diagonal element)\n",
    "    corr_coef = corr_matrix[0, 1]\n",
    "    print(col)\n",
    "    print(f\"Correlation coefficient: {corr_coef}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO FOR DESC STAT + LOW DIM FM: ENSURE I CREATE ALL CHAR/FACTORS USED IN LIT\n",
    "# -CREATE BOTH FOR HOUR OVER HOUR AND DAY OVER DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO feat eng for macro data:\n",
    "# -form snp return\n",
    "# -form snp momentum\n",
    "# -form snp volatility\n",
    "# -form squared market return\n",
    "# -form all chen transformations too\n",
    "# -CREATE BOTH FOR HOUR OVER HOUR AND DAY OVER DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO COMPRESS DOWN THE CHARACTERISTICS AND MACRO VARIABLES FOR REPEATED ONES\n",
    "# -FOR ONES THAT ARE REALLY HARD TO DECIDE / POTENTIALLY IMPORTANT THEN CREATE THE UNI CORR TABLES TO DECIDE LATER (E.G. MCAP)\n",
    "# -COMPRESS DOWN THE MACRO COVARIATES TO SOMETHING CLOSER TO GU 2019 INSTEAD OF RAW MCCRAKEN\n",
    "# -CREATE BOTH FOR HOUR OVER HOUR AND DAY OVER DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO FOR THE DESC STAT AND LOW DIM FM STUFF, LETS WORK AT DAILY LEVEL\n",
    "# -TO REDUCE OUT SOME OF THE NOISE\n",
    "# -REDUCE THE SAMPLE SIZE FOR MORE SIMPLE MODELS TO WORK\n",
    "# -HAVE RESULTS BE SUGGESTIVE OF HOURLY LEVEL PERFORMANCE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO FOR THE HIGH DIM FM PANEL AT HOURLY FREQ, \n",
    "# -LETS WORK WITH DATA IN PRETTY RAW FORM AS NEURAL NETS WILL LEARN HOW TO DO FEAT ENG\n",
    "# -MAYBE SOME OF THE COLUMNS WE CAN SUMMARIZE IF THEIR COVARIANCE IS PRETTY USELESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORM RETURN VARIABLES\n",
    "\n",
    "# Ensure it is sorted\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Form RHS return variables\n",
    "assert(0==df[df.usd_per_token == 0].shape[0])\n",
    "df['covar_r_t']               = df.groupby('asset')['usd_per_token'].pct_change(periods=7)\n",
    "df['covar_r_tm14']            = df.groupby('asset')['usd_per_token'].pct_change(periods=14)\n",
    "df['covar_r_tm21']            = df.groupby('asset')['usd_per_token'].pct_change(periods=21)\n",
    "df['covar_r_tm28']            = df.groupby('asset')['usd_per_token'].pct_change(periods=28)\n",
    "df['covar_r_daily_t']         = df.groupby('asset')['usd_per_token'].pct_change(periods=1)\n",
    "df['covar_r_daily_avg_tm7']   = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(7).mean())\n",
    "df['covar_vol_r_daily_tm7']   = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(7).std())\n",
    "df['covar_vol_r_daily_tm14']  = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(14).std())\n",
    "df['covar_vol_r_daily_tm21']  = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(21).std())\n",
    "df['covar_vol_r_daily_tm28']  = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(28).std())\n",
    "df['covar_skew_r_daily_tm7']  = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(7).skew())\n",
    "df['covar_skew_r_daily_tm14'] = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(14).skew())\n",
    "df['covar_skew_r_daily_tm21'] = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(21).skew())\n",
    "df['covar_skew_r_daily_tm28'] = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(28).skew())\n",
    "df['covar_kurt_r_daily_tm7']  = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(7).kurt())\n",
    "df['covar_kurt_r_daily_tm14'] = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(14).kurt())\n",
    "df['covar_kurt_r_daily_tm21'] = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(21).kurt())\n",
    "df['covar_kurt_r_daily_tm28'] = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(28).kurt())\n",
    "\n",
    "# Form LHS variable\n",
    "df['r_tplus7'] = df.groupby('asset')['covar_r_t'].shift(-7)\n",
    "\n",
    "# Drop rows missing r_tplus7\n",
    "df = df[~df.r_tplus7.isnull()]\n",
    "\n",
    "# Drop 2022 rows\n",
    "df = df[df.date <= '2021-12-26']\n",
    "\n",
    "# Ensure it is sorted and reset index\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# FORM AGE VARIABLE\n",
    "\n",
    "df['covar_age_t'] = (pd.to_datetime(df.date) - pd.to_datetime(df.first_date_cmc)).astype('timedelta64[D]')\n",
    "assert(0 <= np.min(df.covar_age_t))\n",
    "df = df.drop('first_date_cmc', axis=1)\n",
    "\n",
    "# FORM PRICE VARIABLES\n",
    "\n",
    "# Sunday price and log price\n",
    "df['covar_p_t']     = df.usd_per_token.values\n",
    "df['covar_p_log_t'] = np.log(df.usd_per_token.values)\n",
    "\n",
    "# Avg, min, & max price and log price in last week and last 28 days\n",
    "df['covar_p_avg_daily_tm7']      = df.groupby('asset')['usd_per_token'].transform(lambda x: x.rolling(7).mean())\n",
    "df['covar_p_min_daily_tm7']      = df.groupby('asset')['usd_per_token'].transform(lambda x: x.rolling(7).min())\n",
    "df['covar_p_max_daily_tm7']      = df.groupby('asset')['usd_per_token'].transform(lambda x: x.rolling(7).max())\n",
    "df['covar_p_log_avg_daily_tm7']  = df.groupby('asset')['usd_per_token'].transform(lambda x: np.log(x).rolling(7).mean())\n",
    "df['covar_p_log_min_daily_tm7']  = df.groupby('asset')['usd_per_token'].transform(lambda x: np.log(x).rolling(7).min())\n",
    "df['covar_p_log_max_daily_tm7']  = df.groupby('asset')['usd_per_token'].transform(lambda x: np.log(x).rolling(7).max())\n",
    "df['covar_p_avg_daily_tm28']     = df.groupby('asset')['usd_per_token'].transform(lambda x: x.rolling(28).mean())\n",
    "df['covar_p_min_daily_tm28']     = df.groupby('asset')['usd_per_token'].transform(lambda x: x.rolling(28).min())\n",
    "df['covar_p_max_daily_tm28']     = df.groupby('asset')['usd_per_token'].transform(lambda x: x.rolling(28).max())\n",
    "df['covar_p_log_avg_daily_tm28'] = df.groupby('asset')['usd_per_token'].transform(lambda x: np.log(x).rolling(28).mean())\n",
    "df['covar_p_log_min_daily_tm28'] = df.groupby('asset')['usd_per_token'].transform(lambda x: np.log(x).rolling(28).min())\n",
    "df['covar_p_log_max_daily_tm28'] = df.groupby('asset')['usd_per_token'].transform(lambda x: np.log(x).rolling(28).max())\n",
    "\n",
    "# FORM MCAP VARIABLES\n",
    "\n",
    "# Sunday mcap and log mcap\n",
    "df['covar_mcap_t']     = df.usd_mcap.values\n",
    "df['covar_mcap_log_t'] = np.log(df.usd_mcap.values)\n",
    "\n",
    "# Avg, min, & max mcap and log mcap in last week and last 28 days\n",
    "df['covar_mcap_avg_daily_tm7']      = df.groupby('asset')['usd_mcap'].transform(lambda x: x.rolling(7).mean())\n",
    "df['covar_mcap_min_daily_tm7']      = df.groupby('asset')['usd_mcap'].transform(lambda x: x.rolling(7).min())\n",
    "df['covar_mcap_max_daily_tm7']      = df.groupby('asset')['usd_mcap'].transform(lambda x: x.rolling(7).max())\n",
    "df['covar_mcap_log_avg_daily_tm7']  = df.groupby('asset')['usd_mcap'].transform(lambda x: np.log(x).rolling(7).mean())\n",
    "df['covar_mcap_log_min_daily_tm7']  = df.groupby('asset')['usd_mcap'].transform(lambda x: np.log(x).rolling(7).min())\n",
    "df['covar_mcap_log_max_daily_tm7']  = df.groupby('asset')['usd_mcap'].transform(lambda x: np.log(x).rolling(7).max())\n",
    "df['covar_mcap_avg_daily_tm28']     = df.groupby('asset')['usd_mcap'].transform(lambda x: x.rolling(28).mean())\n",
    "df['covar_mcap_min_daily_tm28']     = df.groupby('asset')['usd_mcap'].transform(lambda x: x.rolling(28).min())\n",
    "df['covar_mcap_max_daily_tm28']     = df.groupby('asset')['usd_mcap'].transform(lambda x: x.rolling(28).max())\n",
    "df['covar_mcap_log_avg_daily_tm28'] = df.groupby('asset')['usd_mcap'].transform(lambda x: np.log(x).rolling(28).mean())\n",
    "df['covar_mcap_log_min_daily_tm28'] = df.groupby('asset')['usd_mcap'].transform(lambda x: np.log(x).rolling(28).min())\n",
    "df['covar_mcap_log_max_daily_tm28'] = df.groupby('asset')['usd_mcap'].transform(lambda x: np.log(x).rolling(28).max())\n",
    "\n",
    "# FORM VOLUME VARIABLES\n",
    "\n",
    "# Sunday volume and log volume\n",
    "df['covar_volume_t']     = df.usd_trading_volume_24h.values\n",
    "df['covar_volume_log_t'] = np.log(df.usd_trading_volume_24h.values)\n",
    "\n",
    "# Total, avg, median, min, & max volume and log volume over last week and last 28 days\n",
    "df['covar_volume_sum_daily_tm7']      = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(7).sum())\n",
    "df['covar_volume_avg_daily_tm7']      = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(7).mean())\n",
    "df['covar_volume_med_daily_tm7']      = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(7).median())\n",
    "df['covar_volume_min_daily_tm7']      = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(7).min())\n",
    "df['covar_volume_max_daily_tm7']      = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(7).max())\n",
    "df['covar_volume_log_sum_daily_tm7']  = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(7).sum())\n",
    "df['covar_volume_log_avg_daily_tm7']  = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(7).mean())\n",
    "df['covar_volume_log_med_daily_tm7']  = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(7).median())\n",
    "df['covar_volume_log_min_daily_tm7']  = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(7).min())\n",
    "df['covar_volume_log_max_daily_tm7']  = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(7).max())\n",
    "df['covar_volume_sum_daily_tm28']     = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(28).sum())\n",
    "df['covar_volume_avg_daily_tm28']     = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(28).mean())\n",
    "df['covar_volume_med_daily_tm28']     = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(28).median())\n",
    "df['covar_volume_min_daily_tm28']     = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(28).min())\n",
    "df['covar_volume_max_daily_tm28']     = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(28).max())\n",
    "df['covar_volume_log_sum_daily_tm28'] = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(28).sum())\n",
    "df['covar_volume_log_avg_daily_tm28'] = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(28).mean())\n",
    "df['covar_volume_log_med_daily_tm28'] = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(28).median())\n",
    "df['covar_volume_log_min_daily_tm28'] = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(28).min())\n",
    "df['covar_volume_log_max_daily_tm28'] = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(28).max())\n",
    "# FORM PRICE VOLUME VARIABLES\n",
    "\n",
    "# Sunday price times volume and log of it\n",
    "df['covar_p_volume_t']     = df.covar_p_t * df.covar_volume_t\n",
    "df['covar_p_volume_log_t'] = df.covar_p_log_t * df.covar_volume_log_t\n",
    "\n",
    "# Log average daily volumes times avg price over past week and 28 days. Std too\n",
    "df['covar_p_volume_log_avg_daily_tm7']  = np.log(df.covar_volume_avg_daily_tm7 * df.covar_p_avg_daily_tm7)\n",
    "df['covar_p_volume_log_avg_daily_tm28'] = np.log(df.covar_volume_avg_daily_tm28 * df.covar_p_avg_daily_tm28)\n",
    "df['covar_p_volume_log_std_daily_tm7']  = np.log(df.groupby('asset')['covar_p_volume_t'].transform(lambda x: x.rolling(7).std()))\n",
    "df['covar_p_volume_log_std_daily_tm28'] = np.log(df.groupby('asset')['covar_p_volume_t'].transform(lambda x: x.rolling(28).std()))\n",
    "\n",
    "# DROP PRICE, MCAP, VOLUME VARS\n",
    "\n",
    "df = df.drop(['usd_per_token', 'usd_mcap', 'usd_trading_volume_24h'], axis=1)\n",
    "\n",
    "# Ensure it is sorted and reset index\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORM MACRO VARIABLES\n",
    "\n",
    "# Confirm some columns are not missing for to be made pct change columns\n",
    "assert(0==df[df['active_cryptocurrencies_cmc'].isnull()].shape[0])\n",
    "assert(0==df[df['active_exchanges_cmc'].isnull()].shape[0])\n",
    "assert(0==df[df['active_market_pairs_cmc'].isnull()].shape[0])\n",
    "assert(0==df[df['btc_dominance_cmc'].isnull()].shape[0])\n",
    "assert(0==df[(df.asset == 'ethereum') & df.covar_mcap_t.isnull()].shape[0])\n",
    "\n",
    "# Trading volume variables\n",
    "df['macro_volume_t']             = df.total_volume_24h_cmc.values\n",
    "df['macro_volume_altcoin_t']     = df.altcoin_volume_24h_cmc.values\n",
    "df['macro_volume_log_t']         = np.log(df.total_volume_24h_cmc.values)\n",
    "df['macro_volume_altcoin_log_t'] = np.log(df.altcoin_volume_24h_cmc.values)\n",
    "df['macro_volume_reported_t']             = df.total_volume_24h_reported_cmc.values\n",
    "df['macro_volume_altcoin_reported_t']     = df.altcoin_volume_24h_reported_cmc.values\n",
    "df['macro_volume_reported_log_t']         = np.log(df.total_volume_24h_reported_cmc.values)\n",
    "df['macro_volume_altcoin_reported_log_t'] = np.log(df.altcoin_volume_24h_reported_cmc.values)\n",
    "temp_df = df[df.asset == 'bitcoin'][['date', 'total_volume_24h_cmc', 'altcoin_volume_24h_cmc',\n",
    "                                     'total_volume_24h_reported_cmc', 'altcoin_volume_24h_reported_cmc',\n",
    "                                     'covar_volume_t', 'covar_volume_log_t']]\n",
    "temp_df = temp_df.rename(columns={'covar_volume_t': 'macro_volume_btc_t',\n",
    "                                  'covar_volume_log_t': 'macro_volume_btc_log_t'})\n",
    "temp_df['macro_volume_sum_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_volume_avg_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_volume_min_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_volume_max_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_volume_reported_sum_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_volume_reported_avg_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_volume_reported_min_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_volume_reported_max_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_volume_log_sum_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).sum())\n",
    "temp_df['macro_volume_log_avg_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).mean())\n",
    "temp_df['macro_volume_log_min_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).min())\n",
    "temp_df['macro_volume_log_max_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).max())\n",
    "temp_df['macro_volume_log_reported_sum_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).sum())\n",
    "temp_df['macro_volume_log_reported_avg_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).mean())\n",
    "temp_df['macro_volume_log_reported_min_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).min())\n",
    "temp_df['macro_volume_log_reported_max_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).max())\n",
    "temp_df['macro_volume_sum_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_volume_avg_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_volume_min_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_volume_max_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_volume_reported_sum_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_volume_reported_avg_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_volume_reported_min_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_volume_reported_max_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_volume_log_sum_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).sum())\n",
    "temp_df['macro_volume_log_avg_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).mean())\n",
    "temp_df['macro_volume_log_min_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).min())\n",
    "temp_df['macro_volume_log_max_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).max())\n",
    "temp_df['macro_volume_log_reported_sum_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).sum())\n",
    "temp_df['macro_volume_log_reported_avg_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).mean())\n",
    "temp_df['macro_volume_log_reported_min_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).min())\n",
    "temp_df['macro_volume_log_reported_max_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).max())\n",
    "temp_df['macro_volume_altcoin_sum_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_volume_altcoin_avg_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_volume_altcoin_min_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_volume_altcoin_max_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_volume_altcoin_reported_sum_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_volume_altcoin_reported_avg_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_volume_altcoin_reported_min_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_volume_altcoin_reported_max_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_volume_altcoin_log_sum_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).sum())\n",
    "temp_df['macro_volume_altcoin_log_avg_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).mean())\n",
    "temp_df['macro_volume_altcoin_log_min_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).min())\n",
    "temp_df['macro_volume_altcoin_log_max_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).max())\n",
    "temp_df['macro_volume_altcoin_log_reported_sum_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).sum())\n",
    "temp_df['macro_volume_altcoin_log_reported_avg_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).mean())\n",
    "temp_df['macro_volume_altcoin_log_reported_min_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).min())\n",
    "temp_df['macro_volume_altcoin_log_reported_max_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).max())\n",
    "temp_df['macro_volume_altcoin_sum_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_volume_altcoin_avg_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_volume_altcoin_min_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_volume_altcoin_max_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_volume_altcoin_reported_sum_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_volume_altcoin_reported_avg_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_volume_altcoin_reported_min_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_volume_altcoin_reported_max_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_volume_altcoin_log_sum_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).sum())\n",
    "temp_df['macro_volume_altcoin_log_avg_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).mean())\n",
    "temp_df['macro_volume_altcoin_log_min_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).min())\n",
    "temp_df['macro_volume_altcoin_log_max_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).max())\n",
    "temp_df['macro_volume_altcoin_log_reported_sum_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).sum())\n",
    "temp_df['macro_volume_altcoin_log_reported_avg_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).mean())\n",
    "temp_df['macro_volume_altcoin_log_reported_min_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).min())\n",
    "temp_df['macro_volume_altcoin_log_reported_max_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).max())\n",
    "temp_df['macro_volume_btc_sum_daily_tm7'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_volume_btc_avg_daily_tm7'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_volume_btc_min_daily_tm7'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_volume_btc_max_daily_tm7'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_volume_btc_sum_daily_tm28'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_volume_btc_avg_daily_tm28'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_volume_btc_min_daily_tm28'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_volume_btc_max_daily_tm28'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_volume_btc_log_sum_daily_tm7'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_volume_btc_log_avg_daily_tm7'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_volume_btc_log_min_daily_tm7'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_volume_btc_log_max_daily_tm7'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_volume_btc_log_sum_daily_tm28'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_volume_btc_log_avg_daily_tm28'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_volume_btc_log_min_daily_tm28'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_volume_btc_log_max_daily_tm28'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df = temp_df.drop(['total_volume_24h_cmc', 'altcoin_volume_24h_cmc',\n",
    "                        'total_volume_24h_reported_cmc', 'altcoin_volume_24h_reported_cmc'], axis=1)\n",
    "df = df.drop(['total_volume_24h_cmc', 'altcoin_volume_24h_cmc',\n",
    "              'total_volume_24h_reported_cmc', 'altcoin_volume_24h_reported_cmc'], axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Market cap variables\n",
    "temp_df = df[df.asset == 'bitcoin'][['date', 'total_market_cap_cmc', 'altcoin_market_cap_cmc', \n",
    "                                     'covar_mcap_t', 'covar_mcap_log_t']]\n",
    "temp_df = temp_df.rename(columns={'covar_mcap_t': 'macro_mcap_btc_t',\n",
    "                                  'covar_mcap_log_t': 'macro_mcap_btc_log_t'})\n",
    "temp_df['macro_mcap_t']             = temp_df.total_market_cap_cmc.values\n",
    "temp_df['macro_mcap_altcoin_t']     = temp_df.altcoin_market_cap_cmc.values\n",
    "temp_df['macro_mcap_log_t']         = np.log(temp_df.total_market_cap_cmc.values)\n",
    "temp_df['macro_mcap_altcoin_log_t'] = np.log(temp_df.altcoin_market_cap_cmc.values)\n",
    "assert(0==temp_df[temp_df.total_market_cap_cmc == 0].shape[0])\n",
    "assert(0==temp_df[temp_df.altcoin_market_cap_cmc == 0].shape[0])\n",
    "temp_df['macro_mcap_sum_daily_tm7']      = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_mcap_avg_daily_tm7']      = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_mcap_min_daily_tm7']      = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_mcap_max_daily_tm7']      = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_mcap_log_sum_daily_tm7']  = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).sum())\n",
    "temp_df['macro_mcap_log_avg_daily_tm7']  = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).mean())\n",
    "temp_df['macro_mcap_log_min_daily_tm7']  = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).min())\n",
    "temp_df['macro_mcap_log_max_daily_tm7']  = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).max())\n",
    "temp_df['macro_mcap_ret_t']              = temp_df.total_market_cap_cmc.transform(lambda x: x.pct_change(periods=7))\n",
    "temp_df['macro_mcap_sum_daily_tm28']     = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_mcap_avg_daily_tm28']     = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_mcap_min_daily_tm28']     = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_mcap_max_daily_tm28']     = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_mcap_log_sum_daily_tm28'] = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).sum())\n",
    "temp_df['macro_mcap_log_avg_daily_tm28'] = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).mean())\n",
    "temp_df['macro_mcap_log_min_daily_tm28'] = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).min())\n",
    "temp_df['macro_mcap_log_max_daily_tm28'] = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).max())\n",
    "temp_df['macro_mcap_ret_tm28']           = temp_df.total_market_cap_cmc.transform(lambda x: x.pct_change(periods=28))\n",
    "temp_df['macro_mcap_altcoin_sum_daily_tm7']      = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_mcap_altcoin_avg_daily_tm7']      = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_mcap_altcoin_min_daily_tm7']      = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_mcap_altcoin_max_daily_tm7']      = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_mcap_altcoin_log_sum_daily_tm7']  = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).sum())\n",
    "temp_df['macro_mcap_altcoin_log_avg_daily_tm7']  = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).mean())\n",
    "temp_df['macro_mcap_altcoin_log_min_daily_tm7']  = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).min())\n",
    "temp_df['macro_mcap_altcoin_log_max_daily_tm7']  = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).max())\n",
    "temp_df['macro_mcap_altcoin_ret_t']              = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.pct_change(periods=7))\n",
    "temp_df['macro_mcap_altcoin_sum_daily_tm28']     = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_mcap_altcoin_avg_daily_tm28']     = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_mcap_altcoin_min_daily_tm28']     = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_mcap_altcoin_max_daily_tm28']     = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_mcap_altcoin_log_sum_daily_tm28'] = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).sum())\n",
    "temp_df['macro_mcap_altcoin_log_avg_daily_tm28'] = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).mean())\n",
    "temp_df['macro_mcap_altcoin_log_min_daily_tm28'] = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).min())\n",
    "temp_df['macro_mcap_altcoin_log_max_daily_tm28'] = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).max())\n",
    "temp_df['macro_mcap_altcoin_ret_tm28']           = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.pct_change(periods=28))\n",
    "\n",
    "# Form market cap variables from ATH and cycle low\n",
    "def idxMax(func_df, col):\n",
    "    idxmax = [func_df.date.values[0]]\n",
    "    maxvalue = func_df[col].values[0]\n",
    "    for i in range(1, func_df.shape[0]):\n",
    "        if func_df[col].values[i] > maxvalue:\n",
    "            idxmax.append(func_df.date.values[i])\n",
    "            maxvalue = func_df[col].values[i]\n",
    "        else:\n",
    "            idxmax.append(idxmax[i-1])\n",
    "    return idxmax\n",
    "def cycleLowMcap(func_df, mcap_col, cummax_date_col):\n",
    "    cycle_low_mcap_list = [func_df[mcap_col].values[0]]\n",
    "    for i in range(1, func_df.shape[0]):\n",
    "        start_date = func_df[cummax_date_col].values[i]\n",
    "        end_date   = func_df.date.values[i]\n",
    "        new_cycle_low = np.min(func_df[(func_df.date >= start_date) & \n",
    "                                       (func_df.date <= end_date)][mcap_col].values)\n",
    "        cycle_low_mcap_list.append(new_cycle_low) \n",
    "    return cycle_low_mcap_list\n",
    "temp_df['temp_cummax'] = temp_df.total_market_cap_cmc.cummax()\n",
    "temp_df['temp_cummax_date'] = idxMax(temp_df[['date', 'total_market_cap_cmc']],\n",
    "                                              'total_market_cap_cmc')\n",
    "temp_df['macro_mcap_ret_ath_t'] = (temp_df.macro_mcap_t - temp_df.temp_cummax)/temp_df.temp_cummax\n",
    "temp_df['temp_altcoin_cummax'] = temp_df.altcoin_market_cap_cmc.cummax()\n",
    "temp_df['temp_altcoin_cummax_date'] = idxMax(temp_df[['date', 'altcoin_market_cap_cmc']], \n",
    "                                                      'altcoin_market_cap_cmc')\n",
    "temp_df['macro_mcap_altcoin_ret_ath_t'] = (temp_df.macro_mcap_altcoin_t - temp_df.temp_altcoin_cummax)/temp_df.temp_altcoin_cummax\n",
    "temp_df['temp_cyclelow_mcap'] = cycleLowMcap(temp_df[['date', 'total_market_cap_cmc', 'temp_cummax_date']],\n",
    "                                                     'total_market_cap_cmc', 'temp_cummax_date')\n",
    "temp_df['macro_mcap_ret_low_t'] = (temp_df.macro_mcap_t - temp_df.temp_cyclelow_mcap)/temp_df.temp_cyclelow_mcap\n",
    "temp_df['temp_cyclelow_altcoin_mcap'] = cycleLowMcap(temp_df[['date', 'altcoin_market_cap_cmc', \n",
    "                                                              'temp_altcoin_cummax_date']],\n",
    "                                                              'altcoin_market_cap_cmc', 'temp_altcoin_cummax_date')\n",
    "temp_df['macro_mcap_altcoin_ret_low_t'] = (temp_df.macro_mcap_altcoin_t - \n",
    "                                           temp_df.temp_cyclelow_altcoin_mcap)/temp_df.temp_cyclelow_altcoin_mcap\n",
    "temp_df = temp_df.drop(['temp_cummax', 'temp_cummax_date',\n",
    "                        'temp_altcoin_cummax', 'temp_altcoin_cummax_date',\n",
    "                        'temp_cyclelow_mcap', 'temp_cyclelow_altcoin_mcap'], axis=1)\n",
    "temp_df = temp_df.drop(['total_market_cap_cmc', 'altcoin_market_cap_cmc'], axis=1)\n",
    "df = df.drop(['total_market_cap_cmc', 'altcoin_market_cap_cmc'], axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Set up coinmetrics columns\n",
    "df = df.rename(columns = {'btc_fee_mean_usd_cm':  'macro_btc_fee_avg_t',\n",
    "                          'btc_fee_med_usd_cm':   'macro_btc_fee_med_t',\n",
    "                          'btc_fee_total_usd_cm': 'macro_btc_fee_sum_t',\n",
    "                          'eth_fee_mean_usd_cm':  'macro_eth_fee_avg_t',\n",
    "                          'eth_fee_med_usd_cm':   'macro_eth_fee_med_t',\n",
    "                          'eth_fee_total_usd_cm': 'macro_eth_fee_sum_t',\n",
    "                          'grayscale_defi_assets_in_usd_cm': 'macro_grayscale_defi_assets_t',\n",
    "                          'grayscale_eth_assets_in_usd_cm': 'macro_grayscale_eth_assets_t',\n",
    "                          'grayscale_btc_assets_in_usd_cm': 'macro_grayscale_btc_assets_t'})\n",
    "df = df.drop('grayscale_gbtc_assets_in_usd_cm', axis=1)\n",
    "        \n",
    "# Clean cmc macro columns\n",
    "df = df.rename(columns = {'active_cryptocurrencies_cmc': 'macro_active_cryptos_t', \n",
    "                          'active_exchanges_cmc': 'macro_active_ex_t',\n",
    "                          'active_market_pairs_cmc': 'macro_active_ex_pairs_t'})\n",
    "temp_df = df[['date', 'macro_active_cryptos_t',  \n",
    "              'macro_active_ex_t', 'macro_active_ex_pairs_t']]\n",
    "temp_df = temp_df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
    "temp_df['macro_active_cryptos_pct_chng_tm7']   = temp_df['macro_active_cryptos_t'].pct_change(periods=7)\n",
    "temp_df['macro_active_cryptos_pct_chng_tm28']  = temp_df['macro_active_cryptos_t'].pct_change(periods=28)\n",
    "temp_df['macro_active_ex_pct_chng_tm7']        = temp_df['macro_active_ex_t'].pct_change(periods=7)\n",
    "temp_df['macro_active_ex_pct_chng_tm28']       = temp_df['macro_active_ex_t'].pct_change(periods=28)\n",
    "temp_df['macro_active_ex_pairs_pct_chng_tm7']  = temp_df['macro_active_ex_pairs_t'].pct_change(periods=7)\n",
    "temp_df['macro_active_ex_pairs_pct_chng_tm28'] = temp_df['macro_active_ex_pairs_t'].pct_change(periods=28)\n",
    "temp_df = temp_df.drop(['macro_active_cryptos_t', \n",
    "                        'macro_active_ex_t',\n",
    "                        'macro_active_ex_pairs_t'], axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Clean and put on the fed columns\n",
    "fed_cols = list(df.filter(regex='_fed', axis=1).columns.values)\n",
    "temp_df = df[['date']+fed_cols]\n",
    "temp_df = temp_df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
    "for col in fed_cols:\n",
    "    col_name_core = col.lower()\n",
    "    temp_df = temp_df.rename(columns={col: 'macro_'+col_name_core+'_t'})\n",
    "    temp_df['macro_'+col_name_core+'_pct_chng_tm7'] = temp_df['macro_'+col_name_core+'_t'].pct_change(periods=7)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df['macro_'+col_name_core+'_t'].isnull(), 'macro_'+col_name_core+'_pct_chng_tm7'] = 0\n",
    "    temp_df.loc[(temp_df['macro_'+col_name_core+'_t']==0)&(temp_df['macro_'+col_name_core+'_t'].shift(1)==0), 'macro_'+col_name_core+'_pct_chng_tm7'] = 0\n",
    "    temp_df['macro_'+col_name_core+'_pct_chng_tm28'] = temp_df['macro_'+col_name_core+'_t'].pct_change(periods=28)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df['macro_'+col_name_core+'_t'].isnull(), 'macro_'+col_name_core+'_pct_chng_tm28'] = 0\n",
    "    temp_df.loc[(temp_df['macro_'+col_name_core+'_t']==0)&(temp_df['macro_'+col_name_core+'_t'].shift(1)==0), 'macro_'+col_name_core+'_pct_chng_tm28'] = 0\n",
    "df = df.drop(fed_cols, axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Form cmc exchange macro cols\n",
    "ex_cmc_cols = ['exchange_volume_binance_us_cmc', 'exchange_volume_coinbase_cmc',\n",
    "               'exchange_volume_gemini_cmc', 'exchange_volume_kraken_cmc',\n",
    "               'exchange_volume_kucoin_cmc', 'exchange_pairs_binance_us_cmc',\n",
    "               'exchange_pairs_coinbase_cmc', 'exchange_pairs_gemini_cmc',\n",
    "               'exchange_pairs_kraken_cmc', 'exchange_pairs_kucoin_cmc']\n",
    "ex_cmc_col_name_core = ['macro_ex_volume_binanceus', 'macro_ex_volume_coinbase',\n",
    "                        'macro_ex_volume_gemini', 'macro_ex_volume_kraken',\n",
    "                        'macro_ex_volume_kucoin', 'macro_ex_pairs_binance_us',\n",
    "                        'macro_ex_pairs_coinbase', 'macro_ex_pairs_gemini',\n",
    "                        'macro_ex_pairs_kraken', 'macro_ex_pairs_kucoin']\n",
    "temp_df = df[['date']+ex_cmc_cols]\n",
    "temp_df = temp_df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
    "for col, new_col_core in zip(ex_cmc_cols, ex_cmc_col_name_core):\n",
    "    temp_df = temp_df.rename(columns={col: new_col_core+'_t'})\n",
    "    temp_df[new_col_core+'_sum_daily_tm7'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(7).sum())\n",
    "    temp_df[new_col_core+'_avg_daily_tm7'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(7).mean())\n",
    "    temp_df[new_col_core+'_min_daily_tm7'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(7).min())\n",
    "    temp_df[new_col_core+'_max_daily_tm7'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(7).max())\n",
    "    temp_df[new_col_core+'_pct_chng_tm7'] = temp_df[new_col_core+'_t'].pct_change(periods=7)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col_core+'_t'].isnull(), new_col_core+'_pct_chng_tm7'] = 0\n",
    "    temp_df.loc[(temp_df[new_col_core+'_t']==0)&\n",
    "                (temp_df[new_col_core+'_t'].shift(1)==0), new_col_core+'_pct_chng_tm7'] = 0\n",
    "    temp_df[new_col_core+'_sum_daily_tm28'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(28).sum())\n",
    "    temp_df[new_col_core+'_avg_daily_tm28'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(28).mean())\n",
    "    temp_df[new_col_core+'_min_daily_tm28'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(28).min())\n",
    "    temp_df[new_col_core+'_max_daily_tm28'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(28).max())\n",
    "    temp_df[new_col_core+'_pct_chng_tm28'] = temp_df[new_col_core+'_t'].pct_change(periods=28)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col_core+'_t'].isnull(), new_col_core+'_pct_chng_tm28'] = 0\n",
    "    temp_df.loc[(temp_df[new_col_core+'_t']==0)&\n",
    "                (temp_df[new_col_core+'_t'].shift(1)==0), new_col_core+'_pct_chng_tm28'] = 0\n",
    "df = df.drop(ex_cmc_cols, axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Form btc and eth dominance and macro returns\n",
    "temp_df = df[df.asset == 'bitcoin'][['date', 'covar_r_t', 'covar_r_tm28', 'covar_r_daily_t']]\n",
    "temp_df = temp_df.rename(columns={'covar_r_t': 'macro_btc_ret_t',\n",
    "                                  'covar_r_tm28': 'macro_btc_ret_tm28'})\n",
    "temp_df = temp_df[~temp_df.covar_r_daily_t.isnull()]\n",
    "temp_df['macro_btc_ret_avg_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_btc_ret_min_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_btc_ret_max_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_btc_ret_std_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_btc_ret_avg_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_btc_ret_min_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_btc_ret_max_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_btc_ret_std_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df = temp_df[~temp_df.macro_btc_ret_tm28.isnull()]\n",
    "temp_df = temp_df.drop('covar_r_daily_t', axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='left',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "temp_df = df[df.asset == 'ethereum'][['date', 'covar_r_t', 'covar_r_tm28', 'covar_r_daily_t']]\n",
    "temp_df = temp_df.rename(columns={'covar_r_t': 'macro_eth_ret_t',\n",
    "                                  'covar_r_tm28': 'macro_eth_ret_tm28'})\n",
    "temp_df = temp_df[~temp_df.covar_r_daily_t.isnull()]\n",
    "temp_df['macro_eth_ret_avg_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_eth_ret_min_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_eth_ret_max_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_eth_ret_std_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_eth_ret_avg_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_eth_ret_min_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_eth_ret_max_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_eth_ret_std_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df = temp_df[~temp_df.macro_eth_ret_tm28.isnull()]\n",
    "temp_df = temp_df.drop('covar_r_daily_t', axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='left',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "temp_df = df[['date','btc_dominance_cmc']]\n",
    "temp_df = temp_df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
    "temp_df = temp_df.rename(columns={'btc_dominance_cmc': 'macro_btc_dom_t'})\n",
    "temp_df['macro_btc_dom_avg_daily_tm7']  = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_btc_dom_min_daily_tm7']  = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_btc_dom_max_daily_tm7']  = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_btc_dom_std_daily_tm7']  = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(7).std())\n",
    "temp_df['macro_btc_dom_pct_chng_tm7']   = temp_df.macro_btc_dom_t.pct_change(periods=7)\n",
    "temp_df['macro_btc_dom_avg_daily_tm28'] = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_btc_dom_min_daily_tm28'] = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_btc_dom_max_daily_tm28'] = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_btc_dom_std_daily_tm28'] = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(28).std())\n",
    "temp_df['macro_btc_dom_pct_chng_tm28']  = temp_df.macro_btc_dom_t.pct_change(periods=28)\n",
    "df = df.drop('btc_dominance_cmc', axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='left',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "temp_df = df[df.asset == 'ethereum'][['date','covar_mcap_t','macro_mcap_t']]\n",
    "temp_df = temp_df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
    "temp_df['macro_eth_dom_t'] = temp_df.covar_mcap_t / temp_df.macro_mcap_t\n",
    "temp_df = temp_df.drop(['covar_mcap_t', 'macro_mcap_t'], axis=1)\n",
    "temp_df['macro_eth_dom_avg_daily_tm7']  = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_eth_dom_min_daily_tm7']  = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_eth_dom_max_daily_tm7']  = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_eth_dom_std_daily_tm7']  = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(7).std())\n",
    "temp_df['macro_eth_dom_pct_chng_tm7']   = temp_df.macro_eth_dom_t.pct_change(periods=7)\n",
    "temp_df['macro_eth_dom_avg_daily_tm28'] = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_eth_dom_min_daily_tm28'] = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_eth_dom_max_daily_tm28'] = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_eth_dom_std_daily_tm28'] = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(28).std())\n",
    "temp_df['macro_eth_dom_pct_chng_tm28']  = temp_df.macro_eth_dom_t.pct_change(periods=28)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='left',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Form stablecoin metrics\n",
    "temp_df = df[['date','usd_per_usdt_cmc',\n",
    "              'usd_mcap_usdt_cmc', 'usd_volume_24h_usdt_cmc']]\n",
    "temp_df = temp_df[~temp_df.usd_per_usdt_cmc.isnull()]\n",
    "temp_df = temp_df[~temp_df.usd_mcap_usdt_cmc.isnull()]\n",
    "temp_df = temp_df[~temp_df.usd_volume_24h_usdt_cmc.isnull()]\n",
    "temp_df = temp_df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
    "temp_df['macro_usdt_volume_t'] = temp_df.usd_volume_24h_usdt_cmc.values\n",
    "temp_df['macro_usdt_mcap_t'] = temp_df.usd_mcap_usdt_cmc.values\n",
    "temp_df['macro_usdt_sum_daily_dev_from_1_tm7'] = temp_df.usd_per_usdt_cmc.transform(lambda x: np.abs(x-1).rolling(7).sum())\n",
    "temp_df['macro_usdt_std_daily_dev_from_1_tm7'] = temp_df.usd_per_usdt_cmc.transform(lambda x: np.abs(x-1).rolling(7).std())\n",
    "temp_df['macro_usdt_macro_pct_chng_tm7'] = temp_df.macro_usdt_mcap_t.pct_change(periods=7)\n",
    "temp_df['macro_usdt_volume_sum_daily_tm7'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_usdt_volume_avg_daily_tm7'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_usdt_volume_min_daily_tm7'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_usdt_volume_max_daily_tm7'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_usdt_volume_pct_chng_tm7']  = temp_df.macro_usdt_volume_t.pct_change(periods=7)\n",
    "temp_df['macro_usdt_sum_daily_dev_from_1_tm28'] = temp_df.usd_per_usdt_cmc.transform(lambda x: np.abs(x-1).rolling(28).sum())\n",
    "temp_df['macro_usdt_std_daily_dev_from_1_tm28'] = temp_df.usd_per_usdt_cmc.transform(lambda x: np.abs(x-1).rolling(28).std())\n",
    "temp_df['macro_usdt_macro_pct_chng_tm28'] = temp_df.macro_usdt_mcap_t.pct_change(periods=28)\n",
    "temp_df['macro_usdt_volume_sum_daily_tm28'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_usdt_volume_avg_daily_tm28'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_usdt_volume_min_daily_tm28'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_usdt_volume_max_daily_tm28'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_usdt_volume_pct_chng_tm28']  = temp_df.macro_usdt_volume_t.pct_change(periods=28)\n",
    "temp_df = temp_df.drop(['usd_per_usdt_cmc', 'usd_mcap_usdt_cmc', \n",
    "                        'usd_volume_24h_usdt_cmc'], axis=1)\n",
    "df = df.drop(['usd_per_usdt_cmc', 'usd_mcap_usdt_cmc', 'usd_volume_24h_usdt_cmc'], axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='left',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Ensure san macro cols are clean and rename them\n",
    "san_macro_cols =  ['token_mcap_avg_stock_to_flow_san',\n",
    "                   'token_mcap_avg_mvrv_usd_intraday_san',\n",
    "                   'token_mcap_avg_mcd_collat_ratio_san',\n",
    "                   'token_sum_cexes_to_dex_flow_san',\n",
    "                   'token_sum_exchanges_to_defi_flow_san',\n",
    "                   'token_sum_whale_to_defi_flow_san',\n",
    "                   'token_sum_dex_traders_to_defi_flow_san',\n",
    "                   'token_sum_whale_defi_balance_san',\n",
    "                   'token_sum_traders_to_defi_flow_san',\n",
    "                   'token_sum_traders_defi_balance_san',\n",
    "                   'ethereum_defi_total_value_locked_usd_san',\n",
    "                   'ethereum_nft_trade_volume_usd_san',\n",
    "                   'ethereum_nft_trades_count_san',\n",
    "                   'ethereum_nft_retail_trade_volume_usd_san',\n",
    "                   'ethereum_nft_whale_trade_volume_usd_san',\n",
    "                   'ethereum_nft_whale_trades_count_san',\n",
    "                   'ethereum_percent_of_whale_stablecoin_total_supply_san',\n",
    "                   'bitcoin_miners_to_exchanges_flow_san',\n",
    "                   'ethereum_miners_to_exchanges_flow_san',\n",
    "                   'ethereum_miners_exchange_balance_san',\n",
    "                   'ethereum_traders_to_defi_flow_san',\n",
    "                   'ethereum_traders_defi_balance_san',\n",
    "                   'ethereum_mvrv_usd_intraday_san',\n",
    "                   'ethereum_stock_to_flow_san']\n",
    "new_san_macro_col_names = ['macro_stock_to_flow',\n",
    "                           'macro_mvrv',\n",
    "                           'macro_mcd_collat_ratio',\n",
    "                           'macro_cex_to_dex_flow',\n",
    "                           'macro_ex_to_defi_flow',\n",
    "                           'macro_whale_to_defi_flow',\n",
    "                           'macro_dex_to_defi_flow',\n",
    "                           'macro_whale_defi_balance',\n",
    "                           'macro_traders_to_defi_flow',\n",
    "                           'macro_trades_defi_balance',\n",
    "                           'macro_eth_defi_tvl',\n",
    "                           'macro_nft_trade_volume',\n",
    "                           'macro_nft_trade_count',\n",
    "                           'macro_nft_retail_trade_volume',\n",
    "                           'macro_nft_whale_trade_volume',\n",
    "                           'macro_nft_whale_trade_count',\n",
    "                           'macro_eth_prct_whale_stblcoin_total_supply',\n",
    "                           'macro_btc_miner_to_ex_flow',\n",
    "                           'macro_eth_miner_to_ex_flow',\n",
    "                           'macro_eth_miner_ex_balance',\n",
    "                           'macro_eth_trader_to_defi_flow',\n",
    "                           'macro_eth_trader_defi_balance',\n",
    "                           'macro_eth_mvrv',\n",
    "                           'macro_eth_stock_to_flow']\n",
    "temp_df = df[['date']+san_macro_cols]\n",
    "temp_df = temp_df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
    "for col, new_col_name_core in zip(san_macro_cols, new_san_macro_col_names):\n",
    "    temp_df = temp_df.rename(columns={col: new_col_name_core+'_t'})\n",
    "    temp_df[new_col_name_core+'_avg_daily_tm7'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(7).mean())\n",
    "    temp_df[new_col_name_core+'_std_daily_tm7'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(7).std())\n",
    "    temp_df[new_col_name_core+'_min_daily_tm7'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(7).min())\n",
    "    temp_df[new_col_name_core+'_max_daily_tm7'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(7).max())\n",
    "    temp_df[new_col_name_core+'_pct_chng_tm7']  = temp_df[new_col_name_core+'_t'].pct_change(periods=7)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col_name_core+'_t'].isnull(), new_col_name_core+'_pct_chng_tm7'] = 0\n",
    "    temp_df.loc[(temp_df[new_col_name_core+'_t']==0)&\n",
    "                (temp_df[new_col_name_core+'_t'].shift(1)==0), new_col_name_core+'_pct_chng_tm7'] = 0\n",
    "    temp_df[new_col_name_core+'_avg_daily_tm28'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(28).mean())\n",
    "    temp_df[new_col_name_core+'_std_daily_tm28'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(28).std())\n",
    "    temp_df[new_col_name_core+'_min_daily_tm28'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(28).min())\n",
    "    temp_df[new_col_name_core+'_max_daily_tm28'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(28).max())\n",
    "    temp_df[new_col_name_core+'_pct_chng_tm28']  = temp_df[new_col_name_core+'_t'].pct_change(periods=28)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col_name_core+'_t'].isnull(), new_col_name_core+'_pct_chng_tm28'] = 0\n",
    "    temp_df.loc[(temp_df[new_col_name_core+'_t']==0)&\n",
    "                (temp_df[new_col_name_core+'_t'].shift(1)==0), new_col_name_core+'_pct_chng_tm28'] = 0\n",
    "df = df.drop(san_macro_cols, axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Combine SAN dev variables into a macro variable\n",
    "temp_df = df[['date', 'dev_activity_contributors_count_san',\n",
    "              'github_activity_san', 'github_activity_contributors_count_san',\n",
    "              'dev_activ_san']]\n",
    "temp_df = temp_df.groupby('date').sum()\n",
    "temp_df = pd.DataFrame(temp_df.sum(axis=1))\n",
    "temp_df = temp_df.rename(columns={0:'macro_dev_activ_t'})\n",
    "assert(0==temp_df[temp_df.macro_dev_activ_t.isnull()].shape[0])\n",
    "temp_df = temp_df.reset_index()\n",
    "temp_df['macro_dev_activ_avg_daily_tm7']  = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_dev_activ_std_daily_tm7']  = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(7).std())\n",
    "temp_df['macro_dev_activ_min_daily_tm7']  = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_dev_activ_max_daily_tm7']  = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_dev_activ_pct_chng_tm7']   = temp_df.macro_dev_activ_t.pct_change(periods=7)\n",
    "temp_df['macro_dev_activ_avg_daily_tm28'] = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_dev_activ_std_daily_tm28'] = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(28).std())\n",
    "temp_df['macro_dev_activ_min_daily_tm28'] = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_dev_activ_max_daily_tm28'] = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_dev_activ_pct_chng_tm28']  = temp_df.macro_dev_activ_t.pct_change(periods=28)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Create macro var out of san supply on/off exchanges\n",
    "temp_df = df[['date', 'supply_on_exchanges_san',\n",
    "              'supply_outside_exchanges_san']]\n",
    "temp_df = temp_df.groupby('date').sum()\n",
    "temp_df = temp_df.reset_index()\n",
    "for col, new_col in zip(['supply_on_exchanges_san', 'supply_outside_exchanges_san'],\n",
    "                        ['macro_supply_on_ex', 'macro_supply_off_ex']):\n",
    "    temp_df = temp_df.rename(columns={col:new_col+'_t'})\n",
    "    temp_df[new_col+'_avg_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).mean())\n",
    "    temp_df[new_col+'_std_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).std())\n",
    "    temp_df[new_col+'_min_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).min())\n",
    "    temp_df[new_col+'_max_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).max())\n",
    "    temp_df[new_col+'_pct_chng_tm7']  = temp_df[new_col+'_t'].pct_change(periods=7)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col+'_t'].isnull(), new_col+'_pct_chng_tm7'] = 0\n",
    "    temp_df.loc[(temp_df[new_col+'_t']==0)&\n",
    "                (temp_df[new_col+'_t'].shift(1)==0), new_col+'_pct_chng_tm7'] = 0\n",
    "    temp_df[new_col+'_avg_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).mean())\n",
    "    temp_df[new_col+'_std_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).std())\n",
    "    temp_df[new_col+'_min_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).min())\n",
    "    temp_df[new_col+'_max_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).max())\n",
    "    temp_df[new_col+'_pct_chng_tm28'] = temp_df[new_col+'_t'].pct_change(periods=28)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col+'_t'].isnull(), new_col+'_pct_chng_tm28'] = 0\n",
    "    temp_df.loc[(temp_df[new_col+'_t']==0)&\n",
    "                (temp_df[new_col+'_t'].shift(1)==0), new_col+'_pct_chng_tm28'] = 0\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "san_sent_cols = ['sentiment_balance_total_san',\n",
    "                 'sentiment_negative_total_san',\n",
    "                 'sentiment_positive_total_san',\n",
    "                 'social_volume_total_san']\n",
    "temp_df = df[['date', 'asset']+san_sent_cols]\n",
    "for col in san_sent_cols:\n",
    "    temp_df[col] = temp_df.groupby('asset')[col].transform(lambda x: x/np.max(x))\n",
    "temp_df = temp_df.drop('asset', axis=1)\n",
    "temp_df = temp_df.groupby('date').sum()\n",
    "temp_df = temp_df.reset_index()\n",
    "new_san_cols = ['macro_san_sent_bal', 'macro_san_sent_neg',\n",
    "                'macro_san_sent_pos', 'macro_san_social_volume']\n",
    "for col, new_col in zip(san_sent_cols, new_san_cols):\n",
    "    temp_df = temp_df.rename(columns={col:new_col+'_t'})\n",
    "    temp_df[new_col+'_avg_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).mean())\n",
    "    temp_df[new_col+'_std_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).std())\n",
    "    temp_df[new_col+'_min_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).min())\n",
    "    temp_df[new_col+'_max_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).max())\n",
    "    temp_df[new_col+'_pct_chng_tm7']  = temp_df[new_col+'_t'].pct_change(periods=7)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col+'_t'].isnull(), new_col+'_pct_chng_tm7'] = 0\n",
    "    temp_df.loc[(temp_df[new_col+'_t']==0)&\n",
    "                (temp_df[new_col+'_t'].shift(1)==0), new_col+'_pct_chng_tm7'] = 0\n",
    "    temp_df[new_col+'_avg_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).mean())\n",
    "    temp_df[new_col+'_std_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).std())\n",
    "    temp_df[new_col+'_min_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).min())\n",
    "    temp_df[new_col+'_max_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).max())\n",
    "    temp_df[new_col+'_pct_chng_tm28'] = temp_df[new_col+'_t'].pct_change(periods=28)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col+'_t'].isnull(), new_col+'_pct_chng_tm28'] = 0\n",
    "    temp_df.loc[(temp_df[new_col+'_t']==0)&\n",
    "                (temp_df[new_col+'_t'].shift(1)==0), new_col+'_pct_chng_tm28'] = 0\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Drop macro columns with any missing in 2016 and onward\n",
    "macro_cols = list(df.filter(regex='macro', axis=1).columns.values)\n",
    "missing_df = df[df.date.dt.year >= 2016][macro_cols].isnull().sum()\n",
    "missing_df = missing_df[missing_df > 0]\n",
    "df = df.drop(list(missing_df.index.values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN STRICTLY CROSS SECTIONALLY VARYING VARIABLES\n",
    "\n",
    "cs_vars = ['consensus_pow',\n",
    "           'sector_dex',\n",
    "           'sector_cex',\n",
    "           'sector_smart_contracts',\n",
    "           'sector_currency',\n",
    "           'sector_defi',\n",
    "           'sector_data',\n",
    "           'sector_games',\n",
    "           'sector_stablecoin',\n",
    "           'sector_compute',\n",
    "           'sector_metaverse',\n",
    "           'sector_privacy',\n",
    "           'sector_infra',\n",
    "           'sector_nft',\n",
    "           'ecosystem_avalanche',\n",
    "           'ecosystem_binance',\n",
    "           'ecosystem_cosmos',\n",
    "           'ecosystem_eth',\n",
    "           'ecosystem_polkadot',\n",
    "           'ecosystem_polygon',\n",
    "           'ecosystem_solana',\n",
    "           'mineable_cmc',\n",
    "           'pos_cmc',\n",
    "           'platform_cmc']\n",
    "cs_vars += list(df.filter(regex='_messari', axis=1).columns.values)\n",
    "\n",
    "# Fix vars to be purely CS varying\n",
    "for col in cs_vars:\n",
    "    assert(df.shape[0]==df[col].isin([0,1]).shape[0])\n",
    "    df[col] = df.groupby('asset')[col].transform(lambda x: x.max())\n",
    "    assets  = np.unique(df.asset.values)\n",
    "    for asset in assets:\n",
    "        asset_values = df[df.asset == asset][col].values\n",
    "        assert(np.all(asset_values == asset_values[0]))\n",
    "\n",
    "# Rename and confirm not missing\n",
    "for col in cs_vars:\n",
    "    new_col = col.replace('_cmc', '')\n",
    "    new_col = new_col.replace('_messari', '')\n",
    "    new_col = 'cs_'+new_col+'_t'\n",
    "    df = df.rename(columns={col: new_col})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO SAVE THE DATA FRAME FOR DESC STAT AND UNI FACTOR WORK AT DAILY FREQ WHERE WE CUT DOWN TO JUST WHEN ASSET IS TRADABLE FOR EACH MONTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO DO THE NORMALIZATION OF RHS AND THEN SAVE THE PANEL FOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANK NORMALIZE THE COVAR VARS TO REPLACE WITH LIN SPACED -1 TO 1\n",
    "# NOTE: This cell takes ~15 minutes.\n",
    "def normalizeVector(x):\n",
    "    '''\n",
    "    Accepts a numpy array\n",
    "    Returns a numpy array of same length with values \n",
    "        from -1 and 1, inclusive, linearly spaced.\n",
    "    '''\n",
    "    return np.linspace(-1, 1, num=x.shape[0])\n",
    "\n",
    "for col in covar_cols:\n",
    "    df = df.sort_values(by=['date', col])\n",
    "    df['temp_col'] = df[~df[col].isnull()].groupby(['date'])[col].transform(normalizeVector)\n",
    "    df.loc[df[col].isnull(), 'temp_col'] = np.nan\n",
    "    assert(df[col].isnull().sum()==df['temp_col'].isnull().sum())\n",
    "    df = df.drop(col, axis=1)\n",
    "    df = df.rename(columns={'temp_col':col})\n",
    "    assert(-1 <= np.min(df[col]))\n",
    "    assert(1 >= np.max(df[col]))\n",
    "\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP MACRO COLS TO -1 TO 1, LOOPING OVER THE WEEKS TO RESPECT TEMPORAL DEPENDENCE\n",
    "# NOTE: this cell takes about 30 minutes\n",
    "max_week_idx = np.max(df.week_idx)\n",
    "for col in macro_cols:\n",
    "    temp_df = df[['week_idx', col]].drop_duplicates(subset='week_idx').reset_index(drop=True)\n",
    "    assert(0==temp_df[col].isnull().sum())\n",
    "    temp_df.loc[temp_df.week_idx==1, 'temp_col'] = 0\n",
    "\n",
    "    for idx in range(2,int(max_week_idx)+1):   \n",
    "        col_values = temp_df[temp_df.week_idx <= idx][col].values\n",
    "        idx_value  = temp_df[temp_df.week_idx == idx][col].values\n",
    "        assert(len(idx_value)==1)\n",
    "        idx_value  = idx_value[0]\n",
    "        sorted_col_values = np.sort(col_values)\n",
    "        rank = np.where(sorted_col_values == idx_value)[0][0]\n",
    "        normed_values = normalizeVector(sorted_col_values)\n",
    "        normed_value = normed_values[rank]\n",
    "        temp_df.loc[temp_df.week_idx == idx, 'temp_col'] = normed_value\n",
    "\n",
    "    temp_df = temp_df.drop(col, axis=1)\n",
    "    temp_df = temp_df.rename(columns={'temp_col': col})\n",
    "    df = df.drop(col, axis=1)\n",
    "    nrows_b4 = df.shape[0]\n",
    "    df = df.merge(temp_df,\n",
    "                  on='week_idx',\n",
    "                  how='inner',\n",
    "                  validate='many_to_one')\n",
    "    assert(df.shape[0]==nrows_b4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL CLEAN\n",
    "\n",
    "# Ensure columns have the appropriate range\n",
    "assert(1==np.nanmax(df.drop(['r_tplus7','asset','week_idx','date'],axis=1).values))\n",
    "assert(-1==np.nanmin(df.drop(['r_tplus7','asset','week_idx','date'],axis=1).values))\n",
    "\n",
    "# Resort columns\n",
    "cols = list(df.columns.values)\n",
    "first_cols = ['date', 'week_idx', 'asset', 'r_tplus7']\n",
    "for col in first_cols:\n",
    "    cols.remove(col)\n",
    "cols.sort()\n",
    "df = df[first_cols + cols]\n",
    "\n",
    "# Resort and reindex\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO WHEN DONE, LOOK AT look at DIST OF ALL COLUMNS TO ENSURE LOOKS RIGHT\n",
    "# -OVERALL, OVER TIME, BY ASSET, AND OVER TIME ASSET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO SAVE THE CLEAN HOURLY AND DAILY PANELS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
