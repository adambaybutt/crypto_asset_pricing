{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO LAY OUT STRUCTURE FOR THIS NOTEBOOK\n",
    "\n",
    "# -feat eng macro\n",
    "# -cut down to study period\n",
    "# -form daily panel for desc stat and low-dim factor models\n",
    "# -form hourly panel for high-dim factor models\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def formLiteratureFactors() -> pd.DataFrame:\n",
    "\n",
    "# acccount for fact that assets leave the panel and return\n",
    "# Form factors used in lit\n",
    "# Create both for 24h and 1h freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def formRemainingCharacteristics() -> pd.DataFrame:\n",
    "\n",
    "# pass in just the panel and not the macro data to make it more simple\n",
    "# acccount for fact that assets leave the panel and return\n",
    "# Create both for 24h and 1h freq\n",
    "# Form factors from my characteristics to summarize the really redudanant ones\n",
    "# Look for highly correlated charactersitics to consider condensing down further\n",
    "\n",
    "# confirm all characteristics have been processed\n",
    "# scope distribution of eahc column to confirm they look OK\n",
    "# -OVERALL, OVER TIME, BY ASSET, AND OVER TIME ASSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def formMacroCovariates() -> pd.DataFrame:\n",
    "\n",
    "# -split out the macro variables to merge back on so i work at timeseries level and not panel?\n",
    "# -so passs in just like the macro_df\n",
    "# -Drop really useless macro covariates for which i have something with reasoanble corr to it\n",
    "# -CREATE BOTH FOR HOUR OVER HOUR AND DAY OVER DAY\n",
    "# -form snp momentum\n",
    "# -form snp volatility\n",
    "# -form squared market return\n",
    "# -Summarize macro columns as there are just too damn many; use Goyal 8 as guide\n",
    "\n",
    "# look at dist of columns to make sure looks right\n",
    "# -OVERALL, OVER TIME, BY ASSET, AND OVER TIME ASSET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def finalClean()\n",
    "\n",
    "# merge panel and macro back together\n",
    "# cut down to study period\n",
    "# ensure all dates are present\n",
    "# report out assets that don't ahve consecutive days to eyeball when they enter and leave\n",
    "# ensure no missing\n",
    "# ensure all cols have appropriate range\n",
    "# ensure rows and cols sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def formDailyPanel():\n",
    "\n",
    "# cut down to daily level\n",
    "# drop columns that are really about hourly stuff\n",
    "# send it back and save in main\n",
    "# save the daily panel\n",
    "\n",
    "# TODO NOTE THIS IN APPROPRIATE NOTEBOOKS:\n",
    "# -when he imports for uni factor: cut down to asset univser, drop macro, and drop global_price\n",
    "# -when for low-dim: drop global_price, normalize characteristics, just drop macro, or drop all for just returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def formHourlyPanel():\n",
    "\n",
    "# DROP COLS\n",
    "# drop global_price\n",
    "# drop teh cols really about daily stuff or maybe keep?\n",
    "\n",
    "# NORMALIZE COLS\n",
    "# do transformations of characteirstics to cross sectional -1 to 1\n",
    "# for macro, do transformation to make it stationary and take whatever form of it gives stationary\n",
    "# -follow Pelger on this for the options and then come up with metric for most stationary and above some threshold\n",
    "# -do it programatically\n",
    "# to normalize macro, shift to -1 to 1 from end of validation and back; then for all test do it recursively for each new ob\n",
    "# -make sure this doesn't break correlation that much\n",
    "\n",
    "# ensure no missing\n",
    "# ensure all columns are -1 to 1?\n",
    "# ensure rows and cols are sorted\n",
    "# ensure i have all dates\n",
    "# send it back and save in main\n",
    "# save the hourly panel\n",
    "\n",
    "# save train_val_df and test_df separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO CAN USE THIS FOR SCOPING UNIVARIATE CORR\n",
    "# ADD TO IT TO LOOK AT MUTUAL INFO\n",
    "# ADD TO IT TO LOOK AT CORR TO BOTH FREQ OF RETURNS\n",
    "\n",
    "series2 = df.price_usd[1:].values\n",
    "for col in df.columns.values[1:-2]:\n",
    "    series1 = df[col][:-1].values\n",
    "\n",
    "    # Find indices where both series have non-missing values\n",
    "    non_missing_indices = np.logical_not(np.isnan(series1) | np.isnan(series2))\n",
    "\n",
    "    # Compute the correlation using non-missing values only\n",
    "    corr_matrix = np.corrcoef(series1[non_missing_indices], series2[non_missing_indices])\n",
    "\n",
    "    # Extract the correlation coefficient (off-diagonal element)\n",
    "    corr_coef = corr_matrix[0, 1]\n",
    "    print(col)\n",
    "    print(f\"Correlation coefficient: {corr_coef}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD NOTES ON HOW I MADE COLUMNS AND WHAT COLUMNS TO MAKE\n",
    "\n",
    "# Ensure it is sorted\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Form RHS return variables\n",
    "assert(0==df[df.usd_per_token == 0].shape[0])\n",
    "df['covar_r_t']               = df.groupby('asset')['usd_per_token'].pct_change(periods=7)\n",
    "df['covar_r_tm14']            = df.groupby('asset')['usd_per_token'].pct_change(periods=14)\n",
    "df['covar_r_tm21']            = df.groupby('asset')['usd_per_token'].pct_change(periods=21)\n",
    "df['covar_r_tm28']            = df.groupby('asset')['usd_per_token'].pct_change(periods=28)\n",
    "df['covar_r_daily_t']         = df.groupby('asset')['usd_per_token'].pct_change(periods=1)\n",
    "df['covar_r_daily_avg_tm7']   = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(7).mean())\n",
    "df['covar_vol_r_daily_tm7']   = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(7).std())\n",
    "df['covar_vol_r_daily_tm14']  = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(14).std())\n",
    "df['covar_vol_r_daily_tm21']  = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(21).std())\n",
    "df['covar_vol_r_daily_tm28']  = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(28).std())\n",
    "df['covar_skew_r_daily_tm7']  = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(7).skew())\n",
    "df['covar_skew_r_daily_tm14'] = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(14).skew())\n",
    "df['covar_skew_r_daily_tm21'] = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(21).skew())\n",
    "df['covar_skew_r_daily_tm28'] = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(28).skew())\n",
    "df['covar_kurt_r_daily_tm7']  = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(7).kurt())\n",
    "df['covar_kurt_r_daily_tm14'] = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(14).kurt())\n",
    "df['covar_kurt_r_daily_tm21'] = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(21).kurt())\n",
    "df['covar_kurt_r_daily_tm28'] = df.groupby('asset')['covar_r_daily_t'].transform(lambda x: x.rolling(28).kurt())\n",
    "\n",
    "# FORM AGE VARIABLE\n",
    "\n",
    "df['covar_age_t'] = (pd.to_datetime(df.date) - pd.to_datetime(df.first_date_cmc)).astype('timedelta64[D]')\n",
    "assert(0 <= np.min(df.covar_age_t))\n",
    "df = df.drop('first_date_cmc', axis=1)\n",
    "\n",
    "# FORM PRICE VARIABLES\n",
    "\n",
    "# Sunday price and log price\n",
    "df['covar_p_t']     = df.usd_per_token.values\n",
    "df['covar_p_log_t'] = np.log(df.usd_per_token.values)\n",
    "\n",
    "# Avg, min, & max price and log price in last week and last 28 days\n",
    "df['covar_p_avg_daily_tm7']      = df.groupby('asset')['usd_per_token'].transform(lambda x: x.rolling(7).mean())\n",
    "df['covar_p_min_daily_tm7']      = df.groupby('asset')['usd_per_token'].transform(lambda x: x.rolling(7).min())\n",
    "df['covar_p_max_daily_tm7']      = df.groupby('asset')['usd_per_token'].transform(lambda x: x.rolling(7).max())\n",
    "df['covar_p_log_avg_daily_tm7']  = df.groupby('asset')['usd_per_token'].transform(lambda x: np.log(x).rolling(7).mean())\n",
    "df['covar_p_log_min_daily_tm7']  = df.groupby('asset')['usd_per_token'].transform(lambda x: np.log(x).rolling(7).min())\n",
    "df['covar_p_log_max_daily_tm7']  = df.groupby('asset')['usd_per_token'].transform(lambda x: np.log(x).rolling(7).max())\n",
    "df['covar_p_avg_daily_tm28']     = df.groupby('asset')['usd_per_token'].transform(lambda x: x.rolling(28).mean())\n",
    "df['covar_p_min_daily_tm28']     = df.groupby('asset')['usd_per_token'].transform(lambda x: x.rolling(28).min())\n",
    "df['covar_p_max_daily_tm28']     = df.groupby('asset')['usd_per_token'].transform(lambda x: x.rolling(28).max())\n",
    "df['covar_p_log_avg_daily_tm28'] = df.groupby('asset')['usd_per_token'].transform(lambda x: np.log(x).rolling(28).mean())\n",
    "df['covar_p_log_min_daily_tm28'] = df.groupby('asset')['usd_per_token'].transform(lambda x: np.log(x).rolling(28).min())\n",
    "df['covar_p_log_max_daily_tm28'] = df.groupby('asset')['usd_per_token'].transform(lambda x: np.log(x).rolling(28).max())\n",
    "\n",
    "# FORM MCAP VARIABLES\n",
    "\n",
    "# Sunday mcap and log mcap\n",
    "df['covar_mcap_t']     = df.usd_mcap.values\n",
    "df['covar_mcap_log_t'] = np.log(df.usd_mcap.values)\n",
    "\n",
    "# Avg, min, & max mcap and log mcap in last week and last 28 days\n",
    "df['covar_mcap_avg_daily_tm7']      = df.groupby('asset')['usd_mcap'].transform(lambda x: x.rolling(7).mean())\n",
    "df['covar_mcap_min_daily_tm7']      = df.groupby('asset')['usd_mcap'].transform(lambda x: x.rolling(7).min())\n",
    "df['covar_mcap_max_daily_tm7']      = df.groupby('asset')['usd_mcap'].transform(lambda x: x.rolling(7).max())\n",
    "df['covar_mcap_log_avg_daily_tm7']  = df.groupby('asset')['usd_mcap'].transform(lambda x: np.log(x).rolling(7).mean())\n",
    "df['covar_mcap_log_min_daily_tm7']  = df.groupby('asset')['usd_mcap'].transform(lambda x: np.log(x).rolling(7).min())\n",
    "df['covar_mcap_log_max_daily_tm7']  = df.groupby('asset')['usd_mcap'].transform(lambda x: np.log(x).rolling(7).max())\n",
    "df['covar_mcap_avg_daily_tm28']     = df.groupby('asset')['usd_mcap'].transform(lambda x: x.rolling(28).mean())\n",
    "df['covar_mcap_min_daily_tm28']     = df.groupby('asset')['usd_mcap'].transform(lambda x: x.rolling(28).min())\n",
    "df['covar_mcap_max_daily_tm28']     = df.groupby('asset')['usd_mcap'].transform(lambda x: x.rolling(28).max())\n",
    "df['covar_mcap_log_avg_daily_tm28'] = df.groupby('asset')['usd_mcap'].transform(lambda x: np.log(x).rolling(28).mean())\n",
    "df['covar_mcap_log_min_daily_tm28'] = df.groupby('asset')['usd_mcap'].transform(lambda x: np.log(x).rolling(28).min())\n",
    "df['covar_mcap_log_max_daily_tm28'] = df.groupby('asset')['usd_mcap'].transform(lambda x: np.log(x).rolling(28).max())\n",
    "\n",
    "# FORM VOLUME VARIABLES\n",
    "\n",
    "# Sunday volume and log volume\n",
    "df['covar_volume_t']     = df.usd_trading_volume_24h.values\n",
    "df['covar_volume_log_t'] = np.log(df.usd_trading_volume_24h.values)\n",
    "\n",
    "# Total, avg, median, min, & max volume and log volume over last week and last 28 days\n",
    "df['covar_volume_sum_daily_tm7']      = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(7).sum())\n",
    "df['covar_volume_avg_daily_tm7']      = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(7).mean())\n",
    "df['covar_volume_med_daily_tm7']      = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(7).median())\n",
    "df['covar_volume_min_daily_tm7']      = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(7).min())\n",
    "df['covar_volume_max_daily_tm7']      = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(7).max())\n",
    "df['covar_volume_log_sum_daily_tm7']  = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(7).sum())\n",
    "df['covar_volume_log_avg_daily_tm7']  = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(7).mean())\n",
    "df['covar_volume_log_med_daily_tm7']  = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(7).median())\n",
    "df['covar_volume_log_min_daily_tm7']  = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(7).min())\n",
    "df['covar_volume_log_max_daily_tm7']  = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(7).max())\n",
    "df['covar_volume_sum_daily_tm28']     = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(28).sum())\n",
    "df['covar_volume_avg_daily_tm28']     = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(28).mean())\n",
    "df['covar_volume_med_daily_tm28']     = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(28).median())\n",
    "df['covar_volume_min_daily_tm28']     = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(28).min())\n",
    "df['covar_volume_max_daily_tm28']     = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: x.rolling(28).max())\n",
    "df['covar_volume_log_sum_daily_tm28'] = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(28).sum())\n",
    "df['covar_volume_log_avg_daily_tm28'] = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(28).mean())\n",
    "df['covar_volume_log_med_daily_tm28'] = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(28).median())\n",
    "df['covar_volume_log_min_daily_tm28'] = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(28).min())\n",
    "df['covar_volume_log_max_daily_tm28'] = df.groupby('asset')['usd_trading_volume_24h'].transform(lambda x: np.log(x).rolling(28).max())\n",
    "# FORM PRICE VOLUME VARIABLES\n",
    "\n",
    "# Sunday price times volume and log of it\n",
    "df['covar_p_volume_t']     = df.covar_p_t * df.covar_volume_t\n",
    "df['covar_p_volume_log_t'] = df.covar_p_log_t * df.covar_volume_log_t\n",
    "\n",
    "# Log average daily volumes times avg price over past week and 28 days. Std too\n",
    "df['covar_p_volume_log_avg_daily_tm7']  = np.log(df.covar_volume_avg_daily_tm7 * df.covar_p_avg_daily_tm7)\n",
    "df['covar_p_volume_log_avg_daily_tm28'] = np.log(df.covar_volume_avg_daily_tm28 * df.covar_p_avg_daily_tm28)\n",
    "df['covar_p_volume_log_std_daily_tm7']  = np.log(df.groupby('asset')['covar_p_volume_t'].transform(lambda x: x.rolling(7).std()))\n",
    "df['covar_p_volume_log_std_daily_tm28'] = np.log(df.groupby('asset')['covar_p_volume_t'].transform(lambda x: x.rolling(28).std()))\n",
    "\n",
    "# DROP PRICE, MCAP, VOLUME VARS\n",
    "\n",
    "df = df.drop(['usd_per_token', 'usd_mcap', 'usd_trading_volume_24h'], axis=1)\n",
    "\n",
    "# Ensure it is sorted and reset index\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOME NOTES ON OLD MACRO COLS THAT I MADE\n",
    "\n",
    "# Confirm some columns are not missing for to be made pct change columns\n",
    "assert(0==df[df['active_cryptocurrencies_cmc'].isnull()].shape[0])\n",
    "assert(0==df[df['active_exchanges_cmc'].isnull()].shape[0])\n",
    "assert(0==df[df['active_market_pairs_cmc'].isnull()].shape[0])\n",
    "assert(0==df[df['btc_dominance_cmc'].isnull()].shape[0])\n",
    "assert(0==df[(df.asset == 'ethereum') & df.covar_mcap_t.isnull()].shape[0])\n",
    "\n",
    "# Trading volume variables\n",
    "df['macro_volume_t']             = df.total_volume_24h_cmc.values\n",
    "df['macro_volume_altcoin_t']     = df.altcoin_volume_24h_cmc.values\n",
    "df['macro_volume_log_t']         = np.log(df.total_volume_24h_cmc.values)\n",
    "df['macro_volume_altcoin_log_t'] = np.log(df.altcoin_volume_24h_cmc.values)\n",
    "df['macro_volume_reported_t']             = df.total_volume_24h_reported_cmc.values\n",
    "df['macro_volume_altcoin_reported_t']     = df.altcoin_volume_24h_reported_cmc.values\n",
    "df['macro_volume_reported_log_t']         = np.log(df.total_volume_24h_reported_cmc.values)\n",
    "df['macro_volume_altcoin_reported_log_t'] = np.log(df.altcoin_volume_24h_reported_cmc.values)\n",
    "temp_df = df[df.asset == 'bitcoin'][['date', 'total_volume_24h_cmc', 'altcoin_volume_24h_cmc',\n",
    "                                     'total_volume_24h_reported_cmc', 'altcoin_volume_24h_reported_cmc',\n",
    "                                     'covar_volume_t', 'covar_volume_log_t']]\n",
    "temp_df = temp_df.rename(columns={'covar_volume_t': 'macro_volume_btc_t',\n",
    "                                  'covar_volume_log_t': 'macro_volume_btc_log_t'})\n",
    "temp_df['macro_volume_sum_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_volume_avg_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_volume_min_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_volume_max_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_volume_reported_sum_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_volume_reported_avg_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_volume_reported_min_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_volume_reported_max_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_volume_log_sum_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).sum())\n",
    "temp_df['macro_volume_log_avg_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).mean())\n",
    "temp_df['macro_volume_log_min_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).min())\n",
    "temp_df['macro_volume_log_max_daily_tm7'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).max())\n",
    "temp_df['macro_volume_log_reported_sum_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).sum())\n",
    "temp_df['macro_volume_log_reported_avg_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).mean())\n",
    "temp_df['macro_volume_log_reported_min_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).min())\n",
    "temp_df['macro_volume_log_reported_max_daily_tm7'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).max())\n",
    "temp_df['macro_volume_sum_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_volume_avg_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_volume_min_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_volume_max_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_volume_reported_sum_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_volume_reported_avg_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_volume_reported_min_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_volume_reported_max_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_volume_log_sum_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).sum())\n",
    "temp_df['macro_volume_log_avg_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).mean())\n",
    "temp_df['macro_volume_log_min_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).min())\n",
    "temp_df['macro_volume_log_max_daily_tm28'] = temp_df.total_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).max())\n",
    "temp_df['macro_volume_log_reported_sum_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).sum())\n",
    "temp_df['macro_volume_log_reported_avg_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).mean())\n",
    "temp_df['macro_volume_log_reported_min_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).min())\n",
    "temp_df['macro_volume_log_reported_max_daily_tm28'] = temp_df.total_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).max())\n",
    "temp_df['macro_volume_altcoin_sum_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_volume_altcoin_avg_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_volume_altcoin_min_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_volume_altcoin_max_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_volume_altcoin_reported_sum_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_volume_altcoin_reported_avg_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_volume_altcoin_reported_min_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_volume_altcoin_reported_max_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_volume_altcoin_log_sum_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).sum())\n",
    "temp_df['macro_volume_altcoin_log_avg_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).mean())\n",
    "temp_df['macro_volume_altcoin_log_min_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).min())\n",
    "temp_df['macro_volume_altcoin_log_max_daily_tm7'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(7).max())\n",
    "temp_df['macro_volume_altcoin_log_reported_sum_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).sum())\n",
    "temp_df['macro_volume_altcoin_log_reported_avg_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).mean())\n",
    "temp_df['macro_volume_altcoin_log_reported_min_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).min())\n",
    "temp_df['macro_volume_altcoin_log_reported_max_daily_tm7'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(7).max())\n",
    "temp_df['macro_volume_altcoin_sum_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_volume_altcoin_avg_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_volume_altcoin_min_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_volume_altcoin_max_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_volume_altcoin_reported_sum_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_volume_altcoin_reported_avg_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_volume_altcoin_reported_min_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_volume_altcoin_reported_max_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_volume_altcoin_log_sum_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).sum())\n",
    "temp_df['macro_volume_altcoin_log_avg_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).mean())\n",
    "temp_df['macro_volume_altcoin_log_min_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).min())\n",
    "temp_df['macro_volume_altcoin_log_max_daily_tm28'] = temp_df.altcoin_volume_24h_cmc.transform(lambda x: np.log(x).rolling(28).max())\n",
    "temp_df['macro_volume_altcoin_log_reported_sum_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).sum())\n",
    "temp_df['macro_volume_altcoin_log_reported_avg_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).mean())\n",
    "temp_df['macro_volume_altcoin_log_reported_min_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).min())\n",
    "temp_df['macro_volume_altcoin_log_reported_max_daily_tm28'] = temp_df.altcoin_volume_24h_reported_cmc.transform(lambda x: np.log(x).rolling(28).max())\n",
    "temp_df['macro_volume_btc_sum_daily_tm7'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_volume_btc_avg_daily_tm7'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_volume_btc_min_daily_tm7'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_volume_btc_max_daily_tm7'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_volume_btc_sum_daily_tm28'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_volume_btc_avg_daily_tm28'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_volume_btc_min_daily_tm28'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_volume_btc_max_daily_tm28'] = temp_df.macro_volume_btc_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_volume_btc_log_sum_daily_tm7'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_volume_btc_log_avg_daily_tm7'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_volume_btc_log_min_daily_tm7'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_volume_btc_log_max_daily_tm7'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_volume_btc_log_sum_daily_tm28'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_volume_btc_log_avg_daily_tm28'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_volume_btc_log_min_daily_tm28'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_volume_btc_log_max_daily_tm28'] = temp_df.macro_volume_btc_log_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df = temp_df.drop(['total_volume_24h_cmc', 'altcoin_volume_24h_cmc',\n",
    "                        'total_volume_24h_reported_cmc', 'altcoin_volume_24h_reported_cmc'], axis=1)\n",
    "df = df.drop(['total_volume_24h_cmc', 'altcoin_volume_24h_cmc',\n",
    "              'total_volume_24h_reported_cmc', 'altcoin_volume_24h_reported_cmc'], axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Market cap variables\n",
    "temp_df = df[df.asset == 'bitcoin'][['date', 'total_market_cap_cmc', 'altcoin_market_cap_cmc', \n",
    "                                     'covar_mcap_t', 'covar_mcap_log_t']]\n",
    "temp_df = temp_df.rename(columns={'covar_mcap_t': 'macro_mcap_btc_t',\n",
    "                                  'covar_mcap_log_t': 'macro_mcap_btc_log_t'})\n",
    "temp_df['macro_mcap_t']             = temp_df.total_market_cap_cmc.values\n",
    "temp_df['macro_mcap_altcoin_t']     = temp_df.altcoin_market_cap_cmc.values\n",
    "temp_df['macro_mcap_log_t']         = np.log(temp_df.total_market_cap_cmc.values)\n",
    "temp_df['macro_mcap_altcoin_log_t'] = np.log(temp_df.altcoin_market_cap_cmc.values)\n",
    "assert(0==temp_df[temp_df.total_market_cap_cmc == 0].shape[0])\n",
    "assert(0==temp_df[temp_df.altcoin_market_cap_cmc == 0].shape[0])\n",
    "temp_df['macro_mcap_sum_daily_tm7']      = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_mcap_avg_daily_tm7']      = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_mcap_min_daily_tm7']      = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_mcap_max_daily_tm7']      = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_mcap_log_sum_daily_tm7']  = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).sum())\n",
    "temp_df['macro_mcap_log_avg_daily_tm7']  = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).mean())\n",
    "temp_df['macro_mcap_log_min_daily_tm7']  = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).min())\n",
    "temp_df['macro_mcap_log_max_daily_tm7']  = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).max())\n",
    "temp_df['macro_mcap_ret_t']              = temp_df.total_market_cap_cmc.transform(lambda x: x.pct_change(periods=7))\n",
    "temp_df['macro_mcap_sum_daily_tm28']     = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_mcap_avg_daily_tm28']     = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_mcap_min_daily_tm28']     = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_mcap_max_daily_tm28']     = temp_df.total_market_cap_cmc.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_mcap_log_sum_daily_tm28'] = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).sum())\n",
    "temp_df['macro_mcap_log_avg_daily_tm28'] = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).mean())\n",
    "temp_df['macro_mcap_log_min_daily_tm28'] = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).min())\n",
    "temp_df['macro_mcap_log_max_daily_tm28'] = temp_df.total_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).max())\n",
    "temp_df['macro_mcap_ret_tm28']           = temp_df.total_market_cap_cmc.transform(lambda x: x.pct_change(periods=28))\n",
    "temp_df['macro_mcap_altcoin_sum_daily_tm7']      = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_mcap_altcoin_avg_daily_tm7']      = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_mcap_altcoin_min_daily_tm7']      = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_mcap_altcoin_max_daily_tm7']      = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_mcap_altcoin_log_sum_daily_tm7']  = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).sum())\n",
    "temp_df['macro_mcap_altcoin_log_avg_daily_tm7']  = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).mean())\n",
    "temp_df['macro_mcap_altcoin_log_min_daily_tm7']  = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).min())\n",
    "temp_df['macro_mcap_altcoin_log_max_daily_tm7']  = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(7).max())\n",
    "temp_df['macro_mcap_altcoin_ret_t']              = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.pct_change(periods=7))\n",
    "temp_df['macro_mcap_altcoin_sum_daily_tm28']     = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_mcap_altcoin_avg_daily_tm28']     = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_mcap_altcoin_min_daily_tm28']     = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_mcap_altcoin_max_daily_tm28']     = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_mcap_altcoin_log_sum_daily_tm28'] = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).sum())\n",
    "temp_df['macro_mcap_altcoin_log_avg_daily_tm28'] = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).mean())\n",
    "temp_df['macro_mcap_altcoin_log_min_daily_tm28'] = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).min())\n",
    "temp_df['macro_mcap_altcoin_log_max_daily_tm28'] = temp_df.altcoin_market_cap_cmc.transform(lambda x: np.log(x).rolling(28).max())\n",
    "temp_df['macro_mcap_altcoin_ret_tm28']           = temp_df.altcoin_market_cap_cmc.transform(lambda x: x.pct_change(periods=28))\n",
    "\n",
    "# Form market cap variables from ATH and cycle low\n",
    "def idxMax(func_df, col):\n",
    "    idxmax = [func_df.date.values[0]]\n",
    "    maxvalue = func_df[col].values[0]\n",
    "    for i in range(1, func_df.shape[0]):\n",
    "        if func_df[col].values[i] > maxvalue:\n",
    "            idxmax.append(func_df.date.values[i])\n",
    "            maxvalue = func_df[col].values[i]\n",
    "        else:\n",
    "            idxmax.append(idxmax[i-1])\n",
    "    return idxmax\n",
    "def cycleLowMcap(func_df, mcap_col, cummax_date_col):\n",
    "    cycle_low_mcap_list = [func_df[mcap_col].values[0]]\n",
    "    for i in range(1, func_df.shape[0]):\n",
    "        start_date = func_df[cummax_date_col].values[i]\n",
    "        end_date   = func_df.date.values[i]\n",
    "        new_cycle_low = np.min(func_df[(func_df.date >= start_date) & \n",
    "                                       (func_df.date <= end_date)][mcap_col].values)\n",
    "        cycle_low_mcap_list.append(new_cycle_low) \n",
    "    return cycle_low_mcap_list\n",
    "temp_df['temp_cummax'] = temp_df.total_market_cap_cmc.cummax()\n",
    "temp_df['temp_cummax_date'] = idxMax(temp_df[['date', 'total_market_cap_cmc']],\n",
    "                                              'total_market_cap_cmc')\n",
    "temp_df['macro_mcap_ret_ath_t'] = (temp_df.macro_mcap_t - temp_df.temp_cummax)/temp_df.temp_cummax\n",
    "temp_df['temp_altcoin_cummax'] = temp_df.altcoin_market_cap_cmc.cummax()\n",
    "temp_df['temp_altcoin_cummax_date'] = idxMax(temp_df[['date', 'altcoin_market_cap_cmc']], \n",
    "                                                      'altcoin_market_cap_cmc')\n",
    "temp_df['macro_mcap_altcoin_ret_ath_t'] = (temp_df.macro_mcap_altcoin_t - temp_df.temp_altcoin_cummax)/temp_df.temp_altcoin_cummax\n",
    "temp_df['temp_cyclelow_mcap'] = cycleLowMcap(temp_df[['date', 'total_market_cap_cmc', 'temp_cummax_date']],\n",
    "                                                     'total_market_cap_cmc', 'temp_cummax_date')\n",
    "temp_df['macro_mcap_ret_low_t'] = (temp_df.macro_mcap_t - temp_df.temp_cyclelow_mcap)/temp_df.temp_cyclelow_mcap\n",
    "temp_df['temp_cyclelow_altcoin_mcap'] = cycleLowMcap(temp_df[['date', 'altcoin_market_cap_cmc', \n",
    "                                                              'temp_altcoin_cummax_date']],\n",
    "                                                              'altcoin_market_cap_cmc', 'temp_altcoin_cummax_date')\n",
    "temp_df['macro_mcap_altcoin_ret_low_t'] = (temp_df.macro_mcap_altcoin_t - \n",
    "                                           temp_df.temp_cyclelow_altcoin_mcap)/temp_df.temp_cyclelow_altcoin_mcap\n",
    "temp_df = temp_df.drop(['temp_cummax', 'temp_cummax_date',\n",
    "                        'temp_altcoin_cummax', 'temp_altcoin_cummax_date',\n",
    "                        'temp_cyclelow_mcap', 'temp_cyclelow_altcoin_mcap'], axis=1)\n",
    "temp_df = temp_df.drop(['total_market_cap_cmc', 'altcoin_market_cap_cmc'], axis=1)\n",
    "df = df.drop(['total_market_cap_cmc', 'altcoin_market_cap_cmc'], axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Set up coinmetrics columns\n",
    "df = df.rename(columns = {'btc_fee_mean_usd_cm':  'macro_btc_fee_avg_t',\n",
    "                          'btc_fee_med_usd_cm':   'macro_btc_fee_med_t',\n",
    "                          'btc_fee_total_usd_cm': 'macro_btc_fee_sum_t',\n",
    "                          'eth_fee_mean_usd_cm':  'macro_eth_fee_avg_t',\n",
    "                          'eth_fee_med_usd_cm':   'macro_eth_fee_med_t',\n",
    "                          'eth_fee_total_usd_cm': 'macro_eth_fee_sum_t',\n",
    "                          'grayscale_defi_assets_in_usd_cm': 'macro_grayscale_defi_assets_t',\n",
    "                          'grayscale_eth_assets_in_usd_cm': 'macro_grayscale_eth_assets_t',\n",
    "                          'grayscale_btc_assets_in_usd_cm': 'macro_grayscale_btc_assets_t'})\n",
    "df = df.drop('grayscale_gbtc_assets_in_usd_cm', axis=1)\n",
    "        \n",
    "# Clean cmc macro columns\n",
    "df = df.rename(columns = {'active_cryptocurrencies_cmc': 'macro_active_cryptos_t', \n",
    "                          'active_exchanges_cmc': 'macro_active_ex_t',\n",
    "                          'active_market_pairs_cmc': 'macro_active_ex_pairs_t'})\n",
    "temp_df = df[['date', 'macro_active_cryptos_t',  \n",
    "              'macro_active_ex_t', 'macro_active_ex_pairs_t']]\n",
    "temp_df = temp_df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
    "temp_df['macro_active_cryptos_pct_chng_tm7']   = temp_df['macro_active_cryptos_t'].pct_change(periods=7)\n",
    "temp_df['macro_active_cryptos_pct_chng_tm28']  = temp_df['macro_active_cryptos_t'].pct_change(periods=28)\n",
    "temp_df['macro_active_ex_pct_chng_tm7']        = temp_df['macro_active_ex_t'].pct_change(periods=7)\n",
    "temp_df['macro_active_ex_pct_chng_tm28']       = temp_df['macro_active_ex_t'].pct_change(periods=28)\n",
    "temp_df['macro_active_ex_pairs_pct_chng_tm7']  = temp_df['macro_active_ex_pairs_t'].pct_change(periods=7)\n",
    "temp_df['macro_active_ex_pairs_pct_chng_tm28'] = temp_df['macro_active_ex_pairs_t'].pct_change(periods=28)\n",
    "temp_df = temp_df.drop(['macro_active_cryptos_t', \n",
    "                        'macro_active_ex_t',\n",
    "                        'macro_active_ex_pairs_t'], axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Clean and put on the fed columns\n",
    "fed_cols = list(df.filter(regex='_fed', axis=1).columns.values)\n",
    "temp_df = df[['date']+fed_cols]\n",
    "temp_df = temp_df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
    "for col in fed_cols:\n",
    "    col_name_core = col.lower()\n",
    "    temp_df = temp_df.rename(columns={col: 'macro_'+col_name_core+'_t'})\n",
    "    temp_df['macro_'+col_name_core+'_pct_chng_tm7'] = temp_df['macro_'+col_name_core+'_t'].pct_change(periods=7)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df['macro_'+col_name_core+'_t'].isnull(), 'macro_'+col_name_core+'_pct_chng_tm7'] = 0\n",
    "    temp_df.loc[(temp_df['macro_'+col_name_core+'_t']==0)&(temp_df['macro_'+col_name_core+'_t'].shift(1)==0), 'macro_'+col_name_core+'_pct_chng_tm7'] = 0\n",
    "    temp_df['macro_'+col_name_core+'_pct_chng_tm28'] = temp_df['macro_'+col_name_core+'_t'].pct_change(periods=28)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df['macro_'+col_name_core+'_t'].isnull(), 'macro_'+col_name_core+'_pct_chng_tm28'] = 0\n",
    "    temp_df.loc[(temp_df['macro_'+col_name_core+'_t']==0)&(temp_df['macro_'+col_name_core+'_t'].shift(1)==0), 'macro_'+col_name_core+'_pct_chng_tm28'] = 0\n",
    "df = df.drop(fed_cols, axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Form cmc exchange macro cols\n",
    "ex_cmc_cols = ['exchange_volume_binance_us_cmc', 'exchange_volume_coinbase_cmc',\n",
    "               'exchange_volume_gemini_cmc', 'exchange_volume_kraken_cmc',\n",
    "               'exchange_volume_kucoin_cmc', 'exchange_pairs_binance_us_cmc',\n",
    "               'exchange_pairs_coinbase_cmc', 'exchange_pairs_gemini_cmc',\n",
    "               'exchange_pairs_kraken_cmc', 'exchange_pairs_kucoin_cmc']\n",
    "ex_cmc_col_name_core = ['macro_ex_volume_binanceus', 'macro_ex_volume_coinbase',\n",
    "                        'macro_ex_volume_gemini', 'macro_ex_volume_kraken',\n",
    "                        'macro_ex_volume_kucoin', 'macro_ex_pairs_binance_us',\n",
    "                        'macro_ex_pairs_coinbase', 'macro_ex_pairs_gemini',\n",
    "                        'macro_ex_pairs_kraken', 'macro_ex_pairs_kucoin']\n",
    "temp_df = df[['date']+ex_cmc_cols]\n",
    "temp_df = temp_df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
    "for col, new_col_core in zip(ex_cmc_cols, ex_cmc_col_name_core):\n",
    "    temp_df = temp_df.rename(columns={col: new_col_core+'_t'})\n",
    "    temp_df[new_col_core+'_sum_daily_tm7'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(7).sum())\n",
    "    temp_df[new_col_core+'_avg_daily_tm7'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(7).mean())\n",
    "    temp_df[new_col_core+'_min_daily_tm7'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(7).min())\n",
    "    temp_df[new_col_core+'_max_daily_tm7'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(7).max())\n",
    "    temp_df[new_col_core+'_pct_chng_tm7'] = temp_df[new_col_core+'_t'].pct_change(periods=7)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col_core+'_t'].isnull(), new_col_core+'_pct_chng_tm7'] = 0\n",
    "    temp_df.loc[(temp_df[new_col_core+'_t']==0)&\n",
    "                (temp_df[new_col_core+'_t'].shift(1)==0), new_col_core+'_pct_chng_tm7'] = 0\n",
    "    temp_df[new_col_core+'_sum_daily_tm28'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(28).sum())\n",
    "    temp_df[new_col_core+'_avg_daily_tm28'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(28).mean())\n",
    "    temp_df[new_col_core+'_min_daily_tm28'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(28).min())\n",
    "    temp_df[new_col_core+'_max_daily_tm28'] = temp_df[new_col_core+'_t'].transform(lambda x: x.rolling(28).max())\n",
    "    temp_df[new_col_core+'_pct_chng_tm28'] = temp_df[new_col_core+'_t'].pct_change(periods=28)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col_core+'_t'].isnull(), new_col_core+'_pct_chng_tm28'] = 0\n",
    "    temp_df.loc[(temp_df[new_col_core+'_t']==0)&\n",
    "                (temp_df[new_col_core+'_t'].shift(1)==0), new_col_core+'_pct_chng_tm28'] = 0\n",
    "df = df.drop(ex_cmc_cols, axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Form btc and eth dominance and macro returns\n",
    "temp_df = df[df.asset == 'bitcoin'][['date', 'covar_r_t', 'covar_r_tm28', 'covar_r_daily_t']]\n",
    "temp_df = temp_df.rename(columns={'covar_r_t': 'macro_btc_ret_t',\n",
    "                                  'covar_r_tm28': 'macro_btc_ret_tm28'})\n",
    "temp_df = temp_df[~temp_df.covar_r_daily_t.isnull()]\n",
    "temp_df['macro_btc_ret_avg_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_btc_ret_min_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_btc_ret_max_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_btc_ret_std_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_btc_ret_avg_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_btc_ret_min_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_btc_ret_max_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_btc_ret_std_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df = temp_df[~temp_df.macro_btc_ret_tm28.isnull()]\n",
    "temp_df = temp_df.drop('covar_r_daily_t', axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='left',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "temp_df = df[df.asset == 'ethereum'][['date', 'covar_r_t', 'covar_r_tm28', 'covar_r_daily_t']]\n",
    "temp_df = temp_df.rename(columns={'covar_r_t': 'macro_eth_ret_t',\n",
    "                                  'covar_r_tm28': 'macro_eth_ret_tm28'})\n",
    "temp_df = temp_df[~temp_df.covar_r_daily_t.isnull()]\n",
    "temp_df['macro_eth_ret_avg_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_eth_ret_min_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_eth_ret_max_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_eth_ret_std_daily_tm7'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_eth_ret_avg_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_eth_ret_min_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_eth_ret_max_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_eth_ret_std_daily_tm28'] = temp_df.covar_r_daily_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df = temp_df[~temp_df.macro_eth_ret_tm28.isnull()]\n",
    "temp_df = temp_df.drop('covar_r_daily_t', axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='left',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "temp_df = df[['date','btc_dominance_cmc']]\n",
    "temp_df = temp_df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
    "temp_df = temp_df.rename(columns={'btc_dominance_cmc': 'macro_btc_dom_t'})\n",
    "temp_df['macro_btc_dom_avg_daily_tm7']  = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_btc_dom_min_daily_tm7']  = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_btc_dom_max_daily_tm7']  = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_btc_dom_std_daily_tm7']  = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(7).std())\n",
    "temp_df['macro_btc_dom_pct_chng_tm7']   = temp_df.macro_btc_dom_t.pct_change(periods=7)\n",
    "temp_df['macro_btc_dom_avg_daily_tm28'] = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_btc_dom_min_daily_tm28'] = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_btc_dom_max_daily_tm28'] = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_btc_dom_std_daily_tm28'] = temp_df.macro_btc_dom_t.transform(lambda x: x.rolling(28).std())\n",
    "temp_df['macro_btc_dom_pct_chng_tm28']  = temp_df.macro_btc_dom_t.pct_change(periods=28)\n",
    "df = df.drop('btc_dominance_cmc', axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='left',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "temp_df = df[df.asset == 'ethereum'][['date','covar_mcap_t','macro_mcap_t']]\n",
    "temp_df = temp_df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
    "temp_df['macro_eth_dom_t'] = temp_df.covar_mcap_t / temp_df.macro_mcap_t\n",
    "temp_df = temp_df.drop(['covar_mcap_t', 'macro_mcap_t'], axis=1)\n",
    "temp_df['macro_eth_dom_avg_daily_tm7']  = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_eth_dom_min_daily_tm7']  = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_eth_dom_max_daily_tm7']  = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_eth_dom_std_daily_tm7']  = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(7).std())\n",
    "temp_df['macro_eth_dom_pct_chng_tm7']   = temp_df.macro_eth_dom_t.pct_change(periods=7)\n",
    "temp_df['macro_eth_dom_avg_daily_tm28'] = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_eth_dom_min_daily_tm28'] = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_eth_dom_max_daily_tm28'] = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_eth_dom_std_daily_tm28'] = temp_df.macro_eth_dom_t.transform(lambda x: x.rolling(28).std())\n",
    "temp_df['macro_eth_dom_pct_chng_tm28']  = temp_df.macro_eth_dom_t.pct_change(periods=28)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='left',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Form stablecoin metrics\n",
    "temp_df = df[['date','usd_per_usdt_cmc',\n",
    "              'usd_mcap_usdt_cmc', 'usd_volume_24h_usdt_cmc']]\n",
    "temp_df = temp_df[~temp_df.usd_per_usdt_cmc.isnull()]\n",
    "temp_df = temp_df[~temp_df.usd_mcap_usdt_cmc.isnull()]\n",
    "temp_df = temp_df[~temp_df.usd_volume_24h_usdt_cmc.isnull()]\n",
    "temp_df = temp_df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
    "temp_df['macro_usdt_volume_t'] = temp_df.usd_volume_24h_usdt_cmc.values\n",
    "temp_df['macro_usdt_mcap_t'] = temp_df.usd_mcap_usdt_cmc.values\n",
    "temp_df['macro_usdt_sum_daily_dev_from_1_tm7'] = temp_df.usd_per_usdt_cmc.transform(lambda x: np.abs(x-1).rolling(7).sum())\n",
    "temp_df['macro_usdt_std_daily_dev_from_1_tm7'] = temp_df.usd_per_usdt_cmc.transform(lambda x: np.abs(x-1).rolling(7).std())\n",
    "temp_df['macro_usdt_macro_pct_chng_tm7'] = temp_df.macro_usdt_mcap_t.pct_change(periods=7)\n",
    "temp_df['macro_usdt_volume_sum_daily_tm7'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(7).sum())\n",
    "temp_df['macro_usdt_volume_avg_daily_tm7'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_usdt_volume_min_daily_tm7'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_usdt_volume_max_daily_tm7'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_usdt_volume_pct_chng_tm7']  = temp_df.macro_usdt_volume_t.pct_change(periods=7)\n",
    "temp_df['macro_usdt_sum_daily_dev_from_1_tm28'] = temp_df.usd_per_usdt_cmc.transform(lambda x: np.abs(x-1).rolling(28).sum())\n",
    "temp_df['macro_usdt_std_daily_dev_from_1_tm28'] = temp_df.usd_per_usdt_cmc.transform(lambda x: np.abs(x-1).rolling(28).std())\n",
    "temp_df['macro_usdt_macro_pct_chng_tm28'] = temp_df.macro_usdt_mcap_t.pct_change(periods=28)\n",
    "temp_df['macro_usdt_volume_sum_daily_tm28'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(28).sum())\n",
    "temp_df['macro_usdt_volume_avg_daily_tm28'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_usdt_volume_min_daily_tm28'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_usdt_volume_max_daily_tm28'] = temp_df.macro_usdt_volume_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_usdt_volume_pct_chng_tm28']  = temp_df.macro_usdt_volume_t.pct_change(periods=28)\n",
    "temp_df = temp_df.drop(['usd_per_usdt_cmc', 'usd_mcap_usdt_cmc', \n",
    "                        'usd_volume_24h_usdt_cmc'], axis=1)\n",
    "df = df.drop(['usd_per_usdt_cmc', 'usd_mcap_usdt_cmc', 'usd_volume_24h_usdt_cmc'], axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='left',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Ensure san macro cols are clean and rename them\n",
    "san_macro_cols =  ['token_mcap_avg_stock_to_flow_san',\n",
    "                   'token_mcap_avg_mvrv_usd_intraday_san',\n",
    "                   'token_mcap_avg_mcd_collat_ratio_san',\n",
    "                   'token_sum_cexes_to_dex_flow_san',\n",
    "                   'token_sum_exchanges_to_defi_flow_san',\n",
    "                   'token_sum_whale_to_defi_flow_san',\n",
    "                   'token_sum_dex_traders_to_defi_flow_san',\n",
    "                   'token_sum_whale_defi_balance_san',\n",
    "                   'token_sum_traders_to_defi_flow_san',\n",
    "                   'token_sum_traders_defi_balance_san',\n",
    "                   'ethereum_defi_total_value_locked_usd_san',\n",
    "                   'ethereum_nft_trade_volume_usd_san',\n",
    "                   'ethereum_nft_trades_count_san',\n",
    "                   'ethereum_nft_retail_trade_volume_usd_san',\n",
    "                   'ethereum_nft_whale_trade_volume_usd_san',\n",
    "                   'ethereum_nft_whale_trades_count_san',\n",
    "                   'ethereum_percent_of_whale_stablecoin_total_supply_san',\n",
    "                   'bitcoin_miners_to_exchanges_flow_san',\n",
    "                   'ethereum_miners_to_exchanges_flow_san',\n",
    "                   'ethereum_miners_exchange_balance_san',\n",
    "                   'ethereum_traders_to_defi_flow_san',\n",
    "                   'ethereum_traders_defi_balance_san',\n",
    "                   'ethereum_mvrv_usd_intraday_san',\n",
    "                   'ethereum_stock_to_flow_san']\n",
    "new_san_macro_col_names = ['macro_stock_to_flow',\n",
    "                           'macro_mvrv',\n",
    "                           'macro_mcd_collat_ratio',\n",
    "                           'macro_cex_to_dex_flow',\n",
    "                           'macro_ex_to_defi_flow',\n",
    "                           'macro_whale_to_defi_flow',\n",
    "                           'macro_dex_to_defi_flow',\n",
    "                           'macro_whale_defi_balance',\n",
    "                           'macro_traders_to_defi_flow',\n",
    "                           'macro_trades_defi_balance',\n",
    "                           'macro_eth_defi_tvl',\n",
    "                           'macro_nft_trade_volume',\n",
    "                           'macro_nft_trade_count',\n",
    "                           'macro_nft_retail_trade_volume',\n",
    "                           'macro_nft_whale_trade_volume',\n",
    "                           'macro_nft_whale_trade_count',\n",
    "                           'macro_eth_prct_whale_stblcoin_total_supply',\n",
    "                           'macro_btc_miner_to_ex_flow',\n",
    "                           'macro_eth_miner_to_ex_flow',\n",
    "                           'macro_eth_miner_ex_balance',\n",
    "                           'macro_eth_trader_to_defi_flow',\n",
    "                           'macro_eth_trader_defi_balance',\n",
    "                           'macro_eth_mvrv',\n",
    "                           'macro_eth_stock_to_flow']\n",
    "temp_df = df[['date']+san_macro_cols]\n",
    "temp_df = temp_df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
    "for col, new_col_name_core in zip(san_macro_cols, new_san_macro_col_names):\n",
    "    temp_df = temp_df.rename(columns={col: new_col_name_core+'_t'})\n",
    "    temp_df[new_col_name_core+'_avg_daily_tm7'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(7).mean())\n",
    "    temp_df[new_col_name_core+'_std_daily_tm7'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(7).std())\n",
    "    temp_df[new_col_name_core+'_min_daily_tm7'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(7).min())\n",
    "    temp_df[new_col_name_core+'_max_daily_tm7'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(7).max())\n",
    "    temp_df[new_col_name_core+'_pct_chng_tm7']  = temp_df[new_col_name_core+'_t'].pct_change(periods=7)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col_name_core+'_t'].isnull(), new_col_name_core+'_pct_chng_tm7'] = 0\n",
    "    temp_df.loc[(temp_df[new_col_name_core+'_t']==0)&\n",
    "                (temp_df[new_col_name_core+'_t'].shift(1)==0), new_col_name_core+'_pct_chng_tm7'] = 0\n",
    "    temp_df[new_col_name_core+'_avg_daily_tm28'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(28).mean())\n",
    "    temp_df[new_col_name_core+'_std_daily_tm28'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(28).std())\n",
    "    temp_df[new_col_name_core+'_min_daily_tm28'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(28).min())\n",
    "    temp_df[new_col_name_core+'_max_daily_tm28'] = temp_df[new_col_name_core+'_t'].transform(lambda x: x.rolling(28).max())\n",
    "    temp_df[new_col_name_core+'_pct_chng_tm28']  = temp_df[new_col_name_core+'_t'].pct_change(periods=28)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col_name_core+'_t'].isnull(), new_col_name_core+'_pct_chng_tm28'] = 0\n",
    "    temp_df.loc[(temp_df[new_col_name_core+'_t']==0)&\n",
    "                (temp_df[new_col_name_core+'_t'].shift(1)==0), new_col_name_core+'_pct_chng_tm28'] = 0\n",
    "df = df.drop(san_macro_cols, axis=1)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Combine SAN dev variables into a macro variable\n",
    "temp_df = df[['date', 'dev_activity_contributors_count_san',\n",
    "              'github_activity_san', 'github_activity_contributors_count_san',\n",
    "              'dev_activ_san']]\n",
    "temp_df = temp_df.groupby('date').sum()\n",
    "temp_df = pd.DataFrame(temp_df.sum(axis=1))\n",
    "temp_df = temp_df.rename(columns={0:'macro_dev_activ_t'})\n",
    "assert(0==temp_df[temp_df.macro_dev_activ_t.isnull()].shape[0])\n",
    "temp_df = temp_df.reset_index()\n",
    "temp_df['macro_dev_activ_avg_daily_tm7']  = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(7).mean())\n",
    "temp_df['macro_dev_activ_std_daily_tm7']  = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(7).std())\n",
    "temp_df['macro_dev_activ_min_daily_tm7']  = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(7).min())\n",
    "temp_df['macro_dev_activ_max_daily_tm7']  = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(7).max())\n",
    "temp_df['macro_dev_activ_pct_chng_tm7']   = temp_df.macro_dev_activ_t.pct_change(periods=7)\n",
    "temp_df['macro_dev_activ_avg_daily_tm28'] = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(28).mean())\n",
    "temp_df['macro_dev_activ_std_daily_tm28'] = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(28).std())\n",
    "temp_df['macro_dev_activ_min_daily_tm28'] = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(28).min())\n",
    "temp_df['macro_dev_activ_max_daily_tm28'] = temp_df.macro_dev_activ_t.transform(lambda x: x.rolling(28).max())\n",
    "temp_df['macro_dev_activ_pct_chng_tm28']  = temp_df.macro_dev_activ_t.pct_change(periods=28)\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Create macro var out of san supply on/off exchanges\n",
    "temp_df = df[['date', 'supply_on_exchanges_san',\n",
    "              'supply_outside_exchanges_san']]\n",
    "temp_df = temp_df.groupby('date').sum()\n",
    "temp_df = temp_df.reset_index()\n",
    "for col, new_col in zip(['supply_on_exchanges_san', 'supply_outside_exchanges_san'],\n",
    "                        ['macro_supply_on_ex', 'macro_supply_off_ex']):\n",
    "    temp_df = temp_df.rename(columns={col:new_col+'_t'})\n",
    "    temp_df[new_col+'_avg_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).mean())\n",
    "    temp_df[new_col+'_std_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).std())\n",
    "    temp_df[new_col+'_min_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).min())\n",
    "    temp_df[new_col+'_max_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).max())\n",
    "    temp_df[new_col+'_pct_chng_tm7']  = temp_df[new_col+'_t'].pct_change(periods=7)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col+'_t'].isnull(), new_col+'_pct_chng_tm7'] = 0\n",
    "    temp_df.loc[(temp_df[new_col+'_t']==0)&\n",
    "                (temp_df[new_col+'_t'].shift(1)==0), new_col+'_pct_chng_tm7'] = 0\n",
    "    temp_df[new_col+'_avg_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).mean())\n",
    "    temp_df[new_col+'_std_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).std())\n",
    "    temp_df[new_col+'_min_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).min())\n",
    "    temp_df[new_col+'_max_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).max())\n",
    "    temp_df[new_col+'_pct_chng_tm28'] = temp_df[new_col+'_t'].pct_change(periods=28)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col+'_t'].isnull(), new_col+'_pct_chng_tm28'] = 0\n",
    "    temp_df.loc[(temp_df[new_col+'_t']==0)&\n",
    "                (temp_df[new_col+'_t'].shift(1)==0), new_col+'_pct_chng_tm28'] = 0\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "san_sent_cols = ['sentiment_balance_total_san',\n",
    "                 'sentiment_negative_total_san',\n",
    "                 'sentiment_positive_total_san',\n",
    "                 'social_volume_total_san']\n",
    "temp_df = df[['date', 'asset']+san_sent_cols]\n",
    "for col in san_sent_cols:\n",
    "    temp_df[col] = temp_df.groupby('asset')[col].transform(lambda x: x/np.max(x))\n",
    "temp_df = temp_df.drop('asset', axis=1)\n",
    "temp_df = temp_df.groupby('date').sum()\n",
    "temp_df = temp_df.reset_index()\n",
    "new_san_cols = ['macro_san_sent_bal', 'macro_san_sent_neg',\n",
    "                'macro_san_sent_pos', 'macro_san_social_volume']\n",
    "for col, new_col in zip(san_sent_cols, new_san_cols):\n",
    "    temp_df = temp_df.rename(columns={col:new_col+'_t'})\n",
    "    temp_df[new_col+'_avg_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).mean())\n",
    "    temp_df[new_col+'_std_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).std())\n",
    "    temp_df[new_col+'_min_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).min())\n",
    "    temp_df[new_col+'_max_daily_tm7']  = temp_df[new_col+'_t'].transform(lambda x: x.rolling(7).max())\n",
    "    temp_df[new_col+'_pct_chng_tm7']  = temp_df[new_col+'_t'].pct_change(periods=7)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col+'_t'].isnull(), new_col+'_pct_chng_tm7'] = 0\n",
    "    temp_df.loc[(temp_df[new_col+'_t']==0)&\n",
    "                (temp_df[new_col+'_t'].shift(1)==0), new_col+'_pct_chng_tm7'] = 0\n",
    "    temp_df[new_col+'_avg_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).mean())\n",
    "    temp_df[new_col+'_std_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).std())\n",
    "    temp_df[new_col+'_min_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).min())\n",
    "    temp_df[new_col+'_max_daily_tm28'] = temp_df[new_col+'_t'].transform(lambda x: x.rolling(28).max())\n",
    "    temp_df[new_col+'_pct_chng_tm28'] = temp_df[new_col+'_t'].pct_change(periods=28)\n",
    "    temp_df.loc[(temp_df.date=='2016-1-03') & temp_df[new_col+'_t'].isnull(), new_col+'_pct_chng_tm28'] = 0\n",
    "    temp_df.loc[(temp_df[new_col+'_t']==0)&\n",
    "                (temp_df[new_col+'_t'].shift(1)==0), new_col+'_pct_chng_tm28'] = 0\n",
    "nrows_b4 = df.shape[0]\n",
    "df = df.merge(temp_df,\n",
    "              on='date',\n",
    "              how='inner',\n",
    "              validate='many_to_one')\n",
    "assert(df.shape[0]==nrows_b4)\n",
    "df = df.sort_values(by=['date', 'asset']).reset_index(drop=True)\n",
    "\n",
    "# Drop macro columns with any missing in 2016 and onward\n",
    "macro_cols = list(df.filter(regex='macro', axis=1).columns.values)\n",
    "missing_df = df[df.date.dt.year >= 2016][macro_cols].isnull().sum()\n",
    "missing_df = missing_df[missing_df > 0]\n",
    "df = df.drop(list(missing_df.index.values), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
