{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab026fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to use the quantools, due to my crap path names have to add to sys path\n",
    "import sys\n",
    "sys.path.insert(0, '/home/adam/Dropbox/2-creations/2-crafts/7-buidl/0-utils/quant_tools/code')\n",
    "\n",
    "# IMPORT PACKAGES\n",
    "from typing import List, Dict\n",
    "from sklearn import decomposition\n",
    "from datetime import datetime\n",
    "from tools import QuantTools\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "359205d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsetRhsAndRows(df: pd.DataFrame, lhs_col: str) -> pd.DataFrame:\n",
    "    # Rename mcap column to use for mcap-weighted averages\n",
    "    df = df.rename(columns = {'char_size_t': 'mcap', 'char_r_tm7': 'r_ex_tp0'})\n",
    "    # Subset to relevant columns\n",
    "    df = df[['date', 'asset', lhs_col, 'r_ex_tp0', 'mcap']].copy()\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69f8d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineFirstDayOfMonthsInTestPeriod(df: pd.DataFrame, test_start_date: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Determine the first day of each month within the test period starting from the given date.\n",
    "\n",
    "    :param df: DataFrame containing the date column for determining the test period range.\n",
    "    :param test_start_date: The test start date in the format '%Y-%m-%d'.\n",
    "\n",
    "    :return: A list of dates representing the first day of each month within the test period.\n",
    "    \"\"\"\n",
    "    test_start_datetime = datetime.strptime(test_start_date, '%Y-%m-%d')\n",
    "    assert test_start_datetime.day == 1, \"Test start date does not start on first day of a month.\"\n",
    "    \n",
    "    test_period_months = []\n",
    "    max_date = np.max(df.date)\n",
    "    current_date = test_start_datetime\n",
    "    while current_date <= max_date:\n",
    "        test_period_months.append(current_date.strftime('%Y-%m-%d'))\n",
    "        current_date += pd.DateOffset(months=1)\n",
    "        \n",
    "    return test_period_months\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37f948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFactorsWithPCA(in_df: pd.DataFrame, lhs_col: str, num_factor: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Constructs factors using Principal Component Analysis (PCA) on a panel of asset returns.\n",
    "\n",
    "    :param in_df: DataFrame containing the panel data of asset returns.\n",
    "    :param lhs_col: The name of the column in in_df containing the t+1 asset returns.\n",
    "    :param num_factor: The number of principal components to calc for factors.\n",
    "    :return: DataFrame containing the factors constructed using PCA with a ``date'' column.\n",
    "\n",
    "    The input DataFrame must have 'date', 'asset', and the specified lhs_col columns. \n",
    "    The function first reshapes the data into a T (time) x N (assets) matrix and computes\n",
    "    the sample covariance matrix. It then performs PCA on this covariance matrix, retaining\n",
    "    the specified number of factors, and returns them in a DataFrame.\n",
    "    \"\"\"\n",
    "    # Reshape to TxN matrix of returns\n",
    "    wide_df = in_df.pivot(index='date', columns='asset', values=lhs_col)\n",
    "\n",
    "    # Fill missing with cross-sectional average\n",
    "    wide_df = wide_df.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "    assert(0 == wide_df.isnull().sum().sum())\n",
    "    returns_mat = wide_df.values # NOTE: T x N\n",
    "    returns_demeaned_mat = returns_mat - np.mean(returns_mat, axis=0)\n",
    "\n",
    "    # Form sample covariance matrix\n",
    "    cov = (np.matmul(np.transpose(returns_demeaned_mat), returns_demeaned_mat) \n",
    "        / returns_demeaned_mat.shape[0])\n",
    "\n",
    "    # Form eigenvectors for given number of factors\n",
    "    pca = decomposition.PCA(n_components=num_factor)\n",
    "    pcs = pca.fit_transform(cov) # N x num_factor pc's\n",
    "    pcs = pcs.astype(np.float64)\n",
    "\n",
    "    # Form the factors\n",
    "    factors = np.matmul(returns_mat, pcs)\n",
    "    factors_df = pd.DataFrame(index=wide_df.index,\n",
    "        data=factors, columns=['pca'+str(i) for i in range(1,1+num_factor)])\n",
    "\n",
    "    return factors_df.reset_index()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "699ba5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitAndPredict(\n",
    "    lhs_df: pd.DataFrame, lhs_col: str, factors_df: pd.DataFrame, oos_start_date: str\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fits a multiple linear regression model to the given factors and asset returns, \n",
    "        and then uses the fitted model to predict out-of-sample (OOS) returns.\n",
    "\n",
    "    :param lhs_df: DataFrame containing the left-hand-side (dependent) data, \n",
    "        including 'date', 'asset', and the specified lhs_col (return data).\n",
    "    :param lhs_col: The name of the column in lhs_df containing the t+1 asset returns.\n",
    "    :param factors_df: DataFrame containing the factor data along with a 'date' column.\n",
    "    :param oos_start_date: The start date for the out-of-sample predictions.\n",
    "    :return: DataFrame containing the out-of-sample predictions ('yhats') \n",
    "        along with the corresponding 'date', 'asset', and observed t+1 returns.\n",
    "\n",
    "    The function first calculates the beta coefficients (beta hats) for each asset \n",
    "        using the data up to the oos_start_date. Then, it uses these coefficients \n",
    "        to make out-of-sample predictions for each asset for dates on or after the oos_start_date.\n",
    "\n",
    "    If an asset in the test period does not exist in the training data, \n",
    "        the average of the beta hats from the training data is used for prediction.\n",
    "\n",
    "    Note: The lhs_df and factors_df DataFrames must have a 'date' column,\n",
    "        and the dates in lhs_df must correspond to the dates in factors_df.\n",
    "    \"\"\"\n",
    "\n",
    "    # Form columns in factor df\n",
    "    factor_cols = list(factors_df.columns)\n",
    "    factor_cols.remove('date')\n",
    "\n",
    "    # Calc each asset's beta hats\n",
    "    asset_universe = list(np.unique(lhs_df[lhs_df.date<oos_start_date].asset.values))\n",
    "    asset_beta_hats_dict = {key: None for key in asset_universe}\n",
    "    for asset in asset_universe:\n",
    "        # form relevant data\n",
    "        train_lhs_df = lhs_df[(lhs_df.asset==asset) & (lhs_df.date < oos_start_date)][['date', lhs_col]].copy()\n",
    "        train_df     = train_lhs_df.merge(factors_df, on='date', how='left', validate='one_to_one')\n",
    "        train_rhs    = train_df[factor_cols]\n",
    "        train_lhs    = train_df[lhs_col]\n",
    "        train_rhs    = sm.add_constant(train_rhs)\n",
    "\n",
    "        # calc beta hats\n",
    "        model = sm.OLS(train_lhs, train_rhs)\n",
    "        results = model.fit()\n",
    "\n",
    "        # save beta hats\n",
    "        asset_beta_hats_dict[asset] = list(results.params.values)\n",
    "\n",
    "    # Calc avg beta hat in case we need it\n",
    "    avg_beta_hats = np.mean(list(asset_beta_hats_dict.values()), axis=0)\n",
    "\n",
    "    # Form test period rhs\n",
    "    test_rhs = factors_df[factors_df.date>=oos_start_date]\n",
    "\n",
    "    # Calc test yhats\n",
    "    oos_df = lhs_df[lhs_df.date>=oos_start_date][['date', 'asset', lhs_col]].copy()\n",
    "    oos_df = oos_df.sort_values(by=['date', 'asset'], ignore_index=True)\n",
    "    oos_df['yhats'] = np.zeros(len(oos_df))\n",
    "    test_assets = list(np.unique(oos_df.asset.values))\n",
    "    for asset in test_assets:\n",
    "        # if we did not have the test asset in training data, take average of beta hats\n",
    "        if asset not in asset_beta_hats_dict.keys():\n",
    "            asset_beta_hats = avg_beta_hats\n",
    "        else:\n",
    "            asset_beta_hats = np.array(asset_beta_hats_dict[asset])\n",
    "\n",
    "        # form asset test rhs\n",
    "        asset_test_dates = list(np.unique(oos_df[oos_df.asset==asset].date.values))\n",
    "        asset_test_rhs = factors_df[factors_df.date.isin(asset_test_dates)][factor_cols]\n",
    "        asset_test_rhs = sm.add_constant(asset_test_rhs)\n",
    "\n",
    "        # calc asset yhats\n",
    "        asset_yhats = np.matmul(asset_test_rhs.values, asset_beta_hats)\n",
    "\n",
    "        # save values\n",
    "        oos_df.loc[oos_df.asset==asset, 'yhats'] = asset_yhats\n",
    "\n",
    "    return oos_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a11d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitAndPredictTestPeriod(\n",
    "    df: pd.DataFrame, asset_universe_dict: dict, lhs_col: str, test_start_date: str, num_factors: int\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fits a multiple linear regression model using given number of factors built with PCA\n",
    "        and predicts asset returns for the test period.\n",
    "\n",
    "    :param df: DataFrame containing asset information, \n",
    "        including 'date', 'asset', lhs_col (return data) columns.\n",
    "    :param asset_universe_dict: Dictionary mapping dates to a list of assets that are relevant for that date.\n",
    "    :param lhs_col: The name of the column in df containing the asset returns.\n",
    "    :param test_start_date: The start date for the test period predictions.\n",
    "    :param num_factors: The maximum number of factors to consider in the PCA.\n",
    "    :return: DataFrame containing the predicted returns (yhats) for each asset, \n",
    "        considering different numbers of factors used in the PCA.\n",
    "\n",
    "    The function iterates over the test period months and uses the \n",
    "        buildFactorsWithPCA and fitAndPredict functions to generate predictions (yhats) \n",
    "        for various numbers of factors (from 1 to num_factors). \n",
    "        The predicted returns are aggregated and returned in a DataFrame.\n",
    "\n",
    "    The DataFrame df must include the columns 'date', 'asset', and lhs_col.\n",
    "        The dates in asset_universe_dict should correspond to the test period months, \n",
    "        and the assets should match those in df.\n",
    "\n",
    "    Note: This function relies on the determineFirstDayOfMonthsInTestPeriod function \n",
    "        to get the first day of the month for all test period months, and on the \n",
    "        buildFactorsWithPCA and fitAndPredict functions for factor construction and prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the first day of the month for all test period months\n",
    "    test_period_months = determineFirstDayOfMonthsInTestPeriod(df, test_start_date)\n",
    "\n",
    "    # Generate yhats for each model\n",
    "    test_df = df[df.date >= test_start_date][['date', 'asset', lhs_col]].reset_index(drop=True).copy()\n",
    "    for num_factor in range(1,1+num_factors):\n",
    "        # iterate over all the test period months to gen yhats\n",
    "        temp_dfs = []\n",
    "        for test_period_month in test_period_months:\n",
    "            # form the relevant dataset\n",
    "            asset_universe = asset_universe_dict[test_period_month]\n",
    "            one_month_ahead = datetime.strptime(test_period_month, '%Y-%m-%d') + pd.DateOffset(months=1)\n",
    "            rel_df = df[(df.asset.isin(asset_universe)) \n",
    "                & (df.date < one_month_ahead)][['date', 'asset', lhs_col, 'r_ex_tp0']].copy()\n",
    "\n",
    "            # form factors\n",
    "            factors_df = buildFactorsWithPCA(rel_df, 'r_ex_tp0', num_factor)\n",
    "\n",
    "            # fit and predict\n",
    "            lhs_df = rel_df[['date', 'asset', lhs_col]].copy()\n",
    "            temp_df = fitAndPredict(lhs_df, lhs_col, factors_df, test_period_month)\n",
    "\n",
    "            # save results across the test months\n",
    "            temp_dfs.append(temp_df)\n",
    "        \n",
    "        # aggregate results across the test period for this combo\n",
    "        temp_df = pd.concat(temp_dfs)\n",
    "        temp_df = temp_df.drop(lhs_col, axis=1)\n",
    "        temp_df = temp_df.rename(columns={'yhats': 'yhats_'+str(num_factor)+'_factors'})\n",
    "\n",
    "        # merge results for this combo onto the main df\n",
    "        test_df = test_df.merge(temp_df, on=['date', 'asset'], how='inner', validate='one_to_one')\n",
    "\n",
    "    return test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "651329f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reportResults(\n",
    "    test_df: pd.DataFrame, lhs_col: str, num_qntls_prtls: int, num_factors: int, periods_in_year: int, out_fp: str\n",
    "    ) -> None:\n",
    "    # Confirm we are studying quintile portfolios \n",
    "    assert(num_qntls_prtls==5),\"Update results to programatically form the results df.\"\n",
    "\n",
    "    # Initialize results object\n",
    "    results_df = pd.DataFrame(data = {\n",
    "            '1': [], '2': [], '3': [], '4': [], '5': [], '5-1': [], 'sharpe': [], 't-stat': []\n",
    "        })\n",
    "    results_df['num_factors'] = 1+np.arange(num_factors)\n",
    "\n",
    "    # Generate results for each num_factors\n",
    "    for num_factor in range(1,1+num_factors):\n",
    "        # form relevant dataframe\n",
    "        yhat_col = 'yhats_'+str(num_factor)+'_factors'\n",
    "        t_df = test_df[['date', 'asset', lhs_col, 'mcap', yhat_col]].copy()\n",
    "\n",
    "        # randomly sort\n",
    "        t_df = t_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        # sort the dataframe by 'date' and yhats column\n",
    "        t_df = t_df.sort_values(['date', yhat_col])\n",
    "\n",
    "        # form quantiles\n",
    "        t_df['rank_within_date'] = t_df.groupby('date')[yhat_col].rank(method='first')\n",
    "        t_df['rank_ratio'] = t_df.groupby('date')['rank_within_date'].transform(lambda x: x / x.max())\n",
    "        quantile_bins = list(np.arange(0, num_qntls_prtls+1)/num_qntls_prtls)\n",
    "        t_df['quant'] = 1+pd.cut(t_df['rank_ratio'], bins=quantile_bins, labels=False, include_lowest=True)\n",
    "        t_df = t_df.drop(columns=['rank_within_date', 'rank_ratio'])\n",
    "\n",
    "        # form quantile returns\n",
    "        t_df['weighted_return'] = t_df[lhs_col] * t_df.mcap\n",
    "        grouped_df = t_df.groupby(['date', 'quant'])[['weighted_return', 'mcap']].sum().reset_index()\n",
    "        grouped_df[lhs_col] = grouped_df['weighted_return'] / grouped_df['mcap']\n",
    "        date_quantile_avg_returns_df = grouped_df[['date', 'quant', lhs_col]].copy()\n",
    "        quantile_avg_returns = date_quantile_avg_returns_df.groupby('quant')[lhs_col].apply(lambda x: QuantTools.calcTSAvgReturn(x, annualized=False))\n",
    "\n",
    "        # form ts avg of long short strat and its sharpe and tstat\n",
    "        top_quantile = num_qntls_prtls\n",
    "        bottom_quantile = 1\n",
    "        diff_date_quantile_avg_returns_df = date_quantile_avg_returns_df.pivot_table(index='date', columns='quant', values=lhs_col)\n",
    "        diff_date_quantile_avg_returns_df['top_bottom_diff'] = (diff_date_quantile_avg_returns_df[top_quantile] \n",
    "                                                                - diff_date_quantile_avg_returns_df[bottom_quantile])\n",
    "        top_bottom_diff_returns = diff_date_quantile_avg_returns_df['top_bottom_diff'].values\n",
    "        top_bottom_diff_average = QuantTools.calcTSAvgReturn(top_bottom_diff_returns, annualized=False)\n",
    "        sharpe_top_bottom_diff = QuantTools.calcSharpe(top_bottom_diff_returns, periods_in_year)\n",
    "        t_stat_top_bottom_diff = (np.sqrt(len(diff_date_quantile_avg_returns_df))\n",
    "                        *QuantTools.calcTSAvgReturn(top_bottom_diff_returns, annualized=False)\n",
    "                        / QuantTools.calcSD(top_bottom_diff_returns, annualized=False))\n",
    "\n",
    "        # format results\n",
    "        top_bottom_diff_avg_rounded = np.round(top_bottom_diff_average, 4)\n",
    "        if (np.abs(t_stat_top_bottom_diff) > 2.576):\n",
    "            top_bottom_diff_result = str(top_bottom_diff_avg_rounded)+\"***\"\n",
    "        elif (np.abs(t_stat_top_bottom_diff) > 1.96):\n",
    "            top_bottom_diff_result = str(top_bottom_diff_avg_rounded)+\"**\"\n",
    "        elif (np.abs(t_stat_top_bottom_diff) > 1.645):\n",
    "            top_bottom_diff_result = str(top_bottom_diff_avg_rounded)+\"*\"\n",
    "        else:\n",
    "            top_bottom_diff_result = str(top_bottom_diff_avg_rounded)\n",
    "\n",
    "        for i in range(1,num_qntls_prtls+1):\n",
    "            results_df.loc[results_df.num_factors==num_factor, str(i)] = np.round(quantile_avg_returns[i], 4)\n",
    "        results_df.loc[results_df.num_factors==num_factor, '5-1'] = top_bottom_diff_result\n",
    "        results_df.loc[results_df.num_factors==num_factor, 'sharpe'] = np.round(sharpe_top_bottom_diff, 2)\n",
    "        results_df.loc[results_df.num_factors==num_factor, 't-stat'] = np.round(t_stat_top_bottom_diff, 2)\n",
    "\n",
    "    # Save the results\n",
    "    with pd.ExcelWriter(out_fp, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer: \n",
    "        results_df.to_excel(writer, sheet_name='raw_pca')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6953a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # set args\n",
    "    IN_FP           = '../data/clean/panel_weekly.pkl'\n",
    "    ASSET_IN_FP     = '../data/clean/asset_universe_dict.pickle'\n",
    "    OUT_FP          = '../output/low_dim_fm/low_dim_fms.xlsx'\n",
    "    LHS_COL         = 'r_ex_tp7'\n",
    "    VAL_START_DATE  = '2021-07-01'\n",
    "    TEST_START_DATE = '2022-07-01'\n",
    "    PERIODS_IN_YEAR = 52\n",
    "    NUM_QNTLS_PRTLS = 5\n",
    "    NUM_FACTORS     = 7\n",
    "    \n",
    "    # read in data\n",
    "    with open(ASSET_IN_FP, \"rb\") as f:\n",
    "        asset_universe_dict = pickle.load(f)\n",
    "    all_df = pd.read_pickle(IN_FP)\n",
    "\n",
    "    # subset data\n",
    "    df = subsetRhsAndRows(all_df, LHS_COL)\n",
    "\n",
    "    # generate test period yhats\n",
    "    test_df = fitAndPredictTestPeriod(\n",
    "        df, asset_universe_dict, LHS_COL, TEST_START_DATE, NUM_FACTORS)\n",
    "    \n",
    "    # report results\n",
    "    test_df = test_df.merge(\n",
    "        df[['date', 'asset', 'mcap']], on=['date', 'asset'], how='left', validate='one_to_one')\n",
    "    reportResults(test_df, LHS_COL, NUM_QNTLS_PRTLS, NUM_FACTORS, PERIODS_IN_YEAR, OUT_FP)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f14a76dcff07d5b93f2c0fc65ce65c8ac7788ddb1ef5c63daa3feefa016fa519"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
