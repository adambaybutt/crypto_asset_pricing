{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6359323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import date\n",
    "from requests import Session\n",
    "import json\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import json.decoder\n",
    "from typing import Dict, Any, Optional\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf65d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiateAPI(base_url: str, API_KEY: str) -> Session:\n",
    "    \"\"\" confirm the cmc api is working for the set api key.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): the url for the pro api at cmc. \n",
    "    \n",
    "    Returns:\n",
    "        session (requests.Session): request class for pinging cmc.\n",
    "    \"\"\"\n",
    "    endpoint = '/v1/key/info'\n",
    "    headers = {'Accepts': 'application/json',\n",
    "               'X-CMC_PRO_API_KEY': API_KEY}\n",
    "    final_url = base_url + endpoint\n",
    "    session = Session()\n",
    "    session.headers.update(headers)\n",
    "    r = session.get(final_url)\n",
    "    print(r.json())\n",
    "\n",
    "    return session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fad6930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCMCApiCall(session: Session, url: str, params: dict, retries: int=3) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\" makes an API call to CoinMarketCap using the provided requests.Session object.\n",
    "    \n",
    "    Args:\n",
    "        session (requests.Session): A requests.Session object that will be used to make the API call.\n",
    "        url (str): The API endpoint URL to call.\n",
    "        params (dict): A dictionary of parameters to include in the API call.\n",
    "        retries (int): The number of times to retry the API call if it fails. Default is 3.\n",
    "        \n",
    "    Returns:\n",
    "        data (dict): the data from the api response, or None if the api call failed.\n",
    "    \"\"\"\n",
    "    for attempt in range(retries):\n",
    "        response = session.get(url, params=params)\n",
    "        if response.ok:\n",
    "            try:\n",
    "                return response.json()['data']\n",
    "            except json.decoder.JSONDecodeError as e:\n",
    "                print(f'Error decoding JSON response: {str(e)}')\n",
    "        else:\n",
    "            # There was an error, retry after a short delay\n",
    "            print(f'The API call failed with status code {response.status_code}, retrying...')\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    print('The api call failed after 3 attempts.')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10cec1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtainTopCMCAssets(base_url: str, session: Session, start_date: date, end_date: date) -> list:\n",
    "    \"\"\" obtain the top cmc assets for each month of the study peiod.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): The url for the pro api at cmc. \n",
    "        session (Session): A requests.Session object that will be used to make the API call.\n",
    "        start_date (date): A datetime.date object representing the start date for the study period.\n",
    "        end_date (date): A datetime.date object representing the end date for the study period.\n",
    "    \n",
    "    Returns:\n",
    "        unique_token_cmc_ids (list): unique cmc asset integer ids.\n",
    "    \"\"\"\n",
    "    # specify the dates to obtain\n",
    "    dates = [start_date]\n",
    "    current_date = start_date+relativedelta(months=1)\n",
    "    while current_date <= end_date:\n",
    "        dates.append(current_date)\n",
    "        current_date += relativedelta(months=1)\n",
    "\n",
    "    # set up target url\n",
    "    endpoint = '/v1/cryptocurrency/listings/historical'\n",
    "    url = f\"{base_url}{endpoint}\"\n",
    "\n",
    "    # obtain the top 500 assets by cmc ranking for each month in the study period\n",
    "    asset_cmc_ids = []\n",
    "    for date in dates:\n",
    "        # set up params for call\n",
    "        if date.year <= 2016:\n",
    "            limit = 50\n",
    "        elif date.year <= 2019:\n",
    "            limit = 300\n",
    "        else:\n",
    "            limit = 500\n",
    "        params = {'date': date,\n",
    "                  'limit': limit,\n",
    "                  'convert': 'USD',\n",
    "                  'aux': 'cmc_rank'}\n",
    "\n",
    "        # make the call\n",
    "        data = makeCMCApiCall(session, url, params)\n",
    "\n",
    "        # extract the asset ids\n",
    "        new_assets = [asset['id'] for asset in data]\n",
    "        asset_cmc_ids.extend(new_assets)\n",
    "\n",
    "        # space out calls\n",
    "        time.sleep(1)\n",
    "        print(date)\n",
    "\n",
    "    # drop redundant assets\n",
    "    unique_asset_cmc_ids = list(np.unique(np.array(asset_cmc_ids)))\n",
    "\n",
    "    return unique_asset_cmc_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d764cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formDataframeOfTopCMCAssets(base_url: str, session: Session, cmc_ids: list) -> pd.DataFrame():\n",
    "    \"\"\" pull all cmc meta data for assets and merge onto universe of top assets in cmc_ids.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): the url for the pro api at cmc. \n",
    "        session (Session): A requests.Session object that will be used to make the API call.\n",
    "        cmc_ids (list): top assets by cmc ranking.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        cw_df (pd.DataFrame): dataframe of asset meta data for top assets by cmc ranking.\n",
    "    \"\"\"\n",
    "\n",
    "    # set up target url for obtaining mapping from id to asset info\n",
    "    endpoint = '/v1/cryptocurrency/map'\n",
    "    url = f\"{base_url}{endpoint}\"\n",
    "\n",
    "    # obtain the CMC mapping of IDs to asset info\n",
    "    full_data = []\n",
    "    starts = [1, 5001, 10001, 15001]\n",
    "    for start in starts:\n",
    "        # set up params for call\n",
    "        params = {'listing_status': 'active,inactive,untracked',\n",
    "                  'limit': 5000,\n",
    "                  'start': start,\n",
    "                  'aux': 'platform,first_historical_data,last_historical_data'}\n",
    "\n",
    "        # make the call\n",
    "        data = makeCMCApiCall(session, url, params)\n",
    "\n",
    "        # Append the results\n",
    "        full_data.extend(data)\n",
    "\n",
    "        # space out calls\n",
    "        time.sleep(1)\n",
    "\n",
    "    # clean up asset info dictionaries\n",
    "    clean_full_data = []\n",
    "    for asset_dict in full_data:\n",
    "        new_dict = {}\n",
    "        new_dict['cmc_id'] = asset_dict['id']\n",
    "        new_dict['cmc_symbol'] = asset_dict['symbol']\n",
    "        new_dict['name'] = asset_dict['name']\n",
    "        new_dict['cmc_slug'] = asset_dict['slug']\n",
    "        try:\n",
    "            new_dict['cmc_first_date'] = asset_dict['first_historical_data']\n",
    "            new_dict['cmc_last_date'] = asset_dict['last_historical_data']\n",
    "        except KeyError:\n",
    "            new_dict['cmc_first_date'] = None\n",
    "            new_dict['cmc_last_date'] = None\n",
    "        if asset_dict['platform'] != None:\n",
    "            new_dict['platform_cmc_slug'] = asset_dict['platform']['slug']\n",
    "        else:\n",
    "            new_dict['platform_cmc_slug'] = None\n",
    "        clean_full_data.append(new_dict)\n",
    "\n",
    "    cmc_assets_df = pd.DataFrame(clean_full_data)\n",
    "\n",
    "    # Merge down to just the assets of interest\n",
    "    target_assets_df = pd.DataFrame(data = {'cmc_id': cmc_ids})\n",
    "    cw_df = cmc_assets_df.merge(target_assets_df,\n",
    "                                on='cmc_id',\n",
    "                                how='inner',\n",
    "                                validate='one_to_one')\n",
    "\n",
    "    # reset index and sort\n",
    "    cw_df = cw_df.sort_values(by='cmc_id', ignore_index=True)\n",
    "\n",
    "    return cw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb6a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullPriceMcapVolume(base_url: str, session: Session, \n",
    "        cw_df: pd.DataFrame, start_date: date, end_date: date) -> pd.DataFrame:\n",
    "    \"\"\" pulls historical price, volume, and mcap data for asset ids in cw_df.\n",
    "    \n",
    "    Args:\n",
    "        base_url (str): The base URL for the CoinMarketCap API.\n",
    "        session (requests.Session): A requests.Session object to be used to make the API calls.\n",
    "        cw_df (pd.DataFrame): A pandas DataFrame that contains information about the assets to \n",
    "                                 retrieve data for. Must include columns 'cmc_id' and 'cmc_slug'.\n",
    "        start_date (date): A datetime.date object representing the start date for the study period.\n",
    "        end_date (date): A datetime.date object representing the end date for the study period.\n",
    "        \n",
    "    Returns:\n",
    "        df (pd.DataFrame): price, volume, and mcap for target assets within specified date range. \n",
    "                           The DataFrame has columns 'cmc_id', 'date', 'usd_per_asset', 'usd_mcap',\n",
    "                           and 'usd_volume_24h'.\n",
    "    \"\"\"\n",
    "    # initialize list to build\n",
    "    cw_dfs = []\n",
    "\n",
    "    # set up target url\n",
    "    endpoint = '/v1/cryptocurrency/quotes/historical'\n",
    "    url = f\"{base_url}{endpoint}\"\n",
    "\n",
    "    # loop over assets\n",
    "    asset_ids = list(cw_df.cmc_id.values)\n",
    "    asset_names = list(cw_df.cmc_slug.values)\n",
    "    for i, (asset_id, asset_name) in enumerate(zip(asset_ids, asset_names)):\n",
    "        # monitor progress\n",
    "        print(f\"Processing the {i+1}th asset ({(i+1)/len(asset_ids)*100:.2f}%): {asset_name}\")\n",
    "\n",
    "        # build parameters\n",
    "        params = {'id': str(asset_id),\n",
    "                  'time_start': start_date.strftime('%Y-%m-%d'),\n",
    "                  'time_end': end_date.strftime('%Y-%m-%d'),\n",
    "                  'count': 1,\n",
    "                  'interval': '1d',\n",
    "                  'convert': 'USD'} \n",
    "        \n",
    "        # make the api call\n",
    "        data = makeCMCApiCall(session, url, params, retries=3)\n",
    "\n",
    "        # clean the data\n",
    "        if data != None:\n",
    "            if data['is_fiat'] == 0:\n",
    "                asset_quote_dict_list = []\n",
    "                for quote in data['quotes']:\n",
    "                    new_dict = {}\n",
    "                    new_dict['date']           = quote['quote']['USD']['timestamp'][:10]\n",
    "                    new_dict['usd_per_asset']  = quote['quote']['USD']['price']\n",
    "                    new_dict['usd_volume_24h'] = quote['quote']['USD']['volume_24h']\n",
    "                    new_dict['usd_mcap']       = quote['quote']['USD']['market_cap']\n",
    "                    asset_quote_dict_list.append(new_dict)\n",
    "\n",
    "                cw_df = pd.DataFrame(asset_quote_dict_list)\n",
    "                cw_df['cmc_id'] = data['id']\n",
    "                cw_dfs.append(cw_df)\n",
    "            else:\n",
    "                print(f\"{data['name']} is fiat\")        \n",
    "\n",
    "        # space out calls\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    # build final dataframe\n",
    "    df = pd.concat(cw_dfs)\n",
    "\n",
    "    return df            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "221b6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialCleanAssetMetadata(cw_df: pd.DataFrame, column_map: dict, dropna: bool = True) -> pd.DataFrame:\n",
    "    \"\"\" Clean asset metadata to return cleaned dataframe. \n",
    "\n",
    "    Args:\n",
    "        cw_df (pd.DataFrame): DataFrame containing asset metadata to be cleaned.\n",
    "        column_map (dict): a mapping of the current column names to the desired column names.\n",
    "        dropna (bool): whether to drop any rows with missing values in key columns.\n",
    "    \n",
    "    Returns:\n",
    "        cw_df (pd.DataFrame): cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # confirm has required columns\n",
    "    for k, v in column_map.items():\n",
    "        if k not in cw_df.columns:\n",
    "            raise ValueError(f\"Input DataFrame must contain '{k}' column.\")\n",
    "        \n",
    "    # apply column map renaming\n",
    "    cw_df = cw_df.rename(columns=column_map)\n",
    "\n",
    "    # subset to useful columns\n",
    "    cw_df = cw_df[['cmc_id', 'slug_cmc', 'symbol_cmc', 'first_date_cmc', 'last_date_cmc']]\n",
    "\n",
    "    # convert date columns to date type\n",
    "    cw_df['first_date_cmc'] = pd.to_datetime(cw_df.first_date_cmc, format='%Y-%m-%d', utc=False)\n",
    "    cw_df['last_date_cmc'] = pd.to_datetime(cw_df.last_date_cmc, format='%Y-%m-%d', utc=False)\n",
    "\n",
    "    # drop rows with missing values in key columns\n",
    "    if dropna:\n",
    "        cw_df = cw_df.dropna(subset=['cmc_id', 'slug_cmc'])\n",
    "    \n",
    "    # assert that each row has a unique `cmc_id` and `slug_cmc` value (if desired)\n",
    "    if len(cw_df) != len(cw_df['cmc_id'].unique()):\n",
    "        raise ValueError(\"Input DataFrame has non-unique 'cmc_id' values.\")\n",
    "    if len(cw_df) != len(cw_df['slug_cmc'].unique()):\n",
    "        raise ValueError(\"Input DataFrame has non-unique 'slug_cmc' values.\")\n",
    "    \n",
    "    # sort values and reset index\n",
    "    cw_df = cw_df.sort_values(by='cmc_id', ignore_index=True)\n",
    "\n",
    "    return cw_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdbeaab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialCleanPanel(panel_df: pd.DataFrame, start_year: int=2015, end_date: str='2023-02-02', ) -> pd.DataFrame:\n",
    "    \"\"\" clean panel of cmc prices, volume, and mcap data.\n",
    "     \n",
    "    Args:\n",
    "        panel_df (pandas.DataFrame): panel data to clean.\n",
    "        start_year (int): the minimum year to include in the DataFrame (default: 2015).\n",
    "        end_date (str): the maximum date (inclusive) to include in the DataFrame (default: '2023-02-02').\n",
    "\n",
    "    Returns:\n",
    "        (pd.DataFrame): The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # confirm has the right columns\n",
    "    expected_cols = ['date', 'cmc_id', 'usd_per_token', 'usd_mcap', 'usd_volume_24h']\n",
    "    if not all(col in panel_df.columns for col in expected_cols):\n",
    "        raise ValueError(f\"Missing expected columns: {expected_cols}\")\n",
    "    \n",
    "    # rename columns to standard convention (with data source name in it)\n",
    "    panel_df = panel_df.rename(columns = {'usd_per_token': 'usd_per_token_cmc',\n",
    "                                          'usd_mcap': 'usd_mcap_cmc',\n",
    "                                          'usd_volume_24h': 'usd_volume_24h_cmc'})\n",
    "\n",
    "    # convert columns to correct data type\n",
    "    panel_df['date'] = pd.to_datetime(panel_df.date, format='%Y-%m-%d', utc=False)\n",
    "\n",
    "    # set column order\n",
    "    panel_df = panel_df[['date', 'cmc_id', 'usd_per_token_cmc', 'usd_mcap_cmc', 'usd_volume_24h_cmc']]\n",
    "\n",
    "    # drop rows\n",
    "    panel_df = panel_df[(panel_df.date.dt.year >= 2015) & (panel_df.date <= '2023-02-02')]\n",
    "    panel_df = panel_df.dropna(how='any', subset=['date', 'cmc_id'])\n",
    "    panel_df = panel_df.dropna(how='all', subset=['usd_per_token_cmc', 'usd_mcap_cmc', 'usd_volume_24h_cmc'])\n",
    "\n",
    "    # form list of data columns to work with\n",
    "    data_cols = list(panel_df.columns.values)\n",
    "    data_cols.remove('date')\n",
    "    data_cols.remove('cmc_id')\n",
    "\n",
    "    # set negative values to missing and too large values to missing\n",
    "    for col in data_cols:\n",
    "        panel_df.loc[panel_df[col] < 0, col] = np.nan\n",
    "        panel_df.loc[panel_df[col] > 2e12, col] = np.nan\n",
    "\n",
    "    # drop duplicated rows across id columns\n",
    "    panel_df = panel_df.drop_duplicates(subset=['date', 'cmc_id'])\n",
    "\n",
    "    # sort values and reset index\n",
    "    panel_df = panel_df.sort_values(by=['date', 'cmc_id'], \n",
    "                                    ignore_index=True)\n",
    "\n",
    "    return panel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57682fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcGeomAvg(returns: np.array,\n",
    "    annualized: bool=False,\n",
    "    periods_in_year: int=None) -> float: \n",
    "    \"\"\" Calculate the geometric average of a vector of simple returns.\n",
    "\n",
    "    Args:\n",
    "        returns (np.array): vector of a simple returns at any frequency.\n",
    "        annualized (bool): whether to annualize the statistic.\n",
    "        periods_in_year (int): how many periods of the given frequency are in a year.\n",
    "\n",
    "    Returns:\n",
    "        (float): scalar geometric average.\n",
    "    \"\"\"\n",
    "    geom_avg_at_given_freq = np.prod(1+returns)**(1/len(returns))-1\n",
    "    if annualized==False:\n",
    "        return geom_avg_at_given_freq\n",
    "    else:\n",
    "        return (geom_avg_at_given_freq+1)**periods_in_year-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bafebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepPanelForInitialInclusiveCriteria(panel_df: pd.DataFrame, cw_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" performs various ad hoc cleaning to prep the panel further for applying inclusion criteria.\n",
    "    \n",
    "    Args:\n",
    "        panel_df (pd.DataFrame): panel of asset prices, trading volumes, and mcaps from cmc.\n",
    "        cw_df (pd.DataFrame): identifying variables for the assets.\n",
    "        \n",
    "    Returns:\n",
    "        panel_df (pd.DataFrame): cleaned panel.\n",
    "    \"\"\"\n",
    "    # manually remove tokens from panel\n",
    "    tokens_to_remove = [770, 776, 3787, 8644, 9103]\n",
    "    panel_df = panel_df[~panel_df.cmc_id.isin(tokens_to_remove)]\n",
    "\n",
    "    # merge on cmc slug and drop the cmc id\n",
    "    panel_df = panel_df.merge(cw_df[['cmc_id', 'slug_cmc']],\n",
    "                              on='cmc_id',\n",
    "                              how='inner',\n",
    "                              validate='many_to_one')\n",
    "    panel_df = panel_df.drop('cmc_id', axis=1)\n",
    "    panel_df = panel_df[['date', 'slug_cmc', 'usd_per_token_cmc', 'usd_mcap_cmc', 'usd_volume_24h_cmc']]\n",
    "    panel_df = panel_df.sort_values(by=['date', 'slug_cmc'], ignore_index=True)\n",
    "\n",
    "    # adjust particular values\n",
    "    panel_df.loc[(panel_df.slug_cmc=='uquid-coin') & \n",
    "                  panel_df.usd_volume_24h_cmc.isnull(), 'usd_volume_24h_cmc'] = 0\n",
    "\n",
    "    # ensure no missing in the df\n",
    "    assert(0==panel_df.isnull().sum().sum())\n",
    "\n",
    "    # ensure unique on key columns\n",
    "    dups = panel_df.duplicated(subset=['date', 'slug_cmc'])\n",
    "    assert(~dups.any()),('there are duplicates in the data on keys date and slug_cmc')\n",
    "\n",
    "    # drop more tokens manually\n",
    "    # NOTES: ampleforth is a stablecoin, pax gold is a gold stablecoin, index, and wrapped tokens\n",
    "    wrapped_tokens_to_drop = ['ampleforth', 'cryptoindex-com-100', 'pax-gold',\n",
    "                            'wrapped-centrifuge', 'wrapped-luna-token', 'wrapped-ncg', 'wrapped-nxm']\n",
    "    panel_df = panel_df[~panel_df.slug_cmc.isin(wrapped_tokens_to_drop)]\n",
    "\n",
    "    return panel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ff2149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcGeomAvg(returns: np.array,\n",
    "    annualized: bool=False,\n",
    "    periods_in_year: int=None) -> float: \n",
    "    \"\"\" Calculate the geometric average of a vector of simple returns.\n",
    "\n",
    "    Args:\n",
    "        returns (np.array): vector of a simple returns at any frequency.\n",
    "        annualized (bool): whether to annualize the statistic.\n",
    "        periods_in_year (int): how many periods of the given frequency are in a year.\n",
    "\n",
    "    Returns:\n",
    "        (float): scalar geometric average.\n",
    "    \"\"\"\n",
    "    if not isinstance(returns, np.ndarray):\n",
    "        raise TypeError(\"Input 'returns' must be a NumPy array\")\n",
    "    if annualized and periods_in_year is None:\n",
    "        raise ValueError(\"Input 'periods_in_year' must be provided if 'annualized' is True\")\n",
    "    geom_avg_at_given_freq = np.prod(1 + returns) ** (1 / np.size(returns)) - 1\n",
    "    return (geom_avg_at_given_freq + 1) ** periods_in_year - 1 if annualized else geom_avg_at_given_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaae27a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildInitialAssetUniverse(panel_df: pd.DataFrame, start_date: date, end_date: date) -> dict:\n",
    "    \"\"\" build an initial universe of assets to pull data for.\n",
    "    \n",
    "    Args:\n",
    "        panel_df (pd.DataFrame): panel of asset prices, trading volumes, and mcaps from cmc.\n",
    "        start_date (date): A datetime.date object representing the start date for the study period.\n",
    "        end_date (date): A datetime.date object representing the end date for the study period.\n",
    "    \n",
    "    Returns:\n",
    "        asset_universe (dict): keys of start of each month in study period with associated value\n",
    "                               of list of asset names to include.\n",
    "    \"\"\"\n",
    "    # specify the dates to obtain\n",
    "    dates = [start_date.strftime('%Y-%m-%d')]\n",
    "    current_date = start_date+relativedelta(months=1)\n",
    "    while current_date <= end_date:\n",
    "        dates.append(current_date.strftime('%Y-%m-%d'))\n",
    "        current_date += relativedelta(months=1)\n",
    "\n",
    "    # apply suff data, volume, and mcap filters\n",
    "    asset_universe_per_month = []\n",
    "    for i in range(len(dates)-1):\n",
    "        # determine start and end dates for window\n",
    "        start_window = dates[i]\n",
    "        end_window   = dates[i+1]\n",
    "\n",
    "        # build temporary dataframe for this time period\n",
    "        temp_df = panel_df[(panel_df.date >= start_window) & (panel_df.date <= end_window)].copy()\n",
    "\n",
    "        # obtain list of tokens to consider\n",
    "        assets_included = list(np.unique(temp_df[temp_df.date == end_window].slug_cmc.values))\n",
    "\n",
    "        # figure out tokens removed due to insuff data\n",
    "        # note: 28 days ensures at least 4 weeks of data \n",
    "        asset_ns_df = temp_df.groupby('slug_cmc').size()\n",
    "        assets_lost_given_insuff_data = list(asset_ns_df[asset_ns_df < 28].index.values)\n",
    "        for asset in assets_lost_given_insuff_data:\n",
    "            if asset in assets_included:\n",
    "                assets_included.remove(asset)\n",
    "\n",
    "        # Figure out tokens removed due to volume threshold\n",
    "        temp_vol_df = temp_df.groupby('slug_cmc').usd_volume_24h_cmc.min()\n",
    "        assets_lost_given_insuff_vol = list(temp_vol_df[temp_vol_df < 10000].index.values)\n",
    "        for asset in assets_lost_given_insuff_vol:\n",
    "            if asset in assets_included:\n",
    "                assets_included.remove(asset)\n",
    "\n",
    "        # Figure out assets removed due to mcap threshold\n",
    "        current_year = int(end_window[:4]) \n",
    "        if current_year <= 2016:\n",
    "            mcap_threshold = 750000\n",
    "        elif current_year == 2017:\n",
    "            mcap_threshold = 2e6\n",
    "        elif current_year == 2018:\n",
    "            mcap_threshold = 30e6\n",
    "        elif current_year in [2019, 2020]:\n",
    "            mcap_threshold = 15e6\n",
    "        elif current_year >= 2021:\n",
    "            mcap_threshold = 75e6\n",
    "        temp_mcap_df = temp_df.groupby('slug_cmc').usd_mcap_cmc.min()\n",
    "        assets_lost_given_mcap_threshold = list(temp_mcap_df[temp_mcap_df < mcap_threshold].index.values)\n",
    "        for asset in assets_lost_given_mcap_threshold:\n",
    "            if asset in assets_included:\n",
    "                assets_included.remove(asset)\n",
    "\n",
    "        # Report out new asset ever\n",
    "        print('New assets that we have never had are ')\n",
    "        if i != 0:\n",
    "            all_assets = []\n",
    "            for j in range(i-1,-1,-1):\n",
    "                all_assets += asset_universe_per_month[j]\n",
    "            print(np.unique(set(assets_included).difference(set(all_assets))))\n",
    "        else:\n",
    "            print(np.unique(assets_included))\n",
    "        print('\\n')\n",
    "\n",
    "        # Report out assets for this month\n",
    "        print(f'This month\\'s ({end_window}) {len(assets_included)} assets are:')\n",
    "        print(np.unique(assets_included))\n",
    "        print('\\n\\n')\n",
    "\n",
    "        # Add assets to list\n",
    "        asset_universe_per_month.append(list(np.unique(assets_included)))\n",
    "\n",
    "    # build asset universe\n",
    "    asset_universe_dict = {}\n",
    "    for i in range(len(dates)-1):\n",
    "        asset_universe_dict[dates[i+1]] = asset_universe_per_month[i]\n",
    "\n",
    "    return asset_universe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "948b2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineUniqueAssets(asset_universe_dict) -> list:\n",
    "    \"\"\" determine the unique assets in the universe to return as a list. \"\"\"\n",
    "    assets = []\n",
    "    for k, v in asset_universe_dict.items():\n",
    "        assets.extend(v)\n",
    "    assets = list(np.unique(np.array(assets)))\n",
    "    assets.sort()\n",
    "    return assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "150a60bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullCMCMacro(base_url: str, session: Session, start_date: date, end_date: date) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        base_url (str): The base URL for the CoinMarketCap API.\n",
    "        session (requests.Session): A requests.Session object to be used to make the API calls.\n",
    "        start_window (date): A datetime.date object representing the start date for the study period.\n",
    "        end_date (date): A datetime.date object representing the end date for the study period.\n",
    "\n",
    "    Returns:\n",
    "        macro_df (pd.DataFrame): time series data of cmc macro covariates.\n",
    "    \"\"\"\n",
    "        \n",
    "    # set up the call\n",
    "    endpoint = '/v1/global-metrics/quotes/historical'\n",
    "    url      = f\"{base_url}{endpoint}\"\n",
    "    params = {'time_start': start_date.strftime('%Y-%m-%d'),\n",
    "              'time_end': end_date.strftime('%Y-%m-%d'),\n",
    "              'count': 10,\n",
    "              'interval': '1d',\n",
    "              'convert': 'USD',\n",
    "              'aux': 'btc_dominance,active_cryptocurrencies,active_exchanges,active_market_pairs,total_volume_24h,altcoin_market_cap,altcoin_volume_24h'}\n",
    "\n",
    "    # make the call\n",
    "    data = makeCMCApiCall(session, url, params, retries=3)\n",
    "\n",
    "    # initialize dictionary for the data\n",
    "    cmc_macro_dict = {'date': [],\n",
    "                      'total_market_cap': [],\n",
    "                      'total_volume_24h': [],\n",
    "                      'altcoin_market_cap': [],\n",
    "                      'altcoin_volume_24h': [],\n",
    "                      'btc_dominance': [],\n",
    "                      'active_cryptocurrencies': [],\n",
    "                      'active_exchanges': [],\n",
    "                      'active_market_pairs': []}\n",
    "\n",
    "    # convert JSON into dictionary\n",
    "    for days_data in data['quotes']:\n",
    "        cmc_macro_dict['date'].append(days_data['timestamp'])\n",
    "        cmc_macro_dict['total_market_cap'].append(days_data['quote']['USD']['total_market_cap'])\n",
    "        cmc_macro_dict['total_volume_24h'].append(days_data['quote']['USD']['total_volume_24h'])\n",
    "        cmc_macro_dict['altcoin_market_cap'].append(days_data['quote']['USD']['altcoin_market_cap'])\n",
    "        cmc_macro_dict['altcoin_volume_24h'].append(days_data['quote']['USD']['altcoin_volume_24h'])\n",
    "        cmc_macro_dict['btc_dominance'].append(days_data['btc_dominance'])\n",
    "        cmc_macro_dict['active_cryptocurrencies'].append(days_data['active_cryptocurrencies'])\n",
    "        cmc_macro_dict['active_exchanges'].append(days_data['active_exchanges'])\n",
    "        cmc_macro_dict['active_market_pairs'].append(days_data['active_market_pairs'])\n",
    "\n",
    "    # clean up the dataframe to have all study period dates and interpolate missing dates\n",
    "    macro_df = pd.DataFrame(cmc_macro_dict)\n",
    "    macro_df['date'] = pd.to_datetime(macro_df.date).dt.ceil('D')\n",
    "    macro_df['date'] = macro_df.date.dt.strftime('%Y-%m-%d')\n",
    "    macro_df['date'] = pd.to_datetime(macro_df.date, format='%Y-%m-%d', utc=False)\n",
    "\n",
    "    return macro_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08034930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullCMCExchangeHistoricalData(base_url: str, session: Session, start_date: date, end_date: date) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        base_url (str): The base URL for the CoinMarketCap API.\n",
    "        session (requests.Session): A requests.Session object to be used to make the API calls.\n",
    "        start_window (date): A datetime.date object representing the start date for the study period.\n",
    "        end_date (date): A datetime.date object representing the end date for the study period.\n",
    "\n",
    "    Returns:\n",
    "        ex_df (pd.DataFrame): panel data frame of exchange covariates.\n",
    "    \"\"\"\n",
    "    # obtain exchange mapping ids\n",
    "    endpoint = '/v1/exchange/map'\n",
    "    url      = f\"{base_url}{endpoint}\"\n",
    "    params   = {'listing_status': 'active',\n",
    "                'limit': 250,\n",
    "                'sort': \"volume_24h\"}\n",
    "    data = makeCMCApiCall(session, url, params, retries=3)\n",
    "\n",
    "    # subset down to exchanges of interest\n",
    "    exchanges_dict = {'exchange_slug': [],\n",
    "                    'exchange_id': []}\n",
    "    exchanges_to_keep = ['poloniex', 'kraken', 'bitfinex', 'okcoin', 'coinbase-exchange', 'gemini', 'kucoin', 'ftx', 'ftx-us', 'binance-us', 'huobi', 'bitmex',\n",
    "                        'uniswap-v3', 'dydx', 'pancakeswap-v2', 'uniswap-v2', 'sushiswap', 'curve-finance', 'balancer-v2', 'bancor-network']\n",
    "    for ex_data in data:\n",
    "        if ex_data['slug'] in exchanges_to_keep:\n",
    "            exchanges_dict['exchange_slug'].append(ex_data['slug'])\n",
    "            exchanges_dict['exchange_id'].append(ex_data['id'])\n",
    "    exchanges_df = pd.DataFrame(exchanges_dict)\n",
    "\n",
    "    # obtain metadata for exchanges\n",
    "    exchange_ids = ','.join([str(ex_id)for ex_id in exchanges_df.exchange_id.values])\n",
    "    endpoint = '/v1/exchange/info'\n",
    "    url      = f\"{base_url}{endpoint}\"\n",
    "    params   = {'id': exchange_ids,\n",
    "                'aux': 'date_launched'}\n",
    "    data = makeCMCApiCall(session, url, params, retries=3)\n",
    "\n",
    "    # extract the metadata of interest\n",
    "    exchange_metadata_dict = {'exchange_id': [],\n",
    "                            'exchange_date_launched': []}\n",
    "    for k, v in data.items():\n",
    "        exchange_metadata_dict['exchange_id'].append(data[k]['id'])\n",
    "        exchange_metadata_dict['exchange_date_launched'].append(data[k]['date_launched'])\n",
    "    exchange_metadata_df = pd.DataFrame(exchange_metadata_dict)\n",
    "    exchanges_df = exchanges_df.merge(exchange_metadata_df,\n",
    "                                    on='exchange_id',\n",
    "                                    how='inner',\n",
    "                                    validate='one_to_one')\n",
    "\n",
    "    # manually fix some missing data\n",
    "    exchanges_df.loc[exchanges_df.exchange_slug=='pancakeswap-v2', 'exchange_date_launched'] = '2021-04-23T00:00:00.000Z'\n",
    "    exchanges_df.loc[exchanges_df.exchange_slug=='balancer-v2', 'exchange_date_launched'] = '2021-03-31T00:00:00.000Z'\n",
    "            \n",
    "    # obtain the exchange historical data\n",
    "    endpoint = '/v1/exchange/quotes/historical'\n",
    "    url = f\"{base_url}{endpoint}\"\n",
    "    params = {'time_start': start_date.strftime('%Y-%m-%d'),\n",
    "            'time_end': end_date.strftime('%Y-%m-%d'),\n",
    "            'interval': '1d',\n",
    "            'count': 10000,\n",
    "            'convert': 'USD'}\n",
    "\n",
    "    # intialize dict for the data\n",
    "    ex_hist_data_dict = {'exchange_id': [],\n",
    "                        'date': [],\n",
    "                        'exchange_volume_24h': [],\n",
    "                        'num_market_pairs': []}\n",
    "    exchange_ids = list(exchanges_df.exchange_id.values)\n",
    "\n",
    "    # extract the exchange historical information\n",
    "    for exchange_id in exchange_ids: \n",
    "        # update id to pull\n",
    "        params['id'] = exchange_id\n",
    "\n",
    "        # make the call\n",
    "        data = makeCMCApiCall(session, url, params, retries=3)\n",
    "\n",
    "        # extract datat to dict\n",
    "        for ex_data in data['quotes']:\n",
    "            ex_hist_data_dict['exchange_id'].append(exchange_id)\n",
    "            ex_hist_data_dict['date'].append(ex_data['quote']['USD']['timestamp'])\n",
    "            ex_hist_data_dict['exchange_volume_24h'].append(ex_data['quote']['USD']['volume_24h'])\n",
    "            ex_hist_data_dict['num_market_pairs'].append(ex_data['num_market_pairs'])\n",
    "            \n",
    "        # Sleep\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Convert to dataframe\n",
    "    ex_historical_df = pd.DataFrame(ex_hist_data_dict)\n",
    "\n",
    "    # format dates and round to midnight in the future\n",
    "    exchanges_df['exchange_date_launched'] =  pd.to_datetime(exchanges_df['exchange_date_launched'], format='%Y-%m-%d', utc=False).dt.ceil('D')\n",
    "    ex_historical_df['date'] = pd.to_datetime(ex_historical_df['date'], format='%Y-%m-%d', utc=False).dt.ceil('D')\n",
    "\n",
    "    # combine and clean data\n",
    "    ex_df = exchanges_df.merge(ex_historical_df,\n",
    "                                on='exchange_id',\n",
    "                                how='inner',\n",
    "                                validate='one_to_many')\n",
    "    ex_df = ex_df[['date', 'exchange_slug', 'exchange_date_launched', 'exchange_volume_24h', 'num_market_pairs']]\n",
    "    assert(0==ex_df[ex_df.exchange_date_launched>ex_df.date].shape[0]),('some exchanges have data before they launched!')\n",
    "    ex_df = ex_df.rename(columns={'exchange_slug': 'ex_slug_cmc',\n",
    "                                'exchange_date_launched': 'ex_date_launched_cmc',\n",
    "                                'exchange_volume_24h': \"ex_volume_24h_cmc\",\n",
    "                                'num_market_pairs': 'ex_num_market_pairs_cmc'})\n",
    "\n",
    "    return ex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "134d21c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullCMCAssetMetadata(base_url: str, session: Session, start_date: date, end_date: date) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        base_url (str): The base URL for the CoinMarketCap API.\n",
    "        session (requests.Session): A requests.Session object to be used to make the API calls.\n",
    "        start_window (date): A datetime.date object representing the start date for the study period.\n",
    "        end_date (date): A datetime.date object representing the end date for the study period.\n",
    "\n",
    "    Returns:\n",
    "        asset_covars_df (pd.DataFrame): panel data frame of additional asset covariates.\n",
    "    \"\"\"\n",
    "    # set up the call\n",
    "    dates    = list(pd.date_range(start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'), freq='D').strftime('%Y-%m-%d'))\n",
    "    endpoint = '/v1/cryptocurrency/listings/historical'\n",
    "    url      = f\"{base_url}{endpoint}\"\n",
    "    params   = {'limit': 600,\n",
    "                'convert': 'USD',\n",
    "                'sort': 'cmc_rank',\n",
    "                'sort_dir': 'asc',\n",
    "                'aux': 'tags,circulating_supply,total_supply,max_supply,cmc_rank,num_market_pairs'}\n",
    "\n",
    "    # initialize dictionary for the data\n",
    "    covars_dict = {'date': [],\n",
    "                'cmc_id': [],\n",
    "                'num_market_pairs': [],\n",
    "                'max_supply': [],\n",
    "                'circulating_supply': [],\n",
    "                'total_supply': [],\n",
    "                'cmc_rank': [],\n",
    "                'tags': []}\n",
    "\n",
    "    for i in range(len(dates)):\n",
    "        # update current date to pull\n",
    "        current_date = dates[i]\n",
    "        params['date'] = current_date\n",
    "\n",
    "        # monitor progress\n",
    "        print(f\"Processing {current_date} ({(i+1)/len(dates)*100:.2f}% done).\")\n",
    "\n",
    "        # make the call\n",
    "        data = makeCMCApiCall(session, url, params, retries=3)\n",
    "\n",
    "        # add data to dict if in universe\n",
    "        for asset in data:\n",
    "            if asset['slug'] in asset_universe_list:\n",
    "                covars_dict['date'].append(current_date)\n",
    "                covars_dict['cmc_id'].append(asset['id'])\n",
    "                covars_dict['num_market_pairs'].append(asset['num_market_pairs'])\n",
    "                covars_dict['max_supply'].append(asset['max_supply'])\n",
    "                covars_dict['circulating_supply'].append(asset['circulating_supply'])\n",
    "                covars_dict['total_supply'].append(asset['total_supply'])\n",
    "                covars_dict['cmc_rank'].append(asset['cmc_rank'])\n",
    "                covars_dict['tags'].append(asset['tags'])\n",
    "\n",
    "        # space out the calls\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # convert to df\n",
    "    asset_covars_df = pd.DataFrame(covars_dict)\n",
    "\n",
    "    # clean the columns\n",
    "    asset_covars_df['date'] = pd.to_datetime(asset_covars_df['date'], format='%Y-%m-%d', utc=False).dt.ceil('D')\n",
    "    asset_covars_df['date'] = asset_covars_df.date + pd.Timedelta(days=1)\n",
    "\n",
    "    return asset_covars_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5949ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formFinalPanel(panel_df: pd.DataFrame, asset_covars_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" add the asset covars to the main panel of price, volume, and mcap.\n",
    "    \n",
    "    Args:\n",
    "        panel_df (pd.DataFrame): panel with asset price, trading volume, and mcap.\n",
    "        asset_covars_df (p.DataFrame): panel with asset metadata.\n",
    "    \n",
    "    Returns:\n",
    "        panel_df (pd.DataFrame): panel with all asset covariates.\n",
    "    \"\"\"\n",
    "    asset_covars_df = asset_covars_df.merge(cw_df[['cmc_id', 'slug_cmc']],\n",
    "                                        on='cmc_id',\n",
    "                                        how='left',\n",
    "                                        validate='many_to_one')\n",
    "    asset_covars_df = asset_covars_df[asset_covars_df.cmc_id != 3958]\n",
    "    assert(0==asset_covars_df.slug_cmc.isnull().sum())\n",
    "    asset_covars_df = asset_covars_df.drop('cmc_id', axis=1)\n",
    "    panel_df = panel_df.merge(asset_covars_df,\n",
    "                            on=['date', 'slug_cmc'],\n",
    "                            validate='one_to_one',\n",
    "                            how='outer')\n",
    "    return panel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc1ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # set args\n",
    "    api_fp = '../../admin/cmc.txt'\n",
    "    start_date = date(2015, 1, 1)\n",
    "    end_date   = date(2023, 2, 1)\n",
    "    base_url = \"https://pro-api.coinmarketcap.com\"\n",
    "    asset_fp = \"../data/raw/cmc_asset_universe.pkl\"\n",
    "    cw_fp    = \"../data/raw/cmc_cw.pkl\"\n",
    "    panel_fp = \"../data/raw/cmc_price_volume_mcap_panel.pkl\"\n",
    "    ex_fp = \"../data/raw/cmc_exchange_panel.pkl\"\n",
    "    macro_fp = \"../data/raw/cmc_macro.pkl\"\n",
    "    cw_new_old_col_mapping  = {'cmc_symbol': 'symbol_cmc',\n",
    "                               'cmc_slug': 'slug_cmc',\n",
    "                               'cmc_first_date': 'first_date_cmc',\n",
    "                               'cmc_last_date': 'last_date_cmc'}\n",
    "\n",
    "    # import api key\n",
    "    with open(api_fp) as f:\n",
    "        API_KEY = f.readlines()\n",
    "        API_KEY = API_KEY[0].strip()\n",
    "    \n",
    "    # confirm api is working\n",
    "    session = initiateAPI(base_url, API_KEY)\n",
    "\n",
    "    # obtain potential asset ids to include in study\n",
    "    cmc_ids  = obtainTopCMCAssets(base_url, session, start_date, end_date)\n",
    "    cw_df = formDataframeOfTopCMCAssets(base_url, session, cmc_ids)\n",
    "\n",
    "    # obtain price, volume, and mcap data for target assets\n",
    "    panel_df = pullPriceMcapVolume(base_url, session, cw_df, start_date, end_date)\n",
    "\n",
    "    # clean the data\n",
    "    cw_df = initialCleanAssetMetadata(cw_df, cw_new_old_col_mapping)\n",
    "    panel_df = initialCleanPanel(panel_df)\n",
    "\n",
    "    # cut down to initial inclusion criteria so i pull just these across other providers\n",
    "    panel_df = prepPanelForInitialInclusiveCriteria(panel_df, cw_df)\n",
    "    asset_universe_dict = buildInitialAssetUniverse(panel_df, start_date, end_date)\n",
    "    asset_universe_list = determineUniqueAssets(asset_universe_dict)\n",
    "\n",
    "    # pull remaining cmc data\n",
    "    asset_covars_df = pullCMCAssetMetadata(base_url, session, start_date, end_date)\n",
    "    macro_df = pullCMCMacro(base_url, session, start_date, end_date)\n",
    "    ex_df    = pullCMCExchangeHistoricalData(base_url, session, start_date, end_date)\n",
    "\n",
    "    # form the final panel\n",
    "    panel_df = formFinalPanel(panel_df, asset_covars_df)\n",
    "\n",
    "    # save the data\n",
    "    cw_df.to_pickle(cw_fp)\n",
    "    panel_df.to_pickle(panel_fp)\n",
    "    ex_df.to_pickle(ex_fp)\n",
    "    macro_df.to_pickle(macro_fp)\n",
    "    with open(asset_fp, 'wb') as f:\n",
    "        pickle.dump(asset_universe_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "e936aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# -repull and make sure i am getting data for all the assets on the mcap, price, and volume\n",
    "\n",
    "# TODO for script with final universe:\n",
    "# -adjust the asset meta data pull to also extract the price, mcap, and volume\n",
    "# --in that, adjust the date to not add a date but just do the round; confirm this is OK\n",
    "# --in that, take the average value between the two or just the one if one is missing\n",
    "# ---look at counts of both, spread in diff, when i have one but not the other, and when neither, etc.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Jun  1 2022, 11:38:51) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e428bc405edc59f3352e9792cab27c5e28560f7efb4b47308a6c6ea38cd15df2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
