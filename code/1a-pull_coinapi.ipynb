{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2438263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import Any, Dict, Optional\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b490591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeApiCall(url: str, headers: dict, params: dict={}, retries: int = 4) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Makes an API call to the given endpoint with the given parameters.\n",
    "\n",
    "    Args:\n",
    "    - url (str): string representing the URL for the API.\n",
    "    - headers (dict): dictionary containing the headers for the API call.\n",
    "    - params (dict): dictionary containing the parameters for the API call.\n",
    "    - retries (int): integer representing the number of times to retry the API call in case of an error.\n",
    "\n",
    "    Returns:\n",
    "    - response (dict): the data from the API response, or None if the API call failed.\n",
    "    \"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=params, timeout=5)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.warning(f'The API call failed with error: {str(e)}')\n",
    "            if attempt == retries - 1:\n",
    "                logger.error(f'The API call failed after {retries} attempts.')\n",
    "                return None\n",
    "            else:\n",
    "                sleep_time = 4 ** attempt\n",
    "                logger.warning(f'Retrying after {sleep_time} seconds.')\n",
    "                time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c85d7045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullAssetInfo(base_url: str, base_headers: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame containing information about cryptocurrency assets.\n",
    "    \n",
    "    Args:\n",
    "        base_url: A string representing the base URL of the CoinAPI service.\n",
    "        base_headers: A dictionary representing the headers to be sent with the API request.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame containing information about cryptocurrency assets.\n",
    "    \"\"\"\n",
    "    # Build target URL\n",
    "    target_url = 'assets'\n",
    "    url        = f\"{base_url}{target_url}\"\n",
    "    headers    = base_headers.copy()\n",
    "\n",
    "    # Call API and convert to DataFrame\n",
    "    response_json = makeApiCall(url, headers=headers)\n",
    "    df = pd.DataFrame(response_json)\n",
    "\n",
    "    # Convert date columns to datetime\n",
    "    df['data_start'] = pd.to_datetime(df['data_start'])\n",
    "    df['data_end'] = pd.to_datetime(df['data_end'])\n",
    "\n",
    "    # Calculate duration in days\n",
    "    df['duration_days'] = (df['data_end'] - df['data_start']).dt.days\n",
    "\n",
    "    # Subset to cryptocurrency assets\n",
    "    df = df[df['type_is_crypto'] == 1]\n",
    "\n",
    "    # Subset to assets with trading data\n",
    "    df = df[~df['data_start'].isnull() & ~df['data_end'].isnull()]\n",
    "\n",
    "    # Subset to assets with at least four months of history\n",
    "    df = df[df['duration_days'] > 120]\n",
    "\n",
    "    # Subset to assets with data start on or before 2022-09-01\n",
    "    df = df[df['data_start'] <= '2022-09-01']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "049a4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullExchangeInfo(base_url: str, base_headers: dict, target_exchanges: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame containing information about cryptocurrency exchanges.\n",
    "\n",
    "    Args:\n",
    "        base_url: A string representing the base URL of the CoinAPI service.\n",
    "        base_headers: A dictionary representing the headers to be sent with the API request.\n",
    "        target_exchanges: A list of strings with the target exchanges for this study.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame containing information about cryptocurrency exchanges.\n",
    "    \"\"\"\n",
    "    # Build target URL and headers\n",
    "    target_url = 'exchanges'\n",
    "    url        = f\"{base_url}{target_url}\"\n",
    "    headers    = base_headers.copy()\n",
    "\n",
    "    # Call API and convert to DataFrame\n",
    "    response_json = makeApiCall(url, headers=headers)\n",
    "    df = pd.DataFrame(response_json)\n",
    "\n",
    "    # Subset to relevant exchanges\n",
    "    df = df[df.exchange_id.isin(target_exchanges)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fd63c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullMarketInfo(base_url: str, base_headers: dict, target_exchanges: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame containing information about coinapi markets that are on a target exchange with\n",
    "        USD or stablecoin quote asset.\n",
    "\n",
    "    Args:\n",
    "        base_url: A string representing the base URL of the CoinAPI service.\n",
    "        base_headers: A dictionary representing the headers to be sent with the API request.\n",
    "        target_exchanges: A list of strings with the target exchanges for this study.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame containing information about cryptocurrency markets.\n",
    "    \"\"\"\n",
    "    # Build target URL\n",
    "    target_url = 'symbols'\n",
    "    url        = f\"{base_url}{target_url}\"\n",
    "    headers    = base_headers.copy()\n",
    "\n",
    "    # Call API and convert to DataFrame\n",
    "    response_json = makeApiCall(url, headers=headers)\n",
    "    df = pd.DataFrame(response_json)\n",
    "\n",
    "    # subset to exchanges of interest\n",
    "    df = df[df.exchange_id.isin(target_exchanges)]\n",
    "\n",
    "    # clean columns\n",
    "    df['data_start'] = pd.to_datetime(df.data_start)\n",
    "    df['data_end'] = pd.to_datetime(df.data_end)\n",
    "    df['duration_days'] = (df.data_end - df.data_start).dt.days\n",
    "\n",
    "    # subset to assets of interest\n",
    "    df = df[df.symbol_type=='SPOT'] # spot markets\n",
    "    df = df[df.asset_id_quote.isin(['USD', 'USDC', 'USDT'])] # quote asset is fiat USD or stablecoin USD\n",
    "    df = df.dropna(subset=['data_start', 'data_end'])  # have data\n",
    "    df = df[df.duration_days > 120] # have at least four months of data\n",
    "    target_date = pd.Timestamp('2022-09-01')\n",
    "    df = df[df.data_start <= target_date] # have at least four months of data in target window\n",
    "\n",
    "    # remove symbols that are derivatives of other symbols or stablecoins\n",
    "    assets_to_remove = ['WBTC', 'WLUNA', 'WNXM', 'TBTC', 'CUSD', 'MUSD', 'NUSD', 'DAI', 'BUSD', 'CUSDT', \n",
    "        'GUSD', 'LUSD', 'OUSD', 'USDJ', 'USDK', 'USDN', 'USDT', 'USDC', 'AOA', 'AUSD', 'ERN', 'KRW', 'MTL', \n",
    "        'TUSD', 'SUSD', 'USDD', 'UST', 'USTC', 'EUR', 'AUD', 'GBP', 'CAD', 'CBETH', 'LBP', 'SOS']\n",
    "    df = df[~df.asset_id_base.isin(assets_to_remove)]\n",
    "    df = df[~df['asset_id_base'].str.contains('3L|3S')]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46296864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullUSDTandUSDCexchangeRates(base_url: str, base_headers: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame containing prices of usdc and usdt.\n",
    "\n",
    "    Args:\n",
    "        base_url: A string representing the base URL of the CoinAPI service.\n",
    "        base_headers: A dictionary representing the headers to be sent with the API request.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame containing usdt and usdc price timeserieses.\n",
    "    \"\"\"\n",
    "    # set params\n",
    "    headers = base_headers.copy()\n",
    "    params = {'period_id': '1DAY',\n",
    "        'time_start': '2015-01-01',\n",
    "        'time_end': '2023-02-02',\n",
    "        'limit': 5000}\n",
    "    \n",
    "    # pull tether\n",
    "    asset_id = 'USDT'\n",
    "    url = f\"{base_url}exchangerate/{asset_id}/USD/history\"\n",
    "    response_json = makeApiCall(url, headers=headers, params=params)\n",
    "    usdt_df = pd.DataFrame(response_json) \n",
    "\n",
    "    # pull usdc\n",
    "    asset_id = 'USDC'\n",
    "    url = f\"{base_url}exchangerate/{asset_id}/USD/history\"\n",
    "    response_json = makeApiCall(url, headers=headers, params=params)\n",
    "    usdc_df = pd.DataFrame(response_json) \n",
    "\n",
    "    # clean usdc\n",
    "    usdc_df = usdc_df[usdc_df.rate_close!=0].reset_index(drop=True)\n",
    "    usdc_df = usdc_df[usdc_df.time_period_end!='0001-01-01T00:00:00.0000000Z']\n",
    "    usdc_df['date'] = pd.to_datetime(usdc_df.time_period_end, format='%Y-%m-%d').dt.date\n",
    "    usdc_df['usd_per_usdc'] = usdc_df.rate_close\n",
    "    usdc_df = usdc_df[['date', 'usd_per_usdc']]\n",
    "    usdc_df.set_index('date', inplace=True)\n",
    "    date_range = pd.date_range(start=usdc_df.index.min(), end=usdc_df.index.max(), freq='D')\n",
    "    usdc_df = usdc_df.reindex(date_range)\n",
    "    usdc_df.loc[usdc_df.usd_per_usdc>2, 'usd_per_usdc'] = np.nan\n",
    "    usdc_df.loc[usdc_df.usd_per_usdc<0.8, 'usd_per_usdc'] = np.nan\n",
    "    usdc_df['usd_per_usdc'] = usdc_df.usd_per_usdc.ffill()\n",
    "    assert 0 == usdc_df.usd_per_usdc.isnull().sum()\n",
    "    usdc_df = usdc_df.reset_index()\n",
    "    usdc_df = usdc_df.rename(columns={'index': 'date'})\n",
    "\n",
    "    # clean usdt\n",
    "    usdt_df = usdt_df[usdt_df.time_period_end!='0001-01-01T00:00:00.0000000Z']\n",
    "    usdt_df['date'] = pd.to_datetime(usdt_df.time_period_end, format='%Y-%m-%d').dt.date\n",
    "    usdt_df['usd_per_usdt'] = usdt_df.rate_close\n",
    "    usdt_df = usdt_df[['date', 'usd_per_usdt']]\n",
    "    usdt_df.set_index('date', inplace=True)\n",
    "    date_range = pd.date_range(start=usdt_df.index.min(), end=usdt_df.index.max(), freq='D')\n",
    "    usdt_df = usdt_df.reindex(date_range)\n",
    "    usdt_df.loc[usdt_df.usd_per_usdt>2, 'usd_per_usdt'] = np.nan\n",
    "    usdt_df.loc[usdt_df.usd_per_usdt<0.8, 'usd_per_usdt'] = np.nan\n",
    "    usdt_df['usd_per_usdt'] = usdt_df.usd_per_usdt.ffill()\n",
    "    assert 0 == usdt_df.usd_per_usdt.isnull().sum()\n",
    "    usdt_df = usdt_df.reset_index()\n",
    "    usdt_df = usdt_df.rename(columns={'index': 'date'})\n",
    "\n",
    "    # merge\n",
    "    macro_df = usdc_df.merge(usdt_df, on='date', how='outer', validate='one_to_one')\n",
    "    macro_df = macro_df.sort_values(by='date', ignore_index=True)\n",
    "    macro_df['date'] = pd.to_datetime(macro_df.date).dt.date\n",
    "\n",
    "    return macro_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc50a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullMarketData(base_url: str, base_headers: dict, markets_list: list, macro_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a panel DataFrame containing market prices, volumes, and trade counts.\n",
    "\n",
    "    Args:\n",
    "        base_url: A string representing the base URL of the CoinAPI service.\n",
    "        base_headers: A dictionary representing the headers to be sent with the API request.\n",
    "        markets_list: A list of strings of market names to pull.\n",
    "        macro_df: A Pandas DataFrame containing usdt and usdc price timeserieses.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame panel of dates and markets with their usd_per_token prices, \n",
    "            usd_volume_per_24h, and trades.\n",
    "    \"\"\"\n",
    "    # set up object to store all\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # set up args\n",
    "    params = {'period_id': '1DAY', \n",
    "            'time_start': '2015-01-01T00:00:00',\n",
    "            'time_end': '2023-02-02T00:00:00',\n",
    "            'include_empty_items': True,\n",
    "            'limit': 4000}\n",
    "\n",
    "    # pull all markets\n",
    "    for i in range(len(markets_list)):\n",
    "        # update market to pull\n",
    "        market = markets_list[i]\n",
    "\n",
    "        # monitor progress\n",
    "        print(f\"Processing market #{i+1} ({(i+1)/len(markets_list)*100:.2f}%): {market}\")\n",
    "\n",
    "        # make the call\n",
    "        url = f\"{base_url}ohlcv/{market}/history\"\n",
    "        headers = base_headers.copy()\n",
    "        response_json = makeApiCall(url, headers=headers, params=params)\n",
    "\n",
    "        # catch if there is no data\n",
    "        try:\n",
    "            # clean the market_df\n",
    "            market_df = pd.DataFrame(response_json)\n",
    "            market_df['symbol_id'] = market\n",
    "            market_df = market_df[['symbol_id', 'time_period_end', 'price_close', 'volume_traded', 'trades_count']]\n",
    "\n",
    "            # save data\n",
    "            df = pd.concat((df, market_df))\n",
    "        except:\n",
    "            print(f\"{market} did not have data\")\n",
    "            continue\n",
    "\n",
    "    # remove asset-dates where there is a missing price and zero volume\n",
    "    df = df[~(df.price_close.isnull() & (df.volume_traded==0) & (df.trades_count==0))]\n",
    "\n",
    "    # extract names of exchange, base asset, and quote asset\n",
    "    df['exchange'] = df['symbol_id'].str.split('_', n=4, expand=True)[0]\n",
    "    df['asset_id'] = df['symbol_id'].str.split('_', n=4, expand=True)[2]\n",
    "    df['quote_id'] = df['symbol_id'].str.split('_', n=4, expand=True)[3]\n",
    "\n",
    "    # form the date column\n",
    "    df['date'] = pd.to_datetime(df.time_period_end, format='%Y-%m-%d').dt.date\n",
    "    df = df.drop(columns='time_period_end', axis=1)\n",
    "\n",
    "    # merge on usdt and usdc prices\n",
    "    df = df.merge(macro_df, on='date', how='left', validate='many_to_one')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # form the price column\n",
    "    df.loc[df.quote_id=='USD', 'usd_per_token_coinapi'] = df.loc[df.quote_id=='USD', 'price_close']\n",
    "    df.loc[df.quote_id=='USDC', 'usd_per_token_coinapi'] = df.loc[df.quote_id=='USDC', 'price_close']*df.loc[df.quote_id=='USDC', 'usd_per_usdc']\n",
    "    df.loc[df.quote_id=='USDT', 'usd_per_token_coinapi'] = df.loc[df.quote_id=='USDT', 'price_close']*df.loc[df.quote_id=='USDT', 'usd_per_usdt']\n",
    "    assert 0 == df.usd_per_token_coinapi.isnull().sum()\n",
    "\n",
    "    # form volume column\n",
    "    df['usd_volume_per_24h_coinapi'] = df.volume_traded*df.usd_per_token_coinapi\n",
    "\n",
    "    # collapse to the asset date level\n",
    "    grouped = df.groupby(['date', 'asset_id'])\n",
    "    weighted_avg = grouped.apply(lambda x: (x['usd_per_token_coinapi'] * x['usd_volume_per_24h_coinapi']).sum() / x['usd_volume_per_24h_coinapi'].sum())\n",
    "    total_volume = grouped['usd_volume_per_24h_coinapi'].sum()\n",
    "    total_trades = grouped['trades_count'].sum()\n",
    "    df = pd.DataFrame({'usd_per_token_coinapi': weighted_avg, \n",
    "                            'usd_volume_per_24h_coinapi': total_volume, \n",
    "                            'trades_count': total_trades}).reset_index()\n",
    "\n",
    "    # check for valid ranges and dtypes\n",
    "    df = df[(df['usd_per_token_coinapi'] > 0) & (df['usd_per_token_coinapi'] < 1e6)]\n",
    "    df = df[(df['usd_volume_per_24h_coinapi'] > 0) & (df['usd_volume_per_24h_coinapi'] < 1e9)]\n",
    "    df = df[(df['trades_count'] > 0) & (df['trades_count'] < 1e9)]\n",
    "\n",
    "    # ensure dtypes are set\n",
    "    df['usd_per_token_coinapi'] = df['usd_per_token_coinapi'].astype('float32')\n",
    "    df['usd_volume_per_24h_coinapi'] = df['usd_volume_per_24h_coinapi'].astype('float32')\n",
    "    df['trades_count'] = df['trades_count'].astype('float32')\n",
    "\n",
    "    # ensure panel is sorted\n",
    "    df = df.sort_values(by=['date', 'asset_id'], ignore_index=True)\n",
    "    df['date'] = pd.to_datetime(df.date)\n",
    "\n",
    "    # initialize a new df\n",
    "    final_df = pd.DataFrame(data={'date': [], 'asset_id': [], 'usd_per_token_coinapi': [], 'usd_volume_per_24h_coinapi': [], 'trades_count': []})\n",
    "\n",
    "    # ensure panel is sorted\n",
    "    df = df.sort_values(by=['date', 'asset_id'], ignore_index=True)\n",
    "\n",
    "    # loop over all assets to add missing days\n",
    "    assets = list(np.unique(df.asset_id.values))\n",
    "    for asset in assets:\n",
    "        # subset to asset of interest\n",
    "        asset_df = df[df.asset_id==asset].copy()\n",
    "\n",
    "        # determine the date gaps\n",
    "        date_gaps = []\n",
    "        dates = asset_df.date.values\n",
    "        for i in range(1, len(dates)):\n",
    "            date_gaps.append(np.timedelta64(dates[i]-dates[i-1], 'D').astype(int))\n",
    "\n",
    "        # determine new days to add\n",
    "        indices_to_expand = [i for i in range(len(date_gaps)) if (date_gaps[i] > 1) & (date_gaps[i] < 32)]\n",
    "        num_days_to_add = [date_gaps[i] for i in range(len(date_gaps)) if (date_gaps[i] > 1) & (date_gaps[i] < 32)]\n",
    "        start_days = dates[indices_to_expand]\n",
    "        new_days = []\n",
    "        for i in range(len(start_days)):\n",
    "            start_day = start_days[i]\n",
    "            days_to_add = num_days_to_add[i]\n",
    "            for j in range(1, days_to_add):\n",
    "                new_days.append(start_day+np.timedelta64(24*(j), 'h'))\n",
    "        \n",
    "        # add the new days to the asset df\n",
    "        new_asset_df = pd.DataFrame(data={'date': new_days})\n",
    "        new_asset_df['asset_id'] = asset\n",
    "        asset_df = pd.concat((asset_df, new_asset_df))\n",
    "        asset_df = asset_df.sort_values(by='date', ignore_index=True)\n",
    "\n",
    "        # forward fill the price column\n",
    "        asset_df['usd_per_token_coinapi'] = asset_df.usd_per_token_coinapi.ffill()\n",
    "\n",
    "        # replace volume and trades with zeros\n",
    "        asset_df.loc[asset_df.usd_volume_per_24h_coinapi.isnull(), 'usd_volume_per_24h_coinapi'] = 0\n",
    "        asset_df.loc[asset_df.trades_count.isnull(), 'trades_count'] = 0\n",
    "\n",
    "        # add data to master df\n",
    "        final_df = pd.concat((final_df, asset_df))\n",
    "\n",
    "    # final clean\n",
    "    df = final_df.copy()\n",
    "    df = df.rename(columns={'trades_count': 'trades_coinapi'})\n",
    "    df = df.sort_values(by=['date', 'asset_id'], ignore_index=True)\n",
    "    assert not df.duplicated(subset=['date', 'asset_id']).any()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ae037db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullExchangeRates(base_url: str, base_headers: dict, asset_ids: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a panel DataFrame containing exchange rates.\n",
    "\n",
    "    Args:\n",
    "        base_url: A string representing the base URL of the CoinAPI service.\n",
    "        base_headers: A dictionary representing the headers to be sent with the API request.\n",
    "        asset_ids: A list of strings of the asset ids to pull exchange rates for.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame panel of dates and assets with their clean exchange rate from coinapi.\n",
    "    \"\"\"\n",
    "    # set api args\n",
    "    headers = base_headers.copy()\n",
    "    params = {'period_id': '1DAY',\n",
    "                'time_start': '2015-01-01T00:00:00',\n",
    "                'time_end': '2023-02-02T00:00:00',\n",
    "                'limit': 5000}\n",
    "\n",
    "    # initiate df for the results\n",
    "    ref_df = pd.DataFrame()\n",
    "\n",
    "    # pull for all assets\n",
    "    for i in range(len(asset_ids)):\n",
    "        # update asset\n",
    "        asset_id = asset_ids[i]\n",
    "\n",
    "        # monitor progress\n",
    "        print(f\"Processing asset #{i+1} ({(i+1)/len(asset_ids)*100:.2f}%): {asset_id}\")\n",
    "\n",
    "        # make the call\n",
    "        url = f\"{base_url}exchangerate/{asset_id}/USD/history\"\n",
    "        response_json = makeApiCall(url, headers=headers, params=params)\n",
    "        asset_df = pd.DataFrame(response_json)\n",
    "\n",
    "        # clean the df\n",
    "        asset_df = asset_df[asset_df.time_period_end!='0001-01-01T00:00:00.0000000Z']\n",
    "        asset_df['date'] = pd.to_datetime(asset_df.time_period_end).dt.date\n",
    "        asset_df['usd_per_token_ref'] = asset_df.rate_close\n",
    "        asset_df['asset_id'] = asset_id\n",
    "        asset_df = asset_df[['date', 'asset_id', 'usd_per_token_ref']]\n",
    "        ref_df = pd.concat((ref_df, asset_df))\n",
    "\n",
    "        # ensure i pulled data\n",
    "        assert 0 < asset_df.shape[0]\n",
    "\n",
    "    return ref_df.sort_values(by=['date', 'asset_id'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317a40f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # import api key\n",
    "    API_KEY_FP = '../../admin/coinapi.txt'\n",
    "    with open(API_KEY_FP) as f:\n",
    "        API_KEY = f.readlines()[0].strip()\n",
    "\n",
    "    # set args\n",
    "    PANEL_FP = '../data/raw/coinapi_panel.pkl'\n",
    "    MACRO_FP = '../data/raw/coinapi_macro.pkl'\n",
    "    BASE_URL   = 'https://rest.coinapi.io/v1/'\n",
    "    BASE_HEADERS = {'X-CoinAPI-Key': API_KEY}\n",
    "    LEGIT_US_EXCHANGES = ['BINANCEUS', 'BITSTAMP', 'COINBASE', 'CRYPTOCOM', 'FTXUS', \n",
    "        'GEMINI', 'KRAKEN', 'KUCOIN', 'OKCOINUSD']\n",
    "\n",
    "    # confirm api is working\n",
    "    url = 'https://www.coinapi.io/api/subscriptions/usage/rest/history'\n",
    "    response = requests.get(url, headers=BASE_HEADERS)\n",
    "    print(response.json())    \n",
    "\n",
    "    # pull initial asset universe\n",
    "    asset_info_df = pullAssetInfo(BASE_URL, BASE_HEADERS)\n",
    "\n",
    "    # pull exchange info\n",
    "    exchanges_df = pullExchangeInfo(BASE_URL, BASE_HEADERS, LEGIT_US_EXCHANGES)\n",
    "\n",
    "    # pull relevant markets\n",
    "    symbols_df = pullMarketInfo(BASE_URL, BASE_HEADERS, LEGIT_US_EXCHANGES)\n",
    "\n",
    "    # pull usdt and usdc exchange rates\n",
    "    macro_df = pullUSDTandUSDCexchangeRates(BASE_URL, BASE_HEADERS)\n",
    "    macro_df.to_pickle(MACRO_FP)\n",
    "\n",
    "    # pull market data\n",
    "    assert symbols_df.symbol_id.is_unique\n",
    "    markets_list = symbols_df.symbol_id.values\n",
    "    panel_df = pullMarketData(BASE_URL, BASE_HEADERS, markets_list, macro_df)\n",
    "    panel_df.to_pickle(PANEL_FP)\n",
    "\n",
    "    # pull exchange rates\n",
    "    asset_ids = list(np.unique(panel_df.asset_id.values))\n",
    "    ref_df = pullExchangeRates(BASE_URL, BASE_HEADERS, asset_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65345c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm dates are the same type\n",
    "ref_df['date'] = ref_df.date.apply(np.datetime64)\n",
    "\n",
    "# merge exchange rate and market prices together\n",
    "df = ref_df.merge(panel_df, on=['date', 'asset_id'], how='outer', validate='one_to_one')\n",
    "df = df.sort_values(by=['date', 'asset_id'], ignore_index=True)\n",
    "\n",
    "# form list of assets\n",
    "asset_ids = list(np.unique(df.asset_id.values))\n",
    "\n",
    "# loop over assets to find dates that are missing\n",
    "for i in range(len(asset_ids)):\n",
    "    # update asset\n",
    "    asset_id = asset_ids[i]\n",
    "\n",
    "    # monitor progress\n",
    "    print(f\"Processing asset #{i+1} ({(i+1)/len(asset_ids)*100:.2f}%): {asset_id}\")\n",
    "\n",
    "    # subset to this asset\n",
    "    asset_df = df[df.asset_id==asset_id]\n",
    "\n",
    "    # find asset dates that matched\n",
    "    matched_df = asset_df[~asset_df.usd_per_token_coinapi.isnull() & ~asset_df.usd_per_token_ref.isnull()]\n",
    "    matched_df['prct_diff'] = np.abs((matched_df.usd_per_token_coinapi-matched_df.usd_per_token_ref)/matched_df.usd_per_token_ref)\n",
    "\n",
    "    # report matched dates with different prices\n",
    "    print('These are prices that are off:')\n",
    "    print(matched_df[matched_df.prct_diff > 0.5][['date',\t'asset_id',\t'usd_per_token_ref', 'usd_per_token_coinapi']])\n",
    "\n",
    "    # report dates missing from my data\n",
    "    miss_df = asset_df[asset_df.usd_per_token_coinapi.isnull()]\n",
    "    missing_dates = miss_df.date.values\n",
    "    print(f\"I am missing {len(missing_dates)} days in my data as compared to ref exchange rates. Specifically:\")\n",
    "    print(print(missing_dates))\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    # space out calls\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b14a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO make task for tomorrow to re run the coinapi notebook to ensure it works and to confirm "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e428bc405edc59f3352e9792cab27c5e28560f7efb4b47308a6c6ea38cd15df2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
