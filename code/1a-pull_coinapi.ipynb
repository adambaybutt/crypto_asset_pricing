{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2438263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import Any, Dict, Optional\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b490591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeApiCall(url: str, headers: dict, params: dict={}, retries: int = 4) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Makes an API call to the given endpoint with the given parameters.\n",
    "\n",
    "    Args:\n",
    "    - url (str): string representing the URL for the API.\n",
    "    - headers (dict): dictionary containing the headers for the API call.\n",
    "    - params (dict): dictionary containing the parameters for the API call.\n",
    "    - retries (int): integer representing the number of times to retry the API call in case of an error.\n",
    "\n",
    "    Returns:\n",
    "    - response (dict): the data from the API response, or None if the API call failed.\n",
    "    \"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=params, timeout=5)\n",
    "            response.raise_for_status()\n",
    "            if response.ok:\n",
    "                return response.json()\n",
    "            else:\n",
    "                print(f\"The API call failed with status code: {response.status_code}, retrying...\")\n",
    "        except requests.exceptions.Timeout:\n",
    "            # Timeout error, retry after a short delay\n",
    "            print('The API call timed out, retrying...')\n",
    "            time.sleep(1)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # There was an error, retry after a short delay\n",
    "            print(f'The API call failed with error: {str(e)}, retrying...')\n",
    "        if attempt == 0:\n",
    "            time.sleep(1)\n",
    "        elif attempt == 1:\n",
    "            time.sleep(10)\n",
    "        elif attempt == 2:\n",
    "            time.sleep(30)\n",
    "\n",
    "    print(f'The api call failed after {retries} attempts.')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4f0475ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '2023-03-07', 'requests': 1, 'apicalls': 1}, {'date': '2023-03-06', 'requests': 65646, 'apicalls': 2194}]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # import api key\n",
    "    API_KEY_FP = '../../admin/coinapi.txt'\n",
    "    with open(API_KEY_FP) as f:\n",
    "        API_KEY = f.readlines()[0].strip()\n",
    "\n",
    "    # set args\n",
    "    BASE_URL   = 'https://rest.coinapi.io/v1/'\n",
    "    BASE_HEADERS = {'X-CoinAPI-Key': API_KEY}\n",
    "    LEGIT_US_EXCHANGES = ['BINANCEUS', 'BITSTAMP', 'COINBASE', 'CRYPTOCOM', 'FTXUS', \n",
    "                          'GEMINI', 'KRAKEN', 'KUCOIN', 'OKCOINUSD']\n",
    "\n",
    "    # confirm api is working\n",
    "    url = 'https://www.coinapi.io/api/subscriptions/usage/rest/history'\n",
    "    response = requests.get(url, headers=BASE_HEADERS)\n",
    "    print(response.json())    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6c3ec849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO GET ALL ASSET ICONS\n",
    "\n",
    "# pull asset info\n",
    "target_url = 'assets'\n",
    "url = BASE_URL + target_url\n",
    "response_json = makeApiCall(url, headers=BASE_HEADERS)\n",
    "df = pd.DataFrame(response_json)\n",
    "\n",
    "# convert date columns to dates to operate on them\n",
    "df['data_start'] = pd.to_datetime(df.data_start)\n",
    "df['data_end'] = pd.to_datetime(df.data_end)\n",
    "df['duration_days'] = (df.data_end - df.data_start).dt.days\n",
    "\n",
    "# subset to crypto assets\n",
    "df = df[df.type_is_crypto==1]\n",
    "\n",
    "# subset to assets with trading data\n",
    "df = df[~df.data_start.isnull() & ~df.data_end.isnull()]\n",
    "\n",
    "# subset to assets with at least four months of history\n",
    "df = df[df.duration_days > 120]\n",
    "\n",
    "# subset to assets with data start on or before 2022-09-01\n",
    "df = df[df.data_start <= '2022-09-01']\n",
    "\n",
    "# rename\n",
    "assets_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "172d8e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO figure out all legit exchanges\n",
    "\n",
    "target_url = 'exchanges'\n",
    "url = BASE_URL + target_url\n",
    "response_json = makeApiCall(url, headers=BASE_HEADERS)\n",
    "exchanges_df = pd.DataFrame(response_json)\n",
    "exchanges_df = exchanges_df[exchanges_df.exchange_id.isin(LEGIT_US_EXCHANGES)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "7e7527db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO determine all markets on legit exchanges with USD or stablecoin quote\n",
    "\n",
    "# pull all markets\n",
    "target_url = 'symbols'\n",
    "url = BASE_URL + target_url\n",
    "response_json = makeApiCall(url, headers=BASE_HEADERS)\n",
    "symbols_df = pd.DataFrame(response_json)\n",
    "\n",
    "# subset to exchanges of interest\n",
    "symbols_df = symbols_df[symbols_df.exchange_id.isin(LEGIT_US_EXCHANGES)]\n",
    "\n",
    "# subset to assets of interest\n",
    "symbols_df = symbols_df[symbols_df.symbol_type=='SPOT']\n",
    "symbols_df = symbols_df[symbols_df.asset_id_quote.isin(['USD', 'USDC', 'USDT'])]\n",
    "symbols_df['data_start'] = pd.to_datetime(symbols_df.data_start)\n",
    "symbols_df['data_end'] = pd.to_datetime(symbols_df.data_end)\n",
    "symbols_df['duration_days'] = (symbols_df.data_end - symbols_df.data_start).dt.days\n",
    "symbols_df = symbols_df[~symbols_df.data_start.isnull() & ~symbols_df.data_end.isnull()] # have data\n",
    "symbols_df = symbols_df[symbols_df.duration_days > 120] # have at least four months of data\n",
    "symbols_df = symbols_df[symbols_df.data_start <= '2022-09-01'] # have at least four months of data in target window\n",
    "\n",
    "# remove symbols that are derivatives of other symbols\n",
    "symbols_df = symbols_df[~symbols_df.asset_id_base.isin(['WBTC', 'WLUNA', 'WNXM', 'TBTC'])]\n",
    "symbols_df = symbols_df[~symbols_df.asset_id_base.isin(['CUSD', 'MUSD', 'NUSD', 'DAI', 'BUSD', 'CUSDT', \n",
    "    'GUSD', 'LUSD', 'OUSD', 'USDJ', 'USDK', 'USDN', 'USDT', 'USDC'])]\n",
    "symbols_df = symbols_df[~symbols_df.asset_id_base.isin(['AOA', 'AUSD', 'ERN', 'KRW', 'MTL', 'TUSD', \n",
    "    'SUSD', 'USDD', 'UST', 'USTC', 'EUR', 'AUD', 'GBP', 'CAD', 'CBETH', 'LBP', 'SOS'])]\n",
    "symbols_df = symbols_df[~symbols_df['asset_id_base'].str.contains('3L|3S')]\n",
    "symbols_df = symbols_df[~((symbols_df.asset_id_base=='USDT') & (symbols_df.asset_id_quote=='USDC'))]\n",
    "symbols_df = symbols_df[~((symbols_df.asset_id_quote=='USDT') & (symbols_df.asset_id_base=='USDC'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518e787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO pull USDT and USDC exchange rates\n",
    "\n",
    "# pull tether\n",
    "asset_id = 'USDT'\n",
    "params = {'period_id': '1DAY',\n",
    "    'time_start': '2015-01-01',\n",
    "    'time_end': '2023-02-02',\n",
    "    'limit': 5000}\n",
    "url = f\"{BASE_URL}exchangerate/{asset_id}/USD/history\"\n",
    "headers = BASE_HEADERS.copy()\n",
    "response_json = makeApiCall(url, headers=BASE_HEADERS, params=params)\n",
    "usdt_df = pd.DataFrame(response_json) \n",
    "\n",
    "# pull usdc\n",
    "asset_id = 'USDC'\n",
    "url = f\"{BASE_URL}exchangerate/{asset_id}/USD/history\"\n",
    "headers = BASE_HEADERS.copy()\n",
    "response_json = makeApiCall(url, headers=BASE_HEADERS, params=params)\n",
    "usdc_df = pd.DataFrame(response_json) \n",
    "\n",
    "# clean usdc\n",
    "usdc_df = usdc_df[usdc_df.rate_close!=0].reset_index(drop=True)\n",
    "usdc_df = usdc_df[usdc_df.time_period_end!='0001-01-01T00:00:00.0000000Z']\n",
    "usdc_df['date'] = pd.to_datetime(usdc_df.time_period_end, format='%Y-%m-%d').dt.date\n",
    "usdc_df['usd_per_usdc'] = usdc_df.rate_close\n",
    "usdc_df = usdc_df[['date', 'usd_per_usdc']]\n",
    "usdc_df.set_index('date', inplace=True)\n",
    "date_range = pd.date_range(start=usdc_df.index.min(), end=usdc_df.index.max(), freq='D')\n",
    "usdc_df = usdc_df.reindex(date_range)\n",
    "usdc_df.loc[usdc_df.usd_per_usdc>2, 'usd_per_usdc'] = np.nan\n",
    "usdc_df.loc[usdc_df.usd_per_usdc<0.8, 'usd_per_usdc'] = np.nan\n",
    "usdc_df['usd_per_usdc'] = usdc_df.usd_per_usdc.ffill()\n",
    "assert 0 == usdc_df.usd_per_usdc.isnull().sum()\n",
    "usdc_df = usdc_df.reset_index()\n",
    "usdc_df = usdc_df.rename(columns={'index': 'date'})\n",
    "\n",
    "# clean usdt\n",
    "usdt_df = usdt_df[usdt_df.time_period_end!='0001-01-01T00:00:00.0000000Z']\n",
    "usdt_df['date'] = pd.to_datetime(usdt_df.time_period_end, format='%Y-%m-%d').dt.date\n",
    "usdt_df['usd_per_usdt'] = usdt_df.rate_close\n",
    "usdt_df = usdt_df[['date', 'usd_per_usdt']]\n",
    "usdt_df.set_index('date', inplace=True)\n",
    "date_range = pd.date_range(start=usdt_df.index.min(), end=usdt_df.index.max(), freq='D')\n",
    "usdt_df = usdt_df.reindex(date_range)\n",
    "usdt_df.loc[usdt_df.usd_per_usdt>2, 'usd_per_usdt'] = np.nan\n",
    "usdt_df.loc[usdt_df.usd_per_usdt<0.8, 'usd_per_usdt'] = np.nan\n",
    "usdt_df['usd_per_usdt'] = usdt_df.usd_per_usdt.ffill()\n",
    "assert 0 == usdt_df.usd_per_usdt.isnull().sum()\n",
    "usdt_df = usdt_df.reset_index()\n",
    "usdt_df = usdt_df.rename(columns={'index': 'date'})\n",
    "\n",
    "# merge\n",
    "macro_df = usdc_df.merge(usdt_df, on='date', how='outer', validate='one_to_one')\n",
    "macro_df = macro_df.sort_values(by='date', ignore_index=True)\n",
    "macro_df['date'] = pd.to_datetime(macro_df.date).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db8bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO pull data for all markets\n",
    "\n",
    "# form markets to pull\n",
    "assert symbols_df.symbol_id.is_unique\n",
    "markets_list = symbols_df.symbol_id.values\n",
    "\n",
    "# set up object to store all\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# pull all markets\n",
    "for i in range(len(markets_list)):\n",
    "    # update market to pull\n",
    "    market = markets_list[i]\n",
    "\n",
    "    # monitor progress\n",
    "    print(f\"Processing market #{i+1} ({(i+1)/len(markets_list)*100:.2f}%): {market}\")\n",
    "\n",
    "    # make the call\n",
    "    url = f\"{BASE_URL}ohlcv/{market}/history\"\n",
    "    headers = BASE_HEADERS.copy()\n",
    "    params = {'period_id': '1DAY', \n",
    "            'time_start': '2015-01-01T00:00:00',\n",
    "            'time_end': '2023-02-02T00:00:00',\n",
    "            'include_empty_items': True,\n",
    "            'limit': 4000}\n",
    "    response_json = makeApiCall(url, headers=BASE_HEADERS, params=params)\n",
    "\n",
    "    # clean the df\n",
    "    df = pd.DataFrame(response_json)\n",
    "    df['symbol_id'] = market\n",
    "    df = df[['symbol_id', 'time_period_end', 'price_close', 'volume_traded', 'trades_count']]\n",
    "\n",
    "    # save data\n",
    "    results_df = pd.concat((results_df, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "1254b43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('temp_backup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO clean the results\n",
    "\n",
    "# remove asset-dates where there is a missing price and zero volume\n",
    "results_df = results_df[~(results_df.price_close.isnull() & (results_df.volume_traded==0) & (results_df.trades_count==0))]\n",
    "\n",
    "# extract names of exchange, base asset, and quote asset\n",
    "results_df['exchange'] = results_df['symbol_id'].str.split('_', n=4, expand=True)[0]\n",
    "results_df['asset_id'] = results_df['symbol_id'].str.split('_', n=4, expand=True)[2]\n",
    "results_df['quote_id'] = results_df['symbol_id'].str.split('_', n=4, expand=True)[3]\n",
    "\n",
    "# form the date column\n",
    "results_df['date'] = pd.to_datetime(results_df.time_period_end, format='%Y-%m-%d').dt.date\n",
    "results_df = results_df.drop(columns='time_period_end', axis=1)\n",
    "\n",
    "# merge on usdt and usdc prices\n",
    "results_df = results_df.merge(macro_df, on='date', how='left', validate='many_to_one')\n",
    "results_df['date'] = pd.to_datetime(results_df['date'])\n",
    "\n",
    "# form the price column\n",
    "results_df.loc[results_df.quote_id=='USD', 'usd_per_token_coinapi'] = results_df.loc[results_df.quote_id=='USD', 'price_close']\n",
    "results_df.loc[results_df.quote_id=='USDC', 'usd_per_token_coinapi'] = results_df.loc[results_df.quote_id=='USDC', 'price_close']*results_df.loc[results_df.quote_id=='USDC', 'usd_per_usdc']\n",
    "results_df.loc[results_df.quote_id=='USDT', 'usd_per_token_coinapi'] = results_df.loc[results_df.quote_id=='USDT', 'price_close']*results_df.loc[results_df.quote_id=='USDT', 'usd_per_usdt']\n",
    "assert 0 == results_df.usd_per_token_coinapi.isnull().sum()\n",
    "\n",
    "# form volume column\n",
    "results_df['usd_volume_per_24h_coinapi'] = results_df.volume_traded*results_df.usd_per_token_coinapi\n",
    "\n",
    "# collapse to the asset date level\n",
    "grouped = results_df.groupby(['date', 'asset_id'])\n",
    "weighted_avg = grouped.apply(lambda x: (x['usd_per_token_coinapi'] * x['usd_volume_per_24h_coinapi']).sum() / x['usd_volume_per_24h_coinapi'].sum())\n",
    "total_volume = grouped['usd_volume_per_24h_coinapi'].sum()\n",
    "total_trades = grouped['trades_count'].sum()\n",
    "panel_df = pd.DataFrame({'usd_per_token_coinapi': weighted_avg, \n",
    "                         'usd_volume_per_24h_coinapi': total_volume, \n",
    "                         'trades_count': total_trades}).reset_index()\n",
    "panel_df['date'] = pd.to_datetime(panel_df.date)\n",
    "\n",
    "# check for valid ranges and dtypes\n",
    "panel_df = panel_df[(panel_df['usd_per_token_coinapi'] > 0) & (panel_df['usd_per_token_coinapi'] < 1e6)]\n",
    "panel_df = panel_df[(panel_df['usd_volume_per_24h_coinapi'] > 0) & (panel_df['usd_volume_per_24h_coinapi'] < 1e9)]\n",
    "panel_df = panel_df[(panel_df['trades_count'] > 0) & (panel_df['trades_count'] < 1e6)]\n",
    "\n",
    "\n",
    "# ensure dtypes are set\n",
    "panel_df['usd_per_token_coinapi'] = panel_df['usd_per_token_coinapi'].astype('float32')\n",
    "panel_df['usd_volume_per_24h_coinapi'] = panel_df['usd_volume_per_24h_coinapi'].astype('float32')\n",
    "panel_df['trades_count'] = panel_df['trades_count'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "b51a7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure panel is sorted\n",
    "panel_df = panel_df.sort_values(by=['date', 'asset_id'], ignore_index=True)\n",
    "panel_df['date'] = pd.to_datetime(panel_df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "29a56f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a new df\n",
    "df = pd.DataFrame(data={'date': [], 'asset_id': [], 'usd_per_token_coinapi': [], 'usd_volume_per_24h_coinapi': [], 'trades_count': []})\n",
    "\n",
    "# ensure panel is sorted\n",
    "panel_df = panel_df.sort_values(by=['date', 'asset_id'], ignore_index=True)\n",
    "\n",
    "# loop over all assets\n",
    "assets = list(np.unique(panel_df.asset_id.values))\n",
    "for asset in assets:\n",
    "    # subset to asset of interest\n",
    "    asset_df = panel_df[panel_df.asset_id==asset].copy()\n",
    "\n",
    "    # determine the date gaps\n",
    "    date_gaps = []\n",
    "    dates = asset_df.date.values\n",
    "    for i in range(1, len(dates)):\n",
    "        date_gaps.append((dates[i]-dates[i-1]).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "80b11ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset = assets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456da6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each date gap above 1 and below 32, \n",
    "# grab the start date\n",
    "# add to a new array the number of days after corresponding to diff array\n",
    "# add these days to the asset df\n",
    "# sort\n",
    "# forward fill the price column\n",
    "# set volume and trades to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "52813c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    422\n",
       "2      4\n",
       "4      1\n",
       "5      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=date_gaps).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "bde4a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO for all assets, go pull exchange rates\n",
    "# check that i am not missing tons of asset-dates between my panel and these exchange rates\n",
    "# check also that my prices are not way off\n",
    "\n",
    "# pull tether\n",
    "asset_id = 'USDT'\n",
    "params = {'period_id': '1DAY',\n",
    "    'time_start': '2015-01-01',\n",
    "    'time_end': '2023-02-02',\n",
    "    'limit': 5000}\n",
    "url = f\"{BASE_URL}exchangerate/{asset_id}/USD/history\"\n",
    "headers = BASE_HEADERS.copy()\n",
    "response_json = makeApiCall(url, headers=BASE_HEADERS, params=params)\n",
    "usdt_df = pd.DataFrame(response_json) \n",
    "\n",
    "# try the asset and USD\n",
    "# if not that, try asset and USDC; then USDT; then BTC; then ETH; then just report if not avaialaable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ffed492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO pull best ask and bid from those markets to obtain volume weighted spread\n",
    "\n",
    "url = 'https://rest.coinapi.io/v1/quotes/BITSTAMP_SPOT_BTC_USD/history?time_start=2016-01-01T00:00:00'\n",
    "\n",
    "\n",
    "time_start = 1\n",
    "time_end = 2\n",
    "limit = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8d61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO make task to pull hourly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b14a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e428bc405edc59f3352e9792cab27c5e28560f7efb4b47308a6c6ea38cd15df2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
