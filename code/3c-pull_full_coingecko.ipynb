{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from typing import Dict, List\n",
    "from datetime import datetime\n",
    "from helper_functions import Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formCoingeckoAssetUniverse(base_url: str, base_params: Dict[str, str], asset_universe: List[str]) -> pd.DataFrame:\n",
    "    \"\"\" Form universe of coingecko assets mapped to coinmetrics asset ids.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): Base URL for the API.\n",
    "        base_params (Dict[str, str]): Base parameters for the API.  \n",
    "        asset_universe (List[str]): list of strings of coinmetrics asset IDs.\n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): crosswalk betwen asset_cg IDs and asset_cm IDs.\n",
    "    \n",
    "    \"\"\"\n",
    "    # set ids that we will drop to make one to one mapping\n",
    "    ids_to_drop = ['acala', 'aavegotchi-alpha', 'alphacoin', 'polyalpha-finance', 'apemove',\n",
    "        'flux', 'zelcash', 'sol-wormhole', 'wrapped-solana', 'playground-waves-floor-index',\n",
    "        'velocimeter-flow', 'unicorn-token', 'uniswap-wormhole', 'superrarebears-rare', 'unique-one',\n",
    "        'twitfi', 'truebit-protocol', 'tron-bsc', 't', 'thorchain-erc20', 'san-diego-coin',\n",
    "        'the-sandbox-wormhole', 'retawars-goldrose-token', 'green-ride-token', 'synergy-diamonds',\n",
    "        'supernova', 'superciety', 'aztec-nodes-sun', 'stox', 'gmt-token', 'atlas-fc-fan-token',\n",
    "        'atlantis', 'smartlands', 'shibchain', 'shiba-inu-wormhole', 'rose', 'rose-finance',\n",
    "        'heco-peg-xrp', 'binance-peg-xrp', 'retawars-goldrose-token', 'green-ride-token', 'rad',\n",
    "        'quick', 'qi-dao', 'qiswap', 'galatasaray-fan-token', 'poly-maximus', 'binance-peg-polkadot',\n",
    "        'playchip', 'planet', 'plair', 'orcadao', 'binance-peg-ontology', 'binance-coin-wormhole',\n",
    "        'heco-peg-bnb', 'oec-binance-coin', 'meta-dance', 'mechaverse', 'mask-vault-nftx',\n",
    "        'laro', 'binance-peg-litecoin', 'audius-wormhole', 'listenify', 'lido-dao-wormhole',\n",
    "        'avalanche-wormhole', 'binance-peg-avalanche', 'binance-peg-bitcoin-cash', 'binance-peg-cardano',\n",
    "        'compound-coin', 'bondly-defi', 'avatly', 'constitutiondao-wormhole', 'covicoin',\n",
    "        'creamlands', 'icecream-finance', 'decentraland-wormhole', 'genesis-mana', 'binance-peg-dogecoin',\n",
    "        'dydx-wormhole', 'binance-peg-eos', 'ethereum-wormhole', 'binance-peg-filecoin', 'ftx-wormhole',\n",
    "        'gas-dao', 'game', 'ecowatt', 'cybertronchain', 'hymnode', 'binance-peg-iotex']\n",
    "\n",
    "    # obtain coingecko asset ids\n",
    "    endpoint = '/coins/list'\n",
    "    url = f\"{base_url}{endpoint}\"                           \n",
    "    params = base_params.copy()\n",
    "    params['include_platform'] = 'false'\n",
    "    response_json = Helper.makeApiCall(url, headers={}, params=params)\n",
    "    df = pd.DataFrame(response_json)\n",
    "    df = df.drop(columns='name', axis=1)\n",
    "\n",
    "    # subset down to matched assets\n",
    "    df = df[df.symbol.isin(asset_universe)]\n",
    "\n",
    "    # remove duplicated assets\n",
    "    df = df[~df.id.isin(ids_to_drop)]\n",
    "\n",
    "    # manually add one missing asset\n",
    "    df = pd.concat([df, pd.DataFrame(data={'id': ['nano'], 'symbol': ['nano']})])\n",
    "\n",
    "    # rename\n",
    "    df = df.rename(columns={'id': 'asset_cg', 'symbol': 'asset_cm'})\n",
    "\n",
    "    # confirm full one to one mapping\n",
    "    assert len(asset_universe) == np.sum(np.unique(df.asset_cm.values) == np.unique(asset_universe))\n",
    "\n",
    "    # return\n",
    "    return df.sort_values(by='asset_cm', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullAssetCovariates(base_url: str, base_params: Dict[str, str], gecko_id_universe: List[str], start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    \"\"\" Pull various asset covariates for a given universe of CoinGecko IDs.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): The base URL for the Coingecko API.\n",
    "        base_params (dict): A dictionary containing the basic parameters for the Coingecko API call.\n",
    "        gecko_id_universe (list): A list of unique gecko ids to pull.\n",
    "        study_start (str): string time for the start of the study window in format 'YYYY-MM-DD'.\n",
    "        study_end (str): string time for the end of the study window in format 'YYYY-MM-DD'.\n",
    "            \n",
    "    Returns:\n",
    "        asset_covars_df (pd.DataFrame): panel data with asset covariates.\n",
    "    \"\"\"\n",
    "    # set up object to store all\n",
    "    gecko_covars_dict = {'date':[],\n",
    "                        'asset_gecko': [],\n",
    "                        'usd_per_token_cg': [],\n",
    "                        'usd_volume_cg': [],\n",
    "                        'usd_mcap_cg': [],\n",
    "                        'twitter_followers': [],\n",
    "                        'reddit_average_posts_48h': [],\n",
    "                        'reddit_average_comments_48h': [],\n",
    "                        'reddit_subscribers': [],\n",
    "                        'reddit_accounts_active_48h': [],\n",
    "                        'forks': [],\n",
    "                        'stars': [],\n",
    "                        'subscribers': [],\n",
    "                        'total_issues': [],\n",
    "                        'closed_issues': [],\n",
    "                        'pull_requests_merged': [],\n",
    "                        'pull_request_contributors': [],\n",
    "                        'code_additions_4_weeks': [],\n",
    "                        'code_deletions_4_weeks': [],\n",
    "                        'commit_count_4_weeks': [],\n",
    "                        'alexa_rank': []}\n",
    "\n",
    "\n",
    "    # loop over assets to pull\n",
    "    for i in range(len(gecko_id_universe)):\n",
    "        # set current id to pull\n",
    "        gecko_id = gecko_id_universe[i]\n",
    "\n",
    "        # monitor progress\n",
    "        print(f\"Processing id #{i+1} ({(i+1)/len(gecko_id_universe)*100:.2f}%): {gecko_id}\")\n",
    "\n",
    "        # set up endpoint\n",
    "        endpoint = f\"/coins/{gecko_id}/history\"\n",
    "        url = f\"{base_url}{endpoint}\"\n",
    "\n",
    "        # set up params\n",
    "        params = base_params.copy()\n",
    "        params['id'] = gecko_id\n",
    "\n",
    "        # extract dates for this asset\n",
    "        all_dates  = Helper.generateDailyDateList(start_date, end_date)\n",
    "\n",
    "        # Loop over all dates to pull\n",
    "        for current_date in all_dates:\n",
    "            # update params\n",
    "            params['date'] = current_date[8:]+current_date[4:8]+current_date[:4]\n",
    "\n",
    "            # make the call\n",
    "            response_json = Helper.makeApiCall(url, headers={}, params=params)\n",
    "\n",
    "            if 'market_data' in response_json.keys():\n",
    "                # add data to results dict\n",
    "                gecko_covars_dict['date'].append(np.datetime64(datetime.strptime(current_date, '%Y-%m-%d'), 'D'))\n",
    "                gecko_covars_dict['asset_cg'].append(response_json['id'])\n",
    "                if 'market_data' in response_json.keys():\n",
    "                    gecko_covars_dict['usd_per_token_cg'].append(response_json['market_data']['current_price']['usd'])\n",
    "                    gecko_covars_dict['usd_volume_cg'].append(response_json['market_data']['total_volume']['usd'])\n",
    "                    gecko_covars_dict['usd_mcap_cg'].append(response_json['market_data']['market_cap']['usd'])\n",
    "                else:\n",
    "                    gecko_covars_dict['usd_per_token_cg'].append(None)\n",
    "                    gecko_covars_dict['usd_volume_cg'].append(None)\n",
    "                    gecko_covars_dict['usd_mcap_cg'].append(None)\n",
    "                if 'community_data' in response_json.keys():\n",
    "                    gecko_covars_dict['twitter_followers'].append(response_json['community_data']['twitter_followers'])\n",
    "                    gecko_covars_dict['reddit_average_posts_48h'].append(response_json['community_data']['reddit_average_posts_48h'])\n",
    "                    gecko_covars_dict['reddit_average_comments_48h'].append(response_json['community_data']['reddit_average_comments_48h'])\n",
    "                    gecko_covars_dict['reddit_subscribers'].append(response_json['community_data']['reddit_subscribers'])\n",
    "                    gecko_covars_dict['reddit_accounts_active_48h'].append(response_json['community_data']['reddit_accounts_active_48h'])  \n",
    "                else:\n",
    "                    gecko_covars_dict['twitter_followers'].append(None)\n",
    "                    gecko_covars_dict['reddit_average_posts_48h'].append(None)\n",
    "                    gecko_covars_dict['reddit_average_comments_48h'].append(None)\n",
    "                    gecko_covars_dict['reddit_subscribers'].append(None)\n",
    "                    gecko_covars_dict['reddit_accounts_active_48h'].append(None)\n",
    "                if 'developer_data' in response_json.keys():\n",
    "                    gecko_covars_dict['forks'].append(response_json['developer_data']['forks'])\n",
    "                    gecko_covars_dict['stars'].append(response_json['developer_data']['stars'])\n",
    "                    gecko_covars_dict['subscribers'].append(response_json['developer_data']['subscribers'])\n",
    "                    gecko_covars_dict['total_issues'].append(response_json['developer_data']['total_issues'])\n",
    "                    gecko_covars_dict['closed_issues'].append(response_json['developer_data']['closed_issues'])\n",
    "                    gecko_covars_dict['pull_requests_merged'].append(response_json['developer_data']['pull_requests_merged'])\n",
    "                    gecko_covars_dict['pull_request_contributors'].append(response_json['developer_data']['pull_request_contributors'])\n",
    "                    gecko_covars_dict['code_additions_4_weeks'].append(response_json['developer_data']['code_additions_deletions_4_weeks']['additions'])\n",
    "                    gecko_covars_dict['code_deletions_4_weeks'].append(response_json['developer_data']['code_additions_deletions_4_weeks']['deletions'])\n",
    "                    gecko_covars_dict['commit_count_4_weeks'].append(response_json['developer_data']['commit_count_4_weeks'])\n",
    "                else:\n",
    "                    gecko_covars_dict['forks'].append(None)\n",
    "                    gecko_covars_dict['stars'].append(None)\n",
    "                    gecko_covars_dict['subscribers'].append(None)\n",
    "                    gecko_covars_dict['total_issues'].append(None)\n",
    "                    gecko_covars_dict['closed_issues'].append(None)\n",
    "                    gecko_covars_dict['pull_requests_merged'].append(None)\n",
    "                    gecko_covars_dict['pull_request_contributors'].append(None)\n",
    "                    gecko_covars_dict['code_additions_4_weeks'].append(None)\n",
    "                    gecko_covars_dict['code_deletions_4_weeks'].append(None)\n",
    "                    gecko_covars_dict['commit_count_4_weeks'].append(None)\n",
    "                if 'public_interest_stats' in response_json.keys():\n",
    "                    gecko_covars_dict['alexa_rank'].append(response_json['public_interest_stats']['alexa_rank'])\n",
    "                else:\n",
    "                    gecko_covars_dict['alexa_rank'].append(None)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # space out the calls\n",
    "            time.sleep(0.1)\n",
    "\n",
    "    # convert to df to return\n",
    "    panel_df = pd.DataFrame(gecko_covars_dict)\n",
    "\n",
    "    # clean up the data\n",
    "    panel_df = panel_df.drop_duplicates(subset=['date', 'asset_cg'])\n",
    "\n",
    "    return panel_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(V3) To the Moon!\n",
      "Processing id #1 (0.36%): 0x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The API call failed with error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n",
      "Retrying after 0.92 seconds.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set args\n",
    "    CW_IN_FP = '../data/derived/cm_to_coinapi_cw.pkl'\n",
    "    ASSET_IN_FP = '../data/clean/asset_universe_dict.pickle'\n",
    "    API_FP = '../../admin/coingecko.txt'\n",
    "    START_DATE = '2016-07-01'\n",
    "    END_DATE = '2023-01-02'\n",
    "    BASE_URL = \"https://pro-api.coingecko.com/api/v3\"\n",
    "    PANEL_OUT_FP = \"../data/raw/coingecko_panel.pkl\"\n",
    "    CW_OUT_FP = '../data/raw/coingecko_coinmetrics_cw.pkl'\n",
    "\n",
    "    # Import asset universe and cw\n",
    "    cw_df = pd.read_pickle(CW_IN_FP)\n",
    "    with open(ASSET_IN_FP, \"rb\") as f:\n",
    "        asset_universe_dict = pickle.load(f)\n",
    "    asset_universe = Helper.findUniqueAssets(asset_universe_dict)\n",
    "\n",
    "    # import api key and set base parameters\n",
    "    with open(API_FP) as f:\n",
    "        API_KEY = f.readlines()\n",
    "        API_KEY = API_KEY[0].strip()\n",
    "    BASE_PARAMS = {'x_cg_pro_api_key': API_KEY}\n",
    "\n",
    "    # Test it is working\n",
    "    r = requests.get(f\"{BASE_URL}/ping\", params=BASE_PARAMS)\n",
    "    print(r.json()['gecko_says'])\n",
    "\n",
    "    # Form crosswalk\n",
    "    cg_df = formCoingeckoAssetUniverse(BASE_URL, BASE_PARAMS, asset_universe)\n",
    "    cg_df.to_pickle(CW_OUT_FP)\n",
    "\n",
    "    # Pull covariates to build the panel\n",
    "    gecko_id_universe = list(np.unique(cg_df.asset_cg.values))\n",
    "    panel_df = pullAssetCovariates(BASE_URL, BASE_PARAMS, gecko_id_universe, START_DATE, END_DATE)\n",
    "    panel_df.to_pickle(PANEL_OUT_FP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e428bc405edc59f3352e9792cab27c5e28560f7efb4b47308a6c6ea38cd15df2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
